{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5460984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_circles\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a83ec6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_circles(n_samples=100, noise=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf24a19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=X[:,0],y=X[:,1],hue=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66b40cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test ,y_train,y_test = train_test_split(X,y, test_size=0.20, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e28e0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train).float()  \n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "\n",
    "X_test_tensor = torch.from_numpy(X_test).float()  # for class labels \n",
    "y_test_tensor = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "388a3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping in tensordata and dataloader class\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49de6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a985c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def train_model(model, train_loader, test_loader, epochs=3500, lr=0.01):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for input_feature_batch, input_label_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(input_feature_batch)\n",
    "            loss = loss_fn(preds, input_label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_train_loss/ len(train_loader)\n",
    "        train_losses.append(avg_train_loss)    \n",
    "        \n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for input_feature_batch,input_label_batch in test_loader:\n",
    "                 preds = model(input_feature_batch)\n",
    "                 loss = loss_fn(preds, input_label_batch)\n",
    "                 running_test_loss += loss.item()\n",
    "                 \n",
    "        avg_test_loss = running_test_loss/ len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Test Loss = {avg_test_loss}:.4f\")        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b7cef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c3cfa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "153758a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c072874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6981, Test Loss = 0.6906965374946594:.4f\n",
      "Epoch 2: Train Loss = 0.6828, Test Loss = 0.7064290642738342:.4f\n",
      "Epoch 3: Train Loss = 0.6808, Test Loss = 0.7193055152893066:.4f\n",
      "Epoch 4: Train Loss = 0.6656, Test Loss = 0.7211390733718872:.4f\n",
      "Epoch 5: Train Loss = 0.6661, Test Loss = 0.7231111526489258:.4f\n",
      "Epoch 6: Train Loss = 0.6705, Test Loss = 0.7195166349411011:.4f\n",
      "Epoch 7: Train Loss = 0.6564, Test Loss = 0.7140768766403198:.4f\n",
      "Epoch 8: Train Loss = 0.6501, Test Loss = 0.7052623629570007:.4f\n",
      "Epoch 9: Train Loss = 0.6407, Test Loss = 0.6944932341575623:.4f\n",
      "Epoch 10: Train Loss = 0.6341, Test Loss = 0.6879469752311707:.4f\n",
      "Epoch 11: Train Loss = 0.6300, Test Loss = 0.6898680329322815:.4f\n",
      "Epoch 12: Train Loss = 0.6302, Test Loss = 0.6918803453445435:.4f\n",
      "Epoch 13: Train Loss = 0.6210, Test Loss = 0.6876088976860046:.4f\n",
      "Epoch 14: Train Loss = 0.6134, Test Loss = 0.6890446543693542:.4f\n",
      "Epoch 15: Train Loss = 0.6052, Test Loss = 0.6866765022277832:.4f\n",
      "Epoch 16: Train Loss = 0.5988, Test Loss = 0.690564751625061:.4f\n",
      "Epoch 17: Train Loss = 0.6053, Test Loss = 0.6920303106307983:.4f\n",
      "Epoch 18: Train Loss = 0.5886, Test Loss = 0.6882878541946411:.4f\n",
      "Epoch 19: Train Loss = 0.6017, Test Loss = 0.6848815679550171:.4f\n",
      "Epoch 20: Train Loss = 0.5796, Test Loss = 0.6756203770637512:.4f\n",
      "Epoch 21: Train Loss = 0.5730, Test Loss = 0.672775387763977:.4f\n",
      "Epoch 22: Train Loss = 0.5610, Test Loss = 0.6701385378837585:.4f\n",
      "Epoch 23: Train Loss = 0.5629, Test Loss = 0.6759995222091675:.4f\n",
      "Epoch 24: Train Loss = 0.5621, Test Loss = 0.6716715693473816:.4f\n",
      "Epoch 25: Train Loss = 0.5624, Test Loss = 0.666009783744812:.4f\n",
      "Epoch 26: Train Loss = 0.5474, Test Loss = 0.6590965986251831:.4f\n",
      "Epoch 27: Train Loss = 0.5316, Test Loss = 0.663993239402771:.4f\n",
      "Epoch 28: Train Loss = 0.5475, Test Loss = 0.6677786111831665:.4f\n",
      "Epoch 29: Train Loss = 0.5195, Test Loss = 0.6601710915565491:.4f\n",
      "Epoch 30: Train Loss = 0.5166, Test Loss = 0.6623643040657043:.4f\n",
      "Epoch 31: Train Loss = 0.5230, Test Loss = 0.6596208810806274:.4f\n",
      "Epoch 32: Train Loss = 0.5056, Test Loss = 0.6535757780075073:.4f\n",
      "Epoch 33: Train Loss = 0.5023, Test Loss = 0.6508191823959351:.4f\n",
      "Epoch 34: Train Loss = 0.4918, Test Loss = 0.6455593705177307:.4f\n",
      "Epoch 35: Train Loss = 0.4992, Test Loss = 0.6394075155258179:.4f\n",
      "Epoch 36: Train Loss = 0.5003, Test Loss = 0.6386370062828064:.4f\n",
      "Epoch 37: Train Loss = 0.4913, Test Loss = 0.6295346021652222:.4f\n",
      "Epoch 38: Train Loss = 0.4779, Test Loss = 0.6363282203674316:.4f\n",
      "Epoch 39: Train Loss = 0.4705, Test Loss = 0.6431959271430969:.4f\n",
      "Epoch 40: Train Loss = 0.4717, Test Loss = 0.6509969830513:.4f\n",
      "Epoch 41: Train Loss = 0.4612, Test Loss = 0.6496778726577759:.4f\n",
      "Epoch 42: Train Loss = 0.4613, Test Loss = 0.6468750834465027:.4f\n",
      "Epoch 43: Train Loss = 0.4688, Test Loss = 0.6327131390571594:.4f\n",
      "Epoch 44: Train Loss = 0.4390, Test Loss = 0.6121285557746887:.4f\n",
      "Epoch 45: Train Loss = 0.4526, Test Loss = 0.6093171834945679:.4f\n",
      "Epoch 46: Train Loss = 0.4508, Test Loss = 0.6197305917739868:.4f\n",
      "Epoch 47: Train Loss = 0.4428, Test Loss = 0.6245301961898804:.4f\n",
      "Epoch 48: Train Loss = 0.4450, Test Loss = 0.6164676547050476:.4f\n",
      "Epoch 49: Train Loss = 0.4363, Test Loss = 0.6099375486373901:.4f\n",
      "Epoch 50: Train Loss = 0.4197, Test Loss = 0.6154540777206421:.4f\n",
      "Epoch 51: Train Loss = 0.4310, Test Loss = 0.615747332572937:.4f\n",
      "Epoch 52: Train Loss = 0.4395, Test Loss = 0.6115614771842957:.4f\n",
      "Epoch 53: Train Loss = 0.4286, Test Loss = 0.6042799949645996:.4f\n",
      "Epoch 54: Train Loss = 0.4012, Test Loss = 0.6044682264328003:.4f\n",
      "Epoch 55: Train Loss = 0.3923, Test Loss = 0.6056694388389587:.4f\n",
      "Epoch 56: Train Loss = 0.3996, Test Loss = 0.6082779169082642:.4f\n",
      "Epoch 57: Train Loss = 0.4057, Test Loss = 0.6055452823638916:.4f\n",
      "Epoch 58: Train Loss = 0.3819, Test Loss = 0.5923483967781067:.4f\n",
      "Epoch 59: Train Loss = 0.4002, Test Loss = 0.5956531167030334:.4f\n",
      "Epoch 60: Train Loss = 0.3902, Test Loss = 0.5884509682655334:.4f\n",
      "Epoch 61: Train Loss = 0.3939, Test Loss = 0.6035479307174683:.4f\n",
      "Epoch 62: Train Loss = 0.4026, Test Loss = 0.6124391555786133:.4f\n",
      "Epoch 63: Train Loss = 0.3829, Test Loss = 0.6032857894897461:.4f\n",
      "Epoch 64: Train Loss = 0.3683, Test Loss = 0.6019140481948853:.4f\n",
      "Epoch 65: Train Loss = 0.3743, Test Loss = 0.6016561985015869:.4f\n",
      "Epoch 66: Train Loss = 0.3955, Test Loss = 0.6089810132980347:.4f\n",
      "Epoch 67: Train Loss = 0.3773, Test Loss = 0.588705837726593:.4f\n",
      "Epoch 68: Train Loss = 0.3566, Test Loss = 0.5726116299629211:.4f\n",
      "Epoch 69: Train Loss = 0.3563, Test Loss = 0.578621506690979:.4f\n",
      "Epoch 70: Train Loss = 0.3693, Test Loss = 0.5888180136680603:.4f\n",
      "Epoch 71: Train Loss = 0.3472, Test Loss = 0.595170259475708:.4f\n",
      "Epoch 72: Train Loss = 0.3399, Test Loss = 0.6044135093688965:.4f\n",
      "Epoch 73: Train Loss = 0.3408, Test Loss = 0.6110717058181763:.4f\n",
      "Epoch 74: Train Loss = 0.3723, Test Loss = 0.5980939865112305:.4f\n",
      "Epoch 75: Train Loss = 0.3437, Test Loss = 0.5792093276977539:.4f\n",
      "Epoch 76: Train Loss = 0.3416, Test Loss = 0.5725910067558289:.4f\n",
      "Epoch 77: Train Loss = 0.3223, Test Loss = 0.5854114294052124:.4f\n",
      "Epoch 78: Train Loss = 0.3437, Test Loss = 0.5979796648025513:.4f\n",
      "Epoch 79: Train Loss = 0.3452, Test Loss = 0.5970162153244019:.4f\n",
      "Epoch 80: Train Loss = 0.3531, Test Loss = 0.5805200934410095:.4f\n",
      "Epoch 81: Train Loss = 0.3304, Test Loss = 0.5718094110488892:.4f\n",
      "Epoch 82: Train Loss = 0.3377, Test Loss = 0.5709894299507141:.4f\n",
      "Epoch 83: Train Loss = 0.3300, Test Loss = 0.5768131017684937:.4f\n",
      "Epoch 84: Train Loss = 0.3186, Test Loss = 0.5788084268569946:.4f\n",
      "Epoch 85: Train Loss = 0.3237, Test Loss = 0.5865435004234314:.4f\n",
      "Epoch 86: Train Loss = 0.3237, Test Loss = 0.5791879892349243:.4f\n",
      "Epoch 87: Train Loss = 0.3239, Test Loss = 0.5865982174873352:.4f\n",
      "Epoch 88: Train Loss = 0.3108, Test Loss = 0.5808683037757874:.4f\n",
      "Epoch 89: Train Loss = 0.3018, Test Loss = 0.5808187127113342:.4f\n",
      "Epoch 90: Train Loss = 0.2965, Test Loss = 0.5835956335067749:.4f\n",
      "Epoch 91: Train Loss = 0.2964, Test Loss = 0.581170916557312:.4f\n",
      "Epoch 92: Train Loss = 0.3293, Test Loss = 0.5891557931900024:.4f\n",
      "Epoch 93: Train Loss = 0.3015, Test Loss = 0.6001845598220825:.4f\n",
      "Epoch 94: Train Loss = 0.3239, Test Loss = 0.5997702479362488:.4f\n",
      "Epoch 95: Train Loss = 0.3164, Test Loss = 0.5929334759712219:.4f\n",
      "Epoch 96: Train Loss = 0.3016, Test Loss = 0.5688517689704895:.4f\n",
      "Epoch 97: Train Loss = 0.3040, Test Loss = 0.5725769996643066:.4f\n",
      "Epoch 98: Train Loss = 0.2897, Test Loss = 0.5800156593322754:.4f\n",
      "Epoch 99: Train Loss = 0.2785, Test Loss = 0.5707429647445679:.4f\n",
      "Epoch 100: Train Loss = 0.3055, Test Loss = 0.5691033601760864:.4f\n",
      "Epoch 101: Train Loss = 0.2819, Test Loss = 0.575586199760437:.4f\n",
      "Epoch 102: Train Loss = 0.2730, Test Loss = 0.5863024592399597:.4f\n",
      "Epoch 103: Train Loss = 0.2855, Test Loss = 0.5905833840370178:.4f\n",
      "Epoch 104: Train Loss = 0.2682, Test Loss = 0.5786148905754089:.4f\n",
      "Epoch 105: Train Loss = 0.2963, Test Loss = 0.5757663249969482:.4f\n",
      "Epoch 106: Train Loss = 0.2838, Test Loss = 0.5747426748275757:.4f\n",
      "Epoch 107: Train Loss = 0.2884, Test Loss = 0.5745193958282471:.4f\n",
      "Epoch 108: Train Loss = 0.2909, Test Loss = 0.5750080347061157:.4f\n",
      "Epoch 109: Train Loss = 0.2773, Test Loss = 0.5934649705886841:.4f\n",
      "Epoch 110: Train Loss = 0.2896, Test Loss = 0.6124055981636047:.4f\n",
      "Epoch 111: Train Loss = 0.3016, Test Loss = 0.624626874923706:.4f\n",
      "Epoch 112: Train Loss = 0.2700, Test Loss = 0.604047954082489:.4f\n",
      "Epoch 113: Train Loss = 0.2783, Test Loss = 0.576615571975708:.4f\n",
      "Epoch 114: Train Loss = 0.2846, Test Loss = 0.5626561045646667:.4f\n",
      "Epoch 115: Train Loss = 0.2583, Test Loss = 0.5682274699211121:.4f\n",
      "Epoch 116: Train Loss = 0.2688, Test Loss = 0.5833826065063477:.4f\n",
      "Epoch 117: Train Loss = 0.2699, Test Loss = 0.6016112565994263:.4f\n",
      "Epoch 118: Train Loss = 0.2932, Test Loss = 0.6085766553878784:.4f\n",
      "Epoch 119: Train Loss = 0.2584, Test Loss = 0.5804733037948608:.4f\n",
      "Epoch 120: Train Loss = 0.2951, Test Loss = 0.5628443360328674:.4f\n",
      "Epoch 121: Train Loss = 0.2731, Test Loss = 0.5651732087135315:.4f\n",
      "Epoch 122: Train Loss = 0.2770, Test Loss = 0.5643542408943176:.4f\n",
      "Epoch 123: Train Loss = 0.2595, Test Loss = 0.5699648261070251:.4f\n",
      "Epoch 124: Train Loss = 0.2499, Test Loss = 0.5710371732711792:.4f\n",
      "Epoch 125: Train Loss = 0.2615, Test Loss = 0.5682838559150696:.4f\n",
      "Epoch 126: Train Loss = 0.2557, Test Loss = 0.5747218132019043:.4f\n",
      "Epoch 127: Train Loss = 0.2614, Test Loss = 0.5894310474395752:.4f\n",
      "Epoch 128: Train Loss = 0.2397, Test Loss = 0.6066613793373108:.4f\n",
      "Epoch 129: Train Loss = 0.2637, Test Loss = 0.6141005754470825:.4f\n",
      "Epoch 130: Train Loss = 0.2608, Test Loss = 0.6023986339569092:.4f\n",
      "Epoch 131: Train Loss = 0.2698, Test Loss = 0.6095585227012634:.4f\n",
      "Epoch 132: Train Loss = 0.2364, Test Loss = 0.598716139793396:.4f\n",
      "Epoch 133: Train Loss = 0.2557, Test Loss = 0.5893495082855225:.4f\n",
      "Epoch 134: Train Loss = 0.2457, Test Loss = 0.5784364342689514:.4f\n",
      "Epoch 135: Train Loss = 0.2407, Test Loss = 0.5851594805717468:.4f\n",
      "Epoch 136: Train Loss = 0.2350, Test Loss = 0.5938949584960938:.4f\n",
      "Epoch 137: Train Loss = 0.2485, Test Loss = 0.6033422946929932:.4f\n",
      "Epoch 138: Train Loss = 0.2382, Test Loss = 0.594502329826355:.4f\n",
      "Epoch 139: Train Loss = 0.2360, Test Loss = 0.5914620161056519:.4f\n",
      "Epoch 140: Train Loss = 0.2298, Test Loss = 0.589981198310852:.4f\n",
      "Epoch 141: Train Loss = 0.2452, Test Loss = 0.5961604118347168:.4f\n",
      "Epoch 142: Train Loss = 0.2382, Test Loss = 0.5893512964248657:.4f\n",
      "Epoch 143: Train Loss = 0.2391, Test Loss = 0.5723011493682861:.4f\n",
      "Epoch 144: Train Loss = 0.2492, Test Loss = 0.5709204077720642:.4f\n",
      "Epoch 145: Train Loss = 0.2448, Test Loss = 0.5805655717849731:.4f\n",
      "Epoch 146: Train Loss = 0.2739, Test Loss = 0.5978630185127258:.4f\n",
      "Epoch 147: Train Loss = 0.2811, Test Loss = 0.6216416954994202:.4f\n",
      "Epoch 148: Train Loss = 0.2327, Test Loss = 0.590673565864563:.4f\n",
      "Epoch 149: Train Loss = 0.2483, Test Loss = 0.5841355919837952:.4f\n",
      "Epoch 150: Train Loss = 0.2495, Test Loss = 0.5763899087905884:.4f\n",
      "Epoch 151: Train Loss = 0.2275, Test Loss = 0.5959060788154602:.4f\n",
      "Epoch 152: Train Loss = 0.2440, Test Loss = 0.6089450716972351:.4f\n",
      "Epoch 153: Train Loss = 0.2335, Test Loss = 0.6166905164718628:.4f\n",
      "Epoch 154: Train Loss = 0.2591, Test Loss = 0.6052445769309998:.4f\n",
      "Epoch 155: Train Loss = 0.2243, Test Loss = 0.5991156101226807:.4f\n",
      "Epoch 156: Train Loss = 0.2478, Test Loss = 0.6049339771270752:.4f\n",
      "Epoch 157: Train Loss = 0.2350, Test Loss = 0.6181020736694336:.4f\n",
      "Epoch 158: Train Loss = 0.2384, Test Loss = 0.6073482632637024:.4f\n",
      "Epoch 159: Train Loss = 0.2219, Test Loss = 0.5916334390640259:.4f\n",
      "Epoch 160: Train Loss = 0.2356, Test Loss = 0.5894395709037781:.4f\n",
      "Epoch 161: Train Loss = 0.2131, Test Loss = 0.6158025860786438:.4f\n",
      "Epoch 162: Train Loss = 0.2233, Test Loss = 0.6426803469657898:.4f\n",
      "Epoch 163: Train Loss = 0.2271, Test Loss = 0.621249794960022:.4f\n",
      "Epoch 164: Train Loss = 0.2370, Test Loss = 0.6082419157028198:.4f\n",
      "Epoch 165: Train Loss = 0.2382, Test Loss = 0.6059641242027283:.4f\n",
      "Epoch 166: Train Loss = 0.2440, Test Loss = 0.5995203852653503:.4f\n",
      "Epoch 167: Train Loss = 0.2487, Test Loss = 0.591793417930603:.4f\n",
      "Epoch 168: Train Loss = 0.2079, Test Loss = 0.6110523343086243:.4f\n",
      "Epoch 169: Train Loss = 0.2314, Test Loss = 0.6230151057243347:.4f\n",
      "Epoch 170: Train Loss = 0.2235, Test Loss = 0.6260546445846558:.4f\n",
      "Epoch 171: Train Loss = 0.2406, Test Loss = 0.6242367029190063:.4f\n",
      "Epoch 172: Train Loss = 0.2256, Test Loss = 0.6391023397445679:.4f\n",
      "Epoch 173: Train Loss = 0.2145, Test Loss = 0.617002546787262:.4f\n",
      "Epoch 174: Train Loss = 0.2416, Test Loss = 0.600631058216095:.4f\n",
      "Epoch 175: Train Loss = 0.2207, Test Loss = 0.5995427370071411:.4f\n",
      "Epoch 176: Train Loss = 0.2286, Test Loss = 0.6078305840492249:.4f\n",
      "Epoch 177: Train Loss = 0.2247, Test Loss = 0.6287730932235718:.4f\n",
      "Epoch 178: Train Loss = 0.2304, Test Loss = 0.6300393342971802:.4f\n",
      "Epoch 179: Train Loss = 0.2268, Test Loss = 0.6421483159065247:.4f\n",
      "Epoch 180: Train Loss = 0.2244, Test Loss = 0.6360887289047241:.4f\n",
      "Epoch 181: Train Loss = 0.2214, Test Loss = 0.6305043697357178:.4f\n",
      "Epoch 182: Train Loss = 0.2206, Test Loss = 0.6290963888168335:.4f\n",
      "Epoch 183: Train Loss = 0.2056, Test Loss = 0.6393867135047913:.4f\n",
      "Epoch 184: Train Loss = 0.2083, Test Loss = 0.6309501528739929:.4f\n",
      "Epoch 185: Train Loss = 0.2384, Test Loss = 0.6277002692222595:.4f\n",
      "Epoch 186: Train Loss = 0.2084, Test Loss = 0.6492867469787598:.4f\n",
      "Epoch 187: Train Loss = 0.2178, Test Loss = 0.6494276523590088:.4f\n",
      "Epoch 188: Train Loss = 0.2467, Test Loss = 0.6332542300224304:.4f\n",
      "Epoch 189: Train Loss = 0.2151, Test Loss = 0.6215701699256897:.4f\n",
      "Epoch 190: Train Loss = 0.2228, Test Loss = 0.6048905253410339:.4f\n",
      "Epoch 191: Train Loss = 0.2480, Test Loss = 0.6067940592765808:.4f\n",
      "Epoch 192: Train Loss = 0.2225, Test Loss = 0.6526843309402466:.4f\n",
      "Epoch 193: Train Loss = 0.2196, Test Loss = 0.662466824054718:.4f\n",
      "Epoch 194: Train Loss = 0.2111, Test Loss = 0.640363335609436:.4f\n",
      "Epoch 195: Train Loss = 0.2321, Test Loss = 0.6297966241836548:.4f\n",
      "Epoch 196: Train Loss = 0.2272, Test Loss = 0.6415311098098755:.4f\n",
      "Epoch 197: Train Loss = 0.2179, Test Loss = 0.6480549573898315:.4f\n",
      "Epoch 198: Train Loss = 0.2405, Test Loss = 0.6327438950538635:.4f\n",
      "Epoch 199: Train Loss = 0.2163, Test Loss = 0.6282978653907776:.4f\n",
      "Epoch 200: Train Loss = 0.2199, Test Loss = 0.6349529027938843:.4f\n",
      "Epoch 201: Train Loss = 0.2278, Test Loss = 0.6476453542709351:.4f\n",
      "Epoch 202: Train Loss = 0.2081, Test Loss = 0.6692491173744202:.4f\n",
      "Epoch 203: Train Loss = 0.2462, Test Loss = 0.6755325794219971:.4f\n",
      "Epoch 204: Train Loss = 0.2066, Test Loss = 0.6548024415969849:.4f\n",
      "Epoch 205: Train Loss = 0.2000, Test Loss = 0.6335100531578064:.4f\n",
      "Epoch 206: Train Loss = 0.2113, Test Loss = 0.6270143389701843:.4f\n",
      "Epoch 207: Train Loss = 0.2384, Test Loss = 0.637961745262146:.4f\n",
      "Epoch 208: Train Loss = 0.2149, Test Loss = 0.6645560264587402:.4f\n",
      "Epoch 209: Train Loss = 0.2036, Test Loss = 0.6419024467468262:.4f\n",
      "Epoch 210: Train Loss = 0.2133, Test Loss = 0.6436184644699097:.4f\n",
      "Epoch 211: Train Loss = 0.2064, Test Loss = 0.643095850944519:.4f\n",
      "Epoch 212: Train Loss = 0.2242, Test Loss = 0.6536564826965332:.4f\n",
      "Epoch 213: Train Loss = 0.2246, Test Loss = 0.6793216466903687:.4f\n",
      "Epoch 214: Train Loss = 0.2382, Test Loss = 0.648145318031311:.4f\n",
      "Epoch 215: Train Loss = 0.1901, Test Loss = 0.633886992931366:.4f\n",
      "Epoch 216: Train Loss = 0.1921, Test Loss = 0.631413996219635:.4f\n",
      "Epoch 217: Train Loss = 0.2118, Test Loss = 0.6310268640518188:.4f\n",
      "Epoch 218: Train Loss = 0.1980, Test Loss = 0.6547163724899292:.4f\n",
      "Epoch 219: Train Loss = 0.2014, Test Loss = 0.6671775579452515:.4f\n",
      "Epoch 220: Train Loss = 0.1884, Test Loss = 0.6506644487380981:.4f\n",
      "Epoch 221: Train Loss = 0.2153, Test Loss = 0.6426793336868286:.4f\n",
      "Epoch 222: Train Loss = 0.2188, Test Loss = 0.6512939929962158:.4f\n",
      "Epoch 223: Train Loss = 0.2051, Test Loss = 0.6319228410720825:.4f\n",
      "Epoch 224: Train Loss = 0.2093, Test Loss = 0.6240674257278442:.4f\n",
      "Epoch 225: Train Loss = 0.2002, Test Loss = 0.6388822793960571:.4f\n",
      "Epoch 226: Train Loss = 0.1975, Test Loss = 0.6550744771957397:.4f\n",
      "Epoch 227: Train Loss = 0.2045, Test Loss = 0.6723293662071228:.4f\n",
      "Epoch 228: Train Loss = 0.1869, Test Loss = 0.6547058820724487:.4f\n",
      "Epoch 229: Train Loss = 0.2063, Test Loss = 0.6358951926231384:.4f\n",
      "Epoch 230: Train Loss = 0.2022, Test Loss = 0.6313241720199585:.4f\n",
      "Epoch 231: Train Loss = 0.1926, Test Loss = 0.6608277559280396:.4f\n",
      "Epoch 232: Train Loss = 0.2207, Test Loss = 0.6774069666862488:.4f\n",
      "Epoch 233: Train Loss = 0.2136, Test Loss = 0.7079617977142334:.4f\n",
      "Epoch 234: Train Loss = 0.2081, Test Loss = 0.6889141798019409:.4f\n",
      "Epoch 235: Train Loss = 0.1931, Test Loss = 0.6779969334602356:.4f\n",
      "Epoch 236: Train Loss = 0.2047, Test Loss = 0.6542593240737915:.4f\n",
      "Epoch 237: Train Loss = 0.2315, Test Loss = 0.6529306173324585:.4f\n",
      "Epoch 238: Train Loss = 0.2248, Test Loss = 0.6360585689544678:.4f\n",
      "Epoch 239: Train Loss = 0.2022, Test Loss = 0.6424263119697571:.4f\n",
      "Epoch 240: Train Loss = 0.2368, Test Loss = 0.6378333568572998:.4f\n",
      "Epoch 241: Train Loss = 0.1967, Test Loss = 0.6517423391342163:.4f\n",
      "Epoch 242: Train Loss = 0.1962, Test Loss = 0.6529155373573303:.4f\n",
      "Epoch 243: Train Loss = 0.2035, Test Loss = 0.6425114274024963:.4f\n",
      "Epoch 244: Train Loss = 0.2305, Test Loss = 0.6422234773635864:.4f\n",
      "Epoch 245: Train Loss = 0.1969, Test Loss = 0.6628796458244324:.4f\n",
      "Epoch 246: Train Loss = 0.1858, Test Loss = 0.7000993490219116:.4f\n",
      "Epoch 247: Train Loss = 0.2165, Test Loss = 0.6935199499130249:.4f\n",
      "Epoch 248: Train Loss = 0.2104, Test Loss = 0.7018935680389404:.4f\n",
      "Epoch 249: Train Loss = 0.2223, Test Loss = 0.6752490997314453:.4f\n",
      "Epoch 250: Train Loss = 0.2056, Test Loss = 0.6779989004135132:.4f\n",
      "Epoch 251: Train Loss = 0.2162, Test Loss = 0.6819460391998291:.4f\n",
      "Epoch 252: Train Loss = 0.2001, Test Loss = 0.6852499842643738:.4f\n",
      "Epoch 253: Train Loss = 0.2159, Test Loss = 0.6622962951660156:.4f\n",
      "Epoch 254: Train Loss = 0.2037, Test Loss = 0.6401883959770203:.4f\n",
      "Epoch 255: Train Loss = 0.1836, Test Loss = 0.6361833214759827:.4f\n",
      "Epoch 256: Train Loss = 0.1835, Test Loss = 0.6354296207427979:.4f\n",
      "Epoch 257: Train Loss = 0.1956, Test Loss = 0.6601871848106384:.4f\n",
      "Epoch 258: Train Loss = 0.1784, Test Loss = 0.6450533866882324:.4f\n",
      "Epoch 259: Train Loss = 0.1871, Test Loss = 0.6365066766738892:.4f\n",
      "Epoch 260: Train Loss = 0.2168, Test Loss = 0.6537916660308838:.4f\n",
      "Epoch 261: Train Loss = 0.1754, Test Loss = 0.6912633776664734:.4f\n",
      "Epoch 262: Train Loss = 0.1984, Test Loss = 0.7052503228187561:.4f\n",
      "Epoch 263: Train Loss = 0.1897, Test Loss = 0.6529664397239685:.4f\n",
      "Epoch 264: Train Loss = 0.1870, Test Loss = 0.6404742002487183:.4f\n",
      "Epoch 265: Train Loss = 0.1890, Test Loss = 0.640920102596283:.4f\n",
      "Epoch 266: Train Loss = 0.2210, Test Loss = 0.6371408700942993:.4f\n",
      "Epoch 267: Train Loss = 0.2020, Test Loss = 0.6684606671333313:.4f\n",
      "Epoch 268: Train Loss = 0.2174, Test Loss = 0.6811708211898804:.4f\n",
      "Epoch 269: Train Loss = 0.2024, Test Loss = 0.6983158588409424:.4f\n",
      "Epoch 270: Train Loss = 0.1769, Test Loss = 0.6687744855880737:.4f\n",
      "Epoch 271: Train Loss = 0.2264, Test Loss = 0.6509540677070618:.4f\n",
      "Epoch 272: Train Loss = 0.1816, Test Loss = 0.6735618114471436:.4f\n",
      "Epoch 273: Train Loss = 0.1799, Test Loss = 0.6891235709190369:.4f\n",
      "Epoch 274: Train Loss = 0.1872, Test Loss = 0.6951174139976501:.4f\n",
      "Epoch 275: Train Loss = 0.1879, Test Loss = 0.6695545315742493:.4f\n",
      "Epoch 276: Train Loss = 0.2031, Test Loss = 0.6534322500228882:.4f\n",
      "Epoch 277: Train Loss = 0.1833, Test Loss = 0.6736221313476562:.4f\n",
      "Epoch 278: Train Loss = 0.2012, Test Loss = 0.6764544248580933:.4f\n",
      "Epoch 279: Train Loss = 0.1792, Test Loss = 0.6794211268424988:.4f\n",
      "Epoch 280: Train Loss = 0.1672, Test Loss = 0.6695435047149658:.4f\n",
      "Epoch 281: Train Loss = 0.1736, Test Loss = 0.6609053611755371:.4f\n",
      "Epoch 282: Train Loss = 0.1803, Test Loss = 0.6639249920845032:.4f\n",
      "Epoch 283: Train Loss = 0.1956, Test Loss = 0.6662510633468628:.4f\n",
      "Epoch 284: Train Loss = 0.1713, Test Loss = 0.6787490844726562:.4f\n",
      "Epoch 285: Train Loss = 0.1770, Test Loss = 0.6781741976737976:.4f\n",
      "Epoch 286: Train Loss = 0.2099, Test Loss = 0.6738039255142212:.4f\n",
      "Epoch 287: Train Loss = 0.1994, Test Loss = 0.6867406964302063:.4f\n",
      "Epoch 288: Train Loss = 0.1913, Test Loss = 0.6751924753189087:.4f\n",
      "Epoch 289: Train Loss = 0.1938, Test Loss = 0.6798742413520813:.4f\n",
      "Epoch 290: Train Loss = 0.1782, Test Loss = 0.6612563133239746:.4f\n",
      "Epoch 291: Train Loss = 0.1890, Test Loss = 0.66753089427948:.4f\n",
      "Epoch 292: Train Loss = 0.1791, Test Loss = 0.6643816828727722:.4f\n",
      "Epoch 293: Train Loss = 0.1979, Test Loss = 0.6814127564430237:.4f\n",
      "Epoch 294: Train Loss = 0.1633, Test Loss = 0.6954203844070435:.4f\n",
      "Epoch 295: Train Loss = 0.2080, Test Loss = 0.6939405202865601:.4f\n",
      "Epoch 296: Train Loss = 0.1810, Test Loss = 0.6987314820289612:.4f\n",
      "Epoch 297: Train Loss = 0.1881, Test Loss = 0.6532674431800842:.4f\n",
      "Epoch 298: Train Loss = 0.1860, Test Loss = 0.6323879361152649:.4f\n",
      "Epoch 299: Train Loss = 0.1976, Test Loss = 0.644896388053894:.4f\n",
      "Epoch 300: Train Loss = 0.1804, Test Loss = 0.654801070690155:.4f\n",
      "Epoch 301: Train Loss = 0.1858, Test Loss = 0.688140332698822:.4f\n",
      "Epoch 302: Train Loss = 0.2039, Test Loss = 0.685165286064148:.4f\n",
      "Epoch 303: Train Loss = 0.1679, Test Loss = 0.6959322690963745:.4f\n",
      "Epoch 304: Train Loss = 0.2054, Test Loss = 0.6884331703186035:.4f\n",
      "Epoch 305: Train Loss = 0.1836, Test Loss = 0.6804987192153931:.4f\n",
      "Epoch 306: Train Loss = 0.1865, Test Loss = 0.7047547101974487:.4f\n",
      "Epoch 307: Train Loss = 0.1830, Test Loss = 0.7221841812133789:.4f\n",
      "Epoch 308: Train Loss = 0.1944, Test Loss = 0.6915429830551147:.4f\n",
      "Epoch 309: Train Loss = 0.1689, Test Loss = 0.6757789850234985:.4f\n",
      "Epoch 310: Train Loss = 0.1814, Test Loss = 0.6631641387939453:.4f\n",
      "Epoch 311: Train Loss = 0.1651, Test Loss = 0.678907036781311:.4f\n",
      "Epoch 312: Train Loss = 0.1871, Test Loss = 0.6698447465896606:.4f\n",
      "Epoch 313: Train Loss = 0.1856, Test Loss = 0.6688871383666992:.4f\n",
      "Epoch 314: Train Loss = 0.1694, Test Loss = 0.6700190901756287:.4f\n",
      "Epoch 315: Train Loss = 0.1785, Test Loss = 0.6838048696517944:.4f\n",
      "Epoch 316: Train Loss = 0.1891, Test Loss = 0.7204381227493286:.4f\n",
      "Epoch 317: Train Loss = 0.1865, Test Loss = 0.7057418823242188:.4f\n",
      "Epoch 318: Train Loss = 0.1833, Test Loss = 0.657537579536438:.4f\n",
      "Epoch 319: Train Loss = 0.1937, Test Loss = 0.6481915712356567:.4f\n",
      "Epoch 320: Train Loss = 0.1764, Test Loss = 0.6773536205291748:.4f\n",
      "Epoch 321: Train Loss = 0.1842, Test Loss = 0.7019259333610535:.4f\n",
      "Epoch 322: Train Loss = 0.1862, Test Loss = 0.7113545536994934:.4f\n",
      "Epoch 323: Train Loss = 0.1898, Test Loss = 0.6972334980964661:.4f\n",
      "Epoch 324: Train Loss = 0.1947, Test Loss = 0.678986668586731:.4f\n",
      "Epoch 325: Train Loss = 0.1721, Test Loss = 0.6838287115097046:.4f\n",
      "Epoch 326: Train Loss = 0.1642, Test Loss = 0.6892601251602173:.4f\n",
      "Epoch 327: Train Loss = 0.2135, Test Loss = 0.694358229637146:.4f\n",
      "Epoch 328: Train Loss = 0.2072, Test Loss = 0.6894155144691467:.4f\n",
      "Epoch 329: Train Loss = 0.1680, Test Loss = 0.7032846808433533:.4f\n",
      "Epoch 330: Train Loss = 0.1751, Test Loss = 0.7244445085525513:.4f\n",
      "Epoch 331: Train Loss = 0.1843, Test Loss = 0.7037084698677063:.4f\n",
      "Epoch 332: Train Loss = 0.1655, Test Loss = 0.6894593834877014:.4f\n",
      "Epoch 333: Train Loss = 0.1917, Test Loss = 0.6803844571113586:.4f\n",
      "Epoch 334: Train Loss = 0.1831, Test Loss = 0.6898708939552307:.4f\n",
      "Epoch 335: Train Loss = 0.1648, Test Loss = 0.6750278472900391:.4f\n",
      "Epoch 336: Train Loss = 0.2156, Test Loss = 0.6693606376647949:.4f\n",
      "Epoch 337: Train Loss = 0.1740, Test Loss = 0.679577112197876:.4f\n",
      "Epoch 338: Train Loss = 0.1645, Test Loss = 0.6994684934616089:.4f\n",
      "Epoch 339: Train Loss = 0.1810, Test Loss = 0.720233678817749:.4f\n",
      "Epoch 340: Train Loss = 0.1792, Test Loss = 0.6923701167106628:.4f\n",
      "Epoch 341: Train Loss = 0.1826, Test Loss = 0.6832811236381531:.4f\n",
      "Epoch 342: Train Loss = 0.1777, Test Loss = 0.7039707899093628:.4f\n",
      "Epoch 343: Train Loss = 0.1834, Test Loss = 0.7239116430282593:.4f\n",
      "Epoch 344: Train Loss = 0.2077, Test Loss = 0.7056687474250793:.4f\n",
      "Epoch 345: Train Loss = 0.1833, Test Loss = 0.680182695388794:.4f\n",
      "Epoch 346: Train Loss = 0.1835, Test Loss = 0.674569845199585:.4f\n",
      "Epoch 347: Train Loss = 0.1989, Test Loss = 0.6695610284805298:.4f\n",
      "Epoch 348: Train Loss = 0.1747, Test Loss = 0.7010309100151062:.4f\n",
      "Epoch 349: Train Loss = 0.1727, Test Loss = 0.7184299826622009:.4f\n",
      "Epoch 350: Train Loss = 0.1797, Test Loss = 0.7123183608055115:.4f\n",
      "Epoch 351: Train Loss = 0.1709, Test Loss = 0.685229480266571:.4f\n",
      "Epoch 352: Train Loss = 0.1803, Test Loss = 0.679940938949585:.4f\n",
      "Epoch 353: Train Loss = 0.1723, Test Loss = 0.6874896287918091:.4f\n",
      "Epoch 354: Train Loss = 0.1827, Test Loss = 0.719264030456543:.4f\n",
      "Epoch 355: Train Loss = 0.1781, Test Loss = 0.7349565029144287:.4f\n",
      "Epoch 356: Train Loss = 0.1891, Test Loss = 0.7143848538398743:.4f\n",
      "Epoch 357: Train Loss = 0.1722, Test Loss = 0.6964343190193176:.4f\n",
      "Epoch 358: Train Loss = 0.1812, Test Loss = 0.7015511393547058:.4f\n",
      "Epoch 359: Train Loss = 0.1672, Test Loss = 0.6964178681373596:.4f\n",
      "Epoch 360: Train Loss = 0.1683, Test Loss = 0.6971736550331116:.4f\n",
      "Epoch 361: Train Loss = 0.1797, Test Loss = 0.6879401803016663:.4f\n",
      "Epoch 362: Train Loss = 0.1790, Test Loss = 0.7095886468887329:.4f\n",
      "Epoch 363: Train Loss = 0.1628, Test Loss = 0.6808947920799255:.4f\n",
      "Epoch 364: Train Loss = 0.1584, Test Loss = 0.6762510538101196:.4f\n",
      "Epoch 365: Train Loss = 0.1724, Test Loss = 0.6769790053367615:.4f\n",
      "Epoch 366: Train Loss = 0.1809, Test Loss = 0.7032541036605835:.4f\n",
      "Epoch 367: Train Loss = 0.1616, Test Loss = 0.7204229235649109:.4f\n",
      "Epoch 368: Train Loss = 0.1751, Test Loss = 0.7142053842544556:.4f\n",
      "Epoch 369: Train Loss = 0.1900, Test Loss = 0.6867177486419678:.4f\n",
      "Epoch 370: Train Loss = 0.1982, Test Loss = 0.6770163178443909:.4f\n",
      "Epoch 371: Train Loss = 0.1772, Test Loss = 0.7068099975585938:.4f\n",
      "Epoch 372: Train Loss = 0.1750, Test Loss = 0.7438768744468689:.4f\n",
      "Epoch 373: Train Loss = 0.1771, Test Loss = 0.7250214219093323:.4f\n",
      "Epoch 374: Train Loss = 0.1736, Test Loss = 0.7434256076812744:.4f\n",
      "Epoch 375: Train Loss = 0.1733, Test Loss = 0.7270895838737488:.4f\n",
      "Epoch 376: Train Loss = 0.2021, Test Loss = 0.6807904243469238:.4f\n",
      "Epoch 377: Train Loss = 0.1805, Test Loss = 0.6743695139884949:.4f\n",
      "Epoch 378: Train Loss = 0.1842, Test Loss = 0.6937349438667297:.4f\n",
      "Epoch 379: Train Loss = 0.1739, Test Loss = 0.7185527086257935:.4f\n",
      "Epoch 380: Train Loss = 0.1695, Test Loss = 0.7136965990066528:.4f\n",
      "Epoch 381: Train Loss = 0.1846, Test Loss = 0.6991405487060547:.4f\n",
      "Epoch 382: Train Loss = 0.1550, Test Loss = 0.6881791353225708:.4f\n",
      "Epoch 383: Train Loss = 0.1813, Test Loss = 0.6975732445716858:.4f\n",
      "Epoch 384: Train Loss = 0.1665, Test Loss = 0.6893802285194397:.4f\n",
      "Epoch 385: Train Loss = 0.1615, Test Loss = 0.6877011656761169:.4f\n",
      "Epoch 386: Train Loss = 0.1833, Test Loss = 0.698918342590332:.4f\n",
      "Epoch 387: Train Loss = 0.1809, Test Loss = 0.7202122211456299:.4f\n",
      "Epoch 388: Train Loss = 0.1738, Test Loss = 0.7072569727897644:.4f\n",
      "Epoch 389: Train Loss = 0.1943, Test Loss = 0.7031506299972534:.4f\n",
      "Epoch 390: Train Loss = 0.1613, Test Loss = 0.6845394968986511:.4f\n",
      "Epoch 391: Train Loss = 0.1852, Test Loss = 0.681659460067749:.4f\n",
      "Epoch 392: Train Loss = 0.1640, Test Loss = 0.714892566204071:.4f\n",
      "Epoch 393: Train Loss = 0.1739, Test Loss = 0.7282687425613403:.4f\n",
      "Epoch 394: Train Loss = 0.1767, Test Loss = 0.6979676485061646:.4f\n",
      "Epoch 395: Train Loss = 0.1648, Test Loss = 0.6769287586212158:.4f\n",
      "Epoch 396: Train Loss = 0.1775, Test Loss = 0.6866617798805237:.4f\n",
      "Epoch 397: Train Loss = 0.1725, Test Loss = 0.7128831148147583:.4f\n",
      "Epoch 398: Train Loss = 0.1586, Test Loss = 0.7489919662475586:.4f\n",
      "Epoch 399: Train Loss = 0.1658, Test Loss = 0.7213872671127319:.4f\n",
      "Epoch 400: Train Loss = 0.1945, Test Loss = 0.7203519940376282:.4f\n",
      "Epoch 401: Train Loss = 0.1601, Test Loss = 0.7030404806137085:.4f\n",
      "Epoch 402: Train Loss = 0.1681, Test Loss = 0.693906843662262:.4f\n",
      "Epoch 403: Train Loss = 0.1904, Test Loss = 0.695659339427948:.4f\n",
      "Epoch 404: Train Loss = 0.1653, Test Loss = 0.6922580599784851:.4f\n",
      "Epoch 405: Train Loss = 0.1695, Test Loss = 0.6978384256362915:.4f\n",
      "Epoch 406: Train Loss = 0.1659, Test Loss = 0.6929217576980591:.4f\n",
      "Epoch 407: Train Loss = 0.1642, Test Loss = 0.7019209861755371:.4f\n",
      "Epoch 408: Train Loss = 0.1885, Test Loss = 0.7392998933792114:.4f\n",
      "Epoch 409: Train Loss = 0.1721, Test Loss = 0.7445911765098572:.4f\n",
      "Epoch 410: Train Loss = 0.1753, Test Loss = 0.7378055453300476:.4f\n",
      "Epoch 411: Train Loss = 0.1688, Test Loss = 0.7107607126235962:.4f\n",
      "Epoch 412: Train Loss = 0.1690, Test Loss = 0.7002325057983398:.4f\n",
      "Epoch 413: Train Loss = 0.1932, Test Loss = 0.7152825593948364:.4f\n",
      "Epoch 414: Train Loss = 0.1590, Test Loss = 0.7801276445388794:.4f\n",
      "Epoch 415: Train Loss = 0.1894, Test Loss = 0.771098256111145:.4f\n",
      "Epoch 416: Train Loss = 0.1517, Test Loss = 0.7084417343139648:.4f\n",
      "Epoch 417: Train Loss = 0.1693, Test Loss = 0.683281421661377:.4f\n",
      "Epoch 418: Train Loss = 0.2107, Test Loss = 0.6798816919326782:.4f\n",
      "Epoch 419: Train Loss = 0.1888, Test Loss = 0.7403818964958191:.4f\n",
      "Epoch 420: Train Loss = 0.1706, Test Loss = 0.7338849902153015:.4f\n",
      "Epoch 421: Train Loss = 0.1912, Test Loss = 0.7033281922340393:.4f\n",
      "Epoch 422: Train Loss = 0.1724, Test Loss = 0.7072039246559143:.4f\n",
      "Epoch 423: Train Loss = 0.1664, Test Loss = 0.7017884850502014:.4f\n",
      "Epoch 424: Train Loss = 0.1928, Test Loss = 0.7128665447235107:.4f\n",
      "Epoch 425: Train Loss = 0.1686, Test Loss = 0.7091952562332153:.4f\n",
      "Epoch 426: Train Loss = 0.1878, Test Loss = 0.7180424928665161:.4f\n",
      "Epoch 427: Train Loss = 0.1645, Test Loss = 0.7214588522911072:.4f\n",
      "Epoch 428: Train Loss = 0.1730, Test Loss = 0.7219763994216919:.4f\n",
      "Epoch 429: Train Loss = 0.1739, Test Loss = 0.7334287166595459:.4f\n",
      "Epoch 430: Train Loss = 0.1667, Test Loss = 0.7212429642677307:.4f\n",
      "Epoch 431: Train Loss = 0.1843, Test Loss = 0.7366966009140015:.4f\n",
      "Epoch 432: Train Loss = 0.1493, Test Loss = 0.7733511328697205:.4f\n",
      "Epoch 433: Train Loss = 0.1696, Test Loss = 0.7536803483963013:.4f\n",
      "Epoch 434: Train Loss = 0.1876, Test Loss = 0.7578157782554626:.4f\n",
      "Epoch 435: Train Loss = 0.1592, Test Loss = 0.7347279787063599:.4f\n",
      "Epoch 436: Train Loss = 0.1820, Test Loss = 0.7048758268356323:.4f\n",
      "Epoch 437: Train Loss = 0.1610, Test Loss = 0.6825520396232605:.4f\n",
      "Epoch 438: Train Loss = 0.1770, Test Loss = 0.7041599750518799:.4f\n",
      "Epoch 439: Train Loss = 0.1807, Test Loss = 0.7080223560333252:.4f\n",
      "Epoch 440: Train Loss = 0.1563, Test Loss = 0.734218418598175:.4f\n",
      "Epoch 441: Train Loss = 0.1527, Test Loss = 0.7571032643318176:.4f\n",
      "Epoch 442: Train Loss = 0.1604, Test Loss = 0.7368617653846741:.4f\n",
      "Epoch 443: Train Loss = 0.1560, Test Loss = 0.7181025743484497:.4f\n",
      "Epoch 444: Train Loss = 0.1521, Test Loss = 0.7087060213088989:.4f\n",
      "Epoch 445: Train Loss = 0.1547, Test Loss = 0.7144155502319336:.4f\n",
      "Epoch 446: Train Loss = 0.1877, Test Loss = 0.7189823985099792:.4f\n",
      "Epoch 447: Train Loss = 0.1497, Test Loss = 0.7071539759635925:.4f\n",
      "Epoch 448: Train Loss = 0.1708, Test Loss = 0.6953085660934448:.4f\n",
      "Epoch 449: Train Loss = 0.1756, Test Loss = 0.7141606211662292:.4f\n",
      "Epoch 450: Train Loss = 0.1748, Test Loss = 0.764196515083313:.4f\n",
      "Epoch 451: Train Loss = 0.1782, Test Loss = 0.7362250089645386:.4f\n",
      "Epoch 452: Train Loss = 0.1935, Test Loss = 0.7196309566497803:.4f\n",
      "Epoch 453: Train Loss = 0.1629, Test Loss = 0.7402405738830566:.4f\n",
      "Epoch 454: Train Loss = 0.1785, Test Loss = 0.713534951210022:.4f\n",
      "Epoch 455: Train Loss = 0.1675, Test Loss = 0.7014552354812622:.4f\n",
      "Epoch 456: Train Loss = 0.1691, Test Loss = 0.7015619874000549:.4f\n",
      "Epoch 457: Train Loss = 0.1659, Test Loss = 0.7074503898620605:.4f\n",
      "Epoch 458: Train Loss = 0.1838, Test Loss = 0.731605589389801:.4f\n",
      "Epoch 459: Train Loss = 0.1951, Test Loss = 0.7576290369033813:.4f\n",
      "Epoch 460: Train Loss = 0.1647, Test Loss = 0.7693755030632019:.4f\n",
      "Epoch 461: Train Loss = 0.1783, Test Loss = 0.7140939235687256:.4f\n",
      "Epoch 462: Train Loss = 0.1945, Test Loss = 0.6836798191070557:.4f\n",
      "Epoch 463: Train Loss = 0.1778, Test Loss = 0.6937897205352783:.4f\n",
      "Epoch 464: Train Loss = 0.1705, Test Loss = 0.7032839059829712:.4f\n",
      "Epoch 465: Train Loss = 0.1640, Test Loss = 0.7338914275169373:.4f\n",
      "Epoch 466: Train Loss = 0.1463, Test Loss = 0.7542169094085693:.4f\n",
      "Epoch 467: Train Loss = 0.1520, Test Loss = 0.7572551965713501:.4f\n",
      "Epoch 468: Train Loss = 0.1637, Test Loss = 0.7431672811508179:.4f\n",
      "Epoch 469: Train Loss = 0.1838, Test Loss = 0.7288519144058228:.4f\n",
      "Epoch 470: Train Loss = 0.1738, Test Loss = 0.7371343374252319:.4f\n",
      "Epoch 471: Train Loss = 0.1596, Test Loss = 0.7676798701286316:.4f\n",
      "Epoch 472: Train Loss = 0.1543, Test Loss = 0.7921541333198547:.4f\n",
      "Epoch 473: Train Loss = 0.1759, Test Loss = 0.7676502466201782:.4f\n",
      "Epoch 474: Train Loss = 0.1812, Test Loss = 0.7515708208084106:.4f\n",
      "Epoch 475: Train Loss = 0.1764, Test Loss = 0.7633790969848633:.4f\n",
      "Epoch 476: Train Loss = 0.1746, Test Loss = 0.757590115070343:.4f\n",
      "Epoch 477: Train Loss = 0.1491, Test Loss = 0.7648646235466003:.4f\n",
      "Epoch 478: Train Loss = 0.1877, Test Loss = 0.7508400678634644:.4f\n",
      "Epoch 479: Train Loss = 0.1632, Test Loss = 0.7572636604309082:.4f\n",
      "Epoch 480: Train Loss = 0.1562, Test Loss = 0.7383379936218262:.4f\n",
      "Epoch 481: Train Loss = 0.1703, Test Loss = 0.7174049615859985:.4f\n",
      "Epoch 482: Train Loss = 0.1660, Test Loss = 0.7416072487831116:.4f\n",
      "Epoch 483: Train Loss = 0.1582, Test Loss = 0.7361368536949158:.4f\n",
      "Epoch 484: Train Loss = 0.1810, Test Loss = 0.7149349451065063:.4f\n",
      "Epoch 485: Train Loss = 0.1811, Test Loss = 0.715543270111084:.4f\n",
      "Epoch 486: Train Loss = 0.1474, Test Loss = 0.7645478844642639:.4f\n",
      "Epoch 487: Train Loss = 0.1453, Test Loss = 0.7859974503517151:.4f\n",
      "Epoch 488: Train Loss = 0.1798, Test Loss = 0.7683621644973755:.4f\n",
      "Epoch 489: Train Loss = 0.1837, Test Loss = 0.7066600322723389:.4f\n",
      "Epoch 490: Train Loss = 0.1853, Test Loss = 0.6863616704940796:.4f\n",
      "Epoch 491: Train Loss = 0.1721, Test Loss = 0.7072277069091797:.4f\n",
      "Epoch 492: Train Loss = 0.1547, Test Loss = 0.7221161723136902:.4f\n",
      "Epoch 493: Train Loss = 0.1531, Test Loss = 0.7422543168067932:.4f\n",
      "Epoch 494: Train Loss = 0.1559, Test Loss = 0.7467175722122192:.4f\n",
      "Epoch 495: Train Loss = 0.1658, Test Loss = 0.7359150648117065:.4f\n",
      "Epoch 496: Train Loss = 0.1723, Test Loss = 0.7290459871292114:.4f\n",
      "Epoch 497: Train Loss = 0.1705, Test Loss = 0.7244236469268799:.4f\n",
      "Epoch 498: Train Loss = 0.1629, Test Loss = 0.7331681251525879:.4f\n",
      "Epoch 499: Train Loss = 0.1671, Test Loss = 0.7425373792648315:.4f\n",
      "Epoch 500: Train Loss = 0.1570, Test Loss = 0.7137860655784607:.4f\n",
      "Epoch 501: Train Loss = 0.1564, Test Loss = 0.7018015384674072:.4f\n",
      "Epoch 502: Train Loss = 0.1616, Test Loss = 0.7097750902175903:.4f\n",
      "Epoch 503: Train Loss = 0.1449, Test Loss = 0.7225843667984009:.4f\n",
      "Epoch 504: Train Loss = 0.1473, Test Loss = 0.7584973573684692:.4f\n",
      "Epoch 505: Train Loss = 0.1981, Test Loss = 0.764365553855896:.4f\n",
      "Epoch 506: Train Loss = 0.1585, Test Loss = 0.7683955430984497:.4f\n",
      "Epoch 507: Train Loss = 0.1485, Test Loss = 0.7468861937522888:.4f\n",
      "Epoch 508: Train Loss = 0.1618, Test Loss = 0.7114571332931519:.4f\n",
      "Epoch 509: Train Loss = 0.1863, Test Loss = 0.717178225517273:.4f\n",
      "Epoch 510: Train Loss = 0.1654, Test Loss = 0.7578914165496826:.4f\n",
      "Epoch 511: Train Loss = 0.1656, Test Loss = 0.746050238609314:.4f\n",
      "Epoch 512: Train Loss = 0.1762, Test Loss = 0.7306945323944092:.4f\n",
      "Epoch 513: Train Loss = 0.1904, Test Loss = 0.7380868196487427:.4f\n",
      "Epoch 514: Train Loss = 0.1642, Test Loss = 0.7462326288223267:.4f\n",
      "Epoch 515: Train Loss = 0.1683, Test Loss = 0.7659261226654053:.4f\n",
      "Epoch 516: Train Loss = 0.1508, Test Loss = 0.7801986932754517:.4f\n",
      "Epoch 517: Train Loss = 0.1766, Test Loss = 0.759398341178894:.4f\n",
      "Epoch 518: Train Loss = 0.1675, Test Loss = 0.7438463568687439:.4f\n",
      "Epoch 519: Train Loss = 0.1727, Test Loss = 0.7302998304367065:.4f\n",
      "Epoch 520: Train Loss = 0.1591, Test Loss = 0.7408477663993835:.4f\n",
      "Epoch 521: Train Loss = 0.1691, Test Loss = 0.7430155873298645:.4f\n",
      "Epoch 522: Train Loss = 0.1563, Test Loss = 0.7483855485916138:.4f\n",
      "Epoch 523: Train Loss = 0.2029, Test Loss = 0.7625966668128967:.4f\n",
      "Epoch 524: Train Loss = 0.1610, Test Loss = 0.7815051674842834:.4f\n",
      "Epoch 525: Train Loss = 0.1947, Test Loss = 0.8124831318855286:.4f\n",
      "Epoch 526: Train Loss = 0.1825, Test Loss = 0.737102746963501:.4f\n",
      "Epoch 527: Train Loss = 0.1764, Test Loss = 0.7266006469726562:.4f\n",
      "Epoch 528: Train Loss = 0.1642, Test Loss = 0.7324551343917847:.4f\n",
      "Epoch 529: Train Loss = 0.1512, Test Loss = 0.7410210371017456:.4f\n",
      "Epoch 530: Train Loss = 0.1879, Test Loss = 0.7522338628768921:.4f\n",
      "Epoch 531: Train Loss = 0.1548, Test Loss = 0.7388013601303101:.4f\n",
      "Epoch 532: Train Loss = 0.1773, Test Loss = 0.7314490079879761:.4f\n",
      "Epoch 533: Train Loss = 0.1733, Test Loss = 0.7413596510887146:.4f\n",
      "Epoch 534: Train Loss = 0.1687, Test Loss = 0.7954967617988586:.4f\n",
      "Epoch 535: Train Loss = 0.1448, Test Loss = 0.7846344709396362:.4f\n",
      "Epoch 536: Train Loss = 0.1520, Test Loss = 0.778511106967926:.4f\n",
      "Epoch 537: Train Loss = 0.1647, Test Loss = 0.7372391819953918:.4f\n",
      "Epoch 538: Train Loss = 0.1774, Test Loss = 0.7201666831970215:.4f\n",
      "Epoch 539: Train Loss = 0.1663, Test Loss = 0.7487151026725769:.4f\n",
      "Epoch 540: Train Loss = 0.1529, Test Loss = 0.7933579087257385:.4f\n",
      "Epoch 541: Train Loss = 0.1684, Test Loss = 0.7699177265167236:.4f\n",
      "Epoch 542: Train Loss = 0.2026, Test Loss = 0.7229650020599365:.4f\n",
      "Epoch 543: Train Loss = 0.1474, Test Loss = 0.7291734218597412:.4f\n",
      "Epoch 544: Train Loss = 0.1570, Test Loss = 0.7567112445831299:.4f\n",
      "Epoch 545: Train Loss = 0.2022, Test Loss = 0.7607606649398804:.4f\n",
      "Epoch 546: Train Loss = 0.1621, Test Loss = 0.7889224290847778:.4f\n",
      "Epoch 547: Train Loss = 0.1629, Test Loss = 0.8258320689201355:.4f\n",
      "Epoch 548: Train Loss = 0.1472, Test Loss = 0.7854386568069458:.4f\n",
      "Epoch 549: Train Loss = 0.1508, Test Loss = 0.7683500647544861:.4f\n",
      "Epoch 550: Train Loss = 0.1803, Test Loss = 0.7363425493240356:.4f\n",
      "Epoch 551: Train Loss = 0.1627, Test Loss = 0.7740638256072998:.4f\n",
      "Epoch 552: Train Loss = 0.1663, Test Loss = 0.7900546789169312:.4f\n",
      "Epoch 553: Train Loss = 0.1582, Test Loss = 0.7628094553947449:.4f\n",
      "Epoch 554: Train Loss = 0.1839, Test Loss = 0.7747963070869446:.4f\n",
      "Epoch 555: Train Loss = 0.1564, Test Loss = 0.7637626528739929:.4f\n",
      "Epoch 556: Train Loss = 0.1983, Test Loss = 0.7564793825149536:.4f\n",
      "Epoch 557: Train Loss = 0.1745, Test Loss = 0.7685343027114868:.4f\n",
      "Epoch 558: Train Loss = 0.1678, Test Loss = 0.777156412601471:.4f\n",
      "Epoch 559: Train Loss = 0.1777, Test Loss = 0.756446897983551:.4f\n",
      "Epoch 560: Train Loss = 0.1455, Test Loss = 0.7777890563011169:.4f\n",
      "Epoch 561: Train Loss = 0.1554, Test Loss = 0.7899245023727417:.4f\n",
      "Epoch 562: Train Loss = 0.1587, Test Loss = 0.7831555008888245:.4f\n",
      "Epoch 563: Train Loss = 0.1519, Test Loss = 0.761062741279602:.4f\n",
      "Epoch 564: Train Loss = 0.1632, Test Loss = 0.7501259446144104:.4f\n",
      "Epoch 565: Train Loss = 0.1662, Test Loss = 0.757662296295166:.4f\n",
      "Epoch 566: Train Loss = 0.1529, Test Loss = 0.7608150243759155:.4f\n",
      "Epoch 567: Train Loss = 0.1881, Test Loss = 0.7537996172904968:.4f\n",
      "Epoch 568: Train Loss = 0.1550, Test Loss = 0.7671811580657959:.4f\n",
      "Epoch 569: Train Loss = 0.1411, Test Loss = 0.7721072435379028:.4f\n",
      "Epoch 570: Train Loss = 0.1535, Test Loss = 0.7852046489715576:.4f\n",
      "Epoch 571: Train Loss = 0.1401, Test Loss = 0.7814303636550903:.4f\n",
      "Epoch 572: Train Loss = 0.1739, Test Loss = 0.7671246528625488:.4f\n",
      "Epoch 573: Train Loss = 0.1386, Test Loss = 0.781920850276947:.4f\n",
      "Epoch 574: Train Loss = 0.1460, Test Loss = 0.7898210287094116:.4f\n",
      "Epoch 575: Train Loss = 0.1451, Test Loss = 0.7905992865562439:.4f\n",
      "Epoch 576: Train Loss = 0.1674, Test Loss = 0.777994692325592:.4f\n",
      "Epoch 577: Train Loss = 0.1455, Test Loss = 0.7495327591896057:.4f\n",
      "Epoch 578: Train Loss = 0.1816, Test Loss = 0.7403765916824341:.4f\n",
      "Epoch 579: Train Loss = 0.1512, Test Loss = 0.745130717754364:.4f\n",
      "Epoch 580: Train Loss = 0.1464, Test Loss = 0.7412482500076294:.4f\n",
      "Epoch 581: Train Loss = 0.1548, Test Loss = 0.7478171586990356:.4f\n",
      "Epoch 582: Train Loss = 0.1596, Test Loss = 0.7534001469612122:.4f\n",
      "Epoch 583: Train Loss = 0.1523, Test Loss = 0.7896931767463684:.4f\n",
      "Epoch 584: Train Loss = 0.1918, Test Loss = 0.7983540296554565:.4f\n",
      "Epoch 585: Train Loss = 0.1952, Test Loss = 0.7298688888549805:.4f\n",
      "Epoch 586: Train Loss = 0.1771, Test Loss = 0.7286638021469116:.4f\n",
      "Epoch 587: Train Loss = 0.1695, Test Loss = 0.7399444580078125:.4f\n",
      "Epoch 588: Train Loss = 0.1656, Test Loss = 0.8044759035110474:.4f\n",
      "Epoch 589: Train Loss = 0.1663, Test Loss = 0.8839718699455261:.4f\n",
      "Epoch 590: Train Loss = 0.1486, Test Loss = 0.8797033429145813:.4f\n",
      "Epoch 591: Train Loss = 0.1568, Test Loss = 0.8060886263847351:.4f\n",
      "Epoch 592: Train Loss = 0.1534, Test Loss = 0.7418913245201111:.4f\n",
      "Epoch 593: Train Loss = 0.1605, Test Loss = 0.7374805808067322:.4f\n",
      "Epoch 594: Train Loss = 0.1482, Test Loss = 0.7488810420036316:.4f\n",
      "Epoch 595: Train Loss = 0.1595, Test Loss = 0.7558945417404175:.4f\n",
      "Epoch 596: Train Loss = 0.1507, Test Loss = 0.7617169618606567:.4f\n",
      "Epoch 597: Train Loss = 0.1731, Test Loss = 0.7598820328712463:.4f\n",
      "Epoch 598: Train Loss = 0.1498, Test Loss = 0.7799394130706787:.4f\n",
      "Epoch 599: Train Loss = 0.1729, Test Loss = 0.7797731161117554:.4f\n",
      "Epoch 600: Train Loss = 0.1622, Test Loss = 0.7631491422653198:.4f\n",
      "Epoch 601: Train Loss = 0.1546, Test Loss = 0.7869552373886108:.4f\n",
      "Epoch 602: Train Loss = 0.1598, Test Loss = 0.7647165060043335:.4f\n",
      "Epoch 603: Train Loss = 0.1557, Test Loss = 0.7549257874488831:.4f\n",
      "Epoch 604: Train Loss = 0.1789, Test Loss = 0.7399857640266418:.4f\n",
      "Epoch 605: Train Loss = 0.1586, Test Loss = 0.7589796185493469:.4f\n",
      "Epoch 606: Train Loss = 0.1461, Test Loss = 0.7808054685592651:.4f\n",
      "Epoch 607: Train Loss = 0.1419, Test Loss = 0.7722586393356323:.4f\n",
      "Epoch 608: Train Loss = 0.2053, Test Loss = 0.7670463919639587:.4f\n",
      "Epoch 609: Train Loss = 0.1726, Test Loss = 0.8178151845932007:.4f\n",
      "Epoch 610: Train Loss = 0.1716, Test Loss = 0.8718159794807434:.4f\n",
      "Epoch 611: Train Loss = 0.1795, Test Loss = 0.8130711317062378:.4f\n",
      "Epoch 612: Train Loss = 0.1626, Test Loss = 0.7673517465591431:.4f\n",
      "Epoch 613: Train Loss = 0.1736, Test Loss = 0.760230302810669:.4f\n",
      "Epoch 614: Train Loss = 0.1548, Test Loss = 0.7828589677810669:.4f\n",
      "Epoch 615: Train Loss = 0.1608, Test Loss = 0.7895588278770447:.4f\n",
      "Epoch 616: Train Loss = 0.1469, Test Loss = 0.7691218852996826:.4f\n",
      "Epoch 617: Train Loss = 0.1626, Test Loss = 0.7800414562225342:.4f\n",
      "Epoch 618: Train Loss = 0.1484, Test Loss = 0.8163664937019348:.4f\n",
      "Epoch 619: Train Loss = 0.1728, Test Loss = 0.8298053741455078:.4f\n",
      "Epoch 620: Train Loss = 0.1765, Test Loss = 0.8120259046554565:.4f\n",
      "Epoch 621: Train Loss = 0.1775, Test Loss = 0.7877981662750244:.4f\n",
      "Epoch 622: Train Loss = 0.1630, Test Loss = 0.802146315574646:.4f\n",
      "Epoch 623: Train Loss = 0.1623, Test Loss = 0.8264046907424927:.4f\n",
      "Epoch 624: Train Loss = 0.1550, Test Loss = 0.8229080438613892:.4f\n",
      "Epoch 625: Train Loss = 0.1584, Test Loss = 0.8189443349838257:.4f\n",
      "Epoch 626: Train Loss = 0.1606, Test Loss = 0.7923865914344788:.4f\n",
      "Epoch 627: Train Loss = 0.1752, Test Loss = 0.7929810881614685:.4f\n",
      "Epoch 628: Train Loss = 0.1628, Test Loss = 0.8088001012802124:.4f\n",
      "Epoch 629: Train Loss = 0.1603, Test Loss = 0.7971850633621216:.4f\n",
      "Epoch 630: Train Loss = 0.1448, Test Loss = 0.8111848831176758:.4f\n",
      "Epoch 631: Train Loss = 0.1699, Test Loss = 0.7950549125671387:.4f\n",
      "Epoch 632: Train Loss = 0.1784, Test Loss = 0.7928268313407898:.4f\n",
      "Epoch 633: Train Loss = 0.1540, Test Loss = 0.7934916615486145:.4f\n",
      "Epoch 634: Train Loss = 0.1402, Test Loss = 0.7604411840438843:.4f\n",
      "Epoch 635: Train Loss = 0.1603, Test Loss = 0.7548859715461731:.4f\n",
      "Epoch 636: Train Loss = 0.1736, Test Loss = 0.7624205350875854:.4f\n",
      "Epoch 637: Train Loss = 0.1564, Test Loss = 0.8104509115219116:.4f\n",
      "Epoch 638: Train Loss = 0.1499, Test Loss = 0.8022143244743347:.4f\n",
      "Epoch 639: Train Loss = 0.1612, Test Loss = 0.7910722494125366:.4f\n",
      "Epoch 640: Train Loss = 0.1599, Test Loss = 0.7927455902099609:.4f\n",
      "Epoch 641: Train Loss = 0.1499, Test Loss = 0.7689374685287476:.4f\n",
      "Epoch 642: Train Loss = 0.1718, Test Loss = 0.7437635660171509:.4f\n",
      "Epoch 643: Train Loss = 0.1623, Test Loss = 0.7636412978172302:.4f\n",
      "Epoch 644: Train Loss = 0.1964, Test Loss = 0.8111969232559204:.4f\n",
      "Epoch 645: Train Loss = 0.1664, Test Loss = 0.8086031079292297:.4f\n",
      "Epoch 646: Train Loss = 0.1899, Test Loss = 0.7975317239761353:.4f\n",
      "Epoch 647: Train Loss = 0.1549, Test Loss = 0.8145033717155457:.4f\n",
      "Epoch 648: Train Loss = 0.1453, Test Loss = 0.8041632771492004:.4f\n",
      "Epoch 649: Train Loss = 0.1618, Test Loss = 0.7737843990325928:.4f\n",
      "Epoch 650: Train Loss = 0.1671, Test Loss = 0.7476223707199097:.4f\n",
      "Epoch 651: Train Loss = 0.1747, Test Loss = 0.7466394305229187:.4f\n",
      "Epoch 652: Train Loss = 0.1549, Test Loss = 0.7836779952049255:.4f\n",
      "Epoch 653: Train Loss = 0.1514, Test Loss = 0.7947916984558105:.4f\n",
      "Epoch 654: Train Loss = 0.1425, Test Loss = 0.7833532094955444:.4f\n",
      "Epoch 655: Train Loss = 0.1810, Test Loss = 0.7772706747055054:.4f\n",
      "Epoch 656: Train Loss = 0.1504, Test Loss = 0.8100616335868835:.4f\n",
      "Epoch 657: Train Loss = 0.1417, Test Loss = 0.8171011209487915:.4f\n",
      "Epoch 658: Train Loss = 0.1461, Test Loss = 0.8168164491653442:.4f\n",
      "Epoch 659: Train Loss = 0.1838, Test Loss = 0.7712574601173401:.4f\n",
      "Epoch 660: Train Loss = 0.1459, Test Loss = 0.7394891381263733:.4f\n",
      "Epoch 661: Train Loss = 0.1517, Test Loss = 0.7351437211036682:.4f\n",
      "Epoch 662: Train Loss = 0.1875, Test Loss = 0.7553764581680298:.4f\n",
      "Epoch 663: Train Loss = 0.1515, Test Loss = 0.8266453742980957:.4f\n",
      "Epoch 664: Train Loss = 0.1695, Test Loss = 0.8414376974105835:.4f\n",
      "Epoch 665: Train Loss = 0.1602, Test Loss = 0.8269295692443848:.4f\n",
      "Epoch 666: Train Loss = 0.1476, Test Loss = 0.7579305171966553:.4f\n",
      "Epoch 667: Train Loss = 0.1743, Test Loss = 0.7366737127304077:.4f\n",
      "Epoch 668: Train Loss = 0.1644, Test Loss = 0.7769862413406372:.4f\n",
      "Epoch 669: Train Loss = 0.1403, Test Loss = 0.8192715644836426:.4f\n",
      "Epoch 670: Train Loss = 0.1700, Test Loss = 0.8307620882987976:.4f\n",
      "Epoch 671: Train Loss = 0.1428, Test Loss = 0.7829917073249817:.4f\n",
      "Epoch 672: Train Loss = 0.1442, Test Loss = 0.753118634223938:.4f\n",
      "Epoch 673: Train Loss = 0.1485, Test Loss = 0.7489767074584961:.4f\n",
      "Epoch 674: Train Loss = 0.1472, Test Loss = 0.7662562131881714:.4f\n",
      "Epoch 675: Train Loss = 0.1661, Test Loss = 0.7929118871688843:.4f\n",
      "Epoch 676: Train Loss = 0.1507, Test Loss = 0.8224606513977051:.4f\n",
      "Epoch 677: Train Loss = 0.1449, Test Loss = 0.8000949621200562:.4f\n",
      "Epoch 678: Train Loss = 0.1446, Test Loss = 0.7584737539291382:.4f\n",
      "Epoch 679: Train Loss = 0.1576, Test Loss = 0.7353265285491943:.4f\n",
      "Epoch 680: Train Loss = 0.1513, Test Loss = 0.7322929501533508:.4f\n",
      "Epoch 681: Train Loss = 0.1487, Test Loss = 0.7500646114349365:.4f\n",
      "Epoch 682: Train Loss = 0.1797, Test Loss = 0.7637671232223511:.4f\n",
      "Epoch 683: Train Loss = 0.1590, Test Loss = 0.8180413246154785:.4f\n",
      "Epoch 684: Train Loss = 0.1460, Test Loss = 0.8325761556625366:.4f\n",
      "Epoch 685: Train Loss = 0.1510, Test Loss = 0.8365998268127441:.4f\n",
      "Epoch 686: Train Loss = 0.1601, Test Loss = 0.8283756375312805:.4f\n",
      "Epoch 687: Train Loss = 0.1535, Test Loss = 0.7811915874481201:.4f\n",
      "Epoch 688: Train Loss = 0.1372, Test Loss = 0.7383166551589966:.4f\n",
      "Epoch 689: Train Loss = 0.1766, Test Loss = 0.7318285703659058:.4f\n",
      "Epoch 690: Train Loss = 0.1794, Test Loss = 0.779452383518219:.4f\n",
      "Epoch 691: Train Loss = 0.1588, Test Loss = 0.8165000677108765:.4f\n",
      "Epoch 692: Train Loss = 0.1451, Test Loss = 0.8110675811767578:.4f\n",
      "Epoch 693: Train Loss = 0.1813, Test Loss = 0.8015164136886597:.4f\n",
      "Epoch 694: Train Loss = 0.1569, Test Loss = 0.8411378860473633:.4f\n",
      "Epoch 695: Train Loss = 0.1408, Test Loss = 0.8360422253608704:.4f\n",
      "Epoch 696: Train Loss = 0.1404, Test Loss = 0.784202516078949:.4f\n",
      "Epoch 697: Train Loss = 0.1451, Test Loss = 0.7708225250244141:.4f\n",
      "Epoch 698: Train Loss = 0.1804, Test Loss = 0.7704128623008728:.4f\n",
      "Epoch 699: Train Loss = 0.1771, Test Loss = 0.7998976111412048:.4f\n",
      "Epoch 700: Train Loss = 0.1685, Test Loss = 0.8253992199897766:.4f\n",
      "Epoch 701: Train Loss = 0.1527, Test Loss = 0.8295589685440063:.4f\n",
      "Epoch 702: Train Loss = 0.1635, Test Loss = 0.8223370313644409:.4f\n",
      "Epoch 703: Train Loss = 0.1864, Test Loss = 0.828669548034668:.4f\n",
      "Epoch 704: Train Loss = 0.1779, Test Loss = 0.7940982580184937:.4f\n",
      "Epoch 705: Train Loss = 0.1558, Test Loss = 0.8058849573135376:.4f\n",
      "Epoch 706: Train Loss = 0.1584, Test Loss = 0.8249493837356567:.4f\n",
      "Epoch 707: Train Loss = 0.1583, Test Loss = 0.7861409783363342:.4f\n",
      "Epoch 708: Train Loss = 0.1721, Test Loss = 0.7775439620018005:.4f\n",
      "Epoch 709: Train Loss = 0.1608, Test Loss = 0.8051684498786926:.4f\n",
      "Epoch 710: Train Loss = 0.1451, Test Loss = 0.8020173907279968:.4f\n",
      "Epoch 711: Train Loss = 0.1617, Test Loss = 0.7887340188026428:.4f\n",
      "Epoch 712: Train Loss = 0.1691, Test Loss = 0.7986115217208862:.4f\n",
      "Epoch 713: Train Loss = 0.1484, Test Loss = 0.7541354894638062:.4f\n",
      "Epoch 714: Train Loss = 0.1556, Test Loss = 0.7468331456184387:.4f\n",
      "Epoch 715: Train Loss = 0.1473, Test Loss = 0.778803288936615:.4f\n",
      "Epoch 716: Train Loss = 0.1540, Test Loss = 0.8141582608222961:.4f\n",
      "Epoch 717: Train Loss = 0.1803, Test Loss = 0.8149434328079224:.4f\n",
      "Epoch 718: Train Loss = 0.1584, Test Loss = 0.8328011631965637:.4f\n",
      "Epoch 719: Train Loss = 0.1476, Test Loss = 0.7949709296226501:.4f\n",
      "Epoch 720: Train Loss = 0.1490, Test Loss = 0.7672290205955505:.4f\n",
      "Epoch 721: Train Loss = 0.1488, Test Loss = 0.7609232068061829:.4f\n",
      "Epoch 722: Train Loss = 0.1740, Test Loss = 0.7980242967605591:.4f\n",
      "Epoch 723: Train Loss = 0.1631, Test Loss = 0.8331806063652039:.4f\n",
      "Epoch 724: Train Loss = 0.1603, Test Loss = 0.8692079782485962:.4f\n",
      "Epoch 725: Train Loss = 0.1476, Test Loss = 0.9007461667060852:.4f\n",
      "Epoch 726: Train Loss = 0.1465, Test Loss = 0.8437882661819458:.4f\n",
      "Epoch 727: Train Loss = 0.1500, Test Loss = 0.7782739400863647:.4f\n",
      "Epoch 728: Train Loss = 0.1482, Test Loss = 0.7748464941978455:.4f\n",
      "Epoch 729: Train Loss = 0.1489, Test Loss = 0.7944833040237427:.4f\n",
      "Epoch 730: Train Loss = 0.1629, Test Loss = 0.805397629737854:.4f\n",
      "Epoch 731: Train Loss = 0.1719, Test Loss = 0.8396611213684082:.4f\n",
      "Epoch 732: Train Loss = 0.1534, Test Loss = 0.9119237065315247:.4f\n",
      "Epoch 733: Train Loss = 0.1665, Test Loss = 0.9386900663375854:.4f\n",
      "Epoch 734: Train Loss = 0.1836, Test Loss = 0.8504964113235474:.4f\n",
      "Epoch 735: Train Loss = 0.2044, Test Loss = 0.799405038356781:.4f\n",
      "Epoch 736: Train Loss = 0.1385, Test Loss = 0.8432631492614746:.4f\n",
      "Epoch 737: Train Loss = 0.1595, Test Loss = 0.8394343256950378:.4f\n",
      "Epoch 738: Train Loss = 0.1816, Test Loss = 0.8000532388687134:.4f\n",
      "Epoch 739: Train Loss = 0.1567, Test Loss = 0.8215174674987793:.4f\n",
      "Epoch 740: Train Loss = 0.1561, Test Loss = 0.8170889019966125:.4f\n",
      "Epoch 741: Train Loss = 0.1655, Test Loss = 0.8065428733825684:.4f\n",
      "Epoch 742: Train Loss = 0.1657, Test Loss = 0.8515636324882507:.4f\n",
      "Epoch 743: Train Loss = 0.2067, Test Loss = 0.8589760065078735:.4f\n",
      "Epoch 744: Train Loss = 0.1516, Test Loss = 0.7692008018493652:.4f\n",
      "Epoch 745: Train Loss = 0.1809, Test Loss = 0.7442952990531921:.4f\n",
      "Epoch 746: Train Loss = 0.1830, Test Loss = 0.7481557726860046:.4f\n",
      "Epoch 747: Train Loss = 0.1852, Test Loss = 0.8278394937515259:.4f\n",
      "Epoch 748: Train Loss = 0.1520, Test Loss = 0.8373462557792664:.4f\n",
      "Epoch 749: Train Loss = 0.1846, Test Loss = 0.8142825961112976:.4f\n",
      "Epoch 750: Train Loss = 0.1542, Test Loss = 0.8066456913948059:.4f\n",
      "Epoch 751: Train Loss = 0.1495, Test Loss = 0.827996551990509:.4f\n",
      "Epoch 752: Train Loss = 0.1510, Test Loss = 0.8214252591133118:.4f\n",
      "Epoch 753: Train Loss = 0.1351, Test Loss = 0.8026296496391296:.4f\n",
      "Epoch 754: Train Loss = 0.1504, Test Loss = 0.7830647230148315:.4f\n",
      "Epoch 755: Train Loss = 0.1619, Test Loss = 0.7468193769454956:.4f\n",
      "Epoch 756: Train Loss = 0.1737, Test Loss = 0.7717703580856323:.4f\n",
      "Epoch 757: Train Loss = 0.1643, Test Loss = 0.8373239636421204:.4f\n",
      "Epoch 758: Train Loss = 0.1677, Test Loss = 0.8239585757255554:.4f\n",
      "Epoch 759: Train Loss = 0.1493, Test Loss = 0.8197447657585144:.4f\n",
      "Epoch 760: Train Loss = 0.1554, Test Loss = 0.8157435655593872:.4f\n",
      "Epoch 761: Train Loss = 0.1420, Test Loss = 0.7924882769584656:.4f\n",
      "Epoch 762: Train Loss = 0.1495, Test Loss = 0.7755193710327148:.4f\n",
      "Epoch 763: Train Loss = 0.1750, Test Loss = 0.7541128396987915:.4f\n",
      "Epoch 764: Train Loss = 0.1762, Test Loss = 0.7853130102157593:.4f\n",
      "Epoch 765: Train Loss = 0.1508, Test Loss = 0.8329987525939941:.4f\n",
      "Epoch 766: Train Loss = 0.1492, Test Loss = 0.8508707284927368:.4f\n",
      "Epoch 767: Train Loss = 0.1460, Test Loss = 0.8260241746902466:.4f\n",
      "Epoch 768: Train Loss = 0.1618, Test Loss = 0.7850502133369446:.4f\n",
      "Epoch 769: Train Loss = 0.1652, Test Loss = 0.7817461490631104:.4f\n",
      "Epoch 770: Train Loss = 0.1584, Test Loss = 0.8042305111885071:.4f\n",
      "Epoch 771: Train Loss = 0.1451, Test Loss = 0.7771215438842773:.4f\n",
      "Epoch 772: Train Loss = 0.1516, Test Loss = 0.7853963375091553:.4f\n",
      "Epoch 773: Train Loss = 0.1539, Test Loss = 0.821570098400116:.4f\n",
      "Epoch 774: Train Loss = 0.1610, Test Loss = 0.811257004737854:.4f\n",
      "Epoch 775: Train Loss = 0.1600, Test Loss = 0.8198035359382629:.4f\n",
      "Epoch 776: Train Loss = 0.1439, Test Loss = 0.8497675657272339:.4f\n",
      "Epoch 777: Train Loss = 0.1592, Test Loss = 0.8646524548530579:.4f\n",
      "Epoch 778: Train Loss = 0.1607, Test Loss = 0.8453715443611145:.4f\n",
      "Epoch 779: Train Loss = 0.1545, Test Loss = 0.820545494556427:.4f\n",
      "Epoch 780: Train Loss = 0.1584, Test Loss = 0.8282569050788879:.4f\n",
      "Epoch 781: Train Loss = 0.1771, Test Loss = 0.8327205777168274:.4f\n",
      "Epoch 782: Train Loss = 0.1492, Test Loss = 0.8718560338020325:.4f\n",
      "Epoch 783: Train Loss = 0.1792, Test Loss = 0.8521209955215454:.4f\n",
      "Epoch 784: Train Loss = 0.1549, Test Loss = 0.813814640045166:.4f\n",
      "Epoch 785: Train Loss = 0.1451, Test Loss = 0.7641413807868958:.4f\n",
      "Epoch 786: Train Loss = 0.1476, Test Loss = 0.7724806666374207:.4f\n",
      "Epoch 787: Train Loss = 0.1517, Test Loss = 0.814357578754425:.4f\n",
      "Epoch 788: Train Loss = 0.1446, Test Loss = 0.8237978219985962:.4f\n",
      "Epoch 789: Train Loss = 0.1697, Test Loss = 0.8088470697402954:.4f\n",
      "Epoch 790: Train Loss = 0.1614, Test Loss = 0.7959579229354858:.4f\n",
      "Epoch 791: Train Loss = 0.1479, Test Loss = 0.7917115688323975:.4f\n",
      "Epoch 792: Train Loss = 0.1402, Test Loss = 0.8112159967422485:.4f\n",
      "Epoch 793: Train Loss = 0.1480, Test Loss = 0.8002745509147644:.4f\n",
      "Epoch 794: Train Loss = 0.1809, Test Loss = 0.783571183681488:.4f\n",
      "Epoch 795: Train Loss = 0.1387, Test Loss = 0.7600896954536438:.4f\n",
      "Epoch 796: Train Loss = 0.2025, Test Loss = 0.7586201429367065:.4f\n",
      "Epoch 797: Train Loss = 0.1651, Test Loss = 0.829207718372345:.4f\n",
      "Epoch 798: Train Loss = 0.1571, Test Loss = 0.8684775233268738:.4f\n",
      "Epoch 799: Train Loss = 0.1632, Test Loss = 0.8566817045211792:.4f\n",
      "Epoch 800: Train Loss = 0.1404, Test Loss = 0.7883781790733337:.4f\n",
      "Epoch 801: Train Loss = 0.1846, Test Loss = 0.7678039073944092:.4f\n",
      "Epoch 802: Train Loss = 0.1831, Test Loss = 0.8380977511405945:.4f\n",
      "Epoch 803: Train Loss = 0.1566, Test Loss = 0.9394599199295044:.4f\n",
      "Epoch 804: Train Loss = 0.1811, Test Loss = 0.9223488569259644:.4f\n",
      "Epoch 805: Train Loss = 0.1618, Test Loss = 0.834288477897644:.4f\n",
      "Epoch 806: Train Loss = 0.1495, Test Loss = 0.7751879096031189:.4f\n",
      "Epoch 807: Train Loss = 0.1458, Test Loss = 0.7865667343139648:.4f\n",
      "Epoch 808: Train Loss = 0.1405, Test Loss = 0.8023370504379272:.4f\n",
      "Epoch 809: Train Loss = 0.1657, Test Loss = 0.8035622835159302:.4f\n",
      "Epoch 810: Train Loss = 0.1428, Test Loss = 0.8267141580581665:.4f\n",
      "Epoch 811: Train Loss = 0.1970, Test Loss = 0.8415306806564331:.4f\n",
      "Epoch 812: Train Loss = 0.1511, Test Loss = 0.8460322618484497:.4f\n",
      "Epoch 813: Train Loss = 0.1574, Test Loss = 0.8366186022758484:.4f\n",
      "Epoch 814: Train Loss = 0.1508, Test Loss = 0.8291705846786499:.4f\n",
      "Epoch 815: Train Loss = 0.1488, Test Loss = 0.7719253897666931:.4f\n",
      "Epoch 816: Train Loss = 0.1696, Test Loss = 0.757843017578125:.4f\n",
      "Epoch 817: Train Loss = 0.1848, Test Loss = 0.7727329730987549:.4f\n",
      "Epoch 818: Train Loss = 0.1431, Test Loss = 0.8218380808830261:.4f\n",
      "Epoch 819: Train Loss = 0.1563, Test Loss = 0.8332463502883911:.4f\n",
      "Epoch 820: Train Loss = 0.1456, Test Loss = 0.7946711778640747:.4f\n",
      "Epoch 821: Train Loss = 0.1388, Test Loss = 0.7643710374832153:.4f\n",
      "Epoch 822: Train Loss = 0.1509, Test Loss = 0.7547180652618408:.4f\n",
      "Epoch 823: Train Loss = 0.1975, Test Loss = 0.7729088664054871:.4f\n",
      "Epoch 824: Train Loss = 0.1591, Test Loss = 0.856747031211853:.4f\n",
      "Epoch 825: Train Loss = 0.1854, Test Loss = 0.8841602206230164:.4f\n",
      "Epoch 826: Train Loss = 0.1787, Test Loss = 0.8773900866508484:.4f\n",
      "Epoch 827: Train Loss = 0.1616, Test Loss = 0.8255037069320679:.4f\n",
      "Epoch 828: Train Loss = 0.1576, Test Loss = 0.800094723701477:.4f\n",
      "Epoch 829: Train Loss = 0.1728, Test Loss = 0.8439735174179077:.4f\n",
      "Epoch 830: Train Loss = 0.1664, Test Loss = 0.8513182401657104:.4f\n",
      "Epoch 831: Train Loss = 0.1457, Test Loss = 0.8443645238876343:.4f\n",
      "Epoch 832: Train Loss = 0.1527, Test Loss = 0.8436275720596313:.4f\n",
      "Epoch 833: Train Loss = 0.1463, Test Loss = 0.7904655933380127:.4f\n",
      "Epoch 834: Train Loss = 0.1432, Test Loss = 0.761775553226471:.4f\n",
      "Epoch 835: Train Loss = 0.1438, Test Loss = 0.7744868397712708:.4f\n",
      "Epoch 836: Train Loss = 0.1350, Test Loss = 0.7964320778846741:.4f\n",
      "Epoch 837: Train Loss = 0.1790, Test Loss = 0.8244021534919739:.4f\n",
      "Epoch 838: Train Loss = 0.1616, Test Loss = 0.8394532203674316:.4f\n",
      "Epoch 839: Train Loss = 0.1764, Test Loss = 0.8452783823013306:.4f\n",
      "Epoch 840: Train Loss = 0.1527, Test Loss = 0.8123094439506531:.4f\n",
      "Epoch 841: Train Loss = 0.1689, Test Loss = 0.801525890827179:.4f\n",
      "Epoch 842: Train Loss = 0.1316, Test Loss = 0.7907396554946899:.4f\n",
      "Epoch 843: Train Loss = 0.1861, Test Loss = 0.7856005430221558:.4f\n",
      "Epoch 844: Train Loss = 0.1470, Test Loss = 0.8110300898551941:.4f\n",
      "Epoch 845: Train Loss = 0.1706, Test Loss = 0.8131314516067505:.4f\n",
      "Epoch 846: Train Loss = 0.1681, Test Loss = 0.8334927558898926:.4f\n",
      "Epoch 847: Train Loss = 0.1535, Test Loss = 0.860582172870636:.4f\n",
      "Epoch 848: Train Loss = 0.1457, Test Loss = 0.8403784036636353:.4f\n",
      "Epoch 849: Train Loss = 0.1480, Test Loss = 0.826391339302063:.4f\n",
      "Epoch 850: Train Loss = 0.1520, Test Loss = 0.8234721422195435:.4f\n",
      "Epoch 851: Train Loss = 0.1572, Test Loss = 0.8087065815925598:.4f\n",
      "Epoch 852: Train Loss = 0.1410, Test Loss = 0.7943005561828613:.4f\n",
      "Epoch 853: Train Loss = 0.1403, Test Loss = 0.7942415475845337:.4f\n",
      "Epoch 854: Train Loss = 0.1438, Test Loss = 0.8076596260070801:.4f\n",
      "Epoch 855: Train Loss = 0.1402, Test Loss = 0.808220386505127:.4f\n",
      "Epoch 856: Train Loss = 0.1682, Test Loss = 0.8202077150344849:.4f\n",
      "Epoch 857: Train Loss = 0.1456, Test Loss = 0.8786245584487915:.4f\n",
      "Epoch 858: Train Loss = 0.1411, Test Loss = 0.8682801127433777:.4f\n",
      "Epoch 859: Train Loss = 0.1432, Test Loss = 0.8313472867012024:.4f\n",
      "Epoch 860: Train Loss = 0.1522, Test Loss = 0.7772036790847778:.4f\n",
      "Epoch 861: Train Loss = 0.1561, Test Loss = 0.7658413648605347:.4f\n",
      "Epoch 862: Train Loss = 0.1460, Test Loss = 0.8020766377449036:.4f\n",
      "Epoch 863: Train Loss = 0.1498, Test Loss = 0.8436950445175171:.4f\n",
      "Epoch 864: Train Loss = 0.1666, Test Loss = 0.8322452306747437:.4f\n",
      "Epoch 865: Train Loss = 0.1662, Test Loss = 0.8068273663520813:.4f\n",
      "Epoch 866: Train Loss = 0.1506, Test Loss = 0.8135965466499329:.4f\n",
      "Epoch 867: Train Loss = 0.1770, Test Loss = 0.8138028979301453:.4f\n",
      "Epoch 868: Train Loss = 0.1363, Test Loss = 0.778367817401886:.4f\n",
      "Epoch 869: Train Loss = 0.1571, Test Loss = 0.7486347556114197:.4f\n",
      "Epoch 870: Train Loss = 0.1532, Test Loss = 0.7629125118255615:.4f\n",
      "Epoch 871: Train Loss = 0.1767, Test Loss = 0.7773556709289551:.4f\n",
      "Epoch 872: Train Loss = 0.1529, Test Loss = 0.8442050814628601:.4f\n",
      "Epoch 873: Train Loss = 0.1752, Test Loss = 0.859063982963562:.4f\n",
      "Epoch 874: Train Loss = 0.1463, Test Loss = 0.8444533348083496:.4f\n",
      "Epoch 875: Train Loss = 0.1774, Test Loss = 0.8195816278457642:.4f\n",
      "Epoch 876: Train Loss = 0.1501, Test Loss = 0.7883313894271851:.4f\n",
      "Epoch 877: Train Loss = 0.1898, Test Loss = 0.7629395723342896:.4f\n",
      "Epoch 878: Train Loss = 0.1895, Test Loss = 0.8108474612236023:.4f\n",
      "Epoch 879: Train Loss = 0.1473, Test Loss = 0.8737400770187378:.4f\n",
      "Epoch 880: Train Loss = 0.1601, Test Loss = 0.8518037796020508:.4f\n",
      "Epoch 881: Train Loss = 0.1640, Test Loss = 0.8030565977096558:.4f\n",
      "Epoch 882: Train Loss = 0.1924, Test Loss = 0.7850667834281921:.4f\n",
      "Epoch 883: Train Loss = 0.1453, Test Loss = 0.8378697633743286:.4f\n",
      "Epoch 884: Train Loss = 0.1593, Test Loss = 0.8707513809204102:.4f\n",
      "Epoch 885: Train Loss = 0.1465, Test Loss = 0.8588939905166626:.4f\n",
      "Epoch 886: Train Loss = 0.1718, Test Loss = 0.818950355052948:.4f\n",
      "Epoch 887: Train Loss = 0.1718, Test Loss = 0.8076316118240356:.4f\n",
      "Epoch 888: Train Loss = 0.1593, Test Loss = 0.8202158808708191:.4f\n",
      "Epoch 889: Train Loss = 0.1371, Test Loss = 0.8253035545349121:.4f\n",
      "Epoch 890: Train Loss = 0.1597, Test Loss = 0.8171753883361816:.4f\n",
      "Epoch 891: Train Loss = 0.1669, Test Loss = 0.8041136860847473:.4f\n",
      "Epoch 892: Train Loss = 0.1648, Test Loss = 0.8061677813529968:.4f\n",
      "Epoch 893: Train Loss = 0.1457, Test Loss = 0.8137823343276978:.4f\n",
      "Epoch 894: Train Loss = 0.1511, Test Loss = 0.8181158304214478:.4f\n",
      "Epoch 895: Train Loss = 0.1375, Test Loss = 0.8031589388847351:.4f\n",
      "Epoch 896: Train Loss = 0.1711, Test Loss = 0.795939564704895:.4f\n",
      "Epoch 897: Train Loss = 0.1478, Test Loss = 0.809609055519104:.4f\n",
      "Epoch 898: Train Loss = 0.1380, Test Loss = 0.7878232002258301:.4f\n",
      "Epoch 899: Train Loss = 0.1400, Test Loss = 0.8007605671882629:.4f\n",
      "Epoch 900: Train Loss = 0.1410, Test Loss = 0.8372260332107544:.4f\n",
      "Epoch 901: Train Loss = 0.1510, Test Loss = 0.8718741536140442:.4f\n",
      "Epoch 902: Train Loss = 0.1359, Test Loss = 0.8626446723937988:.4f\n",
      "Epoch 903: Train Loss = 0.1627, Test Loss = 0.8263214230537415:.4f\n",
      "Epoch 904: Train Loss = 0.1333, Test Loss = 0.8324114084243774:.4f\n",
      "Epoch 905: Train Loss = 0.1675, Test Loss = 0.8459102511405945:.4f\n",
      "Epoch 906: Train Loss = 0.1953, Test Loss = 0.8990160822868347:.4f\n",
      "Epoch 907: Train Loss = 0.1436, Test Loss = 0.8790912628173828:.4f\n",
      "Epoch 908: Train Loss = 0.1548, Test Loss = 0.8701550364494324:.4f\n",
      "Epoch 909: Train Loss = 0.1436, Test Loss = 0.822138786315918:.4f\n",
      "Epoch 910: Train Loss = 0.1305, Test Loss = 0.8045604825019836:.4f\n",
      "Epoch 911: Train Loss = 0.1499, Test Loss = 0.8151382207870483:.4f\n",
      "Epoch 912: Train Loss = 0.1393, Test Loss = 0.8009761571884155:.4f\n",
      "Epoch 913: Train Loss = 0.1334, Test Loss = 0.7953234314918518:.4f\n",
      "Epoch 914: Train Loss = 0.1410, Test Loss = 0.8221486806869507:.4f\n",
      "Epoch 915: Train Loss = 0.1643, Test Loss = 0.8135617971420288:.4f\n",
      "Epoch 916: Train Loss = 0.1433, Test Loss = 0.8606513738632202:.4f\n",
      "Epoch 917: Train Loss = 0.1382, Test Loss = 0.8401179313659668:.4f\n",
      "Epoch 918: Train Loss = 0.1617, Test Loss = 0.8379361033439636:.4f\n",
      "Epoch 919: Train Loss = 0.1408, Test Loss = 0.8840279579162598:.4f\n",
      "Epoch 920: Train Loss = 0.1348, Test Loss = 0.9007881879806519:.4f\n",
      "Epoch 921: Train Loss = 0.1617, Test Loss = 0.8688367605209351:.4f\n",
      "Epoch 922: Train Loss = 0.1326, Test Loss = 0.7989073395729065:.4f\n",
      "Epoch 923: Train Loss = 0.1399, Test Loss = 0.7845001220703125:.4f\n",
      "Epoch 924: Train Loss = 0.1863, Test Loss = 0.7982481718063354:.4f\n",
      "Epoch 925: Train Loss = 0.1398, Test Loss = 0.8482829332351685:.4f\n",
      "Epoch 926: Train Loss = 0.1823, Test Loss = 0.8736441731452942:.4f\n",
      "Epoch 927: Train Loss = 0.1557, Test Loss = 0.915543258190155:.4f\n",
      "Epoch 928: Train Loss = 0.1546, Test Loss = 0.8740742802619934:.4f\n",
      "Epoch 929: Train Loss = 0.1562, Test Loss = 0.8177559971809387:.4f\n",
      "Epoch 930: Train Loss = 0.1648, Test Loss = 0.8037406802177429:.4f\n",
      "Epoch 931: Train Loss = 0.1669, Test Loss = 0.8519622087478638:.4f\n",
      "Epoch 932: Train Loss = 0.1405, Test Loss = 0.9474958181381226:.4f\n",
      "Epoch 933: Train Loss = 0.1877, Test Loss = 0.9446519613265991:.4f\n",
      "Epoch 934: Train Loss = 0.1593, Test Loss = 0.7946754097938538:.4f\n",
      "Epoch 935: Train Loss = 0.1779, Test Loss = 0.7623407244682312:.4f\n",
      "Epoch 936: Train Loss = 0.1415, Test Loss = 0.7972477674484253:.4f\n",
      "Epoch 937: Train Loss = 0.1634, Test Loss = 0.8182246088981628:.4f\n",
      "Epoch 938: Train Loss = 0.1770, Test Loss = 0.8606458902359009:.4f\n",
      "Epoch 939: Train Loss = 0.1648, Test Loss = 0.8929415941238403:.4f\n",
      "Epoch 940: Train Loss = 0.1705, Test Loss = 0.8833673596382141:.4f\n",
      "Epoch 941: Train Loss = 0.1775, Test Loss = 0.8422355651855469:.4f\n",
      "Epoch 942: Train Loss = 0.1716, Test Loss = 0.8053261637687683:.4f\n",
      "Epoch 943: Train Loss = 0.1655, Test Loss = 0.8242276906967163:.4f\n",
      "Epoch 944: Train Loss = 0.1569, Test Loss = 0.8622258901596069:.4f\n",
      "Epoch 945: Train Loss = 0.1458, Test Loss = 0.8241637349128723:.4f\n",
      "Epoch 946: Train Loss = 0.1467, Test Loss = 0.8223273158073425:.4f\n",
      "Epoch 947: Train Loss = 0.1791, Test Loss = 0.8299724459648132:.4f\n",
      "Epoch 948: Train Loss = 0.1669, Test Loss = 0.881790816783905:.4f\n",
      "Epoch 949: Train Loss = 0.1814, Test Loss = 0.8997544050216675:.4f\n",
      "Epoch 950: Train Loss = 0.1771, Test Loss = 0.919357180595398:.4f\n",
      "Epoch 951: Train Loss = 0.1482, Test Loss = 0.9374977946281433:.4f\n",
      "Epoch 952: Train Loss = 0.1490, Test Loss = 0.872776985168457:.4f\n",
      "Epoch 953: Train Loss = 0.1736, Test Loss = 0.7921251058578491:.4f\n",
      "Epoch 954: Train Loss = 0.1681, Test Loss = 0.791549801826477:.4f\n",
      "Epoch 955: Train Loss = 0.1861, Test Loss = 0.8564035296440125:.4f\n",
      "Epoch 956: Train Loss = 0.1861, Test Loss = 0.9730470776557922:.4f\n",
      "Epoch 957: Train Loss = 0.1746, Test Loss = 0.9599254727363586:.4f\n",
      "Epoch 958: Train Loss = 0.1500, Test Loss = 0.8645528554916382:.4f\n",
      "Epoch 959: Train Loss = 0.1630, Test Loss = 0.8254095315933228:.4f\n",
      "Epoch 960: Train Loss = 0.1440, Test Loss = 0.8303763270378113:.4f\n",
      "Epoch 961: Train Loss = 0.1624, Test Loss = 0.834625244140625:.4f\n",
      "Epoch 962: Train Loss = 0.1658, Test Loss = 0.852380633354187:.4f\n",
      "Epoch 963: Train Loss = 0.1449, Test Loss = 0.879439651966095:.4f\n",
      "Epoch 964: Train Loss = 0.1472, Test Loss = 0.8758959770202637:.4f\n",
      "Epoch 965: Train Loss = 0.1569, Test Loss = 0.8452717065811157:.4f\n",
      "Epoch 966: Train Loss = 0.1697, Test Loss = 0.8337922096252441:.4f\n",
      "Epoch 967: Train Loss = 0.1344, Test Loss = 0.8568170666694641:.4f\n",
      "Epoch 968: Train Loss = 0.1634, Test Loss = 0.8858497738838196:.4f\n",
      "Epoch 969: Train Loss = 0.1705, Test Loss = 0.88044273853302:.4f\n",
      "Epoch 970: Train Loss = 0.1590, Test Loss = 0.8319541811943054:.4f\n",
      "Epoch 971: Train Loss = 0.1808, Test Loss = 0.8410117030143738:.4f\n",
      "Epoch 972: Train Loss = 0.1594, Test Loss = 0.920462965965271:.4f\n",
      "Epoch 973: Train Loss = 0.1648, Test Loss = 0.9858565330505371:.4f\n",
      "Epoch 974: Train Loss = 0.1501, Test Loss = 0.8989440202713013:.4f\n",
      "Epoch 975: Train Loss = 0.1542, Test Loss = 0.8164703249931335:.4f\n",
      "Epoch 976: Train Loss = 0.1622, Test Loss = 0.7894611358642578:.4f\n",
      "Epoch 977: Train Loss = 0.1523, Test Loss = 0.8045819401741028:.4f\n",
      "Epoch 978: Train Loss = 0.1942, Test Loss = 0.8348698616027832:.4f\n",
      "Epoch 979: Train Loss = 0.1454, Test Loss = 0.9292675852775574:.4f\n",
      "Epoch 980: Train Loss = 0.1868, Test Loss = 0.8996112942695618:.4f\n",
      "Epoch 981: Train Loss = 0.1719, Test Loss = 0.8546513319015503:.4f\n",
      "Epoch 982: Train Loss = 0.1668, Test Loss = 0.7953108549118042:.4f\n",
      "Epoch 983: Train Loss = 0.1492, Test Loss = 0.8249746561050415:.4f\n",
      "Epoch 984: Train Loss = 0.1416, Test Loss = 0.8552709817886353:.4f\n",
      "Epoch 985: Train Loss = 0.1754, Test Loss = 0.8679010272026062:.4f\n",
      "Epoch 986: Train Loss = 0.1522, Test Loss = 0.8887012600898743:.4f\n",
      "Epoch 987: Train Loss = 0.1494, Test Loss = 0.8571510314941406:.4f\n",
      "Epoch 988: Train Loss = 0.1370, Test Loss = 0.8314526677131653:.4f\n",
      "Epoch 989: Train Loss = 0.1692, Test Loss = 0.824337363243103:.4f\n",
      "Epoch 990: Train Loss = 0.1505, Test Loss = 0.8533040285110474:.4f\n",
      "Epoch 991: Train Loss = 0.1427, Test Loss = 0.8670738339424133:.4f\n",
      "Epoch 992: Train Loss = 0.1614, Test Loss = 0.8316651582717896:.4f\n",
      "Epoch 993: Train Loss = 0.1470, Test Loss = 0.8266674876213074:.4f\n",
      "Epoch 994: Train Loss = 0.1432, Test Loss = 0.799663245677948:.4f\n",
      "Epoch 995: Train Loss = 0.1772, Test Loss = 0.7856518030166626:.4f\n",
      "Epoch 996: Train Loss = 0.1760, Test Loss = 0.8420408964157104:.4f\n",
      "Epoch 997: Train Loss = 0.1539, Test Loss = 0.9590513110160828:.4f\n",
      "Epoch 998: Train Loss = 0.1484, Test Loss = 0.9806992411613464:.4f\n",
      "Epoch 999: Train Loss = 0.1851, Test Loss = 0.8872214555740356:.4f\n",
      "Epoch 1000: Train Loss = 0.1553, Test Loss = 0.8259559869766235:.4f\n",
      "Epoch 1001: Train Loss = 0.1330, Test Loss = 0.8060210943222046:.4f\n",
      "Epoch 1002: Train Loss = 0.1565, Test Loss = 0.8194286227226257:.4f\n",
      "Epoch 1003: Train Loss = 0.1895, Test Loss = 0.8365478515625:.4f\n",
      "Epoch 1004: Train Loss = 0.1540, Test Loss = 0.9039473533630371:.4f\n",
      "Epoch 1005: Train Loss = 0.1449, Test Loss = 0.9011296033859253:.4f\n",
      "Epoch 1006: Train Loss = 0.1635, Test Loss = 0.8394951820373535:.4f\n",
      "Epoch 1007: Train Loss = 0.1679, Test Loss = 0.8023046255111694:.4f\n",
      "Epoch 1008: Train Loss = 0.1770, Test Loss = 0.7983383536338806:.4f\n",
      "Epoch 1009: Train Loss = 0.1695, Test Loss = 0.8342640995979309:.4f\n",
      "Epoch 1010: Train Loss = 0.1544, Test Loss = 0.8939882516860962:.4f\n",
      "Epoch 1011: Train Loss = 0.1567, Test Loss = 0.8899154663085938:.4f\n",
      "Epoch 1012: Train Loss = 0.1474, Test Loss = 0.8791793584823608:.4f\n",
      "Epoch 1013: Train Loss = 0.1415, Test Loss = 0.8546415567398071:.4f\n",
      "Epoch 1014: Train Loss = 0.1414, Test Loss = 0.816269040107727:.4f\n",
      "Epoch 1015: Train Loss = 0.1371, Test Loss = 0.8146108388900757:.4f\n",
      "Epoch 1016: Train Loss = 0.1450, Test Loss = 0.8075286746025085:.4f\n",
      "Epoch 1017: Train Loss = 0.1747, Test Loss = 0.8028295636177063:.4f\n",
      "Epoch 1018: Train Loss = 0.1528, Test Loss = 0.8103176951408386:.4f\n",
      "Epoch 1019: Train Loss = 0.1731, Test Loss = 0.7987939119338989:.4f\n",
      "Epoch 1020: Train Loss = 0.1562, Test Loss = 0.8539704084396362:.4f\n",
      "Epoch 1021: Train Loss = 0.1503, Test Loss = 0.9398292303085327:.4f\n",
      "Epoch 1022: Train Loss = 0.1513, Test Loss = 0.8956466913223267:.4f\n",
      "Epoch 1023: Train Loss = 0.1356, Test Loss = 0.8263528943061829:.4f\n",
      "Epoch 1024: Train Loss = 0.1389, Test Loss = 0.782252848148346:.4f\n",
      "Epoch 1025: Train Loss = 0.1436, Test Loss = 0.7947584986686707:.4f\n",
      "Epoch 1026: Train Loss = 0.1768, Test Loss = 0.7931714057922363:.4f\n",
      "Epoch 1027: Train Loss = 0.1344, Test Loss = 0.8678900003433228:.4f\n",
      "Epoch 1028: Train Loss = 0.1523, Test Loss = 0.8909449577331543:.4f\n",
      "Epoch 1029: Train Loss = 0.1729, Test Loss = 0.9179086685180664:.4f\n",
      "Epoch 1030: Train Loss = 0.1690, Test Loss = 0.9575902223587036:.4f\n",
      "Epoch 1031: Train Loss = 0.1716, Test Loss = 0.8628776669502258:.4f\n",
      "Epoch 1032: Train Loss = 0.1531, Test Loss = 0.8330448269844055:.4f\n",
      "Epoch 1033: Train Loss = 0.1635, Test Loss = 0.8163067698478699:.4f\n",
      "Epoch 1034: Train Loss = 0.1724, Test Loss = 0.795617938041687:.4f\n",
      "Epoch 1035: Train Loss = 0.1430, Test Loss = 0.8682245016098022:.4f\n",
      "Epoch 1036: Train Loss = 0.1641, Test Loss = 0.9132400751113892:.4f\n",
      "Epoch 1037: Train Loss = 0.1416, Test Loss = 0.888048529624939:.4f\n",
      "Epoch 1038: Train Loss = 0.1390, Test Loss = 0.8619526624679565:.4f\n",
      "Epoch 1039: Train Loss = 0.1518, Test Loss = 0.8410837054252625:.4f\n",
      "Epoch 1040: Train Loss = 0.1714, Test Loss = 0.8374336361885071:.4f\n",
      "Epoch 1041: Train Loss = 0.1675, Test Loss = 0.839197039604187:.4f\n",
      "Epoch 1042: Train Loss = 0.1524, Test Loss = 0.9098430871963501:.4f\n",
      "Epoch 1043: Train Loss = 0.1517, Test Loss = 0.8747959136962891:.4f\n",
      "Epoch 1044: Train Loss = 0.1341, Test Loss = 0.8325136303901672:.4f\n",
      "Epoch 1045: Train Loss = 0.1363, Test Loss = 0.809734046459198:.4f\n",
      "Epoch 1046: Train Loss = 0.1453, Test Loss = 0.8105945587158203:.4f\n",
      "Epoch 1047: Train Loss = 0.1601, Test Loss = 0.8180362582206726:.4f\n",
      "Epoch 1048: Train Loss = 0.1543, Test Loss = 0.8360153436660767:.4f\n",
      "Epoch 1049: Train Loss = 0.1395, Test Loss = 0.8369590044021606:.4f\n",
      "Epoch 1050: Train Loss = 0.1359, Test Loss = 0.824334979057312:.4f\n",
      "Epoch 1051: Train Loss = 0.1556, Test Loss = 0.8204129934310913:.4f\n",
      "Epoch 1052: Train Loss = 0.1748, Test Loss = 0.8371661305427551:.4f\n",
      "Epoch 1053: Train Loss = 0.1383, Test Loss = 0.9064363241195679:.4f\n",
      "Epoch 1054: Train Loss = 0.1900, Test Loss = 0.9102389216423035:.4f\n",
      "Epoch 1055: Train Loss = 0.1447, Test Loss = 0.8446575403213501:.4f\n",
      "Epoch 1056: Train Loss = 0.1904, Test Loss = 0.8233489990234375:.4f\n",
      "Epoch 1057: Train Loss = 0.1663, Test Loss = 0.8808472752571106:.4f\n",
      "Epoch 1058: Train Loss = 0.1740, Test Loss = 0.9347766041755676:.4f\n",
      "Epoch 1059: Train Loss = 0.1691, Test Loss = 0.9308016896247864:.4f\n",
      "Epoch 1060: Train Loss = 0.1542, Test Loss = 0.8685790300369263:.4f\n",
      "Epoch 1061: Train Loss = 0.1786, Test Loss = 0.7990881204605103:.4f\n",
      "Epoch 1062: Train Loss = 0.1806, Test Loss = 0.7882777452468872:.4f\n",
      "Epoch 1063: Train Loss = 0.1409, Test Loss = 0.8086865544319153:.4f\n",
      "Epoch 1064: Train Loss = 0.1671, Test Loss = 0.8243839144706726:.4f\n",
      "Epoch 1065: Train Loss = 0.1792, Test Loss = 0.8618361353874207:.4f\n",
      "Epoch 1066: Train Loss = 0.1525, Test Loss = 0.8810655474662781:.4f\n",
      "Epoch 1067: Train Loss = 0.1503, Test Loss = 0.8126920461654663:.4f\n",
      "Epoch 1068: Train Loss = 0.1387, Test Loss = 0.7961462736129761:.4f\n",
      "Epoch 1069: Train Loss = 0.1388, Test Loss = 0.778889536857605:.4f\n",
      "Epoch 1070: Train Loss = 0.1519, Test Loss = 0.810845673084259:.4f\n",
      "Epoch 1071: Train Loss = 0.1665, Test Loss = 0.8749485015869141:.4f\n",
      "Epoch 1072: Train Loss = 0.1589, Test Loss = 0.9707940220832825:.4f\n",
      "Epoch 1073: Train Loss = 0.1703, Test Loss = 0.9514150619506836:.4f\n",
      "Epoch 1074: Train Loss = 0.1732, Test Loss = 0.8391134142875671:.4f\n",
      "Epoch 1075: Train Loss = 0.1703, Test Loss = 0.8067218661308289:.4f\n",
      "Epoch 1076: Train Loss = 0.1617, Test Loss = 0.799075722694397:.4f\n",
      "Epoch 1077: Train Loss = 0.1623, Test Loss = 0.848706841468811:.4f\n",
      "Epoch 1078: Train Loss = 0.1600, Test Loss = 0.8789663314819336:.4f\n",
      "Epoch 1079: Train Loss = 0.1428, Test Loss = 0.9171805381774902:.4f\n",
      "Epoch 1080: Train Loss = 0.1524, Test Loss = 0.8725676536560059:.4f\n",
      "Epoch 1081: Train Loss = 0.1334, Test Loss = 0.812299907207489:.4f\n",
      "Epoch 1082: Train Loss = 0.1351, Test Loss = 0.7874091267585754:.4f\n",
      "Epoch 1083: Train Loss = 0.2202, Test Loss = 0.7822089791297913:.4f\n",
      "Epoch 1084: Train Loss = 0.1412, Test Loss = 0.878625214099884:.4f\n",
      "Epoch 1085: Train Loss = 0.1333, Test Loss = 0.9304001927375793:.4f\n",
      "Epoch 1086: Train Loss = 0.1550, Test Loss = 0.9133411645889282:.4f\n",
      "Epoch 1087: Train Loss = 0.1568, Test Loss = 0.8872578740119934:.4f\n",
      "Epoch 1088: Train Loss = 0.1303, Test Loss = 0.8351110219955444:.4f\n",
      "Epoch 1089: Train Loss = 0.1455, Test Loss = 0.797629177570343:.4f\n",
      "Epoch 1090: Train Loss = 0.1448, Test Loss = 0.7946988344192505:.4f\n",
      "Epoch 1091: Train Loss = 0.1697, Test Loss = 0.8277608156204224:.4f\n",
      "Epoch 1092: Train Loss = 0.1534, Test Loss = 0.8693548440933228:.4f\n",
      "Epoch 1093: Train Loss = 0.1729, Test Loss = 0.8944634199142456:.4f\n",
      "Epoch 1094: Train Loss = 0.1478, Test Loss = 0.8605856895446777:.4f\n",
      "Epoch 1095: Train Loss = 0.1315, Test Loss = 0.8016499280929565:.4f\n",
      "Epoch 1096: Train Loss = 0.1802, Test Loss = 0.7838491201400757:.4f\n",
      "Epoch 1097: Train Loss = 0.1776, Test Loss = 0.8322604894638062:.4f\n",
      "Epoch 1098: Train Loss = 0.1599, Test Loss = 0.9126999974250793:.4f\n",
      "Epoch 1099: Train Loss = 0.1523, Test Loss = 0.931782066822052:.4f\n",
      "Epoch 1100: Train Loss = 0.1335, Test Loss = 0.9035297632217407:.4f\n",
      "Epoch 1101: Train Loss = 0.1438, Test Loss = 0.8531594276428223:.4f\n",
      "Epoch 1102: Train Loss = 0.1674, Test Loss = 0.8354015350341797:.4f\n",
      "Epoch 1103: Train Loss = 0.1728, Test Loss = 0.8467519879341125:.4f\n",
      "Epoch 1104: Train Loss = 0.1869, Test Loss = 0.8763304948806763:.4f\n",
      "Epoch 1105: Train Loss = 0.1670, Test Loss = 0.9360584020614624:.4f\n",
      "Epoch 1106: Train Loss = 0.1818, Test Loss = 0.9686558842658997:.4f\n",
      "Epoch 1107: Train Loss = 0.1827, Test Loss = 0.9655669331550598:.4f\n",
      "Epoch 1108: Train Loss = 0.1777, Test Loss = 0.932734489440918:.4f\n",
      "Epoch 1109: Train Loss = 0.1574, Test Loss = 0.9259698987007141:.4f\n",
      "Epoch 1110: Train Loss = 0.1608, Test Loss = 0.8624000549316406:.4f\n",
      "Epoch 1111: Train Loss = 0.1773, Test Loss = 0.799824595451355:.4f\n",
      "Epoch 1112: Train Loss = 0.1554, Test Loss = 0.8026909828186035:.4f\n",
      "Epoch 1113: Train Loss = 0.1835, Test Loss = 0.83723384141922:.4f\n",
      "Epoch 1114: Train Loss = 0.1376, Test Loss = 0.9082546234130859:.4f\n",
      "Epoch 1115: Train Loss = 0.1672, Test Loss = 0.9549814462661743:.4f\n",
      "Epoch 1116: Train Loss = 0.1675, Test Loss = 0.9588476419448853:.4f\n",
      "Epoch 1117: Train Loss = 0.1457, Test Loss = 0.86834317445755:.4f\n",
      "Epoch 1118: Train Loss = 0.1525, Test Loss = 0.812526524066925:.4f\n",
      "Epoch 1119: Train Loss = 0.1885, Test Loss = 0.7897034883499146:.4f\n",
      "Epoch 1120: Train Loss = 0.1703, Test Loss = 0.8334925770759583:.4f\n",
      "Epoch 1121: Train Loss = 0.1745, Test Loss = 0.9210851788520813:.4f\n",
      "Epoch 1122: Train Loss = 0.1553, Test Loss = 0.97288978099823:.4f\n",
      "Epoch 1123: Train Loss = 0.1766, Test Loss = 0.9326484799385071:.4f\n",
      "Epoch 1124: Train Loss = 0.1744, Test Loss = 0.8942203521728516:.4f\n",
      "Epoch 1125: Train Loss = 0.1482, Test Loss = 0.8578279614448547:.4f\n",
      "Epoch 1126: Train Loss = 0.1281, Test Loss = 0.837447464466095:.4f\n",
      "Epoch 1127: Train Loss = 0.1511, Test Loss = 0.8307675123214722:.4f\n",
      "Epoch 1128: Train Loss = 0.1500, Test Loss = 0.8070357441902161:.4f\n",
      "Epoch 1129: Train Loss = 0.1360, Test Loss = 0.8008562922477722:.4f\n",
      "Epoch 1130: Train Loss = 0.1762, Test Loss = 0.8190857768058777:.4f\n",
      "Epoch 1131: Train Loss = 0.1629, Test Loss = 0.84923255443573:.4f\n",
      "Epoch 1132: Train Loss = 0.1516, Test Loss = 0.8784769773483276:.4f\n",
      "Epoch 1133: Train Loss = 0.1619, Test Loss = 0.8406878709793091:.4f\n",
      "Epoch 1134: Train Loss = 0.1768, Test Loss = 0.8503211736679077:.4f\n",
      "Epoch 1135: Train Loss = 0.1446, Test Loss = 0.8671314120292664:.4f\n",
      "Epoch 1136: Train Loss = 0.1865, Test Loss = 0.8689505457878113:.4f\n",
      "Epoch 1137: Train Loss = 0.1805, Test Loss = 0.8275974988937378:.4f\n",
      "Epoch 1138: Train Loss = 0.1371, Test Loss = 0.825779139995575:.4f\n",
      "Epoch 1139: Train Loss = 0.1569, Test Loss = 0.8397706151008606:.4f\n",
      "Epoch 1140: Train Loss = 0.1364, Test Loss = 0.8906402587890625:.4f\n",
      "Epoch 1141: Train Loss = 0.1396, Test Loss = 0.9184955358505249:.4f\n",
      "Epoch 1142: Train Loss = 0.1333, Test Loss = 0.8951072692871094:.4f\n",
      "Epoch 1143: Train Loss = 0.1411, Test Loss = 0.874760627746582:.4f\n",
      "Epoch 1144: Train Loss = 0.1430, Test Loss = 0.8360217213630676:.4f\n",
      "Epoch 1145: Train Loss = 0.1405, Test Loss = 0.7997090816497803:.4f\n",
      "Epoch 1146: Train Loss = 0.1422, Test Loss = 0.8056986927986145:.4f\n",
      "Epoch 1147: Train Loss = 0.1490, Test Loss = 0.8412759900093079:.4f\n",
      "Epoch 1148: Train Loss = 0.1330, Test Loss = 0.8725095987319946:.4f\n",
      "Epoch 1149: Train Loss = 0.1696, Test Loss = 0.8630873560905457:.4f\n",
      "Epoch 1150: Train Loss = 0.1427, Test Loss = 0.914830207824707:.4f\n",
      "Epoch 1151: Train Loss = 0.1641, Test Loss = 0.9123506546020508:.4f\n",
      "Epoch 1152: Train Loss = 0.1349, Test Loss = 0.8335469365119934:.4f\n",
      "Epoch 1153: Train Loss = 0.1355, Test Loss = 0.7955524325370789:.4f\n",
      "Epoch 1154: Train Loss = 0.2104, Test Loss = 0.7963238954544067:.4f\n",
      "Epoch 1155: Train Loss = 0.1375, Test Loss = 0.9018484354019165:.4f\n",
      "Epoch 1156: Train Loss = 0.1372, Test Loss = 0.9541090130805969:.4f\n",
      "Epoch 1157: Train Loss = 0.1417, Test Loss = 0.9101799726486206:.4f\n",
      "Epoch 1158: Train Loss = 0.1715, Test Loss = 0.8590112924575806:.4f\n",
      "Epoch 1159: Train Loss = 0.1315, Test Loss = 0.8628037571907043:.4f\n",
      "Epoch 1160: Train Loss = 0.1358, Test Loss = 0.8733394742012024:.4f\n",
      "Epoch 1161: Train Loss = 0.1511, Test Loss = 0.873531699180603:.4f\n",
      "Epoch 1162: Train Loss = 0.1654, Test Loss = 0.8554869890213013:.4f\n",
      "Epoch 1163: Train Loss = 0.1515, Test Loss = 0.8696144223213196:.4f\n",
      "Epoch 1164: Train Loss = 0.1466, Test Loss = 0.8436458706855774:.4f\n",
      "Epoch 1165: Train Loss = 0.1615, Test Loss = 0.8127973675727844:.4f\n",
      "Epoch 1166: Train Loss = 0.1725, Test Loss = 0.8282197117805481:.4f\n",
      "Epoch 1167: Train Loss = 0.1335, Test Loss = 0.8841816186904907:.4f\n",
      "Epoch 1168: Train Loss = 0.1324, Test Loss = 0.9336792826652527:.4f\n",
      "Epoch 1169: Train Loss = 0.1392, Test Loss = 0.9032204747200012:.4f\n",
      "Epoch 1170: Train Loss = 0.1313, Test Loss = 0.8598125576972961:.4f\n",
      "Epoch 1171: Train Loss = 0.1397, Test Loss = 0.8166394233703613:.4f\n",
      "Epoch 1172: Train Loss = 0.2113, Test Loss = 0.7841988205909729:.4f\n",
      "Epoch 1173: Train Loss = 0.1495, Test Loss = 0.8549157381057739:.4f\n",
      "Epoch 1174: Train Loss = 0.1869, Test Loss = 0.8998626470565796:.4f\n",
      "Epoch 1175: Train Loss = 0.1522, Test Loss = 0.9115592837333679:.4f\n",
      "Epoch 1176: Train Loss = 0.1413, Test Loss = 0.8786628842353821:.4f\n",
      "Epoch 1177: Train Loss = 0.1659, Test Loss = 0.8398957252502441:.4f\n",
      "Epoch 1178: Train Loss = 0.1351, Test Loss = 0.8583160638809204:.4f\n",
      "Epoch 1179: Train Loss = 0.1600, Test Loss = 0.8741371035575867:.4f\n",
      "Epoch 1180: Train Loss = 0.1512, Test Loss = 0.9118627309799194:.4f\n",
      "Epoch 1181: Train Loss = 0.1572, Test Loss = 0.9139288067817688:.4f\n",
      "Epoch 1182: Train Loss = 0.1409, Test Loss = 0.8716060519218445:.4f\n",
      "Epoch 1183: Train Loss = 0.1366, Test Loss = 0.8498009443283081:.4f\n",
      "Epoch 1184: Train Loss = 0.1530, Test Loss = 0.8497236371040344:.4f\n",
      "Epoch 1185: Train Loss = 0.1328, Test Loss = 0.8354846239089966:.4f\n",
      "Epoch 1186: Train Loss = 0.1435, Test Loss = 0.8386186361312866:.4f\n",
      "Epoch 1187: Train Loss = 0.1392, Test Loss = 0.8409969210624695:.4f\n",
      "Epoch 1188: Train Loss = 0.1310, Test Loss = 0.8559964895248413:.4f\n",
      "Epoch 1189: Train Loss = 0.1397, Test Loss = 0.8613537549972534:.4f\n",
      "Epoch 1190: Train Loss = 0.1346, Test Loss = 0.8494901657104492:.4f\n",
      "Epoch 1191: Train Loss = 0.1377, Test Loss = 0.8176406621932983:.4f\n",
      "Epoch 1192: Train Loss = 0.1717, Test Loss = 0.838420569896698:.4f\n",
      "Epoch 1193: Train Loss = 0.1389, Test Loss = 0.8472884297370911:.4f\n",
      "Epoch 1194: Train Loss = 0.1364, Test Loss = 0.8513543009757996:.4f\n",
      "Epoch 1195: Train Loss = 0.1609, Test Loss = 0.8617658615112305:.4f\n",
      "Epoch 1196: Train Loss = 0.1385, Test Loss = 0.7998534440994263:.4f\n",
      "Epoch 1197: Train Loss = 0.1370, Test Loss = 0.7670438885688782:.4f\n",
      "Epoch 1198: Train Loss = 0.1436, Test Loss = 0.7666290998458862:.4f\n",
      "Epoch 1199: Train Loss = 0.1753, Test Loss = 0.8099735379219055:.4f\n",
      "Epoch 1200: Train Loss = 0.1366, Test Loss = 0.9035131335258484:.4f\n",
      "Epoch 1201: Train Loss = 0.1472, Test Loss = 0.9335344433784485:.4f\n",
      "Epoch 1202: Train Loss = 0.1455, Test Loss = 0.8612692952156067:.4f\n",
      "Epoch 1203: Train Loss = 0.1511, Test Loss = 0.8135366439819336:.4f\n",
      "Epoch 1204: Train Loss = 0.1416, Test Loss = 0.8061865568161011:.4f\n",
      "Epoch 1205: Train Loss = 0.1441, Test Loss = 0.8035281896591187:.4f\n",
      "Epoch 1206: Train Loss = 0.1491, Test Loss = 0.8269121050834656:.4f\n",
      "Epoch 1207: Train Loss = 0.1639, Test Loss = 0.8572293519973755:.4f\n",
      "Epoch 1208: Train Loss = 0.1522, Test Loss = 0.895474910736084:.4f\n",
      "Epoch 1209: Train Loss = 0.1536, Test Loss = 0.8929079174995422:.4f\n",
      "Epoch 1210: Train Loss = 0.1403, Test Loss = 0.8332263231277466:.4f\n",
      "Epoch 1211: Train Loss = 0.1482, Test Loss = 0.8279608488082886:.4f\n",
      "Epoch 1212: Train Loss = 0.1549, Test Loss = 0.8345441818237305:.4f\n",
      "Epoch 1213: Train Loss = 0.1803, Test Loss = 0.8347476124763489:.4f\n",
      "Epoch 1214: Train Loss = 0.1536, Test Loss = 0.8814341425895691:.4f\n",
      "Epoch 1215: Train Loss = 0.1342, Test Loss = 0.866285502910614:.4f\n",
      "Epoch 1216: Train Loss = 0.1366, Test Loss = 0.8366951942443848:.4f\n",
      "Epoch 1217: Train Loss = 0.1375, Test Loss = 0.8125397562980652:.4f\n",
      "Epoch 1218: Train Loss = 0.1791, Test Loss = 0.799020528793335:.4f\n",
      "Epoch 1219: Train Loss = 0.1483, Test Loss = 0.8377393484115601:.4f\n",
      "Epoch 1220: Train Loss = 0.1604, Test Loss = 0.8792036771774292:.4f\n",
      "Epoch 1221: Train Loss = 0.1930, Test Loss = 0.8923729062080383:.4f\n",
      "Epoch 1222: Train Loss = 0.1600, Test Loss = 0.9077035188674927:.4f\n",
      "Epoch 1223: Train Loss = 0.1364, Test Loss = 0.9369546175003052:.4f\n",
      "Epoch 1224: Train Loss = 0.1864, Test Loss = 0.911475658416748:.4f\n",
      "Epoch 1225: Train Loss = 0.1582, Test Loss = 0.8662338256835938:.4f\n",
      "Epoch 1226: Train Loss = 0.1823, Test Loss = 0.8410240411758423:.4f\n",
      "Epoch 1227: Train Loss = 0.1475, Test Loss = 0.8514135479927063:.4f\n",
      "Epoch 1228: Train Loss = 0.1560, Test Loss = 0.8504209518432617:.4f\n",
      "Epoch 1229: Train Loss = 0.1464, Test Loss = 0.867928683757782:.4f\n",
      "Epoch 1230: Train Loss = 0.1417, Test Loss = 0.8795562982559204:.4f\n",
      "Epoch 1231: Train Loss = 0.1335, Test Loss = 0.8814922571182251:.4f\n",
      "Epoch 1232: Train Loss = 0.1573, Test Loss = 0.8818928599357605:.4f\n",
      "Epoch 1233: Train Loss = 0.1474, Test Loss = 0.9088660478591919:.4f\n",
      "Epoch 1234: Train Loss = 0.1327, Test Loss = 0.891778290271759:.4f\n",
      "Epoch 1235: Train Loss = 0.1444, Test Loss = 0.865155816078186:.4f\n",
      "Epoch 1236: Train Loss = 0.1417, Test Loss = 0.854945957660675:.4f\n",
      "Epoch 1237: Train Loss = 0.1476, Test Loss = 0.8544567823410034:.4f\n",
      "Epoch 1238: Train Loss = 0.1401, Test Loss = 0.8683148622512817:.4f\n",
      "Epoch 1239: Train Loss = 0.1334, Test Loss = 0.8682463765144348:.4f\n",
      "Epoch 1240: Train Loss = 0.1473, Test Loss = 0.8503395318984985:.4f\n",
      "Epoch 1241: Train Loss = 0.1333, Test Loss = 0.850017249584198:.4f\n",
      "Epoch 1242: Train Loss = 0.1783, Test Loss = 0.8577306866645813:.4f\n",
      "Epoch 1243: Train Loss = 0.1633, Test Loss = 0.8729848861694336:.4f\n",
      "Epoch 1244: Train Loss = 0.1610, Test Loss = 0.9074234962463379:.4f\n",
      "Epoch 1245: Train Loss = 0.1547, Test Loss = 0.908446192741394:.4f\n",
      "Epoch 1246: Train Loss = 0.1801, Test Loss = 0.8891128301620483:.4f\n",
      "Epoch 1247: Train Loss = 0.1396, Test Loss = 0.9301742315292358:.4f\n",
      "Epoch 1248: Train Loss = 0.1645, Test Loss = 0.9322698712348938:.4f\n",
      "Epoch 1249: Train Loss = 0.1759, Test Loss = 0.897232174873352:.4f\n",
      "Epoch 1250: Train Loss = 0.1535, Test Loss = 0.9103549718856812:.4f\n",
      "Epoch 1251: Train Loss = 0.1594, Test Loss = 0.9170488119125366:.4f\n",
      "Epoch 1252: Train Loss = 0.1679, Test Loss = 0.9060126543045044:.4f\n",
      "Epoch 1253: Train Loss = 0.1499, Test Loss = 0.8791545629501343:.4f\n",
      "Epoch 1254: Train Loss = 0.1408, Test Loss = 0.840554416179657:.4f\n",
      "Epoch 1255: Train Loss = 0.1760, Test Loss = 0.8371723890304565:.4f\n",
      "Epoch 1256: Train Loss = 0.1302, Test Loss = 0.8571168780326843:.4f\n",
      "Epoch 1257: Train Loss = 0.1323, Test Loss = 0.8959678411483765:.4f\n",
      "Epoch 1258: Train Loss = 0.1505, Test Loss = 0.8781090974807739:.4f\n",
      "Epoch 1259: Train Loss = 0.1525, Test Loss = 0.8449749946594238:.4f\n",
      "Epoch 1260: Train Loss = 0.1939, Test Loss = 0.8355380296707153:.4f\n",
      "Epoch 1261: Train Loss = 0.1695, Test Loss = 0.9046279788017273:.4f\n",
      "Epoch 1262: Train Loss = 0.1668, Test Loss = 0.9485365748405457:.4f\n",
      "Epoch 1263: Train Loss = 0.1589, Test Loss = 0.8953787684440613:.4f\n",
      "Epoch 1264: Train Loss = 0.1735, Test Loss = 0.8884722590446472:.4f\n",
      "Epoch 1265: Train Loss = 0.1457, Test Loss = 0.8315871357917786:.4f\n",
      "Epoch 1266: Train Loss = 0.1570, Test Loss = 0.8048627972602844:.4f\n",
      "Epoch 1267: Train Loss = 0.1618, Test Loss = 0.8222103118896484:.4f\n",
      "Epoch 1268: Train Loss = 0.1597, Test Loss = 0.9144840240478516:.4f\n",
      "Epoch 1269: Train Loss = 0.1335, Test Loss = 0.900671660900116:.4f\n",
      "Epoch 1270: Train Loss = 0.1389, Test Loss = 0.878099799156189:.4f\n",
      "Epoch 1271: Train Loss = 0.1365, Test Loss = 0.8606675267219543:.4f\n",
      "Epoch 1272: Train Loss = 0.1804, Test Loss = 0.8738961219787598:.4f\n",
      "Epoch 1273: Train Loss = 0.1733, Test Loss = 0.8855757713317871:.4f\n",
      "Epoch 1274: Train Loss = 0.1387, Test Loss = 0.8673563003540039:.4f\n",
      "Epoch 1275: Train Loss = 0.1434, Test Loss = 0.8326676487922668:.4f\n",
      "Epoch 1276: Train Loss = 0.1403, Test Loss = 0.8328300714492798:.4f\n",
      "Epoch 1277: Train Loss = 0.1741, Test Loss = 0.8610621690750122:.4f\n",
      "Epoch 1278: Train Loss = 0.1552, Test Loss = 0.9483688473701477:.4f\n",
      "Epoch 1279: Train Loss = 0.1600, Test Loss = 0.9316394925117493:.4f\n",
      "Epoch 1280: Train Loss = 0.1419, Test Loss = 0.9209729433059692:.4f\n",
      "Epoch 1281: Train Loss = 0.1348, Test Loss = 0.8465174436569214:.4f\n",
      "Epoch 1282: Train Loss = 0.1389, Test Loss = 0.8268007040023804:.4f\n",
      "Epoch 1283: Train Loss = 0.1346, Test Loss = 0.8217809796333313:.4f\n",
      "Epoch 1284: Train Loss = 0.1588, Test Loss = 0.8474088907241821:.4f\n",
      "Epoch 1285: Train Loss = 0.1356, Test Loss = 0.8832284212112427:.4f\n",
      "Epoch 1286: Train Loss = 0.1437, Test Loss = 0.8961414098739624:.4f\n",
      "Epoch 1287: Train Loss = 0.1715, Test Loss = 0.8838391304016113:.4f\n",
      "Epoch 1288: Train Loss = 0.1654, Test Loss = 0.9243555068969727:.4f\n",
      "Epoch 1289: Train Loss = 0.1333, Test Loss = 0.9404851794242859:.4f\n",
      "Epoch 1290: Train Loss = 0.1412, Test Loss = 0.9361311793327332:.4f\n",
      "Epoch 1291: Train Loss = 0.1664, Test Loss = 0.8765592575073242:.4f\n",
      "Epoch 1292: Train Loss = 0.1632, Test Loss = 0.8851096034049988:.4f\n",
      "Epoch 1293: Train Loss = 0.1392, Test Loss = 0.9071053266525269:.4f\n",
      "Epoch 1294: Train Loss = 0.1407, Test Loss = 0.9154918789863586:.4f\n",
      "Epoch 1295: Train Loss = 0.1368, Test Loss = 0.9140318632125854:.4f\n",
      "Epoch 1296: Train Loss = 0.1676, Test Loss = 0.8938108682632446:.4f\n",
      "Epoch 1297: Train Loss = 0.1621, Test Loss = 0.8695816993713379:.4f\n",
      "Epoch 1298: Train Loss = 0.1759, Test Loss = 0.8896828889846802:.4f\n",
      "Epoch 1299: Train Loss = 0.1571, Test Loss = 0.938986599445343:.4f\n",
      "Epoch 1300: Train Loss = 0.1719, Test Loss = 0.9281722903251648:.4f\n",
      "Epoch 1301: Train Loss = 0.1509, Test Loss = 0.8961414098739624:.4f\n",
      "Epoch 1302: Train Loss = 0.1639, Test Loss = 0.8547449111938477:.4f\n",
      "Epoch 1303: Train Loss = 0.1784, Test Loss = 0.8540870547294617:.4f\n",
      "Epoch 1304: Train Loss = 0.1557, Test Loss = 0.9328873753547668:.4f\n",
      "Epoch 1305: Train Loss = 0.1337, Test Loss = 0.964855968952179:.4f\n",
      "Epoch 1306: Train Loss = 0.1449, Test Loss = 0.9826493263244629:.4f\n",
      "Epoch 1307: Train Loss = 0.1383, Test Loss = 0.9358986020088196:.4f\n",
      "Epoch 1308: Train Loss = 0.1765, Test Loss = 0.8678020238876343:.4f\n",
      "Epoch 1309: Train Loss = 0.1447, Test Loss = 0.850109875202179:.4f\n",
      "Epoch 1310: Train Loss = 0.1355, Test Loss = 0.8589715957641602:.4f\n",
      "Epoch 1311: Train Loss = 0.1462, Test Loss = 0.8578426241874695:.4f\n",
      "Epoch 1312: Train Loss = 0.1498, Test Loss = 0.8579602241516113:.4f\n",
      "Epoch 1313: Train Loss = 0.1409, Test Loss = 0.8760586977005005:.4f\n",
      "Epoch 1314: Train Loss = 0.1449, Test Loss = 0.8755425214767456:.4f\n",
      "Epoch 1315: Train Loss = 0.1559, Test Loss = 0.854033350944519:.4f\n",
      "Epoch 1316: Train Loss = 0.1544, Test Loss = 0.8771679997444153:.4f\n",
      "Epoch 1317: Train Loss = 0.1463, Test Loss = 0.9447285532951355:.4f\n",
      "Epoch 1318: Train Loss = 0.1390, Test Loss = 0.9083517789840698:.4f\n",
      "Epoch 1319: Train Loss = 0.1342, Test Loss = 0.890234649181366:.4f\n",
      "Epoch 1320: Train Loss = 0.1312, Test Loss = 0.8706035614013672:.4f\n",
      "Epoch 1321: Train Loss = 0.1549, Test Loss = 0.8828023076057434:.4f\n",
      "Epoch 1322: Train Loss = 0.1368, Test Loss = 0.8328339457511902:.4f\n",
      "Epoch 1323: Train Loss = 0.1445, Test Loss = 0.8416229486465454:.4f\n",
      "Epoch 1324: Train Loss = 0.1390, Test Loss = 0.8592000007629395:.4f\n",
      "Epoch 1325: Train Loss = 0.1770, Test Loss = 0.8771839141845703:.4f\n",
      "Epoch 1326: Train Loss = 0.1616, Test Loss = 0.8961848020553589:.4f\n",
      "Epoch 1327: Train Loss = 0.1490, Test Loss = 0.9318604469299316:.4f\n",
      "Epoch 1328: Train Loss = 0.1613, Test Loss = 0.9702829122543335:.4f\n",
      "Epoch 1329: Train Loss = 0.1347, Test Loss = 0.9277595281600952:.4f\n",
      "Epoch 1330: Train Loss = 0.1354, Test Loss = 0.8858994245529175:.4f\n",
      "Epoch 1331: Train Loss = 0.2049, Test Loss = 0.839849591255188:.4f\n",
      "Epoch 1332: Train Loss = 0.1624, Test Loss = 0.8854910731315613:.4f\n",
      "Epoch 1333: Train Loss = 0.1272, Test Loss = 0.9651095271110535:.4f\n",
      "Epoch 1334: Train Loss = 0.1725, Test Loss = 0.993786633014679:.4f\n",
      "Epoch 1335: Train Loss = 0.1663, Test Loss = 0.9738043546676636:.4f\n",
      "Epoch 1336: Train Loss = 0.1370, Test Loss = 0.9053317308425903:.4f\n",
      "Epoch 1337: Train Loss = 0.1322, Test Loss = 0.8788226842880249:.4f\n",
      "Epoch 1338: Train Loss = 0.1482, Test Loss = 0.8759430050849915:.4f\n",
      "Epoch 1339: Train Loss = 0.1659, Test Loss = 0.903689980506897:.4f\n",
      "Epoch 1340: Train Loss = 0.1633, Test Loss = 0.8729055523872375:.4f\n",
      "Epoch 1341: Train Loss = 0.1661, Test Loss = 0.902452290058136:.4f\n",
      "Epoch 1342: Train Loss = 0.1410, Test Loss = 1.00556218624115:.4f\n",
      "Epoch 1343: Train Loss = 0.1322, Test Loss = 1.0180952548980713:.4f\n",
      "Epoch 1344: Train Loss = 0.1450, Test Loss = 0.9755896329879761:.4f\n",
      "Epoch 1345: Train Loss = 0.1544, Test Loss = 0.8980644345283508:.4f\n",
      "Epoch 1346: Train Loss = 0.1909, Test Loss = 0.8422783017158508:.4f\n",
      "Epoch 1347: Train Loss = 0.1654, Test Loss = 0.8837100267410278:.4f\n",
      "Epoch 1348: Train Loss = 0.1390, Test Loss = 0.9406854510307312:.4f\n",
      "Epoch 1349: Train Loss = 0.1685, Test Loss = 0.9472823143005371:.4f\n",
      "Epoch 1350: Train Loss = 0.1618, Test Loss = 0.8979949951171875:.4f\n",
      "Epoch 1351: Train Loss = 0.1473, Test Loss = 0.827635645866394:.4f\n",
      "Epoch 1352: Train Loss = 0.1853, Test Loss = 0.8437457084655762:.4f\n",
      "Epoch 1353: Train Loss = 0.1466, Test Loss = 0.8684163093566895:.4f\n",
      "Epoch 1354: Train Loss = 0.1564, Test Loss = 0.8952268362045288:.4f\n",
      "Epoch 1355: Train Loss = 0.1628, Test Loss = 0.8976478576660156:.4f\n",
      "Epoch 1356: Train Loss = 0.1401, Test Loss = 0.9090389013290405:.4f\n",
      "Epoch 1357: Train Loss = 0.1390, Test Loss = 0.8763288259506226:.4f\n",
      "Epoch 1358: Train Loss = 0.1604, Test Loss = 0.8161202669143677:.4f\n",
      "Epoch 1359: Train Loss = 0.1417, Test Loss = 0.8353604078292847:.4f\n",
      "Epoch 1360: Train Loss = 0.1739, Test Loss = 0.8761751055717468:.4f\n",
      "Epoch 1361: Train Loss = 0.1435, Test Loss = 0.9328708648681641:.4f\n",
      "Epoch 1362: Train Loss = 0.1408, Test Loss = 0.9258394241333008:.4f\n",
      "Epoch 1363: Train Loss = 0.1432, Test Loss = 0.8983237147331238:.4f\n",
      "Epoch 1364: Train Loss = 0.1563, Test Loss = 0.8558948636054993:.4f\n",
      "Epoch 1365: Train Loss = 0.2000, Test Loss = 0.8932488560676575:.4f\n",
      "Epoch 1366: Train Loss = 0.1542, Test Loss = 0.9639819264411926:.4f\n",
      "Epoch 1367: Train Loss = 0.1344, Test Loss = 1.0143343210220337:.4f\n",
      "Epoch 1368: Train Loss = 0.1372, Test Loss = 0.973929226398468:.4f\n",
      "Epoch 1369: Train Loss = 0.1641, Test Loss = 0.927899181842804:.4f\n",
      "Epoch 1370: Train Loss = 0.1811, Test Loss = 0.9009804725646973:.4f\n",
      "Epoch 1371: Train Loss = 0.1491, Test Loss = 0.9138351678848267:.4f\n",
      "Epoch 1372: Train Loss = 0.1258, Test Loss = 0.8882611989974976:.4f\n",
      "Epoch 1373: Train Loss = 0.1664, Test Loss = 0.8707623481750488:.4f\n",
      "Epoch 1374: Train Loss = 0.1387, Test Loss = 0.9062520861625671:.4f\n",
      "Epoch 1375: Train Loss = 0.1642, Test Loss = 0.9077723622322083:.4f\n",
      "Epoch 1376: Train Loss = 0.1888, Test Loss = 0.9200476408004761:.4f\n",
      "Epoch 1377: Train Loss = 0.1258, Test Loss = 0.9599924087524414:.4f\n",
      "Epoch 1378: Train Loss = 0.1709, Test Loss = 0.9557279348373413:.4f\n",
      "Epoch 1379: Train Loss = 0.1497, Test Loss = 0.9608029127120972:.4f\n",
      "Epoch 1380: Train Loss = 0.1443, Test Loss = 0.9233136177062988:.4f\n",
      "Epoch 1381: Train Loss = 0.1334, Test Loss = 0.8796052932739258:.4f\n",
      "Epoch 1382: Train Loss = 0.1405, Test Loss = 0.8734453320503235:.4f\n",
      "Epoch 1383: Train Loss = 0.1428, Test Loss = 0.852120041847229:.4f\n",
      "Epoch 1384: Train Loss = 0.1390, Test Loss = 0.8757266998291016:.4f\n",
      "Epoch 1385: Train Loss = 0.1309, Test Loss = 0.9077038764953613:.4f\n",
      "Epoch 1386: Train Loss = 0.1389, Test Loss = 0.9304970502853394:.4f\n",
      "Epoch 1387: Train Loss = 0.1710, Test Loss = 0.8959884643554688:.4f\n",
      "Epoch 1388: Train Loss = 0.1450, Test Loss = 0.8939437866210938:.4f\n",
      "Epoch 1389: Train Loss = 0.1624, Test Loss = 0.8921569585800171:.4f\n",
      "Epoch 1390: Train Loss = 0.1346, Test Loss = 0.9022432565689087:.4f\n",
      "Epoch 1391: Train Loss = 0.1627, Test Loss = 0.8972921371459961:.4f\n",
      "Epoch 1392: Train Loss = 0.1431, Test Loss = 0.9169840812683105:.4f\n",
      "Epoch 1393: Train Loss = 0.1320, Test Loss = 0.8945966958999634:.4f\n",
      "Epoch 1394: Train Loss = 0.1770, Test Loss = 0.8544492721557617:.4f\n",
      "Epoch 1395: Train Loss = 0.1444, Test Loss = 0.8562749624252319:.4f\n",
      "Epoch 1396: Train Loss = 0.1574, Test Loss = 0.8533557653427124:.4f\n",
      "Epoch 1397: Train Loss = 0.1479, Test Loss = 0.8692081570625305:.4f\n",
      "Epoch 1398: Train Loss = 0.1287, Test Loss = 0.8807112574577332:.4f\n",
      "Epoch 1399: Train Loss = 0.1916, Test Loss = 0.8931498527526855:.4f\n",
      "Epoch 1400: Train Loss = 0.1385, Test Loss = 0.9870090484619141:.4f\n",
      "Epoch 1401: Train Loss = 0.1645, Test Loss = 0.9843875765800476:.4f\n",
      "Epoch 1402: Train Loss = 0.1416, Test Loss = 0.9234183430671692:.4f\n",
      "Epoch 1403: Train Loss = 0.1634, Test Loss = 0.8783262372016907:.4f\n",
      "Epoch 1404: Train Loss = 0.1538, Test Loss = 0.894478976726532:.4f\n",
      "Epoch 1405: Train Loss = 0.1553, Test Loss = 0.9230176210403442:.4f\n",
      "Epoch 1406: Train Loss = 0.1913, Test Loss = 0.9397680163383484:.4f\n",
      "Epoch 1407: Train Loss = 0.1666, Test Loss = 0.9162312746047974:.4f\n",
      "Epoch 1408: Train Loss = 0.1823, Test Loss = 0.8676754832267761:.4f\n",
      "Epoch 1409: Train Loss = 0.1397, Test Loss = 0.8522775769233704:.4f\n",
      "Epoch 1410: Train Loss = 0.1604, Test Loss = 0.8486964106559753:.4f\n",
      "Epoch 1411: Train Loss = 0.1637, Test Loss = 0.855237603187561:.4f\n",
      "Epoch 1412: Train Loss = 0.1732, Test Loss = 0.9239267110824585:.4f\n",
      "Epoch 1413: Train Loss = 0.1661, Test Loss = 1.0526422262191772:.4f\n",
      "Epoch 1414: Train Loss = 0.1535, Test Loss = 1.1079249382019043:.4f\n",
      "Epoch 1415: Train Loss = 0.1788, Test Loss = 1.0141758918762207:.4f\n",
      "Epoch 1416: Train Loss = 0.1424, Test Loss = 0.9077601432800293:.4f\n",
      "Epoch 1417: Train Loss = 0.1703, Test Loss = 0.8593993186950684:.4f\n",
      "Epoch 1418: Train Loss = 0.1747, Test Loss = 0.8954493403434753:.4f\n",
      "Epoch 1419: Train Loss = 0.1528, Test Loss = 0.9725783467292786:.4f\n",
      "Epoch 1420: Train Loss = 0.1519, Test Loss = 0.9683674573898315:.4f\n",
      "Epoch 1421: Train Loss = 0.1291, Test Loss = 0.9291110038757324:.4f\n",
      "Epoch 1422: Train Loss = 0.1344, Test Loss = 0.9017398953437805:.4f\n",
      "Epoch 1423: Train Loss = 0.1558, Test Loss = 0.8906245231628418:.4f\n",
      "Epoch 1424: Train Loss = 0.1401, Test Loss = 0.8766651153564453:.4f\n",
      "Epoch 1425: Train Loss = 0.1504, Test Loss = 0.8792389035224915:.4f\n",
      "Epoch 1426: Train Loss = 0.1354, Test Loss = 0.8894407153129578:.4f\n",
      "Epoch 1427: Train Loss = 0.1662, Test Loss = 0.9059576988220215:.4f\n",
      "Epoch 1428: Train Loss = 0.1363, Test Loss = 0.9521668553352356:.4f\n",
      "Epoch 1429: Train Loss = 0.1539, Test Loss = 0.9639931917190552:.4f\n",
      "Epoch 1430: Train Loss = 0.1510, Test Loss = 0.9068244695663452:.4f\n",
      "Epoch 1431: Train Loss = 0.1409, Test Loss = 0.8464678525924683:.4f\n",
      "Epoch 1432: Train Loss = 0.1382, Test Loss = 0.8468725085258484:.4f\n",
      "Epoch 1433: Train Loss = 0.1420, Test Loss = 0.8862935900688171:.4f\n",
      "Epoch 1434: Train Loss = 0.1318, Test Loss = 0.9223469495773315:.4f\n",
      "Epoch 1435: Train Loss = 0.1368, Test Loss = 0.926527202129364:.4f\n",
      "Epoch 1436: Train Loss = 0.1787, Test Loss = 0.8801660537719727:.4f\n",
      "Epoch 1437: Train Loss = 0.1645, Test Loss = 0.870536208152771:.4f\n",
      "Epoch 1438: Train Loss = 0.1427, Test Loss = 0.8503599166870117:.4f\n",
      "Epoch 1439: Train Loss = 0.1714, Test Loss = 0.856213390827179:.4f\n",
      "Epoch 1440: Train Loss = 0.1420, Test Loss = 0.870650589466095:.4f\n",
      "Epoch 1441: Train Loss = 0.1698, Test Loss = 0.8666397929191589:.4f\n",
      "Epoch 1442: Train Loss = 0.1338, Test Loss = 0.9070922136306763:.4f\n",
      "Epoch 1443: Train Loss = 0.1646, Test Loss = 0.9457009434700012:.4f\n",
      "Epoch 1444: Train Loss = 0.1789, Test Loss = 1.032286286354065:.4f\n",
      "Epoch 1445: Train Loss = 0.1889, Test Loss = 1.0432872772216797:.4f\n",
      "Epoch 1446: Train Loss = 0.1714, Test Loss = 0.9409415125846863:.4f\n",
      "Epoch 1447: Train Loss = 0.1488, Test Loss = 0.8544293642044067:.4f\n",
      "Epoch 1448: Train Loss = 0.1730, Test Loss = 0.8200730085372925:.4f\n",
      "Epoch 1449: Train Loss = 0.1740, Test Loss = 0.8627526164054871:.4f\n",
      "Epoch 1450: Train Loss = 0.1267, Test Loss = 1.0021809339523315:.4f\n",
      "Epoch 1451: Train Loss = 0.1560, Test Loss = 1.063690423965454:.4f\n",
      "Epoch 1452: Train Loss = 0.1712, Test Loss = 0.9618898630142212:.4f\n",
      "Epoch 1453: Train Loss = 0.1274, Test Loss = 0.8863174319267273:.4f\n",
      "Epoch 1454: Train Loss = 0.1591, Test Loss = 0.8609207272529602:.4f\n",
      "Epoch 1455: Train Loss = 0.1716, Test Loss = 0.8729996681213379:.4f\n",
      "Epoch 1456: Train Loss = 0.1313, Test Loss = 0.9207512736320496:.4f\n",
      "Epoch 1457: Train Loss = 0.1324, Test Loss = 0.9333028793334961:.4f\n",
      "Epoch 1458: Train Loss = 0.1291, Test Loss = 0.909604549407959:.4f\n",
      "Epoch 1459: Train Loss = 0.1335, Test Loss = 0.9176968336105347:.4f\n",
      "Epoch 1460: Train Loss = 0.1362, Test Loss = 0.9028412103652954:.4f\n",
      "Epoch 1461: Train Loss = 0.1303, Test Loss = 0.8881499171257019:.4f\n",
      "Epoch 1462: Train Loss = 0.1440, Test Loss = 0.9078420400619507:.4f\n",
      "Epoch 1463: Train Loss = 0.1489, Test Loss = 0.8950724601745605:.4f\n",
      "Epoch 1464: Train Loss = 0.1693, Test Loss = 0.853481113910675:.4f\n",
      "Epoch 1465: Train Loss = 0.1468, Test Loss = 0.8719871640205383:.4f\n",
      "Epoch 1466: Train Loss = 0.1724, Test Loss = 0.884300708770752:.4f\n",
      "Epoch 1467: Train Loss = 0.1498, Test Loss = 0.9268547296524048:.4f\n",
      "Epoch 1468: Train Loss = 0.1422, Test Loss = 0.9868391752243042:.4f\n",
      "Epoch 1469: Train Loss = 0.1362, Test Loss = 0.9812760353088379:.4f\n",
      "Epoch 1470: Train Loss = 0.1573, Test Loss = 0.9631921648979187:.4f\n",
      "Epoch 1471: Train Loss = 0.1652, Test Loss = 0.8965436220169067:.4f\n",
      "Epoch 1472: Train Loss = 0.1344, Test Loss = 0.871969997882843:.4f\n",
      "Epoch 1473: Train Loss = 0.1400, Test Loss = 0.8764697313308716:.4f\n",
      "Epoch 1474: Train Loss = 0.1299, Test Loss = 0.867831826210022:.4f\n",
      "Epoch 1475: Train Loss = 0.1398, Test Loss = 0.896925151348114:.4f\n",
      "Epoch 1476: Train Loss = 0.1670, Test Loss = 0.8949205279350281:.4f\n",
      "Epoch 1477: Train Loss = 0.1471, Test Loss = 0.8903645277023315:.4f\n",
      "Epoch 1478: Train Loss = 0.1319, Test Loss = 0.9044345021247864:.4f\n",
      "Epoch 1479: Train Loss = 0.1354, Test Loss = 0.9083096385002136:.4f\n",
      "Epoch 1480: Train Loss = 0.1577, Test Loss = 0.9108448028564453:.4f\n",
      "Epoch 1481: Train Loss = 0.1358, Test Loss = 0.9347853660583496:.4f\n",
      "Epoch 1482: Train Loss = 0.1713, Test Loss = 0.916570782661438:.4f\n",
      "Epoch 1483: Train Loss = 0.1529, Test Loss = 0.9213548898696899:.4f\n",
      "Epoch 1484: Train Loss = 0.1449, Test Loss = 0.9610864520072937:.4f\n",
      "Epoch 1485: Train Loss = 0.1382, Test Loss = 0.963309109210968:.4f\n",
      "Epoch 1486: Train Loss = 0.1642, Test Loss = 0.949800968170166:.4f\n",
      "Epoch 1487: Train Loss = 0.1533, Test Loss = 0.8800967335700989:.4f\n",
      "Epoch 1488: Train Loss = 0.1296, Test Loss = 0.8572624921798706:.4f\n",
      "Epoch 1489: Train Loss = 0.1427, Test Loss = 0.8589141964912415:.4f\n",
      "Epoch 1490: Train Loss = 0.1667, Test Loss = 0.9005913734436035:.4f\n",
      "Epoch 1491: Train Loss = 0.1594, Test Loss = 0.9596856832504272:.4f\n",
      "Epoch 1492: Train Loss = 0.1353, Test Loss = 1.0011017322540283:.4f\n",
      "Epoch 1493: Train Loss = 0.1633, Test Loss = 0.9985140562057495:.4f\n",
      "Epoch 1494: Train Loss = 0.1475, Test Loss = 0.9696072340011597:.4f\n",
      "Epoch 1495: Train Loss = 0.1882, Test Loss = 0.9313127398490906:.4f\n",
      "Epoch 1496: Train Loss = 0.1956, Test Loss = 0.9617975354194641:.4f\n",
      "Epoch 1497: Train Loss = 0.1503, Test Loss = 1.0161397457122803:.4f\n",
      "Epoch 1498: Train Loss = 0.1618, Test Loss = 1.032304048538208:.4f\n",
      "Epoch 1499: Train Loss = 0.1433, Test Loss = 0.9631847143173218:.4f\n",
      "Epoch 1500: Train Loss = 0.1584, Test Loss = 0.8892837762832642:.4f\n",
      "Epoch 1501: Train Loss = 0.1344, Test Loss = 0.8580133318901062:.4f\n",
      "Epoch 1502: Train Loss = 0.1383, Test Loss = 0.8865030407905579:.4f\n",
      "Epoch 1503: Train Loss = 0.1487, Test Loss = 0.9377244114875793:.4f\n",
      "Epoch 1504: Train Loss = 0.1264, Test Loss = 0.9415991902351379:.4f\n",
      "Epoch 1505: Train Loss = 0.1371, Test Loss = 0.9385735392570496:.4f\n",
      "Epoch 1506: Train Loss = 0.1588, Test Loss = 0.9312111139297485:.4f\n",
      "Epoch 1507: Train Loss = 0.1558, Test Loss = 0.9301137924194336:.4f\n",
      "Epoch 1508: Train Loss = 0.1477, Test Loss = 0.9152075052261353:.4f\n",
      "Epoch 1509: Train Loss = 0.1262, Test Loss = 0.8910493850708008:.4f\n",
      "Epoch 1510: Train Loss = 0.1348, Test Loss = 0.8820565342903137:.4f\n",
      "Epoch 1511: Train Loss = 0.1702, Test Loss = 0.8755903244018555:.4f\n",
      "Epoch 1512: Train Loss = 0.1412, Test Loss = 0.9129271507263184:.4f\n",
      "Epoch 1513: Train Loss = 0.1534, Test Loss = 0.9418315887451172:.4f\n",
      "Epoch 1514: Train Loss = 0.1347, Test Loss = 0.9537372589111328:.4f\n",
      "Epoch 1515: Train Loss = 0.1427, Test Loss = 0.9444162249565125:.4f\n",
      "Epoch 1516: Train Loss = 0.1313, Test Loss = 0.9002437591552734:.4f\n",
      "Epoch 1517: Train Loss = 0.1612, Test Loss = 0.8861955404281616:.4f\n",
      "Epoch 1518: Train Loss = 0.1632, Test Loss = 0.9469696283340454:.4f\n",
      "Epoch 1519: Train Loss = 0.1604, Test Loss = 1.0123487710952759:.4f\n",
      "Epoch 1520: Train Loss = 0.1341, Test Loss = 0.9738110303878784:.4f\n",
      "Epoch 1521: Train Loss = 0.1394, Test Loss = 0.931633472442627:.4f\n",
      "Epoch 1522: Train Loss = 0.1646, Test Loss = 0.8805782198905945:.4f\n",
      "Epoch 1523: Train Loss = 0.1469, Test Loss = 0.9243867993354797:.4f\n",
      "Epoch 1524: Train Loss = 0.1899, Test Loss = 0.9346979260444641:.4f\n",
      "Epoch 1525: Train Loss = 0.1419, Test Loss = 0.9805057644844055:.4f\n",
      "Epoch 1526: Train Loss = 0.1283, Test Loss = 0.9444833993911743:.4f\n",
      "Epoch 1527: Train Loss = 0.1284, Test Loss = 0.9140502214431763:.4f\n",
      "Epoch 1528: Train Loss = 0.1367, Test Loss = 0.9258044362068176:.4f\n",
      "Epoch 1529: Train Loss = 0.1417, Test Loss = 0.8992996215820312:.4f\n",
      "Epoch 1530: Train Loss = 0.1290, Test Loss = 0.8721709251403809:.4f\n",
      "Epoch 1531: Train Loss = 0.1663, Test Loss = 0.8811408281326294:.4f\n",
      "Epoch 1532: Train Loss = 0.1545, Test Loss = 0.9159415364265442:.4f\n",
      "Epoch 1533: Train Loss = 0.1831, Test Loss = 0.9784663319587708:.4f\n",
      "Epoch 1534: Train Loss = 0.1637, Test Loss = 1.0115573406219482:.4f\n",
      "Epoch 1535: Train Loss = 0.1643, Test Loss = 1.0062605142593384:.4f\n",
      "Epoch 1536: Train Loss = 0.1676, Test Loss = 0.9292780160903931:.4f\n",
      "Epoch 1537: Train Loss = 0.1370, Test Loss = 0.9460309743881226:.4f\n",
      "Epoch 1538: Train Loss = 0.1637, Test Loss = 0.947027862071991:.4f\n",
      "Epoch 1539: Train Loss = 0.1406, Test Loss = 0.9493423700332642:.4f\n",
      "Epoch 1540: Train Loss = 0.1386, Test Loss = 0.9369242787361145:.4f\n",
      "Epoch 1541: Train Loss = 0.1345, Test Loss = 0.9115520715713501:.4f\n",
      "Epoch 1542: Train Loss = 0.1614, Test Loss = 0.878546416759491:.4f\n",
      "Epoch 1543: Train Loss = 0.1624, Test Loss = 0.9222103953361511:.4f\n",
      "Epoch 1544: Train Loss = 0.1431, Test Loss = 0.988852858543396:.4f\n",
      "Epoch 1545: Train Loss = 0.1556, Test Loss = 0.9945379495620728:.4f\n",
      "Epoch 1546: Train Loss = 0.1835, Test Loss = 0.9082242250442505:.4f\n",
      "Epoch 1547: Train Loss = 0.1635, Test Loss = 0.9295201301574707:.4f\n",
      "Epoch 1548: Train Loss = 0.1239, Test Loss = 0.917749285697937:.4f\n",
      "Epoch 1549: Train Loss = 0.1398, Test Loss = 0.914167582988739:.4f\n",
      "Epoch 1550: Train Loss = 0.1352, Test Loss = 0.920909583568573:.4f\n",
      "Epoch 1551: Train Loss = 0.1379, Test Loss = 0.9166629910469055:.4f\n",
      "Epoch 1552: Train Loss = 0.1443, Test Loss = 0.8939061164855957:.4f\n",
      "Epoch 1553: Train Loss = 0.1365, Test Loss = 0.8848609924316406:.4f\n",
      "Epoch 1554: Train Loss = 0.1811, Test Loss = 0.8939681053161621:.4f\n",
      "Epoch 1555: Train Loss = 0.1385, Test Loss = 0.9539793133735657:.4f\n",
      "Epoch 1556: Train Loss = 0.1807, Test Loss = 0.9532909393310547:.4f\n",
      "Epoch 1557: Train Loss = 0.1271, Test Loss = 0.8749645948410034:.4f\n",
      "Epoch 1558: Train Loss = 0.1394, Test Loss = 0.864246666431427:.4f\n",
      "Epoch 1559: Train Loss = 0.1353, Test Loss = 0.8725781440734863:.4f\n",
      "Epoch 1560: Train Loss = 0.1665, Test Loss = 0.8676522374153137:.4f\n",
      "Epoch 1561: Train Loss = 0.1532, Test Loss = 0.8868773579597473:.4f\n",
      "Epoch 1562: Train Loss = 0.1407, Test Loss = 0.9074150323867798:.4f\n",
      "Epoch 1563: Train Loss = 0.1648, Test Loss = 0.9414867162704468:.4f\n",
      "Epoch 1564: Train Loss = 0.1627, Test Loss = 0.9383130073547363:.4f\n",
      "Epoch 1565: Train Loss = 0.1552, Test Loss = 0.9250558614730835:.4f\n",
      "Epoch 1566: Train Loss = 0.1484, Test Loss = 0.9364386796951294:.4f\n",
      "Epoch 1567: Train Loss = 0.1529, Test Loss = 0.9131131172180176:.4f\n",
      "Epoch 1568: Train Loss = 0.1452, Test Loss = 0.8644096255302429:.4f\n",
      "Epoch 1569: Train Loss = 0.1426, Test Loss = 0.8801437616348267:.4f\n",
      "Epoch 1570: Train Loss = 0.1432, Test Loss = 0.9042627215385437:.4f\n",
      "Epoch 1571: Train Loss = 0.1334, Test Loss = 0.8562344312667847:.4f\n",
      "Epoch 1572: Train Loss = 0.1713, Test Loss = 0.8514338731765747:.4f\n",
      "Epoch 1573: Train Loss = 0.1658, Test Loss = 0.8887559771537781:.4f\n",
      "Epoch 1574: Train Loss = 0.1619, Test Loss = 0.9854844212532043:.4f\n",
      "Epoch 1575: Train Loss = 0.1806, Test Loss = 0.9815075993537903:.4f\n",
      "Epoch 1576: Train Loss = 0.1344, Test Loss = 0.9846488833427429:.4f\n",
      "Epoch 1577: Train Loss = 0.1670, Test Loss = 0.9623376131057739:.4f\n",
      "Epoch 1578: Train Loss = 0.1572, Test Loss = 0.9787047505378723:.4f\n",
      "Epoch 1579: Train Loss = 0.1512, Test Loss = 1.0086650848388672:.4f\n",
      "Epoch 1580: Train Loss = 0.1471, Test Loss = 0.9506661295890808:.4f\n",
      "Epoch 1581: Train Loss = 0.1429, Test Loss = 0.9359375238418579:.4f\n",
      "Epoch 1582: Train Loss = 0.1409, Test Loss = 0.8987555503845215:.4f\n",
      "Epoch 1583: Train Loss = 0.1725, Test Loss = 0.8922039866447449:.4f\n",
      "Epoch 1584: Train Loss = 0.1427, Test Loss = 0.9441697001457214:.4f\n",
      "Epoch 1585: Train Loss = 0.1329, Test Loss = 0.9838792085647583:.4f\n",
      "Epoch 1586: Train Loss = 0.1617, Test Loss = 0.960700511932373:.4f\n",
      "Epoch 1587: Train Loss = 0.1299, Test Loss = 0.9274054765701294:.4f\n",
      "Epoch 1588: Train Loss = 0.1384, Test Loss = 0.908158004283905:.4f\n",
      "Epoch 1589: Train Loss = 0.1440, Test Loss = 0.8915294408798218:.4f\n",
      "Epoch 1590: Train Loss = 0.1495, Test Loss = 0.8885282278060913:.4f\n",
      "Epoch 1591: Train Loss = 0.1251, Test Loss = 0.899345874786377:.4f\n",
      "Epoch 1592: Train Loss = 0.1803, Test Loss = 0.9129036068916321:.4f\n",
      "Epoch 1593: Train Loss = 0.1907, Test Loss = 0.9540020823478699:.4f\n",
      "Epoch 1594: Train Loss = 0.1495, Test Loss = 0.9795812368392944:.4f\n",
      "Epoch 1595: Train Loss = 0.1414, Test Loss = 0.9280943870544434:.4f\n",
      "Epoch 1596: Train Loss = 0.1313, Test Loss = 0.920974612236023:.4f\n",
      "Epoch 1597: Train Loss = 0.1349, Test Loss = 0.9044375419616699:.4f\n",
      "Epoch 1598: Train Loss = 0.1564, Test Loss = 0.9009555578231812:.4f\n",
      "Epoch 1599: Train Loss = 0.1294, Test Loss = 0.9110434651374817:.4f\n",
      "Epoch 1600: Train Loss = 0.1795, Test Loss = 0.9110102653503418:.4f\n",
      "Epoch 1601: Train Loss = 0.1586, Test Loss = 0.9042972326278687:.4f\n",
      "Epoch 1602: Train Loss = 0.1660, Test Loss = 0.9284397959709167:.4f\n",
      "Epoch 1603: Train Loss = 0.1447, Test Loss = 0.9234225153923035:.4f\n",
      "Epoch 1604: Train Loss = 0.1695, Test Loss = 0.8945364952087402:.4f\n",
      "Epoch 1605: Train Loss = 0.1605, Test Loss = 0.8909009099006653:.4f\n",
      "Epoch 1606: Train Loss = 0.1254, Test Loss = 0.8851655721664429:.4f\n",
      "Epoch 1607: Train Loss = 0.1745, Test Loss = 0.897988498210907:.4f\n",
      "Epoch 1608: Train Loss = 0.1449, Test Loss = 0.8965861201286316:.4f\n",
      "Epoch 1609: Train Loss = 0.1436, Test Loss = 0.9046928286552429:.4f\n",
      "Epoch 1610: Train Loss = 0.1434, Test Loss = 0.9273049235343933:.4f\n",
      "Epoch 1611: Train Loss = 0.1429, Test Loss = 0.9101698994636536:.4f\n",
      "Epoch 1612: Train Loss = 0.1280, Test Loss = 0.891937255859375:.4f\n",
      "Epoch 1613: Train Loss = 0.1370, Test Loss = 0.9102824330329895:.4f\n",
      "Epoch 1614: Train Loss = 0.1496, Test Loss = 0.9195388555526733:.4f\n",
      "Epoch 1615: Train Loss = 0.1311, Test Loss = 0.9244057536125183:.4f\n",
      "Epoch 1616: Train Loss = 0.1493, Test Loss = 0.9104785919189453:.4f\n",
      "Epoch 1617: Train Loss = 0.1262, Test Loss = 0.8709121942520142:.4f\n",
      "Epoch 1618: Train Loss = 0.1418, Test Loss = 0.8586807250976562:.4f\n",
      "Epoch 1619: Train Loss = 0.1317, Test Loss = 0.8720787763595581:.4f\n",
      "Epoch 1620: Train Loss = 0.1327, Test Loss = 0.909643828868866:.4f\n",
      "Epoch 1621: Train Loss = 0.1269, Test Loss = 0.9197875261306763:.4f\n",
      "Epoch 1622: Train Loss = 0.1446, Test Loss = 0.9288383722305298:.4f\n",
      "Epoch 1623: Train Loss = 0.1318, Test Loss = 0.9149129986763:.4f\n",
      "Epoch 1624: Train Loss = 0.1554, Test Loss = 0.9291495084762573:.4f\n",
      "Epoch 1625: Train Loss = 0.1708, Test Loss = 0.945569634437561:.4f\n",
      "Epoch 1626: Train Loss = 0.1462, Test Loss = 0.9690030813217163:.4f\n",
      "Epoch 1627: Train Loss = 0.1801, Test Loss = 0.9824919700622559:.4f\n",
      "Epoch 1628: Train Loss = 0.1545, Test Loss = 0.9813926815986633:.4f\n",
      "Epoch 1629: Train Loss = 0.1681, Test Loss = 0.9037696719169617:.4f\n",
      "Epoch 1630: Train Loss = 0.1412, Test Loss = 0.8722049593925476:.4f\n",
      "Epoch 1631: Train Loss = 0.2014, Test Loss = 0.8846413493156433:.4f\n",
      "Epoch 1632: Train Loss = 0.1415, Test Loss = 0.9246107339859009:.4f\n",
      "Epoch 1633: Train Loss = 0.1608, Test Loss = 0.972525417804718:.4f\n",
      "Epoch 1634: Train Loss = 0.1319, Test Loss = 1.018889307975769:.4f\n",
      "Epoch 1635: Train Loss = 0.1582, Test Loss = 0.9962117075920105:.4f\n",
      "Epoch 1636: Train Loss = 0.1597, Test Loss = 1.0002241134643555:.4f\n",
      "Epoch 1637: Train Loss = 0.1641, Test Loss = 1.0016602277755737:.4f\n",
      "Epoch 1638: Train Loss = 0.1592, Test Loss = 0.93736332654953:.4f\n",
      "Epoch 1639: Train Loss = 0.1645, Test Loss = 0.8933806419372559:.4f\n",
      "Epoch 1640: Train Loss = 0.1466, Test Loss = 0.913092315196991:.4f\n",
      "Epoch 1641: Train Loss = 0.1301, Test Loss = 0.9342375993728638:.4f\n",
      "Epoch 1642: Train Loss = 0.1490, Test Loss = 0.9336020350456238:.4f\n",
      "Epoch 1643: Train Loss = 0.1265, Test Loss = 0.9345823526382446:.4f\n",
      "Epoch 1644: Train Loss = 0.1347, Test Loss = 0.9494646787643433:.4f\n",
      "Epoch 1645: Train Loss = 0.1538, Test Loss = 0.9366089105606079:.4f\n",
      "Epoch 1646: Train Loss = 0.1392, Test Loss = 0.9744507074356079:.4f\n",
      "Epoch 1647: Train Loss = 0.1414, Test Loss = 0.9636809229850769:.4f\n",
      "Epoch 1648: Train Loss = 0.1506, Test Loss = 0.9302756190299988:.4f\n",
      "Epoch 1649: Train Loss = 0.1378, Test Loss = 0.9067630767822266:.4f\n",
      "Epoch 1650: Train Loss = 0.1626, Test Loss = 0.942471981048584:.4f\n",
      "Epoch 1651: Train Loss = 0.1357, Test Loss = 0.9112752676010132:.4f\n",
      "Epoch 1652: Train Loss = 0.1308, Test Loss = 0.9213414192199707:.4f\n",
      "Epoch 1653: Train Loss = 0.1628, Test Loss = 0.9097229838371277:.4f\n",
      "Epoch 1654: Train Loss = 0.1420, Test Loss = 0.8710096478462219:.4f\n",
      "Epoch 1655: Train Loss = 0.1339, Test Loss = 0.8978357315063477:.4f\n",
      "Epoch 1656: Train Loss = 0.1457, Test Loss = 0.9319483637809753:.4f\n",
      "Epoch 1657: Train Loss = 0.1277, Test Loss = 0.9455819129943848:.4f\n",
      "Epoch 1658: Train Loss = 0.1727, Test Loss = 0.9436370730400085:.4f\n",
      "Epoch 1659: Train Loss = 0.1701, Test Loss = 0.9465736150741577:.4f\n",
      "Epoch 1660: Train Loss = 0.1665, Test Loss = 0.9124786257743835:.4f\n",
      "Epoch 1661: Train Loss = 0.1509, Test Loss = 0.9185546636581421:.4f\n",
      "Epoch 1662: Train Loss = 0.1522, Test Loss = 0.9342977404594421:.4f\n",
      "Epoch 1663: Train Loss = 0.1367, Test Loss = 0.9434744119644165:.4f\n",
      "Epoch 1664: Train Loss = 0.1749, Test Loss = 0.9492558240890503:.4f\n",
      "Epoch 1665: Train Loss = 0.1355, Test Loss = 0.9068478345870972:.4f\n",
      "Epoch 1666: Train Loss = 0.1388, Test Loss = 0.8805117607116699:.4f\n",
      "Epoch 1667: Train Loss = 0.1672, Test Loss = 0.908679187297821:.4f\n",
      "Epoch 1668: Train Loss = 0.1400, Test Loss = 0.9970051050186157:.4f\n",
      "Epoch 1669: Train Loss = 0.1373, Test Loss = 0.9847347140312195:.4f\n",
      "Epoch 1670: Train Loss = 0.1982, Test Loss = 0.9426188468933105:.4f\n",
      "Epoch 1671: Train Loss = 0.1332, Test Loss = 0.9720451235771179:.4f\n",
      "Epoch 1672: Train Loss = 0.1257, Test Loss = 0.9612823724746704:.4f\n",
      "Epoch 1673: Train Loss = 0.1547, Test Loss = 0.9548252820968628:.4f\n",
      "Epoch 1674: Train Loss = 0.1764, Test Loss = 0.9172032475471497:.4f\n",
      "Epoch 1675: Train Loss = 0.1551, Test Loss = 0.9131803512573242:.4f\n",
      "Epoch 1676: Train Loss = 0.1587, Test Loss = 0.9204554557800293:.4f\n",
      "Epoch 1677: Train Loss = 0.1783, Test Loss = 0.9297412633895874:.4f\n",
      "Epoch 1678: Train Loss = 0.1279, Test Loss = 0.9540225863456726:.4f\n",
      "Epoch 1679: Train Loss = 0.1438, Test Loss = 0.9778053164482117:.4f\n",
      "Epoch 1680: Train Loss = 0.1358, Test Loss = 0.9801691174507141:.4f\n",
      "Epoch 1681: Train Loss = 0.1681, Test Loss = 0.9481364488601685:.4f\n",
      "Epoch 1682: Train Loss = 0.1686, Test Loss = 0.9552891850471497:.4f\n",
      "Epoch 1683: Train Loss = 0.1668, Test Loss = 0.9123345613479614:.4f\n",
      "Epoch 1684: Train Loss = 0.1379, Test Loss = 0.9631631970405579:.4f\n",
      "Epoch 1685: Train Loss = 0.1317, Test Loss = 0.9597940444946289:.4f\n",
      "Epoch 1686: Train Loss = 0.1647, Test Loss = 0.962481677532196:.4f\n",
      "Epoch 1687: Train Loss = 0.1544, Test Loss = 0.9745939373970032:.4f\n",
      "Epoch 1688: Train Loss = 0.1302, Test Loss = 1.0381128787994385:.4f\n",
      "Epoch 1689: Train Loss = 0.1459, Test Loss = 1.0136467218399048:.4f\n",
      "Epoch 1690: Train Loss = 0.1339, Test Loss = 0.9619137644767761:.4f\n",
      "Epoch 1691: Train Loss = 0.1676, Test Loss = 0.8848077654838562:.4f\n",
      "Epoch 1692: Train Loss = 0.1379, Test Loss = 0.8872288465499878:.4f\n",
      "Epoch 1693: Train Loss = 0.1339, Test Loss = 0.9434078931808472:.4f\n",
      "Epoch 1694: Train Loss = 0.1356, Test Loss = 0.9649044871330261:.4f\n",
      "Epoch 1695: Train Loss = 0.1461, Test Loss = 0.956626296043396:.4f\n",
      "Epoch 1696: Train Loss = 0.1598, Test Loss = 0.9218199849128723:.4f\n",
      "Epoch 1697: Train Loss = 0.1900, Test Loss = 0.9340502023696899:.4f\n",
      "Epoch 1698: Train Loss = 0.1336, Test Loss = 1.018040418624878:.4f\n",
      "Epoch 1699: Train Loss = 0.1730, Test Loss = 1.0435981750488281:.4f\n",
      "Epoch 1700: Train Loss = 0.1354, Test Loss = 0.9687224626541138:.4f\n",
      "Epoch 1701: Train Loss = 0.1402, Test Loss = 0.8668902516365051:.4f\n",
      "Epoch 1702: Train Loss = 0.1370, Test Loss = 0.8511780500411987:.4f\n",
      "Epoch 1703: Train Loss = 0.1659, Test Loss = 0.8873893022537231:.4f\n",
      "Epoch 1704: Train Loss = 0.1463, Test Loss = 0.9948164820671082:.4f\n",
      "Epoch 1705: Train Loss = 0.1356, Test Loss = 1.0118272304534912:.4f\n",
      "Epoch 1706: Train Loss = 0.1657, Test Loss = 1.0065644979476929:.4f\n",
      "Epoch 1707: Train Loss = 0.1628, Test Loss = 0.9972070455551147:.4f\n",
      "Epoch 1708: Train Loss = 0.1299, Test Loss = 0.9684198498725891:.4f\n",
      "Epoch 1709: Train Loss = 0.1846, Test Loss = 0.9303833246231079:.4f\n",
      "Epoch 1710: Train Loss = 0.1603, Test Loss = 0.9782311320304871:.4f\n",
      "Epoch 1711: Train Loss = 0.1566, Test Loss = 1.0230064392089844:.4f\n",
      "Epoch 1712: Train Loss = 0.1479, Test Loss = 1.0028560161590576:.4f\n",
      "Epoch 1713: Train Loss = 0.1801, Test Loss = 0.991446852684021:.4f\n",
      "Epoch 1714: Train Loss = 0.1681, Test Loss = 0.9353461265563965:.4f\n",
      "Epoch 1715: Train Loss = 0.1633, Test Loss = 0.9436895251274109:.4f\n",
      "Epoch 1716: Train Loss = 0.1643, Test Loss = 0.9915943145751953:.4f\n",
      "Epoch 1717: Train Loss = 0.1638, Test Loss = 0.9949309229850769:.4f\n",
      "Epoch 1718: Train Loss = 0.1282, Test Loss = 1.0137269496917725:.4f\n",
      "Epoch 1719: Train Loss = 0.1379, Test Loss = 0.9956687092781067:.4f\n",
      "Epoch 1720: Train Loss = 0.1485, Test Loss = 0.9830228090286255:.4f\n",
      "Epoch 1721: Train Loss = 0.1329, Test Loss = 0.8996923565864563:.4f\n",
      "Epoch 1722: Train Loss = 0.1416, Test Loss = 0.8820250630378723:.4f\n",
      "Epoch 1723: Train Loss = 0.1644, Test Loss = 0.9014631509780884:.4f\n",
      "Epoch 1724: Train Loss = 0.1409, Test Loss = 0.983214259147644:.4f\n",
      "Epoch 1725: Train Loss = 0.1457, Test Loss = 0.9537149667739868:.4f\n",
      "Epoch 1726: Train Loss = 0.1414, Test Loss = 0.9035506248474121:.4f\n",
      "Epoch 1727: Train Loss = 0.1254, Test Loss = 0.8685623407363892:.4f\n",
      "Epoch 1728: Train Loss = 0.1443, Test Loss = 0.8755831718444824:.4f\n",
      "Epoch 1729: Train Loss = 0.1335, Test Loss = 0.9134093523025513:.4f\n",
      "Epoch 1730: Train Loss = 0.1683, Test Loss = 0.9393067359924316:.4f\n",
      "Epoch 1731: Train Loss = 0.1521, Test Loss = 0.9579604268074036:.4f\n",
      "Epoch 1732: Train Loss = 0.1404, Test Loss = 0.9624186754226685:.4f\n",
      "Epoch 1733: Train Loss = 0.1535, Test Loss = 0.8996626734733582:.4f\n",
      "Epoch 1734: Train Loss = 0.1457, Test Loss = 0.9149859547615051:.4f\n",
      "Epoch 1735: Train Loss = 0.1499, Test Loss = 0.9794670343399048:.4f\n",
      "Epoch 1736: Train Loss = 0.1316, Test Loss = 0.9556487798690796:.4f\n",
      "Epoch 1737: Train Loss = 0.1293, Test Loss = 0.9440196752548218:.4f\n",
      "Epoch 1738: Train Loss = 0.1818, Test Loss = 0.9374658465385437:.4f\n",
      "Epoch 1739: Train Loss = 0.1555, Test Loss = 0.9925830960273743:.4f\n",
      "Epoch 1740: Train Loss = 0.1533, Test Loss = 1.003485918045044:.4f\n",
      "Epoch 1741: Train Loss = 0.1288, Test Loss = 0.9369645118713379:.4f\n",
      "Epoch 1742: Train Loss = 0.1260, Test Loss = 0.875495433807373:.4f\n",
      "Epoch 1743: Train Loss = 0.1381, Test Loss = 0.8683711290359497:.4f\n",
      "Epoch 1744: Train Loss = 0.1352, Test Loss = 0.9016752243041992:.4f\n",
      "Epoch 1745: Train Loss = 0.1447, Test Loss = 0.9624465703964233:.4f\n",
      "Epoch 1746: Train Loss = 0.1488, Test Loss = 0.9841782450675964:.4f\n",
      "Epoch 1747: Train Loss = 0.1765, Test Loss = 0.9663289189338684:.4f\n",
      "Epoch 1748: Train Loss = 0.1591, Test Loss = 0.9069893956184387:.4f\n",
      "Epoch 1749: Train Loss = 0.1336, Test Loss = 0.8713680505752563:.4f\n",
      "Epoch 1750: Train Loss = 0.1336, Test Loss = 0.8638141751289368:.4f\n",
      "Epoch 1751: Train Loss = 0.1628, Test Loss = 0.9128524661064148:.4f\n",
      "Epoch 1752: Train Loss = 0.1510, Test Loss = 0.9461694955825806:.4f\n",
      "Epoch 1753: Train Loss = 0.1458, Test Loss = 0.9488990902900696:.4f\n",
      "Epoch 1754: Train Loss = 0.1452, Test Loss = 0.8971068263053894:.4f\n",
      "Epoch 1755: Train Loss = 0.1298, Test Loss = 0.8854424357414246:.4f\n",
      "Epoch 1756: Train Loss = 0.1672, Test Loss = 0.8655729293823242:.4f\n",
      "Epoch 1757: Train Loss = 0.1423, Test Loss = 0.916000485420227:.4f\n",
      "Epoch 1758: Train Loss = 0.1304, Test Loss = 0.9018279314041138:.4f\n",
      "Epoch 1759: Train Loss = 0.1544, Test Loss = 0.8928548693656921:.4f\n",
      "Epoch 1760: Train Loss = 0.1370, Test Loss = 0.9016736745834351:.4f\n",
      "Epoch 1761: Train Loss = 0.1359, Test Loss = 0.8992021679878235:.4f\n",
      "Epoch 1762: Train Loss = 0.1777, Test Loss = 0.9012081027030945:.4f\n",
      "Epoch 1763: Train Loss = 0.1790, Test Loss = 0.9176651239395142:.4f\n",
      "Epoch 1764: Train Loss = 0.1566, Test Loss = 0.9353021383285522:.4f\n",
      "Epoch 1765: Train Loss = 0.1375, Test Loss = 0.9482473134994507:.4f\n",
      "Epoch 1766: Train Loss = 0.1536, Test Loss = 0.9413596987724304:.4f\n",
      "Epoch 1767: Train Loss = 0.1323, Test Loss = 0.9091264605522156:.4f\n",
      "Epoch 1768: Train Loss = 0.1463, Test Loss = 0.9234234094619751:.4f\n",
      "Epoch 1769: Train Loss = 0.1487, Test Loss = 0.8994197845458984:.4f\n",
      "Epoch 1770: Train Loss = 0.1465, Test Loss = 0.9031655192375183:.4f\n",
      "Epoch 1771: Train Loss = 0.1336, Test Loss = 0.9139441251754761:.4f\n",
      "Epoch 1772: Train Loss = 0.1374, Test Loss = 0.9086614847183228:.4f\n",
      "Epoch 1773: Train Loss = 0.1605, Test Loss = 0.9100755453109741:.4f\n",
      "Epoch 1774: Train Loss = 0.1391, Test Loss = 0.9201176762580872:.4f\n",
      "Epoch 1775: Train Loss = 0.1669, Test Loss = 0.9210994839668274:.4f\n",
      "Epoch 1776: Train Loss = 0.1643, Test Loss = 0.950747013092041:.4f\n",
      "Epoch 1777: Train Loss = 0.1290, Test Loss = 0.9893084764480591:.4f\n",
      "Epoch 1778: Train Loss = 0.1661, Test Loss = 0.9921059608459473:.4f\n",
      "Epoch 1779: Train Loss = 0.1611, Test Loss = 0.9626474380493164:.4f\n",
      "Epoch 1780: Train Loss = 0.1412, Test Loss = 0.9801989793777466:.4f\n",
      "Epoch 1781: Train Loss = 0.1273, Test Loss = 0.9799817204475403:.4f\n",
      "Epoch 1782: Train Loss = 0.1555, Test Loss = 0.9651463627815247:.4f\n",
      "Epoch 1783: Train Loss = 0.1442, Test Loss = 0.9954134225845337:.4f\n",
      "Epoch 1784: Train Loss = 0.1617, Test Loss = 0.9872334599494934:.4f\n",
      "Epoch 1785: Train Loss = 0.1288, Test Loss = 1.020186424255371:.4f\n",
      "Epoch 1786: Train Loss = 0.1901, Test Loss = 0.9902657270431519:.4f\n",
      "Epoch 1787: Train Loss = 0.1312, Test Loss = 1.0310068130493164:.4f\n",
      "Epoch 1788: Train Loss = 0.1289, Test Loss = 1.0094530582427979:.4f\n",
      "Epoch 1789: Train Loss = 0.1611, Test Loss = 0.9652902483940125:.4f\n",
      "Epoch 1790: Train Loss = 0.1462, Test Loss = 0.9370071291923523:.4f\n",
      "Epoch 1791: Train Loss = 0.1700, Test Loss = 0.8837410807609558:.4f\n",
      "Epoch 1792: Train Loss = 0.1558, Test Loss = 0.9441773295402527:.4f\n",
      "Epoch 1793: Train Loss = 0.1411, Test Loss = 1.0364996194839478:.4f\n",
      "Epoch 1794: Train Loss = 0.1290, Test Loss = 1.0652101039886475:.4f\n",
      "Epoch 1795: Train Loss = 0.1550, Test Loss = 1.0257771015167236:.4f\n",
      "Epoch 1796: Train Loss = 0.1412, Test Loss = 0.9330975413322449:.4f\n",
      "Epoch 1797: Train Loss = 0.1247, Test Loss = 0.8734825849533081:.4f\n",
      "Epoch 1798: Train Loss = 0.1725, Test Loss = 0.8628865480422974:.4f\n",
      "Epoch 1799: Train Loss = 0.1321, Test Loss = 0.8970257639884949:.4f\n",
      "Epoch 1800: Train Loss = 0.1392, Test Loss = 0.9340445399284363:.4f\n",
      "Epoch 1801: Train Loss = 0.1355, Test Loss = 0.9064990282058716:.4f\n",
      "Epoch 1802: Train Loss = 0.1327, Test Loss = 0.900252640247345:.4f\n",
      "Epoch 1803: Train Loss = 0.1963, Test Loss = 0.8663864135742188:.4f\n",
      "Epoch 1804: Train Loss = 0.1507, Test Loss = 0.9119145274162292:.4f\n",
      "Epoch 1805: Train Loss = 0.1373, Test Loss = 0.9596785306930542:.4f\n",
      "Epoch 1806: Train Loss = 0.1798, Test Loss = 0.940672755241394:.4f\n",
      "Epoch 1807: Train Loss = 0.1245, Test Loss = 0.9146062731742859:.4f\n",
      "Epoch 1808: Train Loss = 0.1588, Test Loss = 0.910521388053894:.4f\n",
      "Epoch 1809: Train Loss = 0.1857, Test Loss = 0.9515085220336914:.4f\n",
      "Epoch 1810: Train Loss = 0.1423, Test Loss = 1.012739658355713:.4f\n",
      "Epoch 1811: Train Loss = 0.1320, Test Loss = 0.9905344247817993:.4f\n",
      "Epoch 1812: Train Loss = 0.1302, Test Loss = 0.9167656898498535:.4f\n",
      "Epoch 1813: Train Loss = 0.1725, Test Loss = 0.8903344869613647:.4f\n",
      "Epoch 1814: Train Loss = 0.1331, Test Loss = 0.9670838117599487:.4f\n",
      "Epoch 1815: Train Loss = 0.1917, Test Loss = 1.020188570022583:.4f\n",
      "Epoch 1816: Train Loss = 0.1636, Test Loss = 0.9686827659606934:.4f\n",
      "Epoch 1817: Train Loss = 0.1761, Test Loss = 0.929833710193634:.4f\n",
      "Epoch 1818: Train Loss = 0.1285, Test Loss = 0.9597152471542358:.4f\n",
      "Epoch 1819: Train Loss = 0.1545, Test Loss = 0.9758704900741577:.4f\n",
      "Epoch 1820: Train Loss = 0.1266, Test Loss = 0.983564555644989:.4f\n",
      "Epoch 1821: Train Loss = 0.1470, Test Loss = 0.9544826745986938:.4f\n",
      "Epoch 1822: Train Loss = 0.1306, Test Loss = 0.9336158633232117:.4f\n",
      "Epoch 1823: Train Loss = 0.1261, Test Loss = 0.9323290586471558:.4f\n",
      "Epoch 1824: Train Loss = 0.1700, Test Loss = 0.9417021870613098:.4f\n",
      "Epoch 1825: Train Loss = 0.1429, Test Loss = 0.9750444293022156:.4f\n",
      "Epoch 1826: Train Loss = 0.1692, Test Loss = 0.940643310546875:.4f\n",
      "Epoch 1827: Train Loss = 0.1432, Test Loss = 0.9157784581184387:.4f\n",
      "Epoch 1828: Train Loss = 0.1276, Test Loss = 0.8971492052078247:.4f\n",
      "Epoch 1829: Train Loss = 0.1659, Test Loss = 0.9105596542358398:.4f\n",
      "Epoch 1830: Train Loss = 0.1488, Test Loss = 0.9445236325263977:.4f\n",
      "Epoch 1831: Train Loss = 0.1299, Test Loss = 0.9519341588020325:.4f\n",
      "Epoch 1832: Train Loss = 0.1943, Test Loss = 0.9571442604064941:.4f\n",
      "Epoch 1833: Train Loss = 0.1349, Test Loss = 0.9009110331535339:.4f\n",
      "Epoch 1834: Train Loss = 0.1316, Test Loss = 0.8784778714179993:.4f\n",
      "Epoch 1835: Train Loss = 0.1868, Test Loss = 0.8719849586486816:.4f\n",
      "Epoch 1836: Train Loss = 0.1948, Test Loss = 0.8903643488883972:.4f\n",
      "Epoch 1837: Train Loss = 0.1471, Test Loss = 0.9384152293205261:.4f\n",
      "Epoch 1838: Train Loss = 0.1522, Test Loss = 0.9754779934883118:.4f\n",
      "Epoch 1839: Train Loss = 0.1555, Test Loss = 0.9641398191452026:.4f\n",
      "Epoch 1840: Train Loss = 0.1408, Test Loss = 0.9027711749076843:.4f\n",
      "Epoch 1841: Train Loss = 0.1327, Test Loss = 0.8520200848579407:.4f\n",
      "Epoch 1842: Train Loss = 0.1388, Test Loss = 0.8726812601089478:.4f\n",
      "Epoch 1843: Train Loss = 0.1453, Test Loss = 0.8763425946235657:.4f\n",
      "Epoch 1844: Train Loss = 0.1772, Test Loss = 0.879771888256073:.4f\n",
      "Epoch 1845: Train Loss = 0.1360, Test Loss = 0.9290968179702759:.4f\n",
      "Epoch 1846: Train Loss = 0.1489, Test Loss = 0.9588801264762878:.4f\n",
      "Epoch 1847: Train Loss = 0.1583, Test Loss = 0.9316215515136719:.4f\n",
      "Epoch 1848: Train Loss = 0.1374, Test Loss = 0.9729549288749695:.4f\n",
      "Epoch 1849: Train Loss = 0.1906, Test Loss = 0.9717522859573364:.4f\n",
      "Epoch 1850: Train Loss = 0.1695, Test Loss = 1.0105531215667725:.4f\n",
      "Epoch 1851: Train Loss = 0.1450, Test Loss = 0.995139479637146:.4f\n",
      "Epoch 1852: Train Loss = 0.1553, Test Loss = 0.9288217425346375:.4f\n",
      "Epoch 1853: Train Loss = 0.1227, Test Loss = 0.9395939707756042:.4f\n",
      "Epoch 1854: Train Loss = 0.1613, Test Loss = 0.9463211894035339:.4f\n",
      "Epoch 1855: Train Loss = 0.1453, Test Loss = 0.965992271900177:.4f\n",
      "Epoch 1856: Train Loss = 0.1428, Test Loss = 0.9217931628227234:.4f\n",
      "Epoch 1857: Train Loss = 0.1671, Test Loss = 0.8877339363098145:.4f\n",
      "Epoch 1858: Train Loss = 0.1845, Test Loss = 0.8587945699691772:.4f\n",
      "Epoch 1859: Train Loss = 0.1632, Test Loss = 0.9006500244140625:.4f\n",
      "Epoch 1860: Train Loss = 0.1373, Test Loss = 0.9806744456291199:.4f\n",
      "Epoch 1861: Train Loss = 0.1433, Test Loss = 1.0264623165130615:.4f\n",
      "Epoch 1862: Train Loss = 0.1708, Test Loss = 0.9940856695175171:.4f\n",
      "Epoch 1863: Train Loss = 0.1365, Test Loss = 0.9039894342422485:.4f\n",
      "Epoch 1864: Train Loss = 0.1690, Test Loss = 0.8599015474319458:.4f\n",
      "Epoch 1865: Train Loss = 0.1427, Test Loss = 0.8938202857971191:.4f\n",
      "Epoch 1866: Train Loss = 0.1353, Test Loss = 0.9073501825332642:.4f\n",
      "Epoch 1867: Train Loss = 0.1252, Test Loss = 0.9407352209091187:.4f\n",
      "Epoch 1868: Train Loss = 0.1677, Test Loss = 0.9487533569335938:.4f\n",
      "Epoch 1869: Train Loss = 0.1427, Test Loss = 0.9676569700241089:.4f\n",
      "Epoch 1870: Train Loss = 0.1346, Test Loss = 0.9413073658943176:.4f\n",
      "Epoch 1871: Train Loss = 0.1401, Test Loss = 0.9504216909408569:.4f\n",
      "Epoch 1872: Train Loss = 0.1341, Test Loss = 0.9521862864494324:.4f\n",
      "Epoch 1873: Train Loss = 0.1563, Test Loss = 0.9329649209976196:.4f\n",
      "Epoch 1874: Train Loss = 0.1408, Test Loss = 0.9160273671150208:.4f\n",
      "Epoch 1875: Train Loss = 0.1364, Test Loss = 0.9006606936454773:.4f\n",
      "Epoch 1876: Train Loss = 0.1375, Test Loss = 0.8981931805610657:.4f\n",
      "Epoch 1877: Train Loss = 0.1314, Test Loss = 0.9485083818435669:.4f\n",
      "Epoch 1878: Train Loss = 0.1873, Test Loss = 0.9831870198249817:.4f\n",
      "Epoch 1879: Train Loss = 0.1509, Test Loss = 1.0106918811798096:.4f\n",
      "Epoch 1880: Train Loss = 0.1589, Test Loss = 0.9599716067314148:.4f\n",
      "Epoch 1881: Train Loss = 0.1394, Test Loss = 0.917369544506073:.4f\n",
      "Epoch 1882: Train Loss = 0.1294, Test Loss = 0.8684688806533813:.4f\n",
      "Epoch 1883: Train Loss = 0.1348, Test Loss = 0.8833352327346802:.4f\n",
      "Epoch 1884: Train Loss = 0.1292, Test Loss = 0.925417423248291:.4f\n",
      "Epoch 1885: Train Loss = 0.1310, Test Loss = 0.9489538073539734:.4f\n",
      "Epoch 1886: Train Loss = 0.1567, Test Loss = 0.9235302805900574:.4f\n",
      "Epoch 1887: Train Loss = 0.1548, Test Loss = 0.9394629597663879:.4f\n",
      "Epoch 1888: Train Loss = 0.1564, Test Loss = 0.9441937208175659:.4f\n",
      "Epoch 1889: Train Loss = 0.1283, Test Loss = 0.978796124458313:.4f\n",
      "Epoch 1890: Train Loss = 0.1675, Test Loss = 0.9762649536132812:.4f\n",
      "Epoch 1891: Train Loss = 0.1971, Test Loss = 0.9353253245353699:.4f\n",
      "Epoch 1892: Train Loss = 0.1323, Test Loss = 0.9768691062927246:.4f\n",
      "Epoch 1893: Train Loss = 0.1642, Test Loss = 0.9906523823738098:.4f\n",
      "Epoch 1894: Train Loss = 0.1521, Test Loss = 0.9049102663993835:.4f\n",
      "Epoch 1895: Train Loss = 0.1376, Test Loss = 0.8915889859199524:.4f\n",
      "Epoch 1896: Train Loss = 0.1622, Test Loss = 0.8723832368850708:.4f\n",
      "Epoch 1897: Train Loss = 0.1599, Test Loss = 0.9077845811843872:.4f\n",
      "Epoch 1898: Train Loss = 0.1576, Test Loss = 0.9455786943435669:.4f\n",
      "Epoch 1899: Train Loss = 0.1823, Test Loss = 0.9270931482315063:.4f\n",
      "Epoch 1900: Train Loss = 0.1309, Test Loss = 0.9228302836418152:.4f\n",
      "Epoch 1901: Train Loss = 0.1610, Test Loss = 0.9140008687973022:.4f\n",
      "Epoch 1902: Train Loss = 0.1436, Test Loss = 0.9668970108032227:.4f\n",
      "Epoch 1903: Train Loss = 0.1402, Test Loss = 1.0289866924285889:.4f\n",
      "Epoch 1904: Train Loss = 0.1585, Test Loss = 1.018188714981079:.4f\n",
      "Epoch 1905: Train Loss = 0.1482, Test Loss = 0.9343463778495789:.4f\n",
      "Epoch 1906: Train Loss = 0.1287, Test Loss = 0.9074608087539673:.4f\n",
      "Epoch 1907: Train Loss = 0.1577, Test Loss = 0.9068672060966492:.4f\n",
      "Epoch 1908: Train Loss = 0.1494, Test Loss = 0.9434264302253723:.4f\n",
      "Epoch 1909: Train Loss = 0.1633, Test Loss = 0.9254212379455566:.4f\n",
      "Epoch 1910: Train Loss = 0.1298, Test Loss = 0.9599285125732422:.4f\n",
      "Epoch 1911: Train Loss = 0.1230, Test Loss = 0.9434873461723328:.4f\n",
      "Epoch 1912: Train Loss = 0.1610, Test Loss = 0.9464393854141235:.4f\n",
      "Epoch 1913: Train Loss = 0.1536, Test Loss = 0.936076283454895:.4f\n",
      "Epoch 1914: Train Loss = 0.1592, Test Loss = 0.9422821998596191:.4f\n",
      "Epoch 1915: Train Loss = 0.1492, Test Loss = 1.0024715662002563:.4f\n",
      "Epoch 1916: Train Loss = 0.1281, Test Loss = 1.0260227918624878:.4f\n",
      "Epoch 1917: Train Loss = 0.1563, Test Loss = 0.9992784261703491:.4f\n",
      "Epoch 1918: Train Loss = 0.1885, Test Loss = 0.942919909954071:.4f\n",
      "Epoch 1919: Train Loss = 0.1793, Test Loss = 0.9497588872909546:.4f\n",
      "Epoch 1920: Train Loss = 0.1609, Test Loss = 1.0203511714935303:.4f\n",
      "Epoch 1921: Train Loss = 0.1460, Test Loss = 1.0423634052276611:.4f\n",
      "Epoch 1922: Train Loss = 0.1373, Test Loss = 1.0080288648605347:.4f\n",
      "Epoch 1923: Train Loss = 0.1652, Test Loss = 0.9563567042350769:.4f\n",
      "Epoch 1924: Train Loss = 0.1327, Test Loss = 0.9653902053833008:.4f\n",
      "Epoch 1925: Train Loss = 0.1377, Test Loss = 0.9587312936782837:.4f\n",
      "Epoch 1926: Train Loss = 0.1416, Test Loss = 0.9488641023635864:.4f\n",
      "Epoch 1927: Train Loss = 0.1434, Test Loss = 0.9295247793197632:.4f\n",
      "Epoch 1928: Train Loss = 0.1357, Test Loss = 0.9348329305648804:.4f\n",
      "Epoch 1929: Train Loss = 0.1372, Test Loss = 0.9193392992019653:.4f\n",
      "Epoch 1930: Train Loss = 0.1373, Test Loss = 0.8776642084121704:.4f\n",
      "Epoch 1931: Train Loss = 0.1675, Test Loss = 0.8648815155029297:.4f\n",
      "Epoch 1932: Train Loss = 0.1387, Test Loss = 0.873133659362793:.4f\n",
      "Epoch 1933: Train Loss = 0.1330, Test Loss = 0.9221475720405579:.4f\n",
      "Epoch 1934: Train Loss = 0.1570, Test Loss = 0.9531041383743286:.4f\n",
      "Epoch 1935: Train Loss = 0.1425, Test Loss = 0.9287725687026978:.4f\n",
      "Epoch 1936: Train Loss = 0.1619, Test Loss = 0.9057843089103699:.4f\n",
      "Epoch 1937: Train Loss = 0.1292, Test Loss = 0.9139387011528015:.4f\n",
      "Epoch 1938: Train Loss = 0.1267, Test Loss = 0.9247850179672241:.4f\n",
      "Epoch 1939: Train Loss = 0.1368, Test Loss = 0.9169915318489075:.4f\n",
      "Epoch 1940: Train Loss = 0.1366, Test Loss = 0.8948473930358887:.4f\n",
      "Epoch 1941: Train Loss = 0.1617, Test Loss = 0.879940390586853:.4f\n",
      "Epoch 1942: Train Loss = 0.1311, Test Loss = 0.9157150387763977:.4f\n",
      "Epoch 1943: Train Loss = 0.1334, Test Loss = 0.9585201144218445:.4f\n",
      "Epoch 1944: Train Loss = 0.1429, Test Loss = 0.9737823605537415:.4f\n",
      "Epoch 1945: Train Loss = 0.1399, Test Loss = 0.9436248540878296:.4f\n",
      "Epoch 1946: Train Loss = 0.1341, Test Loss = 0.9097272753715515:.4f\n",
      "Epoch 1947: Train Loss = 0.1341, Test Loss = 0.897246241569519:.4f\n",
      "Epoch 1948: Train Loss = 0.1340, Test Loss = 0.9059928059577942:.4f\n",
      "Epoch 1949: Train Loss = 0.1547, Test Loss = 0.9472522735595703:.4f\n",
      "Epoch 1950: Train Loss = 0.1237, Test Loss = 0.9566115140914917:.4f\n",
      "Epoch 1951: Train Loss = 0.1486, Test Loss = 0.9536665678024292:.4f\n",
      "Epoch 1952: Train Loss = 0.1643, Test Loss = 0.9121980667114258:.4f\n",
      "Epoch 1953: Train Loss = 0.1455, Test Loss = 0.8793647885322571:.4f\n",
      "Epoch 1954: Train Loss = 0.1561, Test Loss = 0.8638628125190735:.4f\n",
      "Epoch 1955: Train Loss = 0.1698, Test Loss = 0.8990801572799683:.4f\n",
      "Epoch 1956: Train Loss = 0.1281, Test Loss = 0.977841854095459:.4f\n",
      "Epoch 1957: Train Loss = 0.1687, Test Loss = 0.9822169542312622:.4f\n",
      "Epoch 1958: Train Loss = 0.1770, Test Loss = 0.9999129176139832:.4f\n",
      "Epoch 1959: Train Loss = 0.1576, Test Loss = 1.0083922147750854:.4f\n",
      "Epoch 1960: Train Loss = 0.1875, Test Loss = 0.9838377833366394:.4f\n",
      "Epoch 1961: Train Loss = 0.1446, Test Loss = 0.908794105052948:.4f\n",
      "Epoch 1962: Train Loss = 0.2036, Test Loss = 0.8879911303520203:.4f\n",
      "Epoch 1963: Train Loss = 0.1465, Test Loss = 0.9246748685836792:.4f\n",
      "Epoch 1964: Train Loss = 0.1578, Test Loss = 0.9681227803230286:.4f\n",
      "Epoch 1965: Train Loss = 0.1488, Test Loss = 0.9809433817863464:.4f\n",
      "Epoch 1966: Train Loss = 0.1745, Test Loss = 0.9364473223686218:.4f\n",
      "Epoch 1967: Train Loss = 0.1377, Test Loss = 0.9056295156478882:.4f\n",
      "Epoch 1968: Train Loss = 0.1318, Test Loss = 0.9236670732498169:.4f\n",
      "Epoch 1969: Train Loss = 0.1743, Test Loss = 0.9376906156539917:.4f\n",
      "Epoch 1970: Train Loss = 0.1900, Test Loss = 1.0074658393859863:.4f\n",
      "Epoch 1971: Train Loss = 0.1444, Test Loss = 1.0753753185272217:.4f\n",
      "Epoch 1972: Train Loss = 0.1573, Test Loss = 1.04106867313385:.4f\n",
      "Epoch 1973: Train Loss = 0.1708, Test Loss = 0.9677462577819824:.4f\n",
      "Epoch 1974: Train Loss = 0.1580, Test Loss = 0.9434154629707336:.4f\n",
      "Epoch 1975: Train Loss = 0.1411, Test Loss = 0.9573144912719727:.4f\n",
      "Epoch 1976: Train Loss = 0.1340, Test Loss = 0.92195063829422:.4f\n",
      "Epoch 1977: Train Loss = 0.1516, Test Loss = 0.8955601453781128:.4f\n",
      "Epoch 1978: Train Loss = 0.1580, Test Loss = 0.8614910244941711:.4f\n",
      "Epoch 1979: Train Loss = 0.1834, Test Loss = 0.8730382919311523:.4f\n",
      "Epoch 1980: Train Loss = 0.1451, Test Loss = 0.9799375534057617:.4f\n",
      "Epoch 1981: Train Loss = 0.1646, Test Loss = 1.0393816232681274:.4f\n",
      "Epoch 1982: Train Loss = 0.1552, Test Loss = 1.0285234451293945:.4f\n",
      "Epoch 1983: Train Loss = 0.1449, Test Loss = 0.9527958035469055:.4f\n",
      "Epoch 1984: Train Loss = 0.1267, Test Loss = 0.871251106262207:.4f\n",
      "Epoch 1985: Train Loss = 0.1503, Test Loss = 0.8573147058486938:.4f\n",
      "Epoch 1986: Train Loss = 0.1445, Test Loss = 0.8854670524597168:.4f\n",
      "Epoch 1987: Train Loss = 0.1233, Test Loss = 0.9327294230461121:.4f\n",
      "Epoch 1988: Train Loss = 0.1664, Test Loss = 0.9631866216659546:.4f\n",
      "Epoch 1989: Train Loss = 0.1377, Test Loss = 0.9970548748970032:.4f\n",
      "Epoch 1990: Train Loss = 0.1605, Test Loss = 1.00253164768219:.4f\n",
      "Epoch 1991: Train Loss = 0.1475, Test Loss = 1.0357954502105713:.4f\n",
      "Epoch 1992: Train Loss = 0.1586, Test Loss = 0.9906455874443054:.4f\n",
      "Epoch 1993: Train Loss = 0.1241, Test Loss = 0.9045510292053223:.4f\n",
      "Epoch 1994: Train Loss = 0.1378, Test Loss = 0.8662160038948059:.4f\n",
      "Epoch 1995: Train Loss = 0.1379, Test Loss = 0.8667338490486145:.4f\n",
      "Epoch 1996: Train Loss = 0.1393, Test Loss = 0.8862471580505371:.4f\n",
      "Epoch 1997: Train Loss = 0.1544, Test Loss = 0.9347001910209656:.4f\n",
      "Epoch 1998: Train Loss = 0.1377, Test Loss = 1.0355037450790405:.4f\n",
      "Epoch 1999: Train Loss = 0.1462, Test Loss = 1.0298762321472168:.4f\n",
      "Epoch 2000: Train Loss = 0.1724, Test Loss = 0.979753851890564:.4f\n",
      "Epoch 2001: Train Loss = 0.1378, Test Loss = 0.9445999264717102:.4f\n",
      "Epoch 2002: Train Loss = 0.1512, Test Loss = 0.8902126550674438:.4f\n",
      "Epoch 2003: Train Loss = 0.1577, Test Loss = 0.8903385996818542:.4f\n",
      "Epoch 2004: Train Loss = 0.1586, Test Loss = 0.9515520334243774:.4f\n",
      "Epoch 2005: Train Loss = 0.1247, Test Loss = 0.9465426206588745:.4f\n",
      "Epoch 2006: Train Loss = 0.1382, Test Loss = 0.9159296751022339:.4f\n",
      "Epoch 2007: Train Loss = 0.1642, Test Loss = 0.9006085395812988:.4f\n",
      "Epoch 2008: Train Loss = 0.1285, Test Loss = 0.9096220135688782:.4f\n",
      "Epoch 2009: Train Loss = 0.1288, Test Loss = 0.946557879447937:.4f\n",
      "Epoch 2010: Train Loss = 0.1509, Test Loss = 0.9430999755859375:.4f\n",
      "Epoch 2011: Train Loss = 0.1594, Test Loss = 0.8793999552726746:.4f\n",
      "Epoch 2012: Train Loss = 0.1438, Test Loss = 0.8852243423461914:.4f\n",
      "Epoch 2013: Train Loss = 0.1274, Test Loss = 0.894019603729248:.4f\n",
      "Epoch 2014: Train Loss = 0.1414, Test Loss = 0.9266672134399414:.4f\n",
      "Epoch 2015: Train Loss = 0.1440, Test Loss = 0.9271987676620483:.4f\n",
      "Epoch 2016: Train Loss = 0.1524, Test Loss = 0.9241864085197449:.4f\n",
      "Epoch 2017: Train Loss = 0.1770, Test Loss = 0.9152902364730835:.4f\n",
      "Epoch 2018: Train Loss = 0.1517, Test Loss = 0.9324092864990234:.4f\n",
      "Epoch 2019: Train Loss = 0.1483, Test Loss = 0.939669132232666:.4f\n",
      "Epoch 2020: Train Loss = 0.1310, Test Loss = 0.9356257319450378:.4f\n",
      "Epoch 2021: Train Loss = 0.1442, Test Loss = 0.9204373359680176:.4f\n",
      "Epoch 2022: Train Loss = 0.1663, Test Loss = 0.8868644833564758:.4f\n",
      "Epoch 2023: Train Loss = 0.1686, Test Loss = 0.909812331199646:.4f\n",
      "Epoch 2024: Train Loss = 0.1537, Test Loss = 1.0180236101150513:.4f\n",
      "Epoch 2025: Train Loss = 0.1503, Test Loss = 1.0454213619232178:.4f\n",
      "Epoch 2026: Train Loss = 0.1897, Test Loss = 1.0080318450927734:.4f\n",
      "Epoch 2027: Train Loss = 0.1581, Test Loss = 0.8833467364311218:.4f\n",
      "Epoch 2028: Train Loss = 0.1513, Test Loss = 0.8622320890426636:.4f\n",
      "Epoch 2029: Train Loss = 0.1438, Test Loss = 0.8792025446891785:.4f\n",
      "Epoch 2030: Train Loss = 0.1673, Test Loss = 0.9075969457626343:.4f\n",
      "Epoch 2031: Train Loss = 0.1707, Test Loss = 0.9693480730056763:.4f\n",
      "Epoch 2032: Train Loss = 0.1390, Test Loss = 0.9990673065185547:.4f\n",
      "Epoch 2033: Train Loss = 0.1541, Test Loss = 0.9636168479919434:.4f\n",
      "Epoch 2034: Train Loss = 0.1735, Test Loss = 0.9214603304862976:.4f\n",
      "Epoch 2035: Train Loss = 0.1578, Test Loss = 0.9441283345222473:.4f\n",
      "Epoch 2036: Train Loss = 0.1462, Test Loss = 1.0124305486679077:.4f\n",
      "Epoch 2037: Train Loss = 0.1581, Test Loss = 0.9929624795913696:.4f\n",
      "Epoch 2038: Train Loss = 0.1419, Test Loss = 0.9889435768127441:.4f\n",
      "Epoch 2039: Train Loss = 0.1626, Test Loss = 0.9745332598686218:.4f\n",
      "Epoch 2040: Train Loss = 0.1322, Test Loss = 0.996623158454895:.4f\n",
      "Epoch 2041: Train Loss = 0.1504, Test Loss = 1.0002720355987549:.4f\n",
      "Epoch 2042: Train Loss = 0.1370, Test Loss = 0.987754225730896:.4f\n",
      "Epoch 2043: Train Loss = 0.1726, Test Loss = 0.9535385370254517:.4f\n",
      "Epoch 2044: Train Loss = 0.1406, Test Loss = 0.9432320594787598:.4f\n",
      "Epoch 2045: Train Loss = 0.1548, Test Loss = 0.9054082632064819:.4f\n",
      "Epoch 2046: Train Loss = 0.1374, Test Loss = 0.9203547239303589:.4f\n",
      "Epoch 2047: Train Loss = 0.1623, Test Loss = 0.9729354977607727:.4f\n",
      "Epoch 2048: Train Loss = 0.1362, Test Loss = 0.9827064275741577:.4f\n",
      "Epoch 2049: Train Loss = 0.1486, Test Loss = 0.9642635583877563:.4f\n",
      "Epoch 2050: Train Loss = 0.1382, Test Loss = 0.9165512919425964:.4f\n",
      "Epoch 2051: Train Loss = 0.1339, Test Loss = 0.8563106656074524:.4f\n",
      "Epoch 2052: Train Loss = 0.1510, Test Loss = 0.8634967803955078:.4f\n",
      "Epoch 2053: Train Loss = 0.1375, Test Loss = 0.8884274363517761:.4f\n",
      "Epoch 2054: Train Loss = 0.1451, Test Loss = 0.9561548233032227:.4f\n",
      "Epoch 2055: Train Loss = 0.1537, Test Loss = 0.9495390057563782:.4f\n",
      "Epoch 2056: Train Loss = 0.1608, Test Loss = 0.8826004266738892:.4f\n",
      "Epoch 2057: Train Loss = 0.1338, Test Loss = 0.899725079536438:.4f\n",
      "Epoch 2058: Train Loss = 0.1422, Test Loss = 0.9042569398880005:.4f\n",
      "Epoch 2059: Train Loss = 0.1551, Test Loss = 0.922595202922821:.4f\n",
      "Epoch 2060: Train Loss = 0.1300, Test Loss = 0.9281654357910156:.4f\n",
      "Epoch 2061: Train Loss = 0.1520, Test Loss = 0.9230052828788757:.4f\n",
      "Epoch 2062: Train Loss = 0.1663, Test Loss = 0.8941612243652344:.4f\n",
      "Epoch 2063: Train Loss = 0.1294, Test Loss = 0.9247816801071167:.4f\n",
      "Epoch 2064: Train Loss = 0.1616, Test Loss = 0.9489827156066895:.4f\n",
      "Epoch 2065: Train Loss = 0.1353, Test Loss = 0.9652802348136902:.4f\n",
      "Epoch 2066: Train Loss = 0.1350, Test Loss = 0.9612271189689636:.4f\n",
      "Epoch 2067: Train Loss = 0.1743, Test Loss = 0.9256102442741394:.4f\n",
      "Epoch 2068: Train Loss = 0.2069, Test Loss = 0.887847900390625:.4f\n",
      "Epoch 2069: Train Loss = 0.1332, Test Loss = 0.9450780153274536:.4f\n",
      "Epoch 2070: Train Loss = 0.1597, Test Loss = 0.9947603940963745:.4f\n",
      "Epoch 2071: Train Loss = 0.1431, Test Loss = 1.0450624227523804:.4f\n",
      "Epoch 2072: Train Loss = 0.1588, Test Loss = 1.0028648376464844:.4f\n",
      "Epoch 2073: Train Loss = 0.1522, Test Loss = 0.8892501592636108:.4f\n",
      "Epoch 2074: Train Loss = 0.1366, Test Loss = 0.8452558517456055:.4f\n",
      "Epoch 2075: Train Loss = 0.1655, Test Loss = 0.8415997624397278:.4f\n",
      "Epoch 2076: Train Loss = 0.1507, Test Loss = 0.9080244898796082:.4f\n",
      "Epoch 2077: Train Loss = 0.1459, Test Loss = 0.9843511581420898:.4f\n",
      "Epoch 2078: Train Loss = 0.1411, Test Loss = 0.9271855354309082:.4f\n",
      "Epoch 2079: Train Loss = 0.1392, Test Loss = 0.8893769979476929:.4f\n",
      "Epoch 2080: Train Loss = 0.1360, Test Loss = 0.8785750269889832:.4f\n",
      "Epoch 2081: Train Loss = 0.1288, Test Loss = 0.911546528339386:.4f\n",
      "Epoch 2082: Train Loss = 0.1473, Test Loss = 0.9360527992248535:.4f\n",
      "Epoch 2083: Train Loss = 0.1230, Test Loss = 0.9166771173477173:.4f\n",
      "Epoch 2084: Train Loss = 0.1436, Test Loss = 0.9083722829818726:.4f\n",
      "Epoch 2085: Train Loss = 0.1309, Test Loss = 0.8996175527572632:.4f\n",
      "Epoch 2086: Train Loss = 0.1939, Test Loss = 0.8981466293334961:.4f\n",
      "Epoch 2087: Train Loss = 0.1714, Test Loss = 0.9600990414619446:.4f\n",
      "Epoch 2088: Train Loss = 0.1503, Test Loss = 0.9504311680793762:.4f\n",
      "Epoch 2089: Train Loss = 0.1397, Test Loss = 0.9065847396850586:.4f\n",
      "Epoch 2090: Train Loss = 0.1486, Test Loss = 0.8933517336845398:.4f\n",
      "Epoch 2091: Train Loss = 0.1647, Test Loss = 0.929664134979248:.4f\n",
      "Epoch 2092: Train Loss = 0.1314, Test Loss = 0.8945277333259583:.4f\n",
      "Epoch 2093: Train Loss = 0.1254, Test Loss = 0.8807359933853149:.4f\n",
      "Epoch 2094: Train Loss = 0.1364, Test Loss = 0.8799962997436523:.4f\n",
      "Epoch 2095: Train Loss = 0.1584, Test Loss = 0.899756908416748:.4f\n",
      "Epoch 2096: Train Loss = 0.1635, Test Loss = 0.9600933194160461:.4f\n",
      "Epoch 2097: Train Loss = 0.1457, Test Loss = 1.0221874713897705:.4f\n",
      "Epoch 2098: Train Loss = 0.1329, Test Loss = 1.0470582246780396:.4f\n",
      "Epoch 2099: Train Loss = 0.1522, Test Loss = 1.017528772354126:.4f\n",
      "Epoch 2100: Train Loss = 0.1537, Test Loss = 0.9704875946044922:.4f\n",
      "Epoch 2101: Train Loss = 0.1315, Test Loss = 0.9274341464042664:.4f\n",
      "Epoch 2102: Train Loss = 0.1458, Test Loss = 0.8946687579154968:.4f\n",
      "Epoch 2103: Train Loss = 0.1470, Test Loss = 0.8943657875061035:.4f\n",
      "Epoch 2104: Train Loss = 0.1764, Test Loss = 0.9366347193717957:.4f\n",
      "Epoch 2105: Train Loss = 0.1351, Test Loss = 0.9819256067276001:.4f\n",
      "Epoch 2106: Train Loss = 0.1472, Test Loss = 1.0019553899765015:.4f\n",
      "Epoch 2107: Train Loss = 0.1457, Test Loss = 0.9713807106018066:.4f\n",
      "Epoch 2108: Train Loss = 0.1351, Test Loss = 0.9415308833122253:.4f\n",
      "Epoch 2109: Train Loss = 0.1857, Test Loss = 0.9117690324783325:.4f\n",
      "Epoch 2110: Train Loss = 0.1587, Test Loss = 0.9482423067092896:.4f\n",
      "Epoch 2111: Train Loss = 0.1376, Test Loss = 0.9936283230781555:.4f\n",
      "Epoch 2112: Train Loss = 0.1574, Test Loss = 0.97137850522995:.4f\n",
      "Epoch 2113: Train Loss = 0.1359, Test Loss = 0.9767268300056458:.4f\n",
      "Epoch 2114: Train Loss = 0.1365, Test Loss = 0.9834537506103516:.4f\n",
      "Epoch 2115: Train Loss = 0.1870, Test Loss = 0.9617646336555481:.4f\n",
      "Epoch 2116: Train Loss = 0.1564, Test Loss = 0.9941619634628296:.4f\n",
      "Epoch 2117: Train Loss = 0.1420, Test Loss = 1.070026159286499:.4f\n",
      "Epoch 2118: Train Loss = 0.1680, Test Loss = 1.0307369232177734:.4f\n",
      "Epoch 2119: Train Loss = 0.1654, Test Loss = 0.9298410415649414:.4f\n",
      "Epoch 2120: Train Loss = 0.1269, Test Loss = 0.9011034965515137:.4f\n",
      "Epoch 2121: Train Loss = 0.1652, Test Loss = 0.9009048342704773:.4f\n",
      "Epoch 2122: Train Loss = 0.1581, Test Loss = 0.9518352746963501:.4f\n",
      "Epoch 2123: Train Loss = 0.1438, Test Loss = 1.0352120399475098:.4f\n",
      "Epoch 2124: Train Loss = 0.1597, Test Loss = 1.0226333141326904:.4f\n",
      "Epoch 2125: Train Loss = 0.1285, Test Loss = 0.9227772951126099:.4f\n",
      "Epoch 2126: Train Loss = 0.1364, Test Loss = 0.8875147104263306:.4f\n",
      "Epoch 2127: Train Loss = 0.1466, Test Loss = 0.9024645686149597:.4f\n",
      "Epoch 2128: Train Loss = 0.1330, Test Loss = 0.9439765810966492:.4f\n",
      "Epoch 2129: Train Loss = 0.1348, Test Loss = 0.9384713172912598:.4f\n",
      "Epoch 2130: Train Loss = 0.1600, Test Loss = 0.9387966990470886:.4f\n",
      "Epoch 2131: Train Loss = 0.1469, Test Loss = 0.9078127145767212:.4f\n",
      "Epoch 2132: Train Loss = 0.1258, Test Loss = 0.9182699918746948:.4f\n",
      "Epoch 2133: Train Loss = 0.1332, Test Loss = 0.9509543180465698:.4f\n",
      "Epoch 2134: Train Loss = 0.1326, Test Loss = 0.9802901148796082:.4f\n",
      "Epoch 2135: Train Loss = 0.1581, Test Loss = 0.9508206248283386:.4f\n",
      "Epoch 2136: Train Loss = 0.1573, Test Loss = 0.9279389381408691:.4f\n",
      "Epoch 2137: Train Loss = 0.1390, Test Loss = 0.9210644960403442:.4f\n",
      "Epoch 2138: Train Loss = 0.1356, Test Loss = 0.9088066816329956:.4f\n",
      "Epoch 2139: Train Loss = 0.2115, Test Loss = 0.9219668507575989:.4f\n",
      "Epoch 2140: Train Loss = 0.1496, Test Loss = 1.0052192211151123:.4f\n",
      "Epoch 2141: Train Loss = 0.1864, Test Loss = 1.010962724685669:.4f\n",
      "Epoch 2142: Train Loss = 0.1835, Test Loss = 0.9346340298652649:.4f\n",
      "Epoch 2143: Train Loss = 0.1397, Test Loss = 0.9259065389633179:.4f\n",
      "Epoch 2144: Train Loss = 0.1319, Test Loss = 0.9251263737678528:.4f\n",
      "Epoch 2145: Train Loss = 0.1342, Test Loss = 0.9414078593254089:.4f\n",
      "Epoch 2146: Train Loss = 0.1421, Test Loss = 0.9658864140510559:.4f\n",
      "Epoch 2147: Train Loss = 0.1438, Test Loss = 0.9524577856063843:.4f\n",
      "Epoch 2148: Train Loss = 0.1285, Test Loss = 0.9827097654342651:.4f\n",
      "Epoch 2149: Train Loss = 0.1217, Test Loss = 0.9891325235366821:.4f\n",
      "Epoch 2150: Train Loss = 0.1560, Test Loss = 0.9728749990463257:.4f\n",
      "Epoch 2151: Train Loss = 0.1943, Test Loss = 0.9742031097412109:.4f\n",
      "Epoch 2152: Train Loss = 0.1598, Test Loss = 1.0330930948257446:.4f\n",
      "Epoch 2153: Train Loss = 0.1333, Test Loss = 0.9803470373153687:.4f\n",
      "Epoch 2154: Train Loss = 0.1600, Test Loss = 0.9296997785568237:.4f\n",
      "Epoch 2155: Train Loss = 0.1741, Test Loss = 0.9380872845649719:.4f\n",
      "Epoch 2156: Train Loss = 0.1255, Test Loss = 0.9430392384529114:.4f\n",
      "Epoch 2157: Train Loss = 0.1611, Test Loss = 0.9462987780570984:.4f\n",
      "Epoch 2158: Train Loss = 0.1666, Test Loss = 0.9249142408370972:.4f\n",
      "Epoch 2159: Train Loss = 0.1416, Test Loss = 0.9397792816162109:.4f\n",
      "Epoch 2160: Train Loss = 0.1355, Test Loss = 0.9195300340652466:.4f\n",
      "Epoch 2161: Train Loss = 0.1533, Test Loss = 0.9056220054626465:.4f\n",
      "Epoch 2162: Train Loss = 0.1480, Test Loss = 0.9730603098869324:.4f\n",
      "Epoch 2163: Train Loss = 0.1562, Test Loss = 0.9605008363723755:.4f\n",
      "Epoch 2164: Train Loss = 0.1363, Test Loss = 0.940921425819397:.4f\n",
      "Epoch 2165: Train Loss = 0.1277, Test Loss = 0.9271613359451294:.4f\n",
      "Epoch 2166: Train Loss = 0.1598, Test Loss = 0.8916983604431152:.4f\n",
      "Epoch 2167: Train Loss = 0.1391, Test Loss = 0.9049661755561829:.4f\n",
      "Epoch 2168: Train Loss = 0.1599, Test Loss = 0.9312127828598022:.4f\n",
      "Epoch 2169: Train Loss = 0.1569, Test Loss = 0.9726905822753906:.4f\n",
      "Epoch 2170: Train Loss = 0.1535, Test Loss = 0.9544089436531067:.4f\n",
      "Epoch 2171: Train Loss = 0.1517, Test Loss = 0.9536014795303345:.4f\n",
      "Epoch 2172: Train Loss = 0.1267, Test Loss = 0.8812587857246399:.4f\n",
      "Epoch 2173: Train Loss = 0.1272, Test Loss = 0.8803450465202332:.4f\n",
      "Epoch 2174: Train Loss = 0.1458, Test Loss = 0.881119430065155:.4f\n",
      "Epoch 2175: Train Loss = 0.1525, Test Loss = 0.9017230868339539:.4f\n",
      "Epoch 2176: Train Loss = 0.1507, Test Loss = 0.9331100583076477:.4f\n",
      "Epoch 2177: Train Loss = 0.1597, Test Loss = 0.9813291430473328:.4f\n",
      "Epoch 2178: Train Loss = 0.1670, Test Loss = 1.0039297342300415:.4f\n",
      "Epoch 2179: Train Loss = 0.1886, Test Loss = 0.9997167587280273:.4f\n",
      "Epoch 2180: Train Loss = 0.1625, Test Loss = 0.9635151028633118:.4f\n",
      "Epoch 2181: Train Loss = 0.1426, Test Loss = 0.9527281522750854:.4f\n",
      "Epoch 2182: Train Loss = 0.1421, Test Loss = 0.9510228037834167:.4f\n",
      "Epoch 2183: Train Loss = 0.1693, Test Loss = 0.9276283979415894:.4f\n",
      "Epoch 2184: Train Loss = 0.1321, Test Loss = 0.9602680206298828:.4f\n",
      "Epoch 2185: Train Loss = 0.1260, Test Loss = 0.9663273692131042:.4f\n",
      "Epoch 2186: Train Loss = 0.1518, Test Loss = 0.975020706653595:.4f\n",
      "Epoch 2187: Train Loss = 0.1501, Test Loss = 1.002060890197754:.4f\n",
      "Epoch 2188: Train Loss = 0.1423, Test Loss = 0.9352083206176758:.4f\n",
      "Epoch 2189: Train Loss = 0.1208, Test Loss = 0.9072457551956177:.4f\n",
      "Epoch 2190: Train Loss = 0.1351, Test Loss = 0.9260722398757935:.4f\n",
      "Epoch 2191: Train Loss = 0.1592, Test Loss = 0.946392834186554:.4f\n",
      "Epoch 2192: Train Loss = 0.1537, Test Loss = 0.9695895910263062:.4f\n",
      "Epoch 2193: Train Loss = 0.1328, Test Loss = 0.9404932260513306:.4f\n",
      "Epoch 2194: Train Loss = 0.1280, Test Loss = 0.9109794497489929:.4f\n",
      "Epoch 2195: Train Loss = 0.1250, Test Loss = 0.872572124004364:.4f\n",
      "Epoch 2196: Train Loss = 0.1705, Test Loss = 0.884962260723114:.4f\n",
      "Epoch 2197: Train Loss = 0.1429, Test Loss = 0.9648426175117493:.4f\n",
      "Epoch 2198: Train Loss = 0.1751, Test Loss = 1.0031263828277588:.4f\n",
      "Epoch 2199: Train Loss = 0.1265, Test Loss = 0.9478724598884583:.4f\n",
      "Epoch 2200: Train Loss = 0.1267, Test Loss = 0.8975096940994263:.4f\n",
      "Epoch 2201: Train Loss = 0.1250, Test Loss = 0.8903388977050781:.4f\n",
      "Epoch 2202: Train Loss = 0.1315, Test Loss = 0.9105043411254883:.4f\n",
      "Epoch 2203: Train Loss = 0.1424, Test Loss = 0.9273792505264282:.4f\n",
      "Epoch 2204: Train Loss = 0.1418, Test Loss = 0.9736862182617188:.4f\n",
      "Epoch 2205: Train Loss = 0.1443, Test Loss = 0.9916491508483887:.4f\n",
      "Epoch 2206: Train Loss = 0.1287, Test Loss = 0.9398563504219055:.4f\n",
      "Epoch 2207: Train Loss = 0.1443, Test Loss = 0.9007837176322937:.4f\n",
      "Epoch 2208: Train Loss = 0.1600, Test Loss = 0.8775906562805176:.4f\n",
      "Epoch 2209: Train Loss = 0.1460, Test Loss = 0.9661180377006531:.4f\n",
      "Epoch 2210: Train Loss = 0.1380, Test Loss = 0.9772914052009583:.4f\n",
      "Epoch 2211: Train Loss = 0.1234, Test Loss = 0.9782499074935913:.4f\n",
      "Epoch 2212: Train Loss = 0.1442, Test Loss = 0.9597301483154297:.4f\n",
      "Epoch 2213: Train Loss = 0.1538, Test Loss = 0.9415094256401062:.4f\n",
      "Epoch 2214: Train Loss = 0.1248, Test Loss = 0.9892745018005371:.4f\n",
      "Epoch 2215: Train Loss = 0.1424, Test Loss = 0.9905986785888672:.4f\n",
      "Epoch 2216: Train Loss = 0.1424, Test Loss = 0.9663428068161011:.4f\n",
      "Epoch 2217: Train Loss = 0.1668, Test Loss = 0.9820327758789062:.4f\n",
      "Epoch 2218: Train Loss = 0.1364, Test Loss = 0.9811520576477051:.4f\n",
      "Epoch 2219: Train Loss = 0.1347, Test Loss = 0.9852155447006226:.4f\n",
      "Epoch 2220: Train Loss = 0.1270, Test Loss = 0.9677681922912598:.4f\n",
      "Epoch 2221: Train Loss = 0.1403, Test Loss = 0.9388179779052734:.4f\n",
      "Epoch 2222: Train Loss = 0.1527, Test Loss = 0.9029017686843872:.4f\n",
      "Epoch 2223: Train Loss = 0.1412, Test Loss = 0.896153450012207:.4f\n",
      "Epoch 2224: Train Loss = 0.1243, Test Loss = 0.8988197445869446:.4f\n",
      "Epoch 2225: Train Loss = 0.1564, Test Loss = 0.9192188382148743:.4f\n",
      "Epoch 2226: Train Loss = 0.1550, Test Loss = 1.006184458732605:.4f\n",
      "Epoch 2227: Train Loss = 0.1692, Test Loss = 1.119356393814087:.4f\n",
      "Epoch 2228: Train Loss = 0.1520, Test Loss = 1.0062474012374878:.4f\n",
      "Epoch 2229: Train Loss = 0.1345, Test Loss = 0.9189561009407043:.4f\n",
      "Epoch 2230: Train Loss = 0.1352, Test Loss = 0.8630902171134949:.4f\n",
      "Epoch 2231: Train Loss = 0.1708, Test Loss = 0.8805488348007202:.4f\n",
      "Epoch 2232: Train Loss = 0.1744, Test Loss = 0.9894332885742188:.4f\n",
      "Epoch 2233: Train Loss = 0.1608, Test Loss = 1.0159162282943726:.4f\n",
      "Epoch 2234: Train Loss = 0.1454, Test Loss = 0.9862340092658997:.4f\n",
      "Epoch 2235: Train Loss = 0.1544, Test Loss = 0.9924678802490234:.4f\n",
      "Epoch 2236: Train Loss = 0.1468, Test Loss = 0.9784978628158569:.4f\n",
      "Epoch 2237: Train Loss = 0.1495, Test Loss = 0.9482966661453247:.4f\n",
      "Epoch 2238: Train Loss = 0.1265, Test Loss = 0.9562461972236633:.4f\n",
      "Epoch 2239: Train Loss = 0.1254, Test Loss = 0.977694034576416:.4f\n",
      "Epoch 2240: Train Loss = 0.1558, Test Loss = 0.9813749194145203:.4f\n",
      "Epoch 2241: Train Loss = 0.1199, Test Loss = 0.9750496745109558:.4f\n",
      "Epoch 2242: Train Loss = 0.1556, Test Loss = 0.9591072797775269:.4f\n",
      "Epoch 2243: Train Loss = 0.1417, Test Loss = 0.9448506236076355:.4f\n",
      "Epoch 2244: Train Loss = 0.1360, Test Loss = 0.9574832916259766:.4f\n",
      "Epoch 2245: Train Loss = 0.1860, Test Loss = 0.9593673944473267:.4f\n",
      "Epoch 2246: Train Loss = 0.1429, Test Loss = 1.0101011991500854:.4f\n",
      "Epoch 2247: Train Loss = 0.1723, Test Loss = 0.988201916217804:.4f\n",
      "Epoch 2248: Train Loss = 0.1693, Test Loss = 0.9408267140388489:.4f\n",
      "Epoch 2249: Train Loss = 0.1428, Test Loss = 0.928813636302948:.4f\n",
      "Epoch 2250: Train Loss = 0.1271, Test Loss = 0.9088498950004578:.4f\n",
      "Epoch 2251: Train Loss = 0.1661, Test Loss = 0.8975030183792114:.4f\n",
      "Epoch 2252: Train Loss = 0.1361, Test Loss = 0.9346747398376465:.4f\n",
      "Epoch 2253: Train Loss = 0.1773, Test Loss = 0.9240866899490356:.4f\n",
      "Epoch 2254: Train Loss = 0.1548, Test Loss = 1.0135730504989624:.4f\n",
      "Epoch 2255: Train Loss = 0.1573, Test Loss = 1.0822824239730835:.4f\n",
      "Epoch 2256: Train Loss = 0.1619, Test Loss = 0.9753023386001587:.4f\n",
      "Epoch 2257: Train Loss = 0.1350, Test Loss = 0.934221088886261:.4f\n",
      "Epoch 2258: Train Loss = 0.1836, Test Loss = 0.9073531031608582:.4f\n",
      "Epoch 2259: Train Loss = 0.1259, Test Loss = 0.9903050661087036:.4f\n",
      "Epoch 2260: Train Loss = 0.1596, Test Loss = 1.0238431692123413:.4f\n",
      "Epoch 2261: Train Loss = 0.1252, Test Loss = 0.9539583921432495:.4f\n",
      "Epoch 2262: Train Loss = 0.1246, Test Loss = 0.9326953887939453:.4f\n",
      "Epoch 2263: Train Loss = 0.1889, Test Loss = 0.9487350583076477:.4f\n",
      "Epoch 2264: Train Loss = 0.1428, Test Loss = 1.0233267545700073:.4f\n",
      "Epoch 2265: Train Loss = 0.1377, Test Loss = 1.000299096107483:.4f\n",
      "Epoch 2266: Train Loss = 0.1377, Test Loss = 0.9497454762458801:.4f\n",
      "Epoch 2267: Train Loss = 0.1438, Test Loss = 0.9158296585083008:.4f\n",
      "Epoch 2268: Train Loss = 0.1432, Test Loss = 0.9126725196838379:.4f\n",
      "Epoch 2269: Train Loss = 0.1286, Test Loss = 0.9647557139396667:.4f\n",
      "Epoch 2270: Train Loss = 0.1402, Test Loss = 0.9966105222702026:.4f\n",
      "Epoch 2271: Train Loss = 0.1436, Test Loss = 0.9658647775650024:.4f\n",
      "Epoch 2272: Train Loss = 0.1205, Test Loss = 0.9135779142379761:.4f\n",
      "Epoch 2273: Train Loss = 0.1618, Test Loss = 0.8850972056388855:.4f\n",
      "Epoch 2274: Train Loss = 0.1457, Test Loss = 0.9473417401313782:.4f\n",
      "Epoch 2275: Train Loss = 0.1791, Test Loss = 1.035366177558899:.4f\n",
      "Epoch 2276: Train Loss = 0.1566, Test Loss = 0.9926465153694153:.4f\n",
      "Epoch 2277: Train Loss = 0.1740, Test Loss = 0.9614513516426086:.4f\n",
      "Epoch 2278: Train Loss = 0.1600, Test Loss = 0.9918618202209473:.4f\n",
      "Epoch 2279: Train Loss = 0.1280, Test Loss = 0.9667908549308777:.4f\n",
      "Epoch 2280: Train Loss = 0.1524, Test Loss = 0.959044337272644:.4f\n",
      "Epoch 2281: Train Loss = 0.1420, Test Loss = 0.9716280698776245:.4f\n",
      "Epoch 2282: Train Loss = 0.1482, Test Loss = 0.9472821354866028:.4f\n",
      "Epoch 2283: Train Loss = 0.1349, Test Loss = 1.0016257762908936:.4f\n",
      "Epoch 2284: Train Loss = 0.1627, Test Loss = 0.9887882471084595:.4f\n",
      "Epoch 2285: Train Loss = 0.1220, Test Loss = 1.0380569696426392:.4f\n",
      "Epoch 2286: Train Loss = 0.1375, Test Loss = 1.0218263864517212:.4f\n",
      "Epoch 2287: Train Loss = 0.1299, Test Loss = 0.9482724070549011:.4f\n",
      "Epoch 2288: Train Loss = 0.1562, Test Loss = 0.9005328416824341:.4f\n",
      "Epoch 2289: Train Loss = 0.1354, Test Loss = 0.8931038975715637:.4f\n",
      "Epoch 2290: Train Loss = 0.1339, Test Loss = 0.8813340067863464:.4f\n",
      "Epoch 2291: Train Loss = 0.1362, Test Loss = 0.8924986124038696:.4f\n",
      "Epoch 2292: Train Loss = 0.1354, Test Loss = 0.9458737373352051:.4f\n",
      "Epoch 2293: Train Loss = 0.1703, Test Loss = 1.002302885055542:.4f\n",
      "Epoch 2294: Train Loss = 0.1400, Test Loss = 1.090142011642456:.4f\n",
      "Epoch 2295: Train Loss = 0.1297, Test Loss = 1.00959312915802:.4f\n",
      "Epoch 2296: Train Loss = 0.1748, Test Loss = 0.9493193626403809:.4f\n",
      "Epoch 2297: Train Loss = 0.1673, Test Loss = 0.9192918539047241:.4f\n",
      "Epoch 2298: Train Loss = 0.1245, Test Loss = 0.9428189396858215:.4f\n",
      "Epoch 2299: Train Loss = 0.1306, Test Loss = 0.9728435277938843:.4f\n",
      "Epoch 2300: Train Loss = 0.1512, Test Loss = 0.9457670450210571:.4f\n",
      "Epoch 2301: Train Loss = 0.1470, Test Loss = 0.9182863235473633:.4f\n",
      "Epoch 2302: Train Loss = 0.1331, Test Loss = 0.9270137548446655:.4f\n",
      "Epoch 2303: Train Loss = 0.1325, Test Loss = 0.930610179901123:.4f\n",
      "Epoch 2304: Train Loss = 0.1268, Test Loss = 0.9431912302970886:.4f\n",
      "Epoch 2305: Train Loss = 0.1406, Test Loss = 0.9597800970077515:.4f\n",
      "Epoch 2306: Train Loss = 0.1411, Test Loss = 0.9590650796890259:.4f\n",
      "Epoch 2307: Train Loss = 0.1334, Test Loss = 0.9153232574462891:.4f\n",
      "Epoch 2308: Train Loss = 0.1838, Test Loss = 0.8924599885940552:.4f\n",
      "Epoch 2309: Train Loss = 0.1496, Test Loss = 0.9431977272033691:.4f\n",
      "Epoch 2310: Train Loss = 0.1491, Test Loss = 0.9981998205184937:.4f\n",
      "Epoch 2311: Train Loss = 0.1709, Test Loss = 1.042076587677002:.4f\n",
      "Epoch 2312: Train Loss = 0.1471, Test Loss = 1.0416055917739868:.4f\n",
      "Epoch 2313: Train Loss = 0.1477, Test Loss = 0.9888253211975098:.4f\n",
      "Epoch 2314: Train Loss = 0.1622, Test Loss = 0.9530415534973145:.4f\n",
      "Epoch 2315: Train Loss = 0.1361, Test Loss = 0.9672678709030151:.4f\n",
      "Epoch 2316: Train Loss = 0.1429, Test Loss = 0.9699572324752808:.4f\n",
      "Epoch 2317: Train Loss = 0.1291, Test Loss = 0.9313710331916809:.4f\n",
      "Epoch 2318: Train Loss = 0.1517, Test Loss = 0.8764902353286743:.4f\n",
      "Epoch 2319: Train Loss = 0.1556, Test Loss = 0.8656249046325684:.4f\n",
      "Epoch 2320: Train Loss = 0.1568, Test Loss = 0.8893575668334961:.4f\n",
      "Epoch 2321: Train Loss = 0.1573, Test Loss = 0.9315584301948547:.4f\n",
      "Epoch 2322: Train Loss = 0.1555, Test Loss = 0.9573776125907898:.4f\n",
      "Epoch 2323: Train Loss = 0.1470, Test Loss = 0.9762513041496277:.4f\n",
      "Epoch 2324: Train Loss = 0.1357, Test Loss = 0.9471006393432617:.4f\n",
      "Epoch 2325: Train Loss = 0.1774, Test Loss = 0.9374796152114868:.4f\n",
      "Epoch 2326: Train Loss = 0.1686, Test Loss = 0.9324346780776978:.4f\n",
      "Epoch 2327: Train Loss = 0.1451, Test Loss = 1.0390478372573853:.4f\n",
      "Epoch 2328: Train Loss = 0.1497, Test Loss = 1.0137207508087158:.4f\n",
      "Epoch 2329: Train Loss = 0.1282, Test Loss = 0.9723120927810669:.4f\n",
      "Epoch 2330: Train Loss = 0.1275, Test Loss = 0.9023043513298035:.4f\n",
      "Epoch 2331: Train Loss = 0.1339, Test Loss = 0.8994191288948059:.4f\n",
      "Epoch 2332: Train Loss = 0.1461, Test Loss = 0.9239180684089661:.4f\n",
      "Epoch 2333: Train Loss = 0.1568, Test Loss = 0.9334836006164551:.4f\n",
      "Epoch 2334: Train Loss = 0.1676, Test Loss = 0.9926691055297852:.4f\n",
      "Epoch 2335: Train Loss = 0.1447, Test Loss = 1.0008656978607178:.4f\n",
      "Epoch 2336: Train Loss = 0.1340, Test Loss = 0.9658066630363464:.4f\n",
      "Epoch 2337: Train Loss = 0.1295, Test Loss = 0.953914999961853:.4f\n",
      "Epoch 2338: Train Loss = 0.1534, Test Loss = 0.930371880531311:.4f\n",
      "Epoch 2339: Train Loss = 0.1337, Test Loss = 0.9650554656982422:.4f\n",
      "Epoch 2340: Train Loss = 0.1393, Test Loss = 0.9562288522720337:.4f\n",
      "Epoch 2341: Train Loss = 0.1410, Test Loss = 0.9253325462341309:.4f\n",
      "Epoch 2342: Train Loss = 0.1648, Test Loss = 0.9057315587997437:.4f\n",
      "Epoch 2343: Train Loss = 0.1280, Test Loss = 0.9545172452926636:.4f\n",
      "Epoch 2344: Train Loss = 0.1262, Test Loss = 0.9409686923027039:.4f\n",
      "Epoch 2345: Train Loss = 0.1257, Test Loss = 0.9420453310012817:.4f\n",
      "Epoch 2346: Train Loss = 0.1576, Test Loss = 0.9663578271865845:.4f\n",
      "Epoch 2347: Train Loss = 0.1285, Test Loss = 0.981207013130188:.4f\n",
      "Epoch 2348: Train Loss = 0.1689, Test Loss = 0.9787967801094055:.4f\n",
      "Epoch 2349: Train Loss = 0.1473, Test Loss = 0.905653178691864:.4f\n",
      "Epoch 2350: Train Loss = 0.1635, Test Loss = 0.8426262140274048:.4f\n",
      "Epoch 2351: Train Loss = 0.1285, Test Loss = 0.860160231590271:.4f\n",
      "Epoch 2352: Train Loss = 0.1850, Test Loss = 0.9158695340156555:.4f\n",
      "Epoch 2353: Train Loss = 0.1468, Test Loss = 1.037456750869751:.4f\n",
      "Epoch 2354: Train Loss = 0.1328, Test Loss = 1.0534731149673462:.4f\n",
      "Epoch 2355: Train Loss = 0.1322, Test Loss = 0.9787386655807495:.4f\n",
      "Epoch 2356: Train Loss = 0.1314, Test Loss = 0.9192317724227905:.4f\n",
      "Epoch 2357: Train Loss = 0.1274, Test Loss = 0.8861052393913269:.4f\n",
      "Epoch 2358: Train Loss = 0.1602, Test Loss = 0.9108737111091614:.4f\n",
      "Epoch 2359: Train Loss = 0.1312, Test Loss = 0.9839247465133667:.4f\n",
      "Epoch 2360: Train Loss = 0.1785, Test Loss = 1.0181677341461182:.4f\n",
      "Epoch 2361: Train Loss = 0.1392, Test Loss = 1.073946237564087:.4f\n",
      "Epoch 2362: Train Loss = 0.1515, Test Loss = 1.0224478244781494:.4f\n",
      "Epoch 2363: Train Loss = 0.1475, Test Loss = 0.8914089202880859:.4f\n",
      "Epoch 2364: Train Loss = 0.1221, Test Loss = 0.848345160484314:.4f\n",
      "Epoch 2365: Train Loss = 0.1541, Test Loss = 0.8606758117675781:.4f\n",
      "Epoch 2366: Train Loss = 0.1241, Test Loss = 0.9312105178833008:.4f\n",
      "Epoch 2367: Train Loss = 0.1531, Test Loss = 0.9941476583480835:.4f\n",
      "Epoch 2368: Train Loss = 0.1775, Test Loss = 1.0809054374694824:.4f\n",
      "Epoch 2369: Train Loss = 0.1306, Test Loss = 0.9751690030097961:.4f\n",
      "Epoch 2370: Train Loss = 0.1524, Test Loss = 0.9021943807601929:.4f\n",
      "Epoch 2371: Train Loss = 0.1604, Test Loss = 0.9377638101577759:.4f\n",
      "Epoch 2372: Train Loss = 0.1253, Test Loss = 0.9896780252456665:.4f\n",
      "Epoch 2373: Train Loss = 0.1531, Test Loss = 1.0183191299438477:.4f\n",
      "Epoch 2374: Train Loss = 0.1447, Test Loss = 1.0096747875213623:.4f\n",
      "Epoch 2375: Train Loss = 0.1507, Test Loss = 0.9932893514633179:.4f\n",
      "Epoch 2376: Train Loss = 0.1186, Test Loss = 0.9826567769050598:.4f\n",
      "Epoch 2377: Train Loss = 0.1448, Test Loss = 0.9699953198432922:.4f\n",
      "Epoch 2378: Train Loss = 0.1381, Test Loss = 0.9076536297798157:.4f\n",
      "Epoch 2379: Train Loss = 0.1861, Test Loss = 0.8792034983634949:.4f\n",
      "Epoch 2380: Train Loss = 0.1474, Test Loss = 0.9223923683166504:.4f\n",
      "Epoch 2381: Train Loss = 0.1311, Test Loss = 0.9160442352294922:.4f\n",
      "Epoch 2382: Train Loss = 0.1560, Test Loss = 0.8881502151489258:.4f\n",
      "Epoch 2383: Train Loss = 0.1520, Test Loss = 0.9549543261528015:.4f\n",
      "Epoch 2384: Train Loss = 0.1516, Test Loss = 1.0406829118728638:.4f\n",
      "Epoch 2385: Train Loss = 0.1332, Test Loss = 0.9645035862922668:.4f\n",
      "Epoch 2386: Train Loss = 0.1330, Test Loss = 0.8714434504508972:.4f\n",
      "Epoch 2387: Train Loss = 0.1351, Test Loss = 0.8461532592773438:.4f\n",
      "Epoch 2388: Train Loss = 0.1540, Test Loss = 0.8918393850326538:.4f\n",
      "Epoch 2389: Train Loss = 0.1821, Test Loss = 0.9532579183578491:.4f\n",
      "Epoch 2390: Train Loss = 0.1565, Test Loss = 1.0438778400421143:.4f\n",
      "Epoch 2391: Train Loss = 0.1555, Test Loss = 0.9888023138046265:.4f\n",
      "Epoch 2392: Train Loss = 0.1433, Test Loss = 0.9933837056159973:.4f\n",
      "Epoch 2393: Train Loss = 0.1293, Test Loss = 0.9607957005500793:.4f\n",
      "Epoch 2394: Train Loss = 0.1515, Test Loss = 0.9521070718765259:.4f\n",
      "Epoch 2395: Train Loss = 0.1292, Test Loss = 0.9980363845825195:.4f\n",
      "Epoch 2396: Train Loss = 0.1691, Test Loss = 1.0036711692810059:.4f\n",
      "Epoch 2397: Train Loss = 0.1198, Test Loss = 1.010178804397583:.4f\n",
      "Epoch 2398: Train Loss = 0.1492, Test Loss = 0.9833038449287415:.4f\n",
      "Epoch 2399: Train Loss = 0.1261, Test Loss = 0.9579178094863892:.4f\n",
      "Epoch 2400: Train Loss = 0.1315, Test Loss = 0.958808422088623:.4f\n",
      "Epoch 2401: Train Loss = 0.1313, Test Loss = 0.9480795860290527:.4f\n",
      "Epoch 2402: Train Loss = 0.1560, Test Loss = 0.9536529779434204:.4f\n",
      "Epoch 2403: Train Loss = 0.1363, Test Loss = 1.010402798652649:.4f\n",
      "Epoch 2404: Train Loss = 0.1230, Test Loss = 1.0429753065109253:.4f\n",
      "Epoch 2405: Train Loss = 0.1349, Test Loss = 1.0369645357131958:.4f\n",
      "Epoch 2406: Train Loss = 0.1392, Test Loss = 0.9855324625968933:.4f\n",
      "Epoch 2407: Train Loss = 0.1334, Test Loss = 0.9600922465324402:.4f\n",
      "Epoch 2408: Train Loss = 0.1619, Test Loss = 0.9409173727035522:.4f\n",
      "Epoch 2409: Train Loss = 0.1265, Test Loss = 0.8917073011398315:.4f\n",
      "Epoch 2410: Train Loss = 0.1350, Test Loss = 0.8932905197143555:.4f\n",
      "Epoch 2411: Train Loss = 0.1504, Test Loss = 0.9099242091178894:.4f\n",
      "Epoch 2412: Train Loss = 0.1553, Test Loss = 0.9055067300796509:.4f\n",
      "Epoch 2413: Train Loss = 0.1603, Test Loss = 0.966958224773407:.4f\n",
      "Epoch 2414: Train Loss = 0.1329, Test Loss = 0.9828799366950989:.4f\n",
      "Epoch 2415: Train Loss = 0.1544, Test Loss = 0.9565516710281372:.4f\n",
      "Epoch 2416: Train Loss = 0.1448, Test Loss = 0.9838836789131165:.4f\n",
      "Epoch 2417: Train Loss = 0.1440, Test Loss = 0.9794459342956543:.4f\n",
      "Epoch 2418: Train Loss = 0.1282, Test Loss = 0.9862011671066284:.4f\n",
      "Epoch 2419: Train Loss = 0.1779, Test Loss = 0.9637472033500671:.4f\n",
      "Epoch 2420: Train Loss = 0.1475, Test Loss = 0.9954409599304199:.4f\n",
      "Epoch 2421: Train Loss = 0.1569, Test Loss = 0.9537849426269531:.4f\n",
      "Epoch 2422: Train Loss = 0.1346, Test Loss = 0.9399548768997192:.4f\n",
      "Epoch 2423: Train Loss = 0.1197, Test Loss = 0.9121243357658386:.4f\n",
      "Epoch 2424: Train Loss = 0.1306, Test Loss = 0.9283862113952637:.4f\n",
      "Epoch 2425: Train Loss = 0.1181, Test Loss = 0.9336118698120117:.4f\n",
      "Epoch 2426: Train Loss = 0.1383, Test Loss = 0.9510213136672974:.4f\n",
      "Epoch 2427: Train Loss = 0.1223, Test Loss = 0.9508654475212097:.4f\n",
      "Epoch 2428: Train Loss = 0.1692, Test Loss = 0.9588949084281921:.4f\n",
      "Epoch 2429: Train Loss = 0.1258, Test Loss = 0.891710102558136:.4f\n",
      "Epoch 2430: Train Loss = 0.1336, Test Loss = 0.8710776567459106:.4f\n",
      "Epoch 2431: Train Loss = 0.1277, Test Loss = 0.9092626571655273:.4f\n",
      "Epoch 2432: Train Loss = 0.1360, Test Loss = 0.958582878112793:.4f\n",
      "Epoch 2433: Train Loss = 0.1618, Test Loss = 0.955401599407196:.4f\n",
      "Epoch 2434: Train Loss = 0.1535, Test Loss = 0.9348421096801758:.4f\n",
      "Epoch 2435: Train Loss = 0.2012, Test Loss = 0.9098383188247681:.4f\n",
      "Epoch 2436: Train Loss = 0.1482, Test Loss = 1.00253164768219:.4f\n",
      "Epoch 2437: Train Loss = 0.1415, Test Loss = 1.0560719966888428:.4f\n",
      "Epoch 2438: Train Loss = 0.1309, Test Loss = 1.001692533493042:.4f\n",
      "Epoch 2439: Train Loss = 0.1336, Test Loss = 0.9292652010917664:.4f\n",
      "Epoch 2440: Train Loss = 0.1377, Test Loss = 0.9025680422782898:.4f\n",
      "Epoch 2441: Train Loss = 0.1386, Test Loss = 0.9338202476501465:.4f\n",
      "Epoch 2442: Train Loss = 0.1544, Test Loss = 0.9505959749221802:.4f\n",
      "Epoch 2443: Train Loss = 0.1655, Test Loss = 0.9788259267807007:.4f\n",
      "Epoch 2444: Train Loss = 0.1722, Test Loss = 1.0307121276855469:.4f\n",
      "Epoch 2445: Train Loss = 0.1416, Test Loss = 1.1112946271896362:.4f\n",
      "Epoch 2446: Train Loss = 0.1489, Test Loss = 1.0909247398376465:.4f\n",
      "Epoch 2447: Train Loss = 0.1526, Test Loss = 1.0335575342178345:.4f\n",
      "Epoch 2448: Train Loss = 0.1529, Test Loss = 0.8970638513565063:.4f\n",
      "Epoch 2449: Train Loss = 0.1493, Test Loss = 0.8573310971260071:.4f\n",
      "Epoch 2450: Train Loss = 0.1592, Test Loss = 0.910721480846405:.4f\n",
      "Epoch 2451: Train Loss = 0.1558, Test Loss = 1.018078327178955:.4f\n",
      "Epoch 2452: Train Loss = 0.1634, Test Loss = 1.026313066482544:.4f\n",
      "Epoch 2453: Train Loss = 0.1421, Test Loss = 0.9594414830207825:.4f\n",
      "Epoch 2454: Train Loss = 0.1810, Test Loss = 0.9756528735160828:.4f\n",
      "Epoch 2455: Train Loss = 0.1404, Test Loss = 1.0439636707305908:.4f\n",
      "Epoch 2456: Train Loss = 0.1325, Test Loss = 1.0745213031768799:.4f\n",
      "Epoch 2457: Train Loss = 0.1426, Test Loss = 1.081091046333313:.4f\n",
      "Epoch 2458: Train Loss = 0.1475, Test Loss = 1.030376672744751:.4f\n",
      "Epoch 2459: Train Loss = 0.1433, Test Loss = 1.006894826889038:.4f\n",
      "Epoch 2460: Train Loss = 0.1325, Test Loss = 0.9895599484443665:.4f\n",
      "Epoch 2461: Train Loss = 0.1251, Test Loss = 0.9848591089248657:.4f\n",
      "Epoch 2462: Train Loss = 0.1533, Test Loss = 0.9568995237350464:.4f\n",
      "Epoch 2463: Train Loss = 0.1523, Test Loss = 1.003967523574829:.4f\n",
      "Epoch 2464: Train Loss = 0.1165, Test Loss = 1.02944016456604:.4f\n",
      "Epoch 2465: Train Loss = 0.1537, Test Loss = 1.0192595720291138:.4f\n",
      "Epoch 2466: Train Loss = 0.1220, Test Loss = 0.941750168800354:.4f\n",
      "Epoch 2467: Train Loss = 0.1501, Test Loss = 0.8888717889785767:.4f\n",
      "Epoch 2468: Train Loss = 0.1610, Test Loss = 0.908394455909729:.4f\n",
      "Epoch 2469: Train Loss = 0.1463, Test Loss = 1.0047051906585693:.4f\n",
      "Epoch 2470: Train Loss = 0.1355, Test Loss = 1.0700594186782837:.4f\n",
      "Epoch 2471: Train Loss = 0.1345, Test Loss = 1.0912076234817505:.4f\n",
      "Epoch 2472: Train Loss = 0.1355, Test Loss = 1.0790517330169678:.4f\n",
      "Epoch 2473: Train Loss = 0.1421, Test Loss = 1.0215119123458862:.4f\n",
      "Epoch 2474: Train Loss = 0.1289, Test Loss = 0.969149112701416:.4f\n",
      "Epoch 2475: Train Loss = 0.1558, Test Loss = 0.902751624584198:.4f\n",
      "Epoch 2476: Train Loss = 0.1278, Test Loss = 0.9505254030227661:.4f\n",
      "Epoch 2477: Train Loss = 0.1516, Test Loss = 0.9692105054855347:.4f\n",
      "Epoch 2478: Train Loss = 0.1529, Test Loss = 0.977281391620636:.4f\n",
      "Epoch 2479: Train Loss = 0.1849, Test Loss = 0.9976037740707397:.4f\n",
      "Epoch 2480: Train Loss = 0.1907, Test Loss = 1.0098074674606323:.4f\n",
      "Epoch 2481: Train Loss = 0.1240, Test Loss = 1.0344212055206299:.4f\n",
      "Epoch 2482: Train Loss = 0.1292, Test Loss = 1.0281225442886353:.4f\n",
      "Epoch 2483: Train Loss = 0.1344, Test Loss = 0.9312202334403992:.4f\n",
      "Epoch 2484: Train Loss = 0.1261, Test Loss = 0.8939369320869446:.4f\n",
      "Epoch 2485: Train Loss = 0.1291, Test Loss = 0.9144638180732727:.4f\n",
      "Epoch 2486: Train Loss = 0.1450, Test Loss = 0.9443784952163696:.4f\n",
      "Epoch 2487: Train Loss = 0.1351, Test Loss = 1.0268034934997559:.4f\n",
      "Epoch 2488: Train Loss = 0.1407, Test Loss = 1.1177211999893188:.4f\n",
      "Epoch 2489: Train Loss = 0.1341, Test Loss = 1.0926973819732666:.4f\n",
      "Epoch 2490: Train Loss = 0.1340, Test Loss = 0.9752781987190247:.4f\n",
      "Epoch 2491: Train Loss = 0.1301, Test Loss = 0.9344906806945801:.4f\n",
      "Epoch 2492: Train Loss = 0.1449, Test Loss = 0.9148763418197632:.4f\n",
      "Epoch 2493: Train Loss = 0.1458, Test Loss = 0.9442253112792969:.4f\n",
      "Epoch 2494: Train Loss = 0.1568, Test Loss = 0.9862626791000366:.4f\n",
      "Epoch 2495: Train Loss = 0.1849, Test Loss = 1.0326412916183472:.4f\n",
      "Epoch 2496: Train Loss = 0.1371, Test Loss = 1.013999104499817:.4f\n",
      "Epoch 2497: Train Loss = 0.1423, Test Loss = 0.9726158380508423:.4f\n",
      "Epoch 2498: Train Loss = 0.1193, Test Loss = 0.9128772020339966:.4f\n",
      "Epoch 2499: Train Loss = 0.1279, Test Loss = 0.909014105796814:.4f\n",
      "Epoch 2500: Train Loss = 0.1578, Test Loss = 0.94959557056427:.4f\n",
      "Epoch 2501: Train Loss = 0.1346, Test Loss = 0.9208961725234985:.4f\n",
      "Epoch 2502: Train Loss = 0.1215, Test Loss = 0.9106649160385132:.4f\n",
      "Epoch 2503: Train Loss = 0.1463, Test Loss = 0.9155271649360657:.4f\n",
      "Epoch 2504: Train Loss = 0.1454, Test Loss = 0.9213622212409973:.4f\n",
      "Epoch 2505: Train Loss = 0.1226, Test Loss = 0.9627422094345093:.4f\n",
      "Epoch 2506: Train Loss = 0.1345, Test Loss = 0.9618284106254578:.4f\n",
      "Epoch 2507: Train Loss = 0.1366, Test Loss = 0.9126911163330078:.4f\n",
      "Epoch 2508: Train Loss = 0.1502, Test Loss = 0.9017022252082825:.4f\n",
      "Epoch 2509: Train Loss = 0.1593, Test Loss = 0.9136756658554077:.4f\n",
      "Epoch 2510: Train Loss = 0.1482, Test Loss = 0.9461870193481445:.4f\n",
      "Epoch 2511: Train Loss = 0.1456, Test Loss = 0.97398841381073:.4f\n",
      "Epoch 2512: Train Loss = 0.1490, Test Loss = 0.9857107400894165:.4f\n",
      "Epoch 2513: Train Loss = 0.1382, Test Loss = 0.9528315663337708:.4f\n",
      "Epoch 2514: Train Loss = 0.1275, Test Loss = 0.9598633646965027:.4f\n",
      "Epoch 2515: Train Loss = 0.1412, Test Loss = 0.9461833238601685:.4f\n",
      "Epoch 2516: Train Loss = 0.1464, Test Loss = 0.9567052125930786:.4f\n",
      "Epoch 2517: Train Loss = 0.1346, Test Loss = 1.006866693496704:.4f\n",
      "Epoch 2518: Train Loss = 0.1170, Test Loss = 1.006989598274231:.4f\n",
      "Epoch 2519: Train Loss = 0.1181, Test Loss = 0.9787895083427429:.4f\n",
      "Epoch 2520: Train Loss = 0.1224, Test Loss = 0.9457656741142273:.4f\n",
      "Epoch 2521: Train Loss = 0.1446, Test Loss = 0.9383444786071777:.4f\n",
      "Epoch 2522: Train Loss = 0.1693, Test Loss = 0.915015697479248:.4f\n",
      "Epoch 2523: Train Loss = 0.1411, Test Loss = 0.9799882173538208:.4f\n",
      "Epoch 2524: Train Loss = 0.1540, Test Loss = 0.9792057275772095:.4f\n",
      "Epoch 2525: Train Loss = 0.1443, Test Loss = 1.0103460550308228:.4f\n",
      "Epoch 2526: Train Loss = 0.1420, Test Loss = 1.006493091583252:.4f\n",
      "Epoch 2527: Train Loss = 0.1414, Test Loss = 1.0438576936721802:.4f\n",
      "Epoch 2528: Train Loss = 0.1287, Test Loss = 1.013425588607788:.4f\n",
      "Epoch 2529: Train Loss = 0.1230, Test Loss = 0.9477609395980835:.4f\n",
      "Epoch 2530: Train Loss = 0.1486, Test Loss = 0.9100465774536133:.4f\n",
      "Epoch 2531: Train Loss = 0.1339, Test Loss = 0.965489387512207:.4f\n",
      "Epoch 2532: Train Loss = 0.1353, Test Loss = 0.9827077984809875:.4f\n",
      "Epoch 2533: Train Loss = 0.1432, Test Loss = 0.9978391528129578:.4f\n",
      "Epoch 2534: Train Loss = 0.1343, Test Loss = 0.9950762987136841:.4f\n",
      "Epoch 2535: Train Loss = 0.1425, Test Loss = 0.9740069508552551:.4f\n",
      "Epoch 2536: Train Loss = 0.1713, Test Loss = 0.9227005243301392:.4f\n",
      "Epoch 2537: Train Loss = 0.1251, Test Loss = 0.9481630325317383:.4f\n",
      "Epoch 2538: Train Loss = 0.1150, Test Loss = 0.9527257680892944:.4f\n",
      "Epoch 2539: Train Loss = 0.1291, Test Loss = 0.9549301266670227:.4f\n",
      "Epoch 2540: Train Loss = 0.1302, Test Loss = 0.9417303800582886:.4f\n",
      "Epoch 2541: Train Loss = 0.1285, Test Loss = 0.9429105520248413:.4f\n",
      "Epoch 2542: Train Loss = 0.1497, Test Loss = 0.9596819877624512:.4f\n",
      "Epoch 2543: Train Loss = 0.1313, Test Loss = 0.9676867723464966:.4f\n",
      "Epoch 2544: Train Loss = 0.1128, Test Loss = 0.9321263432502747:.4f\n",
      "Epoch 2545: Train Loss = 0.1425, Test Loss = 0.930512547492981:.4f\n",
      "Epoch 2546: Train Loss = 0.1393, Test Loss = 0.9779738187789917:.4f\n",
      "Epoch 2547: Train Loss = 0.1374, Test Loss = 1.0270006656646729:.4f\n",
      "Epoch 2548: Train Loss = 0.1201, Test Loss = 1.063592791557312:.4f\n",
      "Epoch 2549: Train Loss = 0.1483, Test Loss = 1.0509746074676514:.4f\n",
      "Epoch 2550: Train Loss = 0.1396, Test Loss = 1.0080859661102295:.4f\n",
      "Epoch 2551: Train Loss = 0.1546, Test Loss = 0.922960102558136:.4f\n",
      "Epoch 2552: Train Loss = 0.1317, Test Loss = 0.9307126998901367:.4f\n",
      "Epoch 2553: Train Loss = 0.1233, Test Loss = 0.9475517272949219:.4f\n",
      "Epoch 2554: Train Loss = 0.1487, Test Loss = 0.9746980667114258:.4f\n",
      "Epoch 2555: Train Loss = 0.1387, Test Loss = 0.9923371076583862:.4f\n",
      "Epoch 2556: Train Loss = 0.1344, Test Loss = 0.9756289720535278:.4f\n",
      "Epoch 2557: Train Loss = 0.1608, Test Loss = 0.9162178039550781:.4f\n",
      "Epoch 2558: Train Loss = 0.1778, Test Loss = 0.9736668467521667:.4f\n",
      "Epoch 2559: Train Loss = 0.1277, Test Loss = 1.0673425197601318:.4f\n",
      "Epoch 2560: Train Loss = 0.1565, Test Loss = 1.0580742359161377:.4f\n",
      "Epoch 2561: Train Loss = 0.1674, Test Loss = 0.9861706495285034:.4f\n",
      "Epoch 2562: Train Loss = 0.1134, Test Loss = 0.9693859815597534:.4f\n",
      "Epoch 2563: Train Loss = 0.1552, Test Loss = 0.9813046455383301:.4f\n",
      "Epoch 2564: Train Loss = 0.1462, Test Loss = 1.077317237854004:.4f\n",
      "Epoch 2565: Train Loss = 0.1393, Test Loss = 1.1253334283828735:.4f\n",
      "Epoch 2566: Train Loss = 0.1277, Test Loss = 1.1047793626785278:.4f\n",
      "Epoch 2567: Train Loss = 0.1365, Test Loss = 1.0317227840423584:.4f\n",
      "Epoch 2568: Train Loss = 0.1215, Test Loss = 0.9467501640319824:.4f\n",
      "Epoch 2569: Train Loss = 0.1309, Test Loss = 0.8941025733947754:.4f\n",
      "Epoch 2570: Train Loss = 0.1623, Test Loss = 0.8912882804870605:.4f\n",
      "Epoch 2571: Train Loss = 0.1450, Test Loss = 0.9826100468635559:.4f\n",
      "Epoch 2572: Train Loss = 0.1563, Test Loss = 1.0909446477890015:.4f\n",
      "Epoch 2573: Train Loss = 0.1574, Test Loss = 1.0609880685806274:.4f\n",
      "Epoch 2574: Train Loss = 0.1251, Test Loss = 0.9801508784294128:.4f\n",
      "Epoch 2575: Train Loss = 0.1657, Test Loss = 0.9137735366821289:.4f\n",
      "Epoch 2576: Train Loss = 0.1323, Test Loss = 0.9667829275131226:.4f\n",
      "Epoch 2577: Train Loss = 0.1421, Test Loss = 1.0167057514190674:.4f\n",
      "Epoch 2578: Train Loss = 0.1412, Test Loss = 1.0465724468231201:.4f\n",
      "Epoch 2579: Train Loss = 0.1446, Test Loss = 1.006064534187317:.4f\n",
      "Epoch 2580: Train Loss = 0.1437, Test Loss = 0.9715849161148071:.4f\n",
      "Epoch 2581: Train Loss = 0.1183, Test Loss = 0.9481643438339233:.4f\n",
      "Epoch 2582: Train Loss = 0.1238, Test Loss = 0.9395425915718079:.4f\n",
      "Epoch 2583: Train Loss = 0.1595, Test Loss = 0.9255167841911316:.4f\n",
      "Epoch 2584: Train Loss = 0.1773, Test Loss = 0.995323657989502:.4f\n",
      "Epoch 2585: Train Loss = 0.1415, Test Loss = 1.0816577672958374:.4f\n",
      "Epoch 2586: Train Loss = 0.1253, Test Loss = 1.060009241104126:.4f\n",
      "Epoch 2587: Train Loss = 0.1397, Test Loss = 1.0117827653884888:.4f\n",
      "Epoch 2588: Train Loss = 0.1280, Test Loss = 0.9308053255081177:.4f\n",
      "Epoch 2589: Train Loss = 0.1564, Test Loss = 0.9075548052787781:.4f\n",
      "Epoch 2590: Train Loss = 0.1289, Test Loss = 0.968502402305603:.4f\n",
      "Epoch 2591: Train Loss = 0.1227, Test Loss = 1.0201786756515503:.4f\n",
      "Epoch 2592: Train Loss = 0.1533, Test Loss = 1.0193679332733154:.4f\n",
      "Epoch 2593: Train Loss = 0.1217, Test Loss = 0.9232921600341797:.4f\n",
      "Epoch 2594: Train Loss = 0.1171, Test Loss = 0.8829334378242493:.4f\n",
      "Epoch 2595: Train Loss = 0.1543, Test Loss = 0.8868089914321899:.4f\n",
      "Epoch 2596: Train Loss = 0.1193, Test Loss = 0.9370440244674683:.4f\n",
      "Epoch 2597: Train Loss = 0.1544, Test Loss = 0.9862033128738403:.4f\n",
      "Epoch 2598: Train Loss = 0.1190, Test Loss = 0.9401893615722656:.4f\n",
      "Epoch 2599: Train Loss = 0.1219, Test Loss = 0.9285430908203125:.4f\n",
      "Epoch 2600: Train Loss = 0.1377, Test Loss = 0.9344888925552368:.4f\n",
      "Epoch 2601: Train Loss = 0.1577, Test Loss = 0.979716420173645:.4f\n",
      "Epoch 2602: Train Loss = 0.1206, Test Loss = 1.0129767656326294:.4f\n",
      "Epoch 2603: Train Loss = 0.1286, Test Loss = 1.0110328197479248:.4f\n",
      "Epoch 2604: Train Loss = 0.1726, Test Loss = 0.9653022885322571:.4f\n",
      "Epoch 2605: Train Loss = 0.1429, Test Loss = 0.9815228581428528:.4f\n",
      "Epoch 2606: Train Loss = 0.1731, Test Loss = 0.9460644721984863:.4f\n",
      "Epoch 2607: Train Loss = 0.1283, Test Loss = 0.9965440630912781:.4f\n",
      "Epoch 2608: Train Loss = 0.1623, Test Loss = 0.9741412401199341:.4f\n",
      "Epoch 2609: Train Loss = 0.1289, Test Loss = 1.0144566297531128:.4f\n",
      "Epoch 2610: Train Loss = 0.1360, Test Loss = 1.0152082443237305:.4f\n",
      "Epoch 2611: Train Loss = 0.1413, Test Loss = 1.0498021841049194:.4f\n",
      "Epoch 2612: Train Loss = 0.1384, Test Loss = 1.0708261728286743:.4f\n",
      "Epoch 2613: Train Loss = 0.1355, Test Loss = 1.0606777667999268:.4f\n",
      "Epoch 2614: Train Loss = 0.1316, Test Loss = 0.977035403251648:.4f\n",
      "Epoch 2615: Train Loss = 0.1568, Test Loss = 0.9274775385856628:.4f\n",
      "Epoch 2616: Train Loss = 0.1408, Test Loss = 0.942912220954895:.4f\n",
      "Epoch 2617: Train Loss = 0.1464, Test Loss = 0.9346951246261597:.4f\n",
      "Epoch 2618: Train Loss = 0.1374, Test Loss = 0.9174894094467163:.4f\n",
      "Epoch 2619: Train Loss = 0.1465, Test Loss = 0.9203773736953735:.4f\n",
      "Epoch 2620: Train Loss = 0.1380, Test Loss = 0.9390891790390015:.4f\n",
      "Epoch 2621: Train Loss = 0.1438, Test Loss = 1.007893443107605:.4f\n",
      "Epoch 2622: Train Loss = 0.1508, Test Loss = 1.1014955043792725:.4f\n",
      "Epoch 2623: Train Loss = 0.1474, Test Loss = 1.042067527770996:.4f\n",
      "Epoch 2624: Train Loss = 0.1912, Test Loss = 1.038038730621338:.4f\n",
      "Epoch 2625: Train Loss = 0.1358, Test Loss = 1.0383648872375488:.4f\n",
      "Epoch 2626: Train Loss = 0.1404, Test Loss = 0.9733023643493652:.4f\n",
      "Epoch 2627: Train Loss = 0.1647, Test Loss = 0.9667943120002747:.4f\n",
      "Epoch 2628: Train Loss = 0.1340, Test Loss = 1.0081336498260498:.4f\n",
      "Epoch 2629: Train Loss = 0.1290, Test Loss = 1.007352352142334:.4f\n",
      "Epoch 2630: Train Loss = 0.1383, Test Loss = 0.9630735516548157:.4f\n",
      "Epoch 2631: Train Loss = 0.1582, Test Loss = 0.9236825704574585:.4f\n",
      "Epoch 2632: Train Loss = 0.1505, Test Loss = 0.9699424505233765:.4f\n",
      "Epoch 2633: Train Loss = 0.1513, Test Loss = 1.0628001689910889:.4f\n",
      "Epoch 2634: Train Loss = 0.1332, Test Loss = 1.062789797782898:.4f\n",
      "Epoch 2635: Train Loss = 0.1430, Test Loss = 1.0201423168182373:.4f\n",
      "Epoch 2636: Train Loss = 0.1276, Test Loss = 0.9223712086677551:.4f\n",
      "Epoch 2637: Train Loss = 0.1627, Test Loss = 0.9047393798828125:.4f\n",
      "Epoch 2638: Train Loss = 0.1400, Test Loss = 0.9732372164726257:.4f\n",
      "Epoch 2639: Train Loss = 0.1500, Test Loss = 0.9785787463188171:.4f\n",
      "Epoch 2640: Train Loss = 0.1371, Test Loss = 1.0233784914016724:.4f\n",
      "Epoch 2641: Train Loss = 0.1272, Test Loss = 0.9798693656921387:.4f\n",
      "Epoch 2642: Train Loss = 0.1269, Test Loss = 0.9864476919174194:.4f\n",
      "Epoch 2643: Train Loss = 0.1699, Test Loss = 0.9800316095352173:.4f\n",
      "Epoch 2644: Train Loss = 0.1194, Test Loss = 1.0386147499084473:.4f\n",
      "Epoch 2645: Train Loss = 0.1251, Test Loss = 1.0323971509933472:.4f\n",
      "Epoch 2646: Train Loss = 0.1567, Test Loss = 0.9969074130058289:.4f\n",
      "Epoch 2647: Train Loss = 0.1400, Test Loss = 0.9716560244560242:.4f\n",
      "Epoch 2648: Train Loss = 0.1367, Test Loss = 0.9608518481254578:.4f\n",
      "Epoch 2649: Train Loss = 0.1454, Test Loss = 0.943102240562439:.4f\n",
      "Epoch 2650: Train Loss = 0.1323, Test Loss = 0.914242148399353:.4f\n",
      "Epoch 2651: Train Loss = 0.1321, Test Loss = 0.8915740251541138:.4f\n",
      "Epoch 2652: Train Loss = 0.1356, Test Loss = 0.9020609855651855:.4f\n",
      "Epoch 2653: Train Loss = 0.1241, Test Loss = 0.9253266453742981:.4f\n",
      "Epoch 2654: Train Loss = 0.1286, Test Loss = 0.9573222398757935:.4f\n",
      "Epoch 2655: Train Loss = 0.1412, Test Loss = 1.0119330883026123:.4f\n",
      "Epoch 2656: Train Loss = 0.1388, Test Loss = 0.9853620529174805:.4f\n",
      "Epoch 2657: Train Loss = 0.1402, Test Loss = 0.9145190119743347:.4f\n",
      "Epoch 2658: Train Loss = 0.1344, Test Loss = 0.930550217628479:.4f\n",
      "Epoch 2659: Train Loss = 0.1374, Test Loss = 0.9195255041122437:.4f\n",
      "Epoch 2660: Train Loss = 0.1275, Test Loss = 0.9398736953735352:.4f\n",
      "Epoch 2661: Train Loss = 0.1372, Test Loss = 0.943473219871521:.4f\n",
      "Epoch 2662: Train Loss = 0.1451, Test Loss = 0.9580198526382446:.4f\n",
      "Epoch 2663: Train Loss = 0.1181, Test Loss = 0.9953694343566895:.4f\n",
      "Epoch 2664: Train Loss = 0.1272, Test Loss = 0.9817011952400208:.4f\n",
      "Epoch 2665: Train Loss = 0.1265, Test Loss = 0.9479988813400269:.4f\n",
      "Epoch 2666: Train Loss = 0.1406, Test Loss = 0.9313352704048157:.4f\n",
      "Epoch 2667: Train Loss = 0.1380, Test Loss = 0.9174869656562805:.4f\n",
      "Epoch 2668: Train Loss = 0.1257, Test Loss = 0.9257208108901978:.4f\n",
      "Epoch 2669: Train Loss = 0.1197, Test Loss = 0.9298874139785767:.4f\n",
      "Epoch 2670: Train Loss = 0.1518, Test Loss = 0.9197427034378052:.4f\n",
      "Epoch 2671: Train Loss = 0.1356, Test Loss = 0.9892373085021973:.4f\n",
      "Epoch 2672: Train Loss = 0.1335, Test Loss = 1.0160537958145142:.4f\n",
      "Epoch 2673: Train Loss = 0.1212, Test Loss = 0.9951313734054565:.4f\n",
      "Epoch 2674: Train Loss = 0.1372, Test Loss = 0.9876136779785156:.4f\n",
      "Epoch 2675: Train Loss = 0.1161, Test Loss = 0.9776285290718079:.4f\n",
      "Epoch 2676: Train Loss = 0.1256, Test Loss = 0.9816217422485352:.4f\n",
      "Epoch 2677: Train Loss = 0.1242, Test Loss = 0.9949477910995483:.4f\n",
      "Epoch 2678: Train Loss = 0.1277, Test Loss = 0.9591860771179199:.4f\n",
      "Epoch 2679: Train Loss = 0.1195, Test Loss = 0.94451904296875:.4f\n",
      "Epoch 2680: Train Loss = 0.1313, Test Loss = 0.9581958651542664:.4f\n",
      "Epoch 2681: Train Loss = 0.1432, Test Loss = 0.9507395029067993:.4f\n",
      "Epoch 2682: Train Loss = 0.1256, Test Loss = 0.9959737062454224:.4f\n",
      "Epoch 2683: Train Loss = 0.1225, Test Loss = 0.9795764088630676:.4f\n",
      "Epoch 2684: Train Loss = 0.1191, Test Loss = 0.9949655532836914:.4f\n",
      "Epoch 2685: Train Loss = 0.1271, Test Loss = 0.9481717944145203:.4f\n",
      "Epoch 2686: Train Loss = 0.1270, Test Loss = 0.9343695640563965:.4f\n",
      "Epoch 2687: Train Loss = 0.1478, Test Loss = 0.9789707064628601:.4f\n",
      "Epoch 2688: Train Loss = 0.1567, Test Loss = 1.0031193494796753:.4f\n",
      "Epoch 2689: Train Loss = 0.1338, Test Loss = 1.0252022743225098:.4f\n",
      "Epoch 2690: Train Loss = 0.1604, Test Loss = 0.978194534778595:.4f\n",
      "Epoch 2691: Train Loss = 0.1261, Test Loss = 1.0246310234069824:.4f\n",
      "Epoch 2692: Train Loss = 0.1429, Test Loss = 1.0030138492584229:.4f\n",
      "Epoch 2693: Train Loss = 0.1112, Test Loss = 1.0091559886932373:.4f\n",
      "Epoch 2694: Train Loss = 0.1452, Test Loss = 1.005368947982788:.4f\n",
      "Epoch 2695: Train Loss = 0.1264, Test Loss = 0.9642534255981445:.4f\n",
      "Epoch 2696: Train Loss = 0.1390, Test Loss = 0.9651837348937988:.4f\n",
      "Epoch 2697: Train Loss = 0.1230, Test Loss = 0.973480224609375:.4f\n",
      "Epoch 2698: Train Loss = 0.1620, Test Loss = 0.9455154538154602:.4f\n",
      "Epoch 2699: Train Loss = 0.1463, Test Loss = 0.9824870824813843:.4f\n",
      "Epoch 2700: Train Loss = 0.1398, Test Loss = 0.9902960062026978:.4f\n",
      "Epoch 2701: Train Loss = 0.1586, Test Loss = 1.0258920192718506:.4f\n",
      "Epoch 2702: Train Loss = 0.1508, Test Loss = 1.0312381982803345:.4f\n",
      "Epoch 2703: Train Loss = 0.1268, Test Loss = 1.0456105470657349:.4f\n",
      "Epoch 2704: Train Loss = 0.1459, Test Loss = 1.041953444480896:.4f\n",
      "Epoch 2705: Train Loss = 0.1320, Test Loss = 1.0978590250015259:.4f\n",
      "Epoch 2706: Train Loss = 0.1880, Test Loss = 1.0656812191009521:.4f\n",
      "Epoch 2707: Train Loss = 0.1216, Test Loss = 0.9737560153007507:.4f\n",
      "Epoch 2708: Train Loss = 0.1831, Test Loss = 0.9027010202407837:.4f\n",
      "Epoch 2709: Train Loss = 0.1363, Test Loss = 0.9564523696899414:.4f\n",
      "Epoch 2710: Train Loss = 0.1212, Test Loss = 0.9987117648124695:.4f\n",
      "Epoch 2711: Train Loss = 0.1351, Test Loss = 0.9928935766220093:.4f\n",
      "Epoch 2712: Train Loss = 0.1319, Test Loss = 0.9625571966171265:.4f\n",
      "Epoch 2713: Train Loss = 0.1209, Test Loss = 0.9396620988845825:.4f\n",
      "Epoch 2714: Train Loss = 0.1301, Test Loss = 0.9623364210128784:.4f\n",
      "Epoch 2715: Train Loss = 0.1344, Test Loss = 0.9637028574943542:.4f\n",
      "Epoch 2716: Train Loss = 0.1275, Test Loss = 0.9284638166427612:.4f\n",
      "Epoch 2717: Train Loss = 0.1444, Test Loss = 0.9438946843147278:.4f\n",
      "Epoch 2718: Train Loss = 0.1140, Test Loss = 0.9387260675430298:.4f\n",
      "Epoch 2719: Train Loss = 0.1436, Test Loss = 0.9631193280220032:.4f\n",
      "Epoch 2720: Train Loss = 0.1319, Test Loss = 1.0335265398025513:.4f\n",
      "Epoch 2721: Train Loss = 0.1375, Test Loss = 1.0156359672546387:.4f\n",
      "Epoch 2722: Train Loss = 0.1441, Test Loss = 0.9622578620910645:.4f\n",
      "Epoch 2723: Train Loss = 0.1271, Test Loss = 0.9246370196342468:.4f\n",
      "Epoch 2724: Train Loss = 0.1407, Test Loss = 0.9557672739028931:.4f\n",
      "Epoch 2725: Train Loss = 0.1284, Test Loss = 0.9811518788337708:.4f\n",
      "Epoch 2726: Train Loss = 0.1828, Test Loss = 1.002314805984497:.4f\n",
      "Epoch 2727: Train Loss = 0.1488, Test Loss = 1.0157641172409058:.4f\n",
      "Epoch 2728: Train Loss = 0.1170, Test Loss = 0.998406708240509:.4f\n",
      "Epoch 2729: Train Loss = 0.1317, Test Loss = 0.9912277460098267:.4f\n",
      "Epoch 2730: Train Loss = 0.1214, Test Loss = 1.0068280696868896:.4f\n",
      "Epoch 2731: Train Loss = 0.1499, Test Loss = 0.9697273969650269:.4f\n",
      "Epoch 2732: Train Loss = 0.1545, Test Loss = 1.0001957416534424:.4f\n",
      "Epoch 2733: Train Loss = 0.1309, Test Loss = 0.9922669529914856:.4f\n",
      "Epoch 2734: Train Loss = 0.1219, Test Loss = 0.9558030366897583:.4f\n",
      "Epoch 2735: Train Loss = 0.1820, Test Loss = 0.9320157170295715:.4f\n",
      "Epoch 2736: Train Loss = 0.1452, Test Loss = 1.011054515838623:.4f\n",
      "Epoch 2737: Train Loss = 0.1680, Test Loss = 1.0990428924560547:.4f\n",
      "Epoch 2738: Train Loss = 0.1328, Test Loss = 1.0120337009429932:.4f\n",
      "Epoch 2739: Train Loss = 0.1110, Test Loss = 0.9425778388977051:.4f\n",
      "Epoch 2740: Train Loss = 0.1486, Test Loss = 0.9332000613212585:.4f\n",
      "Epoch 2741: Train Loss = 0.1254, Test Loss = 0.9814419746398926:.4f\n",
      "Epoch 2742: Train Loss = 0.1396, Test Loss = 1.0334217548370361:.4f\n",
      "Epoch 2743: Train Loss = 0.1505, Test Loss = 0.9635341763496399:.4f\n",
      "Epoch 2744: Train Loss = 0.1508, Test Loss = 0.9882830381393433:.4f\n",
      "Epoch 2745: Train Loss = 0.1279, Test Loss = 0.977624773979187:.4f\n",
      "Epoch 2746: Train Loss = 0.1335, Test Loss = 0.9564418792724609:.4f\n",
      "Epoch 2747: Train Loss = 0.1315, Test Loss = 0.9375127553939819:.4f\n",
      "Epoch 2748: Train Loss = 0.1162, Test Loss = 0.9167950749397278:.4f\n",
      "Epoch 2749: Train Loss = 0.1468, Test Loss = 0.918411374092102:.4f\n",
      "Epoch 2750: Train Loss = 0.1164, Test Loss = 0.9476163983345032:.4f\n",
      "Epoch 2751: Train Loss = 0.1436, Test Loss = 0.9879987835884094:.4f\n",
      "Epoch 2752: Train Loss = 0.1328, Test Loss = 1.083614468574524:.4f\n",
      "Epoch 2753: Train Loss = 0.1404, Test Loss = 1.0847525596618652:.4f\n",
      "Epoch 2754: Train Loss = 0.1299, Test Loss = 0.9997180700302124:.4f\n",
      "Epoch 2755: Train Loss = 0.1526, Test Loss = 0.9086934924125671:.4f\n",
      "Epoch 2756: Train Loss = 0.1271, Test Loss = 0.9439362287521362:.4f\n",
      "Epoch 2757: Train Loss = 0.1308, Test Loss = 0.99439537525177:.4f\n",
      "Epoch 2758: Train Loss = 0.1165, Test Loss = 1.018776297569275:.4f\n",
      "Epoch 2759: Train Loss = 0.1420, Test Loss = 1.0333518981933594:.4f\n",
      "Epoch 2760: Train Loss = 0.1533, Test Loss = 1.0458009243011475:.4f\n",
      "Epoch 2761: Train Loss = 0.1272, Test Loss = 1.0235925912857056:.4f\n",
      "Epoch 2762: Train Loss = 0.1255, Test Loss = 0.9668753743171692:.4f\n",
      "Epoch 2763: Train Loss = 0.1348, Test Loss = 0.9487072825431824:.4f\n",
      "Epoch 2764: Train Loss = 0.1243, Test Loss = 0.9542657136917114:.4f\n",
      "Epoch 2765: Train Loss = 0.1274, Test Loss = 0.9508482813835144:.4f\n",
      "Epoch 2766: Train Loss = 0.1246, Test Loss = 0.9483733177185059:.4f\n",
      "Epoch 2767: Train Loss = 0.1503, Test Loss = 0.9513723254203796:.4f\n",
      "Epoch 2768: Train Loss = 0.1143, Test Loss = 1.0133178234100342:.4f\n",
      "Epoch 2769: Train Loss = 0.1398, Test Loss = 1.060436725616455:.4f\n",
      "Epoch 2770: Train Loss = 0.1530, Test Loss = 1.0369722843170166:.4f\n",
      "Epoch 2771: Train Loss = 0.1195, Test Loss = 0.9573230743408203:.4f\n",
      "Epoch 2772: Train Loss = 0.1311, Test Loss = 0.9175789952278137:.4f\n",
      "Epoch 2773: Train Loss = 0.1187, Test Loss = 0.9549332857131958:.4f\n",
      "Epoch 2774: Train Loss = 0.1489, Test Loss = 0.9817196726799011:.4f\n",
      "Epoch 2775: Train Loss = 0.1494, Test Loss = 1.031394600868225:.4f\n",
      "Epoch 2776: Train Loss = 0.1478, Test Loss = 1.0027459859848022:.4f\n",
      "Epoch 2777: Train Loss = 0.1224, Test Loss = 0.9744879007339478:.4f\n",
      "Epoch 2778: Train Loss = 0.1257, Test Loss = 0.9509505033493042:.4f\n",
      "Epoch 2779: Train Loss = 0.1754, Test Loss = 0.9569180607795715:.4f\n",
      "Epoch 2780: Train Loss = 0.1503, Test Loss = 1.0451053380966187:.4f\n",
      "Epoch 2781: Train Loss = 0.1496, Test Loss = 1.0503511428833008:.4f\n",
      "Epoch 2782: Train Loss = 0.1315, Test Loss = 0.9970580339431763:.4f\n",
      "Epoch 2783: Train Loss = 0.2265, Test Loss = 0.9377994537353516:.4f\n",
      "Epoch 2784: Train Loss = 0.1175, Test Loss = 1.0100057125091553:.4f\n",
      "Epoch 2785: Train Loss = 0.1298, Test Loss = 1.0836396217346191:.4f\n",
      "Epoch 2786: Train Loss = 0.1476, Test Loss = 1.0193302631378174:.4f\n",
      "Epoch 2787: Train Loss = 0.1696, Test Loss = 0.9168893098831177:.4f\n",
      "Epoch 2788: Train Loss = 0.1170, Test Loss = 0.9376864433288574:.4f\n",
      "Epoch 2789: Train Loss = 0.1178, Test Loss = 1.0008269548416138:.4f\n",
      "Epoch 2790: Train Loss = 0.1219, Test Loss = 1.023739218711853:.4f\n",
      "Epoch 2791: Train Loss = 0.1232, Test Loss = 1.0064423084259033:.4f\n",
      "Epoch 2792: Train Loss = 0.1184, Test Loss = 0.9858559370040894:.4f\n",
      "Epoch 2793: Train Loss = 0.1392, Test Loss = 0.9830670356750488:.4f\n",
      "Epoch 2794: Train Loss = 0.1113, Test Loss = 1.0038014650344849:.4f\n",
      "Epoch 2795: Train Loss = 0.1294, Test Loss = 1.0289151668548584:.4f\n",
      "Epoch 2796: Train Loss = 0.1432, Test Loss = 1.035035252571106:.4f\n",
      "Epoch 2797: Train Loss = 0.1424, Test Loss = 0.9779431223869324:.4f\n",
      "Epoch 2798: Train Loss = 0.1724, Test Loss = 0.9080063700675964:.4f\n",
      "Epoch 2799: Train Loss = 0.1362, Test Loss = 0.9485944509506226:.4f\n",
      "Epoch 2800: Train Loss = 0.1429, Test Loss = 0.9899052381515503:.4f\n",
      "Epoch 2801: Train Loss = 0.1347, Test Loss = 0.9731966853141785:.4f\n",
      "Epoch 2802: Train Loss = 0.1395, Test Loss = 0.9074077606201172:.4f\n",
      "Epoch 2803: Train Loss = 0.1501, Test Loss = 0.9323844909667969:.4f\n",
      "Epoch 2804: Train Loss = 0.1324, Test Loss = 0.9938586354255676:.4f\n",
      "Epoch 2805: Train Loss = 0.1144, Test Loss = 1.0076897144317627:.4f\n",
      "Epoch 2806: Train Loss = 0.1449, Test Loss = 0.9920927286148071:.4f\n",
      "Epoch 2807: Train Loss = 0.1425, Test Loss = 1.0088155269622803:.4f\n",
      "Epoch 2808: Train Loss = 0.1357, Test Loss = 1.0697383880615234:.4f\n",
      "Epoch 2809: Train Loss = 0.1626, Test Loss = 1.1232903003692627:.4f\n",
      "Epoch 2810: Train Loss = 0.1466, Test Loss = 1.016082525253296:.4f\n",
      "Epoch 2811: Train Loss = 0.1213, Test Loss = 0.997492790222168:.4f\n",
      "Epoch 2812: Train Loss = 0.1583, Test Loss = 0.9734493494033813:.4f\n",
      "Epoch 2813: Train Loss = 0.1413, Test Loss = 1.0107065439224243:.4f\n",
      "Epoch 2814: Train Loss = 0.1362, Test Loss = 1.0301449298858643:.4f\n",
      "Epoch 2815: Train Loss = 0.1346, Test Loss = 1.0729281902313232:.4f\n",
      "Epoch 2816: Train Loss = 0.1447, Test Loss = 1.0993303060531616:.4f\n",
      "Epoch 2817: Train Loss = 0.1644, Test Loss = 1.154756784439087:.4f\n",
      "Epoch 2818: Train Loss = 0.1393, Test Loss = 1.0783720016479492:.4f\n",
      "Epoch 2819: Train Loss = 0.1216, Test Loss = 0.9349058270454407:.4f\n",
      "Epoch 2820: Train Loss = 0.1222, Test Loss = 0.884449303150177:.4f\n",
      "Epoch 2821: Train Loss = 0.1385, Test Loss = 0.8959504961967468:.4f\n",
      "Epoch 2822: Train Loss = 0.1214, Test Loss = 0.9711513519287109:.4f\n",
      "Epoch 2823: Train Loss = 0.1345, Test Loss = 1.0391827821731567:.4f\n",
      "Epoch 2824: Train Loss = 0.1728, Test Loss = 1.0301460027694702:.4f\n",
      "Epoch 2825: Train Loss = 0.1334, Test Loss = 1.0471402406692505:.4f\n",
      "Epoch 2826: Train Loss = 0.1204, Test Loss = 1.0074530839920044:.4f\n",
      "Epoch 2827: Train Loss = 0.1402, Test Loss = 0.9740465879440308:.4f\n",
      "Epoch 2828: Train Loss = 0.1385, Test Loss = 0.9580072164535522:.4f\n",
      "Epoch 2829: Train Loss = 0.1541, Test Loss = 0.9670140147209167:.4f\n",
      "Epoch 2830: Train Loss = 0.1253, Test Loss = 1.0530333518981934:.4f\n",
      "Epoch 2831: Train Loss = 0.1398, Test Loss = 1.0722990036010742:.4f\n",
      "Epoch 2832: Train Loss = 0.1403, Test Loss = 1.0624538660049438:.4f\n",
      "Epoch 2833: Train Loss = 0.1203, Test Loss = 1.0320085287094116:.4f\n",
      "Epoch 2834: Train Loss = 0.1515, Test Loss = 0.981269359588623:.4f\n",
      "Epoch 2835: Train Loss = 0.1093, Test Loss = 0.9618895649909973:.4f\n",
      "Epoch 2836: Train Loss = 0.1158, Test Loss = 0.9642851948738098:.4f\n",
      "Epoch 2837: Train Loss = 0.1533, Test Loss = 0.9578827619552612:.4f\n",
      "Epoch 2838: Train Loss = 0.1454, Test Loss = 1.0048848390579224:.4f\n",
      "Epoch 2839: Train Loss = 0.1227, Test Loss = 1.0004985332489014:.4f\n",
      "Epoch 2840: Train Loss = 0.1336, Test Loss = 0.9819449186325073:.4f\n",
      "Epoch 2841: Train Loss = 0.1485, Test Loss = 1.0223308801651:.4f\n",
      "Epoch 2842: Train Loss = 0.1360, Test Loss = 1.0544793605804443:.4f\n",
      "Epoch 2843: Train Loss = 0.1382, Test Loss = 1.0331318378448486:.4f\n",
      "Epoch 2844: Train Loss = 0.1241, Test Loss = 0.9578531980514526:.4f\n",
      "Epoch 2845: Train Loss = 0.1246, Test Loss = 0.9264116287231445:.4f\n",
      "Epoch 2846: Train Loss = 0.1142, Test Loss = 0.9118816256523132:.4f\n",
      "Epoch 2847: Train Loss = 0.1471, Test Loss = 0.9215109944343567:.4f\n",
      "Epoch 2848: Train Loss = 0.1522, Test Loss = 1.0226796865463257:.4f\n",
      "Epoch 2849: Train Loss = 0.1343, Test Loss = 1.07844877243042:.4f\n",
      "Epoch 2850: Train Loss = 0.1229, Test Loss = 1.098831295967102:.4f\n",
      "Epoch 2851: Train Loss = 0.1699, Test Loss = 1.0742824077606201:.4f\n",
      "Epoch 2852: Train Loss = 0.1269, Test Loss = 1.0389370918273926:.4f\n",
      "Epoch 2853: Train Loss = 0.1332, Test Loss = 0.9896999597549438:.4f\n",
      "Epoch 2854: Train Loss = 0.1227, Test Loss = 0.9209175109863281:.4f\n",
      "Epoch 2855: Train Loss = 0.1444, Test Loss = 0.8878073692321777:.4f\n",
      "Epoch 2856: Train Loss = 0.1333, Test Loss = 0.9282565116882324:.4f\n",
      "Epoch 2857: Train Loss = 0.1276, Test Loss = 0.9641060829162598:.4f\n",
      "Epoch 2858: Train Loss = 0.1248, Test Loss = 0.9948613047599792:.4f\n",
      "Epoch 2859: Train Loss = 0.1353, Test Loss = 0.9657972455024719:.4f\n",
      "Epoch 2860: Train Loss = 0.1524, Test Loss = 0.9330092668533325:.4f\n",
      "Epoch 2861: Train Loss = 0.1472, Test Loss = 0.9587435722351074:.4f\n",
      "Epoch 2862: Train Loss = 0.1480, Test Loss = 1.0515062808990479:.4f\n",
      "Epoch 2863: Train Loss = 0.1453, Test Loss = 1.1333931684494019:.4f\n",
      "Epoch 2864: Train Loss = 0.1192, Test Loss = 1.0770002603530884:.4f\n",
      "Epoch 2865: Train Loss = 0.1432, Test Loss = 0.9952068328857422:.4f\n",
      "Epoch 2866: Train Loss = 0.1282, Test Loss = 0.9585087895393372:.4f\n",
      "Epoch 2867: Train Loss = 0.1465, Test Loss = 0.9041914939880371:.4f\n",
      "Epoch 2868: Train Loss = 0.1256, Test Loss = 0.9480912089347839:.4f\n",
      "Epoch 2869: Train Loss = 0.1222, Test Loss = 0.9888116121292114:.4f\n",
      "Epoch 2870: Train Loss = 0.1191, Test Loss = 1.0192656517028809:.4f\n",
      "Epoch 2871: Train Loss = 0.1111, Test Loss = 1.0074607133865356:.4f\n",
      "Epoch 2872: Train Loss = 0.1528, Test Loss = 0.9975582957267761:.4f\n",
      "Epoch 2873: Train Loss = 0.1457, Test Loss = 1.0169602632522583:.4f\n",
      "Epoch 2874: Train Loss = 0.1452, Test Loss = 1.0805928707122803:.4f\n",
      "Epoch 2875: Train Loss = 0.1407, Test Loss = 1.0573265552520752:.4f\n",
      "Epoch 2876: Train Loss = 0.1364, Test Loss = 0.9752153158187866:.4f\n",
      "Epoch 2877: Train Loss = 0.1201, Test Loss = 0.9300729632377625:.4f\n",
      "Epoch 2878: Train Loss = 0.1427, Test Loss = 0.9198086857795715:.4f\n",
      "Epoch 2879: Train Loss = 0.1258, Test Loss = 0.9948135614395142:.4f\n",
      "Epoch 2880: Train Loss = 0.1585, Test Loss = 1.0506017208099365:.4f\n",
      "Epoch 2881: Train Loss = 0.1305, Test Loss = 1.0608763694763184:.4f\n",
      "Epoch 2882: Train Loss = 0.1535, Test Loss = 0.9994481801986694:.4f\n",
      "Epoch 2883: Train Loss = 0.1421, Test Loss = 0.9744428396224976:.4f\n",
      "Epoch 2884: Train Loss = 0.1236, Test Loss = 0.9606924057006836:.4f\n",
      "Epoch 2885: Train Loss = 0.1185, Test Loss = 0.9787595868110657:.4f\n",
      "Epoch 2886: Train Loss = 0.1164, Test Loss = 0.9737399220466614:.4f\n",
      "Epoch 2887: Train Loss = 0.1235, Test Loss = 0.9811438322067261:.4f\n",
      "Epoch 2888: Train Loss = 0.1196, Test Loss = 0.9817989468574524:.4f\n",
      "Epoch 2889: Train Loss = 0.1303, Test Loss = 1.0008597373962402:.4f\n",
      "Epoch 2890: Train Loss = 0.1190, Test Loss = 0.9933578372001648:.4f\n",
      "Epoch 2891: Train Loss = 0.1201, Test Loss = 0.9463555216789246:.4f\n",
      "Epoch 2892: Train Loss = 0.1388, Test Loss = 0.9279141426086426:.4f\n",
      "Epoch 2893: Train Loss = 0.1239, Test Loss = 0.9190020561218262:.4f\n",
      "Epoch 2894: Train Loss = 0.1242, Test Loss = 0.9426249265670776:.4f\n",
      "Epoch 2895: Train Loss = 0.1708, Test Loss = 0.9602811932563782:.4f\n",
      "Epoch 2896: Train Loss = 0.1582, Test Loss = 1.0380442142486572:.4f\n",
      "Epoch 2897: Train Loss = 0.1238, Test Loss = 1.1103845834732056:.4f\n",
      "Epoch 2898: Train Loss = 0.1239, Test Loss = 1.146301507949829:.4f\n",
      "Epoch 2899: Train Loss = 0.1331, Test Loss = 1.0987229347229004:.4f\n",
      "Epoch 2900: Train Loss = 0.1417, Test Loss = 1.0232188701629639:.4f\n",
      "Epoch 2901: Train Loss = 0.1358, Test Loss = 0.9889844655990601:.4f\n",
      "Epoch 2902: Train Loss = 0.1349, Test Loss = 1.0304901599884033:.4f\n",
      "Epoch 2903: Train Loss = 0.1399, Test Loss = 1.013418436050415:.4f\n",
      "Epoch 2904: Train Loss = 0.1309, Test Loss = 1.0527112483978271:.4f\n",
      "Epoch 2905: Train Loss = 0.1409, Test Loss = 1.0676920413970947:.4f\n",
      "Epoch 2906: Train Loss = 0.1241, Test Loss = 1.0667566061019897:.4f\n",
      "Epoch 2907: Train Loss = 0.1228, Test Loss = 1.0666316747665405:.4f\n",
      "Epoch 2908: Train Loss = 0.1256, Test Loss = 0.991773784160614:.4f\n",
      "Epoch 2909: Train Loss = 0.1218, Test Loss = 0.9669564962387085:.4f\n",
      "Epoch 2910: Train Loss = 0.1630, Test Loss = 0.9392989277839661:.4f\n",
      "Epoch 2911: Train Loss = 0.1225, Test Loss = 0.9899449348449707:.4f\n",
      "Epoch 2912: Train Loss = 0.1175, Test Loss = 1.0473753213882446:.4f\n",
      "Epoch 2913: Train Loss = 0.1349, Test Loss = 1.0363203287124634:.4f\n",
      "Epoch 2914: Train Loss = 0.1377, Test Loss = 1.0037841796875:.4f\n",
      "Epoch 2915: Train Loss = 0.1196, Test Loss = 0.9948381185531616:.4f\n",
      "Epoch 2916: Train Loss = 0.1240, Test Loss = 0.9953025579452515:.4f\n",
      "Epoch 2917: Train Loss = 0.1182, Test Loss = 0.996139645576477:.4f\n",
      "Epoch 2918: Train Loss = 0.1177, Test Loss = 0.9628459215164185:.4f\n",
      "Epoch 2919: Train Loss = 0.1252, Test Loss = 0.9235978126525879:.4f\n",
      "Epoch 2920: Train Loss = 0.1367, Test Loss = 0.8925014734268188:.4f\n",
      "Epoch 2921: Train Loss = 0.1163, Test Loss = 0.9233916401863098:.4f\n",
      "Epoch 2922: Train Loss = 0.1190, Test Loss = 0.9523752331733704:.4f\n",
      "Epoch 2923: Train Loss = 0.1137, Test Loss = 0.9584120512008667:.4f\n",
      "Epoch 2924: Train Loss = 0.1242, Test Loss = 0.9661049842834473:.4f\n",
      "Epoch 2925: Train Loss = 0.1223, Test Loss = 0.9840839505195618:.4f\n",
      "Epoch 2926: Train Loss = 0.1186, Test Loss = 0.9955746531486511:.4f\n",
      "Epoch 2927: Train Loss = 0.1305, Test Loss = 1.0080915689468384:.4f\n",
      "Epoch 2928: Train Loss = 0.1224, Test Loss = 0.9953674077987671:.4f\n",
      "Epoch 2929: Train Loss = 0.1240, Test Loss = 0.9529787302017212:.4f\n",
      "Epoch 2930: Train Loss = 0.1352, Test Loss = 0.9619967341423035:.4f\n",
      "Epoch 2931: Train Loss = 0.1413, Test Loss = 1.0009733438491821:.4f\n",
      "Epoch 2932: Train Loss = 0.1270, Test Loss = 0.9994186162948608:.4f\n",
      "Epoch 2933: Train Loss = 0.1233, Test Loss = 0.9664852023124695:.4f\n",
      "Epoch 2934: Train Loss = 0.1278, Test Loss = 0.9684263467788696:.4f\n",
      "Epoch 2935: Train Loss = 0.1366, Test Loss = 0.9840136766433716:.4f\n",
      "Epoch 2936: Train Loss = 0.1185, Test Loss = 1.0084435939788818:.4f\n",
      "Epoch 2937: Train Loss = 0.1235, Test Loss = 0.9995667338371277:.4f\n",
      "Epoch 2938: Train Loss = 0.1310, Test Loss = 0.9406400918960571:.4f\n",
      "Epoch 2939: Train Loss = 0.1264, Test Loss = 0.9404436349868774:.4f\n",
      "Epoch 2940: Train Loss = 0.1633, Test Loss = 0.9479063153266907:.4f\n",
      "Epoch 2941: Train Loss = 0.1305, Test Loss = 1.0213429927825928:.4f\n",
      "Epoch 2942: Train Loss = 0.1273, Test Loss = 1.0405279397964478:.4f\n",
      "Epoch 2943: Train Loss = 0.1169, Test Loss = 1.015142560005188:.4f\n",
      "Epoch 2944: Train Loss = 0.1503, Test Loss = 1.015678882598877:.4f\n",
      "Epoch 2945: Train Loss = 0.1285, Test Loss = 1.0243167877197266:.4f\n",
      "Epoch 2946: Train Loss = 0.1584, Test Loss = 1.0018843412399292:.4f\n",
      "Epoch 2947: Train Loss = 0.1237, Test Loss = 1.0322489738464355:.4f\n",
      "Epoch 2948: Train Loss = 0.1130, Test Loss = 1.0189625024795532:.4f\n",
      "Epoch 2949: Train Loss = 0.1274, Test Loss = 1.0058757066726685:.4f\n",
      "Epoch 2950: Train Loss = 0.1182, Test Loss = 1.0228590965270996:.4f\n",
      "Epoch 2951: Train Loss = 0.1527, Test Loss = 1.0306308269500732:.4f\n",
      "Epoch 2952: Train Loss = 0.1324, Test Loss = 1.0300695896148682:.4f\n",
      "Epoch 2953: Train Loss = 0.1492, Test Loss = 1.0132957696914673:.4f\n",
      "Epoch 2954: Train Loss = 0.1197, Test Loss = 0.9739415049552917:.4f\n",
      "Epoch 2955: Train Loss = 0.1150, Test Loss = 0.952698826789856:.4f\n",
      "Epoch 2956: Train Loss = 0.1214, Test Loss = 0.9465873837471008:.4f\n",
      "Epoch 2957: Train Loss = 0.1248, Test Loss = 0.9887296557426453:.4f\n",
      "Epoch 2958: Train Loss = 0.1085, Test Loss = 1.0067250728607178:.4f\n",
      "Epoch 2959: Train Loss = 0.1504, Test Loss = 1.018887996673584:.4f\n",
      "Epoch 2960: Train Loss = 0.1349, Test Loss = 1.0781787633895874:.4f\n",
      "Epoch 2961: Train Loss = 0.1166, Test Loss = 1.0326980352401733:.4f\n",
      "Epoch 2962: Train Loss = 0.1234, Test Loss = 0.9656124114990234:.4f\n",
      "Epoch 2963: Train Loss = 0.1299, Test Loss = 0.9570413827896118:.4f\n",
      "Epoch 2964: Train Loss = 0.1446, Test Loss = 0.9919657707214355:.4f\n",
      "Epoch 2965: Train Loss = 0.1262, Test Loss = 1.0341883897781372:.4f\n",
      "Epoch 2966: Train Loss = 0.1452, Test Loss = 1.0627888441085815:.4f\n",
      "Epoch 2967: Train Loss = 0.1299, Test Loss = 1.0854206085205078:.4f\n",
      "Epoch 2968: Train Loss = 0.1454, Test Loss = 1.0187606811523438:.4f\n",
      "Epoch 2969: Train Loss = 0.1416, Test Loss = 1.0268442630767822:.4f\n",
      "Epoch 2970: Train Loss = 0.1427, Test Loss = 0.9888774156570435:.4f\n",
      "Epoch 2971: Train Loss = 0.1288, Test Loss = 0.9798277020454407:.4f\n",
      "Epoch 2972: Train Loss = 0.1224, Test Loss = 0.9646720886230469:.4f\n",
      "Epoch 2973: Train Loss = 0.1734, Test Loss = 0.9349260330200195:.4f\n",
      "Epoch 2974: Train Loss = 0.1125, Test Loss = 1.0056989192962646:.4f\n",
      "Epoch 2975: Train Loss = 0.1377, Test Loss = 1.0559289455413818:.4f\n",
      "Epoch 2976: Train Loss = 0.1343, Test Loss = 1.0583385229110718:.4f\n",
      "Epoch 2977: Train Loss = 0.1334, Test Loss = 1.0439996719360352:.4f\n",
      "Epoch 2978: Train Loss = 0.1247, Test Loss = 0.9921836853027344:.4f\n",
      "Epoch 2979: Train Loss = 0.1155, Test Loss = 0.924771785736084:.4f\n",
      "Epoch 2980: Train Loss = 0.1178, Test Loss = 0.9076064229011536:.4f\n",
      "Epoch 2981: Train Loss = 0.1314, Test Loss = 0.9431151151657104:.4f\n",
      "Epoch 2982: Train Loss = 0.1259, Test Loss = 1.0029429197311401:.4f\n",
      "Epoch 2983: Train Loss = 0.1374, Test Loss = 1.0170977115631104:.4f\n",
      "Epoch 2984: Train Loss = 0.1250, Test Loss = 0.9911140203475952:.4f\n",
      "Epoch 2985: Train Loss = 0.1509, Test Loss = 0.9534462690353394:.4f\n",
      "Epoch 2986: Train Loss = 0.1618, Test Loss = 1.0106351375579834:.4f\n",
      "Epoch 2987: Train Loss = 0.1767, Test Loss = 1.1476608514785767:.4f\n",
      "Epoch 2988: Train Loss = 0.1236, Test Loss = 1.0752270221710205:.4f\n",
      "Epoch 2989: Train Loss = 0.1216, Test Loss = 1.018774151802063:.4f\n",
      "Epoch 2990: Train Loss = 0.1436, Test Loss = 0.9105766415596008:.4f\n",
      "Epoch 2991: Train Loss = 0.1295, Test Loss = 0.920082688331604:.4f\n",
      "Epoch 2992: Train Loss = 0.1430, Test Loss = 0.9611164331436157:.4f\n",
      "Epoch 2993: Train Loss = 0.1304, Test Loss = 1.0533336400985718:.4f\n",
      "Epoch 2994: Train Loss = 0.1489, Test Loss = 1.144489049911499:.4f\n",
      "Epoch 2995: Train Loss = 0.1531, Test Loss = 1.113147258758545:.4f\n",
      "Epoch 2996: Train Loss = 0.1272, Test Loss = 0.9975628852844238:.4f\n",
      "Epoch 2997: Train Loss = 0.1216, Test Loss = 0.9135206341743469:.4f\n",
      "Epoch 2998: Train Loss = 0.1876, Test Loss = 0.8944052457809448:.4f\n",
      "Epoch 2999: Train Loss = 0.1277, Test Loss = 0.9948480725288391:.4f\n",
      "Epoch 3000: Train Loss = 0.1463, Test Loss = 1.1109082698822021:.4f\n",
      "Epoch 3001: Train Loss = 0.1332, Test Loss = 1.1045846939086914:.4f\n",
      "Epoch 3002: Train Loss = 0.1358, Test Loss = 1.0982370376586914:.4f\n",
      "Epoch 3003: Train Loss = 0.1389, Test Loss = 1.1104212999343872:.4f\n",
      "Epoch 3004: Train Loss = 0.1322, Test Loss = 1.0706840753555298:.4f\n",
      "Epoch 3005: Train Loss = 0.1526, Test Loss = 0.9913898706436157:.4f\n",
      "Epoch 3006: Train Loss = 0.1113, Test Loss = 0.9940409660339355:.4f\n",
      "Epoch 3007: Train Loss = 0.1302, Test Loss = 0.9940029978752136:.4f\n",
      "Epoch 3008: Train Loss = 0.1264, Test Loss = 1.0083578824996948:.4f\n",
      "Epoch 3009: Train Loss = 0.1509, Test Loss = 1.0366384983062744:.4f\n",
      "Epoch 3010: Train Loss = 0.1660, Test Loss = 1.0020778179168701:.4f\n",
      "Epoch 3011: Train Loss = 0.1410, Test Loss = 1.013615369796753:.4f\n",
      "Epoch 3012: Train Loss = 0.1354, Test Loss = 1.0716979503631592:.4f\n",
      "Epoch 3013: Train Loss = 0.1224, Test Loss = 1.0855762958526611:.4f\n",
      "Epoch 3014: Train Loss = 0.1388, Test Loss = 1.0488845109939575:.4f\n",
      "Epoch 3015: Train Loss = 0.1202, Test Loss = 1.0517996549606323:.4f\n",
      "Epoch 3016: Train Loss = 0.1187, Test Loss = 0.9931795001029968:.4f\n",
      "Epoch 3017: Train Loss = 0.1242, Test Loss = 0.9340417981147766:.4f\n",
      "Epoch 3018: Train Loss = 0.1418, Test Loss = 0.9368343353271484:.4f\n",
      "Epoch 3019: Train Loss = 0.1092, Test Loss = 1.0142571926116943:.4f\n",
      "Epoch 3020: Train Loss = 0.1179, Test Loss = 1.0526773929595947:.4f\n",
      "Epoch 3021: Train Loss = 0.1159, Test Loss = 1.0145790576934814:.4f\n",
      "Epoch 3022: Train Loss = 0.1376, Test Loss = 0.946262538433075:.4f\n",
      "Epoch 3023: Train Loss = 0.1233, Test Loss = 0.9221124649047852:.4f\n",
      "Epoch 3024: Train Loss = 0.1539, Test Loss = 0.9313074946403503:.4f\n",
      "Epoch 3025: Train Loss = 0.1228, Test Loss = 0.9953564405441284:.4f\n",
      "Epoch 3026: Train Loss = 0.1231, Test Loss = 1.0293877124786377:.4f\n",
      "Epoch 3027: Train Loss = 0.1337, Test Loss = 1.0203710794448853:.4f\n",
      "Epoch 3028: Train Loss = 0.1434, Test Loss = 0.9564775228500366:.4f\n",
      "Epoch 3029: Train Loss = 0.1721, Test Loss = 0.9250297546386719:.4f\n",
      "Epoch 3030: Train Loss = 0.1329, Test Loss = 1.034928560256958:.4f\n",
      "Epoch 3031: Train Loss = 0.1405, Test Loss = 1.1761330366134644:.4f\n",
      "Epoch 3032: Train Loss = 0.1765, Test Loss = 1.1615126132965088:.4f\n",
      "Epoch 3033: Train Loss = 0.1373, Test Loss = 1.066589593887329:.4f\n",
      "Epoch 3034: Train Loss = 0.1242, Test Loss = 0.9779354333877563:.4f\n",
      "Epoch 3035: Train Loss = 0.1276, Test Loss = 0.9337732195854187:.4f\n",
      "Epoch 3036: Train Loss = 0.1568, Test Loss = 0.9677645564079285:.4f\n",
      "Epoch 3037: Train Loss = 0.1272, Test Loss = 1.0514529943466187:.4f\n",
      "Epoch 3038: Train Loss = 0.1231, Test Loss = 1.0445187091827393:.4f\n",
      "Epoch 3039: Train Loss = 0.1295, Test Loss = 1.0163503885269165:.4f\n",
      "Epoch 3040: Train Loss = 0.1267, Test Loss = 1.0141077041625977:.4f\n",
      "Epoch 3041: Train Loss = 0.1292, Test Loss = 1.0053324699401855:.4f\n",
      "Epoch 3042: Train Loss = 0.1242, Test Loss = 0.9731472730636597:.4f\n",
      "Epoch 3043: Train Loss = 0.1062, Test Loss = 0.9436230659484863:.4f\n",
      "Epoch 3044: Train Loss = 0.1586, Test Loss = 0.9286877512931824:.4f\n",
      "Epoch 3045: Train Loss = 0.1109, Test Loss = 0.9910710453987122:.4f\n",
      "Epoch 3046: Train Loss = 0.1093, Test Loss = 1.031868577003479:.4f\n",
      "Epoch 3047: Train Loss = 0.1259, Test Loss = 1.0566929578781128:.4f\n",
      "Epoch 3048: Train Loss = 0.1389, Test Loss = 1.0509237051010132:.4f\n",
      "Epoch 3049: Train Loss = 0.1519, Test Loss = 0.9587447047233582:.4f\n",
      "Epoch 3050: Train Loss = 0.1208, Test Loss = 0.9468939900398254:.4f\n",
      "Epoch 3051: Train Loss = 0.1152, Test Loss = 0.9768859148025513:.4f\n",
      "Epoch 3052: Train Loss = 0.1229, Test Loss = 0.9910992383956909:.4f\n",
      "Epoch 3053: Train Loss = 0.1101, Test Loss = 0.9702504873275757:.4f\n",
      "Epoch 3054: Train Loss = 0.1207, Test Loss = 0.9812909960746765:.4f\n",
      "Epoch 3055: Train Loss = 0.1244, Test Loss = 0.9725452661514282:.4f\n",
      "Epoch 3056: Train Loss = 0.1088, Test Loss = 0.9789682626724243:.4f\n",
      "Epoch 3057: Train Loss = 0.1218, Test Loss = 0.9799315333366394:.4f\n",
      "Epoch 3058: Train Loss = 0.1245, Test Loss = 1.0165553092956543:.4f\n",
      "Epoch 3059: Train Loss = 0.1545, Test Loss = 1.028099775314331:.4f\n",
      "Epoch 3060: Train Loss = 0.1106, Test Loss = 1.0852937698364258:.4f\n",
      "Epoch 3061: Train Loss = 0.1465, Test Loss = 1.0794477462768555:.4f\n",
      "Epoch 3062: Train Loss = 0.1387, Test Loss = 1.0309350490570068:.4f\n",
      "Epoch 3063: Train Loss = 0.1220, Test Loss = 1.041229248046875:.4f\n",
      "Epoch 3064: Train Loss = 0.1531, Test Loss = 1.0340781211853027:.4f\n",
      "Epoch 3065: Train Loss = 0.1128, Test Loss = 1.0330512523651123:.4f\n",
      "Epoch 3066: Train Loss = 0.1187, Test Loss = 1.0088095664978027:.4f\n",
      "Epoch 3067: Train Loss = 0.1297, Test Loss = 0.9833943247795105:.4f\n",
      "Epoch 3068: Train Loss = 0.1255, Test Loss = 0.9271500706672668:.4f\n",
      "Epoch 3069: Train Loss = 0.1168, Test Loss = 0.9201266169548035:.4f\n",
      "Epoch 3070: Train Loss = 0.1187, Test Loss = 0.9455175399780273:.4f\n",
      "Epoch 3071: Train Loss = 0.1166, Test Loss = 0.9603804349899292:.4f\n",
      "Epoch 3072: Train Loss = 0.1291, Test Loss = 0.9978886842727661:.4f\n",
      "Epoch 3073: Train Loss = 0.1318, Test Loss = 1.05587899684906:.4f\n",
      "Epoch 3074: Train Loss = 0.1269, Test Loss = 1.0119874477386475:.4f\n",
      "Epoch 3075: Train Loss = 0.1295, Test Loss = 1.0155370235443115:.4f\n",
      "Epoch 3076: Train Loss = 0.1241, Test Loss = 0.9411970376968384:.4f\n",
      "Epoch 3077: Train Loss = 0.1232, Test Loss = 0.9355499148368835:.4f\n",
      "Epoch 3078: Train Loss = 0.1206, Test Loss = 0.9472028613090515:.4f\n",
      "Epoch 3079: Train Loss = 0.1206, Test Loss = 0.9439210891723633:.4f\n",
      "Epoch 3080: Train Loss = 0.1272, Test Loss = 0.9388526082038879:.4f\n",
      "Epoch 3081: Train Loss = 0.1680, Test Loss = 0.9503847360610962:.4f\n",
      "Epoch 3082: Train Loss = 0.1105, Test Loss = 1.0068917274475098:.4f\n",
      "Epoch 3083: Train Loss = 0.1248, Test Loss = 1.0370917320251465:.4f\n",
      "Epoch 3084: Train Loss = 0.1216, Test Loss = 1.0442938804626465:.4f\n",
      "Epoch 3085: Train Loss = 0.1374, Test Loss = 1.0251749753952026:.4f\n",
      "Epoch 3086: Train Loss = 0.1229, Test Loss = 0.9591167569160461:.4f\n",
      "Epoch 3087: Train Loss = 0.1472, Test Loss = 0.9577005505561829:.4f\n",
      "Epoch 3088: Train Loss = 0.1195, Test Loss = 0.9791673421859741:.4f\n",
      "Epoch 3089: Train Loss = 0.1350, Test Loss = 0.9734694361686707:.4f\n",
      "Epoch 3090: Train Loss = 0.1236, Test Loss = 1.0224486589431763:.4f\n",
      "Epoch 3091: Train Loss = 0.1252, Test Loss = 1.050847053527832:.4f\n",
      "Epoch 3092: Train Loss = 0.1384, Test Loss = 1.0343139171600342:.4f\n",
      "Epoch 3093: Train Loss = 0.1108, Test Loss = 1.052616000175476:.4f\n",
      "Epoch 3094: Train Loss = 0.1269, Test Loss = 1.028794288635254:.4f\n",
      "Epoch 3095: Train Loss = 0.1270, Test Loss = 0.9922856092453003:.4f\n",
      "Epoch 3096: Train Loss = 0.1324, Test Loss = 1.0043882131576538:.4f\n",
      "Epoch 3097: Train Loss = 0.1338, Test Loss = 1.0543944835662842:.4f\n",
      "Epoch 3098: Train Loss = 0.1238, Test Loss = 1.053864598274231:.4f\n",
      "Epoch 3099: Train Loss = 0.1147, Test Loss = 1.0141443014144897:.4f\n",
      "Epoch 3100: Train Loss = 0.1178, Test Loss = 0.9474935531616211:.4f\n",
      "Epoch 3101: Train Loss = 0.1205, Test Loss = 0.9759424924850464:.4f\n",
      "Epoch 3102: Train Loss = 0.1114, Test Loss = 0.9974448084831238:.4f\n",
      "Epoch 3103: Train Loss = 0.1207, Test Loss = 1.0118622779846191:.4f\n",
      "Epoch 3104: Train Loss = 0.1274, Test Loss = 1.0117366313934326:.4f\n",
      "Epoch 3105: Train Loss = 0.1377, Test Loss = 0.9930917024612427:.4f\n",
      "Epoch 3106: Train Loss = 0.1439, Test Loss = 0.9877969622612:.4f\n",
      "Epoch 3107: Train Loss = 0.1469, Test Loss = 1.0357224941253662:.4f\n",
      "Epoch 3108: Train Loss = 0.1067, Test Loss = 1.0275911092758179:.4f\n",
      "Epoch 3109: Train Loss = 0.1218, Test Loss = 1.001646637916565:.4f\n",
      "Epoch 3110: Train Loss = 0.1339, Test Loss = 0.9967861175537109:.4f\n",
      "Epoch 3111: Train Loss = 0.1298, Test Loss = 1.0678035020828247:.4f\n",
      "Epoch 3112: Train Loss = 0.1392, Test Loss = 1.10536789894104:.4f\n",
      "Epoch 3113: Train Loss = 0.1144, Test Loss = 1.0433413982391357:.4f\n",
      "Epoch 3114: Train Loss = 0.1345, Test Loss = 1.003678560256958:.4f\n",
      "Epoch 3115: Train Loss = 0.1308, Test Loss = 0.9972833395004272:.4f\n",
      "Epoch 3116: Train Loss = 0.1294, Test Loss = 1.0453251600265503:.4f\n",
      "Epoch 3117: Train Loss = 0.1318, Test Loss = 1.010278582572937:.4f\n",
      "Epoch 3118: Train Loss = 0.1657, Test Loss = 0.9489153027534485:.4f\n",
      "Epoch 3119: Train Loss = 0.1150, Test Loss = 0.9694569706916809:.4f\n",
      "Epoch 3120: Train Loss = 0.1199, Test Loss = 0.9976795315742493:.4f\n",
      "Epoch 3121: Train Loss = 0.1191, Test Loss = 1.000765323638916:.4f\n",
      "Epoch 3122: Train Loss = 0.1176, Test Loss = 0.988144040107727:.4f\n",
      "Epoch 3123: Train Loss = 0.1218, Test Loss = 0.9975382685661316:.4f\n",
      "Epoch 3124: Train Loss = 0.1268, Test Loss = 1.0527013540267944:.4f\n",
      "Epoch 3125: Train Loss = 0.1179, Test Loss = 0.9997093081474304:.4f\n",
      "Epoch 3126: Train Loss = 0.1417, Test Loss = 0.975186824798584:.4f\n",
      "Epoch 3127: Train Loss = 0.1272, Test Loss = 0.9846059679985046:.4f\n",
      "Epoch 3128: Train Loss = 0.1308, Test Loss = 0.9919803738594055:.4f\n",
      "Epoch 3129: Train Loss = 0.1315, Test Loss = 1.0119277238845825:.4f\n",
      "Epoch 3130: Train Loss = 0.1193, Test Loss = 1.0735865831375122:.4f\n",
      "Epoch 3131: Train Loss = 0.1250, Test Loss = 1.0698987245559692:.4f\n",
      "Epoch 3132: Train Loss = 0.1216, Test Loss = 1.0732784271240234:.4f\n",
      "Epoch 3133: Train Loss = 0.1136, Test Loss = 0.9963943362236023:.4f\n",
      "Epoch 3134: Train Loss = 0.1331, Test Loss = 0.9429229497909546:.4f\n",
      "Epoch 3135: Train Loss = 0.1311, Test Loss = 0.9658985137939453:.4f\n",
      "Epoch 3136: Train Loss = 0.1209, Test Loss = 0.9616654515266418:.4f\n",
      "Epoch 3137: Train Loss = 0.1125, Test Loss = 0.9845448732376099:.4f\n",
      "Epoch 3138: Train Loss = 0.1501, Test Loss = 0.9860588908195496:.4f\n",
      "Epoch 3139: Train Loss = 0.1285, Test Loss = 1.0667145252227783:.4f\n",
      "Epoch 3140: Train Loss = 0.1187, Test Loss = 1.0980876684188843:.4f\n",
      "Epoch 3141: Train Loss = 0.1191, Test Loss = 1.0472705364227295:.4f\n",
      "Epoch 3142: Train Loss = 0.1038, Test Loss = 0.9676543474197388:.4f\n",
      "Epoch 3143: Train Loss = 0.1384, Test Loss = 0.9420547485351562:.4f\n",
      "Epoch 3144: Train Loss = 0.1501, Test Loss = 1.0038033723831177:.4f\n",
      "Epoch 3145: Train Loss = 0.1416, Test Loss = 1.0651352405548096:.4f\n",
      "Epoch 3146: Train Loss = 0.1312, Test Loss = 1.0884995460510254:.4f\n",
      "Epoch 3147: Train Loss = 0.1438, Test Loss = 1.0235024690628052:.4f\n",
      "Epoch 3148: Train Loss = 0.1428, Test Loss = 0.9494600296020508:.4f\n",
      "Epoch 3149: Train Loss = 0.1195, Test Loss = 0.974301815032959:.4f\n",
      "Epoch 3150: Train Loss = 0.1335, Test Loss = 0.9935541152954102:.4f\n",
      "Epoch 3151: Train Loss = 0.1353, Test Loss = 0.9746575355529785:.4f\n",
      "Epoch 3152: Train Loss = 0.1123, Test Loss = 1.0163183212280273:.4f\n",
      "Epoch 3153: Train Loss = 0.1522, Test Loss = 1.0534840822219849:.4f\n",
      "Epoch 3154: Train Loss = 0.1231, Test Loss = 1.0424622297286987:.4f\n",
      "Epoch 3155: Train Loss = 0.1302, Test Loss = 1.0705862045288086:.4f\n",
      "Epoch 3156: Train Loss = 0.1152, Test Loss = 0.9987038373947144:.4f\n",
      "Epoch 3157: Train Loss = 0.1239, Test Loss = 0.942699134349823:.4f\n",
      "Epoch 3158: Train Loss = 0.1553, Test Loss = 0.9366883039474487:.4f\n",
      "Epoch 3159: Train Loss = 0.1451, Test Loss = 1.0038810968399048:.4f\n",
      "Epoch 3160: Train Loss = 0.1280, Test Loss = 1.0743520259857178:.4f\n",
      "Epoch 3161: Train Loss = 0.1313, Test Loss = 1.1500009298324585:.4f\n",
      "Epoch 3162: Train Loss = 0.1225, Test Loss = 1.101282000541687:.4f\n",
      "Epoch 3163: Train Loss = 0.1273, Test Loss = 1.0203765630722046:.4f\n",
      "Epoch 3164: Train Loss = 0.1123, Test Loss = 0.9623312950134277:.4f\n",
      "Epoch 3165: Train Loss = 0.1184, Test Loss = 0.9562581181526184:.4f\n",
      "Epoch 3166: Train Loss = 0.1273, Test Loss = 0.9757081270217896:.4f\n",
      "Epoch 3167: Train Loss = 0.1147, Test Loss = 1.0515382289886475:.4f\n",
      "Epoch 3168: Train Loss = 0.1507, Test Loss = 1.093782901763916:.4f\n",
      "Epoch 3169: Train Loss = 0.1412, Test Loss = 0.987251877784729:.4f\n",
      "Epoch 3170: Train Loss = 0.1188, Test Loss = 0.9736120104789734:.4f\n",
      "Epoch 3171: Train Loss = 0.1361, Test Loss = 0.9717020988464355:.4f\n",
      "Epoch 3172: Train Loss = 0.1235, Test Loss = 0.9962724447250366:.4f\n",
      "Epoch 3173: Train Loss = 0.1508, Test Loss = 0.9734460115432739:.4f\n",
      "Epoch 3174: Train Loss = 0.1337, Test Loss = 1.0093486309051514:.4f\n",
      "Epoch 3175: Train Loss = 0.1089, Test Loss = 1.007283091545105:.4f\n",
      "Epoch 3176: Train Loss = 0.1331, Test Loss = 1.0043525695800781:.4f\n",
      "Epoch 3177: Train Loss = 0.1136, Test Loss = 1.044571042060852:.4f\n",
      "Epoch 3178: Train Loss = 0.1433, Test Loss = 1.0530283451080322:.4f\n",
      "Epoch 3179: Train Loss = 0.1133, Test Loss = 1.0414459705352783:.4f\n",
      "Epoch 3180: Train Loss = 0.1380, Test Loss = 1.0028349161148071:.4f\n",
      "Epoch 3181: Train Loss = 0.1114, Test Loss = 1.002576470375061:.4f\n",
      "Epoch 3182: Train Loss = 0.1228, Test Loss = 0.9937664270401001:.4f\n",
      "Epoch 3183: Train Loss = 0.1393, Test Loss = 0.9762237668037415:.4f\n",
      "Epoch 3184: Train Loss = 0.1269, Test Loss = 0.9986335039138794:.4f\n",
      "Epoch 3185: Train Loss = 0.1399, Test Loss = 0.9499332308769226:.4f\n",
      "Epoch 3186: Train Loss = 0.1171, Test Loss = 0.9947208166122437:.4f\n",
      "Epoch 3187: Train Loss = 0.1395, Test Loss = 0.9877120852470398:.4f\n",
      "Epoch 3188: Train Loss = 0.1237, Test Loss = 1.0283048152923584:.4f\n",
      "Epoch 3189: Train Loss = 0.1166, Test Loss = 1.0163404941558838:.4f\n",
      "Epoch 3190: Train Loss = 0.1290, Test Loss = 1.018123984336853:.4f\n",
      "Epoch 3191: Train Loss = 0.1152, Test Loss = 1.055320143699646:.4f\n",
      "Epoch 3192: Train Loss = 0.1395, Test Loss = 1.0588241815567017:.4f\n",
      "Epoch 3193: Train Loss = 0.1183, Test Loss = 0.99781334400177:.4f\n",
      "Epoch 3194: Train Loss = 0.1175, Test Loss = 0.9472944140434265:.4f\n",
      "Epoch 3195: Train Loss = 0.1468, Test Loss = 0.9630010724067688:.4f\n",
      "Epoch 3196: Train Loss = 0.1225, Test Loss = 1.0625678300857544:.4f\n",
      "Epoch 3197: Train Loss = 0.1305, Test Loss = 1.1529074907302856:.4f\n",
      "Epoch 3198: Train Loss = 0.1330, Test Loss = 1.1081172227859497:.4f\n",
      "Epoch 3199: Train Loss = 0.1085, Test Loss = 1.057504415512085:.4f\n",
      "Epoch 3200: Train Loss = 0.1350, Test Loss = 1.0020378828048706:.4f\n",
      "Epoch 3201: Train Loss = 0.1156, Test Loss = 1.01734459400177:.4f\n",
      "Epoch 3202: Train Loss = 0.1119, Test Loss = 1.042235016822815:.4f\n",
      "Epoch 3203: Train Loss = 0.1170, Test Loss = 1.0301872491836548:.4f\n",
      "Epoch 3204: Train Loss = 0.1363, Test Loss = 1.011579990386963:.4f\n",
      "Epoch 3205: Train Loss = 0.1144, Test Loss = 1.0212002992630005:.4f\n",
      "Epoch 3206: Train Loss = 0.1111, Test Loss = 1.0077356100082397:.4f\n",
      "Epoch 3207: Train Loss = 0.1121, Test Loss = 1.0091145038604736:.4f\n",
      "Epoch 3208: Train Loss = 0.1330, Test Loss = 0.9822831153869629:.4f\n",
      "Epoch 3209: Train Loss = 0.1331, Test Loss = 0.9476028680801392:.4f\n",
      "Epoch 3210: Train Loss = 0.1249, Test Loss = 0.9746252298355103:.4f\n",
      "Epoch 3211: Train Loss = 0.1187, Test Loss = 1.015444278717041:.4f\n",
      "Epoch 3212: Train Loss = 0.1228, Test Loss = 1.0228099822998047:.4f\n",
      "Epoch 3213: Train Loss = 0.1439, Test Loss = 1.0267072916030884:.4f\n",
      "Epoch 3214: Train Loss = 0.1353, Test Loss = 1.073547124862671:.4f\n",
      "Epoch 3215: Train Loss = 0.1490, Test Loss = 1.1068265438079834:.4f\n",
      "Epoch 3216: Train Loss = 0.1613, Test Loss = 1.0725467205047607:.4f\n",
      "Epoch 3217: Train Loss = 0.1313, Test Loss = 1.0858750343322754:.4f\n",
      "Epoch 3218: Train Loss = 0.1385, Test Loss = 1.0364916324615479:.4f\n",
      "Epoch 3219: Train Loss = 0.1175, Test Loss = 0.9988430738449097:.4f\n",
      "Epoch 3220: Train Loss = 0.1140, Test Loss = 0.9753977656364441:.4f\n",
      "Epoch 3221: Train Loss = 0.1277, Test Loss = 0.9814737439155579:.4f\n",
      "Epoch 3222: Train Loss = 0.1303, Test Loss = 0.9609962701797485:.4f\n",
      "Epoch 3223: Train Loss = 0.1374, Test Loss = 0.9799644351005554:.4f\n",
      "Epoch 3224: Train Loss = 0.1156, Test Loss = 1.0449824333190918:.4f\n",
      "Epoch 3225: Train Loss = 0.1462, Test Loss = 1.0670469999313354:.4f\n",
      "Epoch 3226: Train Loss = 0.1195, Test Loss = 1.0127511024475098:.4f\n",
      "Epoch 3227: Train Loss = 0.1256, Test Loss = 0.9803511500358582:.4f\n",
      "Epoch 3228: Train Loss = 0.1331, Test Loss = 0.9331097602844238:.4f\n",
      "Epoch 3229: Train Loss = 0.1864, Test Loss = 0.9367272257804871:.4f\n",
      "Epoch 3230: Train Loss = 0.1185, Test Loss = 1.0816131830215454:.4f\n",
      "Epoch 3231: Train Loss = 0.1286, Test Loss = 1.0845015048980713:.4f\n",
      "Epoch 3232: Train Loss = 0.1240, Test Loss = 0.9947002530097961:.4f\n",
      "Epoch 3233: Train Loss = 0.1375, Test Loss = 0.9701789021492004:.4f\n",
      "Epoch 3234: Train Loss = 0.1373, Test Loss = 0.9961841702461243:.4f\n",
      "Epoch 3235: Train Loss = 0.1255, Test Loss = 1.0419576168060303:.4f\n",
      "Epoch 3236: Train Loss = 0.1413, Test Loss = 1.0552470684051514:.4f\n",
      "Epoch 3237: Train Loss = 0.1555, Test Loss = 1.0766652822494507:.4f\n",
      "Epoch 3238: Train Loss = 0.1213, Test Loss = 1.0220692157745361:.4f\n",
      "Epoch 3239: Train Loss = 0.1392, Test Loss = 0.9574857950210571:.4f\n",
      "Epoch 3240: Train Loss = 0.1155, Test Loss = 0.9656674265861511:.4f\n",
      "Epoch 3241: Train Loss = 0.1251, Test Loss = 0.9954134821891785:.4f\n",
      "Epoch 3242: Train Loss = 0.1166, Test Loss = 0.9865782856941223:.4f\n",
      "Epoch 3243: Train Loss = 0.1234, Test Loss = 1.0147123336791992:.4f\n",
      "Epoch 3244: Train Loss = 0.1153, Test Loss = 1.003244400024414:.4f\n",
      "Epoch 3245: Train Loss = 0.1357, Test Loss = 1.0001475811004639:.4f\n",
      "Epoch 3246: Train Loss = 0.1166, Test Loss = 1.061428427696228:.4f\n",
      "Epoch 3247: Train Loss = 0.1178, Test Loss = 1.0751614570617676:.4f\n",
      "Epoch 3248: Train Loss = 0.1255, Test Loss = 1.050762414932251:.4f\n",
      "Epoch 3249: Train Loss = 0.1095, Test Loss = 0.9615594744682312:.4f\n",
      "Epoch 3250: Train Loss = 0.1156, Test Loss = 0.9386146664619446:.4f\n",
      "Epoch 3251: Train Loss = 0.1216, Test Loss = 0.9465935826301575:.4f\n",
      "Epoch 3252: Train Loss = 0.1588, Test Loss = 0.991554856300354:.4f\n",
      "Epoch 3253: Train Loss = 0.1141, Test Loss = 1.0274896621704102:.4f\n",
      "Epoch 3254: Train Loss = 0.1096, Test Loss = 1.01790452003479:.4f\n",
      "Epoch 3255: Train Loss = 0.1178, Test Loss = 1.0295535326004028:.4f\n",
      "Epoch 3256: Train Loss = 0.1161, Test Loss = 1.0186693668365479:.4f\n",
      "Epoch 3257: Train Loss = 0.1252, Test Loss = 0.9880779981613159:.4f\n",
      "Epoch 3258: Train Loss = 0.1233, Test Loss = 0.9615988731384277:.4f\n",
      "Epoch 3259: Train Loss = 0.1366, Test Loss = 0.9629985094070435:.4f\n",
      "Epoch 3260: Train Loss = 0.1314, Test Loss = 0.9664480090141296:.4f\n",
      "Epoch 3261: Train Loss = 0.1456, Test Loss = 0.9925462007522583:.4f\n",
      "Epoch 3262: Train Loss = 0.1609, Test Loss = 1.0366971492767334:.4f\n",
      "Epoch 3263: Train Loss = 0.1188, Test Loss = 1.1221320629119873:.4f\n",
      "Epoch 3264: Train Loss = 0.1763, Test Loss = 1.090877652168274:.4f\n",
      "Epoch 3265: Train Loss = 0.1063, Test Loss = 0.9200873374938965:.4f\n",
      "Epoch 3266: Train Loss = 0.1175, Test Loss = 0.8453429937362671:.4f\n",
      "Epoch 3267: Train Loss = 0.1261, Test Loss = 0.8724187612533569:.4f\n",
      "Epoch 3268: Train Loss = 0.1216, Test Loss = 0.9547712206840515:.4f\n",
      "Epoch 3269: Train Loss = 0.1191, Test Loss = 1.0134952068328857:.4f\n",
      "Epoch 3270: Train Loss = 0.1201, Test Loss = 1.0303263664245605:.4f\n",
      "Epoch 3271: Train Loss = 0.1129, Test Loss = 1.0416018962860107:.4f\n",
      "Epoch 3272: Train Loss = 0.1048, Test Loss = 1.0350900888442993:.4f\n",
      "Epoch 3273: Train Loss = 0.1363, Test Loss = 1.003639817237854:.4f\n",
      "Epoch 3274: Train Loss = 0.1225, Test Loss = 1.0182253122329712:.4f\n",
      "Epoch 3275: Train Loss = 0.1480, Test Loss = 1.0080461502075195:.4f\n",
      "Epoch 3276: Train Loss = 0.1047, Test Loss = 1.0544804334640503:.4f\n",
      "Epoch 3277: Train Loss = 0.1128, Test Loss = 1.0850836038589478:.4f\n",
      "Epoch 3278: Train Loss = 0.1168, Test Loss = 1.0723456144332886:.4f\n",
      "Epoch 3279: Train Loss = 0.1052, Test Loss = 1.0491926670074463:.4f\n",
      "Epoch 3280: Train Loss = 0.1098, Test Loss = 1.046262502670288:.4f\n",
      "Epoch 3281: Train Loss = 0.1243, Test Loss = 1.0370488166809082:.4f\n",
      "Epoch 3282: Train Loss = 0.1152, Test Loss = 1.003043532371521:.4f\n",
      "Epoch 3283: Train Loss = 0.1194, Test Loss = 0.9507139921188354:.4f\n",
      "Epoch 3284: Train Loss = 0.1626, Test Loss = 0.9451603889465332:.4f\n",
      "Epoch 3285: Train Loss = 0.1215, Test Loss = 1.038755178451538:.4f\n",
      "Epoch 3286: Train Loss = 0.1458, Test Loss = 1.0752465724945068:.4f\n",
      "Epoch 3287: Train Loss = 0.1543, Test Loss = 1.0273077487945557:.4f\n",
      "Epoch 3288: Train Loss = 0.1154, Test Loss = 1.0503332614898682:.4f\n",
      "Epoch 3289: Train Loss = 0.1183, Test Loss = 1.0275843143463135:.4f\n",
      "Epoch 3290: Train Loss = 0.1164, Test Loss = 1.0143572092056274:.4f\n",
      "Epoch 3291: Train Loss = 0.1119, Test Loss = 1.0114134550094604:.4f\n",
      "Epoch 3292: Train Loss = 0.1172, Test Loss = 1.0076475143432617:.4f\n",
      "Epoch 3293: Train Loss = 0.1349, Test Loss = 1.0148556232452393:.4f\n",
      "Epoch 3294: Train Loss = 0.1177, Test Loss = 1.007033109664917:.4f\n",
      "Epoch 3295: Train Loss = 0.1181, Test Loss = 1.0314606428146362:.4f\n",
      "Epoch 3296: Train Loss = 0.1182, Test Loss = 1.0277258157730103:.4f\n",
      "Epoch 3297: Train Loss = 0.1231, Test Loss = 1.0221443176269531:.4f\n",
      "Epoch 3298: Train Loss = 0.1239, Test Loss = 0.9861987233161926:.4f\n",
      "Epoch 3299: Train Loss = 0.1239, Test Loss = 0.9372878074645996:.4f\n",
      "Epoch 3300: Train Loss = 0.1229, Test Loss = 0.9587782621383667:.4f\n",
      "Epoch 3301: Train Loss = 0.1287, Test Loss = 1.0154473781585693:.4f\n",
      "Epoch 3302: Train Loss = 0.1260, Test Loss = 0.9836796522140503:.4f\n",
      "Epoch 3303: Train Loss = 0.1102, Test Loss = 0.9517819285392761:.4f\n",
      "Epoch 3304: Train Loss = 0.1269, Test Loss = 0.9569627642631531:.4f\n",
      "Epoch 3305: Train Loss = 0.1242, Test Loss = 0.9765123128890991:.4f\n",
      "Epoch 3306: Train Loss = 0.1107, Test Loss = 0.9822837114334106:.4f\n",
      "Epoch 3307: Train Loss = 0.1339, Test Loss = 0.9920679926872253:.4f\n",
      "Epoch 3308: Train Loss = 0.1386, Test Loss = 1.0130715370178223:.4f\n",
      "Epoch 3309: Train Loss = 0.1259, Test Loss = 1.006659984588623:.4f\n",
      "Epoch 3310: Train Loss = 0.1079, Test Loss = 0.9672098159790039:.4f\n",
      "Epoch 3311: Train Loss = 0.1175, Test Loss = 0.9635893702507019:.4f\n",
      "Epoch 3312: Train Loss = 0.1107, Test Loss = 0.9702022671699524:.4f\n",
      "Epoch 3313: Train Loss = 0.1277, Test Loss = 0.9699136018753052:.4f\n",
      "Epoch 3314: Train Loss = 0.1394, Test Loss = 0.9415519833564758:.4f\n",
      "Epoch 3315: Train Loss = 0.1202, Test Loss = 1.0165914297103882:.4f\n",
      "Epoch 3316: Train Loss = 0.1287, Test Loss = 1.0419261455535889:.4f\n",
      "Epoch 3317: Train Loss = 0.1222, Test Loss = 1.0355335474014282:.4f\n",
      "Epoch 3318: Train Loss = 0.1088, Test Loss = 0.9687674641609192:.4f\n",
      "Epoch 3319: Train Loss = 0.1285, Test Loss = 0.9230955243110657:.4f\n",
      "Epoch 3320: Train Loss = 0.1131, Test Loss = 0.9554736018180847:.4f\n",
      "Epoch 3321: Train Loss = 0.1396, Test Loss = 0.9706047177314758:.4f\n",
      "Epoch 3322: Train Loss = 0.1286, Test Loss = 0.9837146997451782:.4f\n",
      "Epoch 3323: Train Loss = 0.1576, Test Loss = 0.9900975227355957:.4f\n",
      "Epoch 3324: Train Loss = 0.1379, Test Loss = 1.0600274801254272:.4f\n",
      "Epoch 3325: Train Loss = 0.1420, Test Loss = 1.126147985458374:.4f\n",
      "Epoch 3326: Train Loss = 0.1294, Test Loss = 1.0500305891036987:.4f\n",
      "Epoch 3327: Train Loss = 0.1100, Test Loss = 0.9653137922286987:.4f\n",
      "Epoch 3328: Train Loss = 0.1216, Test Loss = 0.9450902938842773:.4f\n",
      "Epoch 3329: Train Loss = 0.1413, Test Loss = 0.9862233400344849:.4f\n",
      "Epoch 3330: Train Loss = 0.1487, Test Loss = 1.0847277641296387:.4f\n",
      "Epoch 3331: Train Loss = 0.1234, Test Loss = 1.1519790887832642:.4f\n",
      "Epoch 3332: Train Loss = 0.1393, Test Loss = 1.0937013626098633:.4f\n",
      "Epoch 3333: Train Loss = 0.1249, Test Loss = 0.9496118426322937:.4f\n",
      "Epoch 3334: Train Loss = 0.1460, Test Loss = 0.9285570979118347:.4f\n",
      "Epoch 3335: Train Loss = 0.1143, Test Loss = 0.9917869567871094:.4f\n",
      "Epoch 3336: Train Loss = 0.1138, Test Loss = 1.0567982196807861:.4f\n",
      "Epoch 3337: Train Loss = 0.1285, Test Loss = 1.0473624467849731:.4f\n",
      "Epoch 3338: Train Loss = 0.1089, Test Loss = 1.0127060413360596:.4f\n",
      "Epoch 3339: Train Loss = 0.1227, Test Loss = 0.9610767364501953:.4f\n",
      "Epoch 3340: Train Loss = 0.1689, Test Loss = 0.9656332731246948:.4f\n",
      "Epoch 3341: Train Loss = 0.1439, Test Loss = 1.0877447128295898:.4f\n",
      "Epoch 3342: Train Loss = 0.1022, Test Loss = 1.1671290397644043:.4f\n",
      "Epoch 3343: Train Loss = 0.1358, Test Loss = 1.161215901374817:.4f\n",
      "Epoch 3344: Train Loss = 0.1391, Test Loss = 1.030029535293579:.4f\n",
      "Epoch 3345: Train Loss = 0.1150, Test Loss = 0.9472759366035461:.4f\n",
      "Epoch 3346: Train Loss = 0.1095, Test Loss = 0.9448992609977722:.4f\n",
      "Epoch 3347: Train Loss = 0.1225, Test Loss = 0.9714543223381042:.4f\n",
      "Epoch 3348: Train Loss = 0.1188, Test Loss = 1.0110087394714355:.4f\n",
      "Epoch 3349: Train Loss = 0.1110, Test Loss = 1.0436527729034424:.4f\n",
      "Epoch 3350: Train Loss = 0.1136, Test Loss = 1.0361008644104004:.4f\n",
      "Epoch 3351: Train Loss = 0.1139, Test Loss = 1.0342613458633423:.4f\n",
      "Epoch 3352: Train Loss = 0.1362, Test Loss = 1.0267401933670044:.4f\n",
      "Epoch 3353: Train Loss = 0.1184, Test Loss = 1.1067181825637817:.4f\n",
      "Epoch 3354: Train Loss = 0.1229, Test Loss = 1.1008373498916626:.4f\n",
      "Epoch 3355: Train Loss = 0.1397, Test Loss = 1.0313023328781128:.4f\n",
      "Epoch 3356: Train Loss = 0.1091, Test Loss = 0.9951121211051941:.4f\n",
      "Epoch 3357: Train Loss = 0.1401, Test Loss = 1.0087080001831055:.4f\n",
      "Epoch 3358: Train Loss = 0.1095, Test Loss = 1.0176746845245361:.4f\n",
      "Epoch 3359: Train Loss = 0.1481, Test Loss = 1.023066759109497:.4f\n",
      "Epoch 3360: Train Loss = 0.1172, Test Loss = 1.0309531688690186:.4f\n",
      "Epoch 3361: Train Loss = 0.1219, Test Loss = 1.0720677375793457:.4f\n",
      "Epoch 3362: Train Loss = 0.1085, Test Loss = 1.0772901773452759:.4f\n",
      "Epoch 3363: Train Loss = 0.1078, Test Loss = 1.0503755807876587:.4f\n",
      "Epoch 3364: Train Loss = 0.1054, Test Loss = 1.009243130683899:.4f\n",
      "Epoch 3365: Train Loss = 0.1087, Test Loss = 0.9924470782279968:.4f\n",
      "Epoch 3366: Train Loss = 0.1203, Test Loss = 1.0171607732772827:.4f\n",
      "Epoch 3367: Train Loss = 0.1586, Test Loss = 1.0228837728500366:.4f\n",
      "Epoch 3368: Train Loss = 0.1431, Test Loss = 1.076470971107483:.4f\n",
      "Epoch 3369: Train Loss = 0.1319, Test Loss = 1.0818778276443481:.4f\n",
      "Epoch 3370: Train Loss = 0.1371, Test Loss = 1.112097144126892:.4f\n",
      "Epoch 3371: Train Loss = 0.1298, Test Loss = 1.0821791887283325:.4f\n",
      "Epoch 3372: Train Loss = 0.1556, Test Loss = 0.9955400228500366:.4f\n",
      "Epoch 3373: Train Loss = 0.1261, Test Loss = 0.9867626428604126:.4f\n",
      "Epoch 3374: Train Loss = 0.1107, Test Loss = 1.049660563468933:.4f\n",
      "Epoch 3375: Train Loss = 0.1542, Test Loss = 1.048324704170227:.4f\n",
      "Epoch 3376: Train Loss = 0.1324, Test Loss = 1.0342307090759277:.4f\n",
      "Epoch 3377: Train Loss = 0.1050, Test Loss = 1.028099775314331:.4f\n",
      "Epoch 3378: Train Loss = 0.1429, Test Loss = 1.0387051105499268:.4f\n",
      "Epoch 3379: Train Loss = 0.1437, Test Loss = 1.0693928003311157:.4f\n",
      "Epoch 3380: Train Loss = 0.1122, Test Loss = 1.0398919582366943:.4f\n",
      "Epoch 3381: Train Loss = 0.1575, Test Loss = 0.9869827032089233:.4f\n",
      "Epoch 3382: Train Loss = 0.1280, Test Loss = 1.0632014274597168:.4f\n",
      "Epoch 3383: Train Loss = 0.1334, Test Loss = 1.1202311515808105:.4f\n",
      "Epoch 3384: Train Loss = 0.1109, Test Loss = 1.0400162935256958:.4f\n",
      "Epoch 3385: Train Loss = 0.1105, Test Loss = 0.9544388055801392:.4f\n",
      "Epoch 3386: Train Loss = 0.1521, Test Loss = 0.9433848261833191:.4f\n",
      "Epoch 3387: Train Loss = 0.1184, Test Loss = 1.0186078548431396:.4f\n",
      "Epoch 3388: Train Loss = 0.1222, Test Loss = 1.0622376203536987:.4f\n",
      "Epoch 3389: Train Loss = 0.1131, Test Loss = 1.0591046810150146:.4f\n",
      "Epoch 3390: Train Loss = 0.1325, Test Loss = 1.0316503047943115:.4f\n",
      "Epoch 3391: Train Loss = 0.1402, Test Loss = 1.0462404489517212:.4f\n",
      "Epoch 3392: Train Loss = 0.1408, Test Loss = 1.1004912853240967:.4f\n",
      "Epoch 3393: Train Loss = 0.1396, Test Loss = 1.017683982849121:.4f\n",
      "Epoch 3394: Train Loss = 0.1302, Test Loss = 1.0092296600341797:.4f\n",
      "Epoch 3395: Train Loss = 0.1374, Test Loss = 1.0174471139907837:.4f\n",
      "Epoch 3396: Train Loss = 0.1164, Test Loss = 1.0568737983703613:.4f\n",
      "Epoch 3397: Train Loss = 0.1253, Test Loss = 1.0790808200836182:.4f\n",
      "Epoch 3398: Train Loss = 0.1166, Test Loss = 1.0098214149475098:.4f\n",
      "Epoch 3399: Train Loss = 0.1106, Test Loss = 0.9807987213134766:.4f\n",
      "Epoch 3400: Train Loss = 0.1356, Test Loss = 0.9622141718864441:.4f\n",
      "Epoch 3401: Train Loss = 0.1123, Test Loss = 0.9731723666191101:.4f\n",
      "Epoch 3402: Train Loss = 0.1231, Test Loss = 1.0034911632537842:.4f\n",
      "Epoch 3403: Train Loss = 0.1092, Test Loss = 1.016569972038269:.4f\n",
      "Epoch 3404: Train Loss = 0.1019, Test Loss = 1.0081254243850708:.4f\n",
      "Epoch 3405: Train Loss = 0.1354, Test Loss = 1.011047601699829:.4f\n",
      "Epoch 3406: Train Loss = 0.1253, Test Loss = 1.0023787021636963:.4f\n",
      "Epoch 3407: Train Loss = 0.1084, Test Loss = 0.9549291729927063:.4f\n",
      "Epoch 3408: Train Loss = 0.1177, Test Loss = 0.9421602487564087:.4f\n",
      "Epoch 3409: Train Loss = 0.1439, Test Loss = 0.9555076360702515:.4f\n",
      "Epoch 3410: Train Loss = 0.1124, Test Loss = 1.058833122253418:.4f\n",
      "Epoch 3411: Train Loss = 0.1207, Test Loss = 1.1269266605377197:.4f\n",
      "Epoch 3412: Train Loss = 0.1215, Test Loss = 1.1141200065612793:.4f\n",
      "Epoch 3413: Train Loss = 0.1064, Test Loss = 1.0229649543762207:.4f\n",
      "Epoch 3414: Train Loss = 0.1547, Test Loss = 1.0068581104278564:.4f\n",
      "Epoch 3415: Train Loss = 0.1420, Test Loss = 0.9795546531677246:.4f\n",
      "Epoch 3416: Train Loss = 0.1256, Test Loss = 1.0110069513320923:.4f\n",
      "Epoch 3417: Train Loss = 0.1308, Test Loss = 0.9911738634109497:.4f\n",
      "Epoch 3418: Train Loss = 0.1207, Test Loss = 0.9783456921577454:.4f\n",
      "Epoch 3419: Train Loss = 0.1189, Test Loss = 1.0076359510421753:.4f\n",
      "Epoch 3420: Train Loss = 0.1093, Test Loss = 1.0390267372131348:.4f\n",
      "Epoch 3421: Train Loss = 0.1042, Test Loss = 1.0556230545043945:.4f\n",
      "Epoch 3422: Train Loss = 0.1270, Test Loss = 1.0544108152389526:.4f\n",
      "Epoch 3423: Train Loss = 0.1109, Test Loss = 1.0395904779434204:.4f\n",
      "Epoch 3424: Train Loss = 0.1154, Test Loss = 1.0023082494735718:.4f\n",
      "Epoch 3425: Train Loss = 0.1035, Test Loss = 0.9722164273262024:.4f\n",
      "Epoch 3426: Train Loss = 0.1407, Test Loss = 0.9888508915901184:.4f\n",
      "Epoch 3427: Train Loss = 0.1106, Test Loss = 1.069591760635376:.4f\n",
      "Epoch 3428: Train Loss = 0.1118, Test Loss = 1.0878987312316895:.4f\n",
      "Epoch 3429: Train Loss = 0.1362, Test Loss = 1.0483860969543457:.4f\n",
      "Epoch 3430: Train Loss = 0.1075, Test Loss = 1.0438404083251953:.4f\n",
      "Epoch 3431: Train Loss = 0.1253, Test Loss = 1.0431323051452637:.4f\n",
      "Epoch 3432: Train Loss = 0.1193, Test Loss = 1.0784960985183716:.4f\n",
      "Epoch 3433: Train Loss = 0.1460, Test Loss = 1.0604677200317383:.4f\n",
      "Epoch 3434: Train Loss = 0.1137, Test Loss = 0.9440194368362427:.4f\n",
      "Epoch 3435: Train Loss = 0.1173, Test Loss = 0.9406439661979675:.4f\n",
      "Epoch 3436: Train Loss = 0.1379, Test Loss = 0.9811277389526367:.4f\n",
      "Epoch 3437: Train Loss = 0.1468, Test Loss = 1.0221177339553833:.4f\n",
      "Epoch 3438: Train Loss = 0.1092, Test Loss = 1.066648244857788:.4f\n",
      "Epoch 3439: Train Loss = 0.1288, Test Loss = 1.0789823532104492:.4f\n",
      "Epoch 3440: Train Loss = 0.1518, Test Loss = 1.000736117362976:.4f\n",
      "Epoch 3441: Train Loss = 0.1622, Test Loss = 1.029997706413269:.4f\n",
      "Epoch 3442: Train Loss = 0.1199, Test Loss = 1.1296087503433228:.4f\n",
      "Epoch 3443: Train Loss = 0.1357, Test Loss = 1.2040866613388062:.4f\n",
      "Epoch 3444: Train Loss = 0.1104, Test Loss = 1.111550211906433:.4f\n",
      "Epoch 3445: Train Loss = 0.1307, Test Loss = 1.0324702262878418:.4f\n",
      "Epoch 3446: Train Loss = 0.1480, Test Loss = 1.0379682779312134:.4f\n",
      "Epoch 3447: Train Loss = 0.1242, Test Loss = 1.1249409914016724:.4f\n",
      "Epoch 3448: Train Loss = 0.1062, Test Loss = 1.133378267288208:.4f\n",
      "Epoch 3449: Train Loss = 0.1361, Test Loss = 1.074509859085083:.4f\n",
      "Epoch 3450: Train Loss = 0.1193, Test Loss = 1.0797319412231445:.4f\n",
      "Epoch 3451: Train Loss = 0.1390, Test Loss = 1.0681579113006592:.4f\n",
      "Epoch 3452: Train Loss = 0.1041, Test Loss = 1.0925201177597046:.4f\n",
      "Epoch 3453: Train Loss = 0.1329, Test Loss = 1.0680283308029175:.4f\n",
      "Epoch 3454: Train Loss = 0.1378, Test Loss = 1.0162650346755981:.4f\n",
      "Epoch 3455: Train Loss = 0.1133, Test Loss = 1.049293041229248:.4f\n",
      "Epoch 3456: Train Loss = 0.1327, Test Loss = 1.056111454963684:.4f\n",
      "Epoch 3457: Train Loss = 0.1511, Test Loss = 1.0322444438934326:.4f\n",
      "Epoch 3458: Train Loss = 0.1105, Test Loss = 1.0893303155899048:.4f\n",
      "Epoch 3459: Train Loss = 0.1308, Test Loss = 1.1024686098098755:.4f\n",
      "Epoch 3460: Train Loss = 0.1248, Test Loss = 1.0496094226837158:.4f\n",
      "Epoch 3461: Train Loss = 0.1177, Test Loss = 1.012911319732666:.4f\n",
      "Epoch 3462: Train Loss = 0.1560, Test Loss = 1.013359546661377:.4f\n",
      "Epoch 3463: Train Loss = 0.1314, Test Loss = 1.0706379413604736:.4f\n",
      "Epoch 3464: Train Loss = 0.1371, Test Loss = 1.0303585529327393:.4f\n",
      "Epoch 3465: Train Loss = 0.1308, Test Loss = 1.072087049484253:.4f\n",
      "Epoch 3466: Train Loss = 0.1109, Test Loss = 1.0883203744888306:.4f\n",
      "Epoch 3467: Train Loss = 0.1106, Test Loss = 1.0308587551116943:.4f\n",
      "Epoch 3468: Train Loss = 0.1184, Test Loss = 1.0024614334106445:.4f\n",
      "Epoch 3469: Train Loss = 0.1061, Test Loss = 1.016188383102417:.4f\n",
      "Epoch 3470: Train Loss = 0.1329, Test Loss = 1.0698753595352173:.4f\n",
      "Epoch 3471: Train Loss = 0.1031, Test Loss = 1.1554051637649536:.4f\n",
      "Epoch 3472: Train Loss = 0.1275, Test Loss = 1.1515406370162964:.4f\n",
      "Epoch 3473: Train Loss = 0.1160, Test Loss = 1.0784075260162354:.4f\n",
      "Epoch 3474: Train Loss = 0.1302, Test Loss = 1.0159859657287598:.4f\n",
      "Epoch 3475: Train Loss = 0.1085, Test Loss = 0.9643538594245911:.4f\n",
      "Epoch 3476: Train Loss = 0.1554, Test Loss = 0.9617882966995239:.4f\n",
      "Epoch 3477: Train Loss = 0.1138, Test Loss = 1.045933723449707:.4f\n",
      "Epoch 3478: Train Loss = 0.1157, Test Loss = 1.1050708293914795:.4f\n",
      "Epoch 3479: Train Loss = 0.1346, Test Loss = 1.0703165531158447:.4f\n",
      "Epoch 3480: Train Loss = 0.1284, Test Loss = 1.0039682388305664:.4f\n",
      "Epoch 3481: Train Loss = 0.1301, Test Loss = 1.0102531909942627:.4f\n",
      "Epoch 3482: Train Loss = 0.1299, Test Loss = 1.0623983144760132:.4f\n",
      "Epoch 3483: Train Loss = 0.1124, Test Loss = 1.0824321508407593:.4f\n",
      "Epoch 3484: Train Loss = 0.1267, Test Loss = 1.0679434537887573:.4f\n",
      "Epoch 3485: Train Loss = 0.1047, Test Loss = 1.059242606163025:.4f\n",
      "Epoch 3486: Train Loss = 0.1069, Test Loss = 1.0628159046173096:.4f\n",
      "Epoch 3487: Train Loss = 0.1096, Test Loss = 1.0727393627166748:.4f\n",
      "Epoch 3488: Train Loss = 0.1033, Test Loss = 1.0237505435943604:.4f\n",
      "Epoch 3489: Train Loss = 0.1211, Test Loss = 1.0310909748077393:.4f\n",
      "Epoch 3490: Train Loss = 0.1232, Test Loss = 0.9938567876815796:.4f\n",
      "Epoch 3491: Train Loss = 0.1205, Test Loss = 0.9737049341201782:.4f\n",
      "Epoch 3492: Train Loss = 0.1241, Test Loss = 1.0160709619522095:.4f\n",
      "Epoch 3493: Train Loss = 0.1048, Test Loss = 1.0203558206558228:.4f\n",
      "Epoch 3494: Train Loss = 0.1370, Test Loss = 1.0093605518341064:.4f\n",
      "Epoch 3495: Train Loss = 0.1234, Test Loss = 1.046255111694336:.4f\n",
      "Epoch 3496: Train Loss = 0.1203, Test Loss = 1.0695116519927979:.4f\n",
      "Epoch 3497: Train Loss = 0.1183, Test Loss = 1.0472910404205322:.4f\n",
      "Epoch 3498: Train Loss = 0.1138, Test Loss = 1.004629373550415:.4f\n",
      "Epoch 3499: Train Loss = 0.1120, Test Loss = 1.0017019510269165:.4f\n",
      "Epoch 3500: Train Loss = 0.1190, Test Loss = 1.0265121459960938:.4f\n"
     ]
    }
   ],
   "source": [
    "model = NN(input_size, num_classes)\n",
    "train_model(model, train_loader, test_loader, epochs = 3500,lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdbdd0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1d4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111f99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e8025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fdb456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be4488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5f45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d209ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39fbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a96c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f558ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c30271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34616a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca974560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da13cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e609714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00626a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
