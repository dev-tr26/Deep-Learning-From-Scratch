{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5460984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_circles\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a83ec6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_circles(n_samples=100, noise=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf24a19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=X[:,0],y=X[:,1],hue=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b40cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test ,y_train,y_test = train_test_split(X,y, test_size=0.20, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28e0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train).float()  \n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "\n",
    "X_test_tensor = torch.from_numpy(X_test).float()  # for class labels \n",
    "y_test_tensor = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388a3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping in tensordata and dataloader class\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49de6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a985c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def train_model(model, train_loader, test_loader, epochs=3500, lr=0.01):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for input_feature_batch, input_label_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(input_feature_batch)\n",
    "            loss = loss_fn(preds, input_label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_train_loss/ len(train_loader)\n",
    "        train_losses.append(avg_train_loss)    \n",
    "        \n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for input_feature_batch,input_label_batch in test_loader:\n",
    "                 preds = model(input_feature_batch)\n",
    "                 loss = loss_fn(preds, input_label_batch)\n",
    "                 running_test_loss += loss.item()\n",
    "                 \n",
    "        avg_test_loss = running_test_loss/ len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Test Loss = {avg_test_loss}:.4f\")        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7cef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c3cfa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153758a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c072874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.7006, Test Loss = 0.7095028758049011:.4f\n",
      "Epoch 2: Train Loss = 0.6887, Test Loss = 0.7079373598098755:.4f\n",
      "Epoch 3: Train Loss = 0.6930, Test Loss = 0.710491955280304:.4f\n",
      "Epoch 4: Train Loss = 0.6926, Test Loss = 0.7106485962867737:.4f\n",
      "Epoch 5: Train Loss = 0.6744, Test Loss = 0.7113333940505981:.4f\n",
      "Epoch 6: Train Loss = 0.6751, Test Loss = 0.7156643271446228:.4f\n",
      "Epoch 7: Train Loss = 0.6754, Test Loss = 0.7200721502304077:.4f\n",
      "Epoch 8: Train Loss = 0.6685, Test Loss = 0.7156940698623657:.4f\n",
      "Epoch 9: Train Loss = 0.6634, Test Loss = 0.7113315463066101:.4f\n",
      "Epoch 10: Train Loss = 0.6592, Test Loss = 0.7125162482261658:.4f\n",
      "Epoch 11: Train Loss = 0.6576, Test Loss = 0.7160705327987671:.4f\n",
      "Epoch 12: Train Loss = 0.6589, Test Loss = 0.7181613445281982:.4f\n",
      "Epoch 13: Train Loss = 0.6517, Test Loss = 0.720185399055481:.4f\n",
      "Epoch 14: Train Loss = 0.6404, Test Loss = 0.7266741991043091:.4f\n",
      "Epoch 15: Train Loss = 0.6462, Test Loss = 0.7254701256752014:.4f\n",
      "Epoch 16: Train Loss = 0.6495, Test Loss = 0.7259663939476013:.4f\n",
      "Epoch 17: Train Loss = 0.6508, Test Loss = 0.7285284996032715:.4f\n",
      "Epoch 18: Train Loss = 0.6467, Test Loss = 0.720901370048523:.4f\n",
      "Epoch 19: Train Loss = 0.6366, Test Loss = 0.7118338346481323:.4f\n",
      "Epoch 20: Train Loss = 0.6289, Test Loss = 0.7132329940795898:.4f\n",
      "Epoch 21: Train Loss = 0.6203, Test Loss = 0.7130031585693359:.4f\n",
      "Epoch 22: Train Loss = 0.6249, Test Loss = 0.718176007270813:.4f\n",
      "Epoch 23: Train Loss = 0.6206, Test Loss = 0.7251623868942261:.4f\n",
      "Epoch 24: Train Loss = 0.6076, Test Loss = 0.7413660287857056:.4f\n",
      "Epoch 25: Train Loss = 0.6133, Test Loss = 0.7520914077758789:.4f\n",
      "Epoch 26: Train Loss = 0.6073, Test Loss = 0.7526057958602905:.4f\n",
      "Epoch 27: Train Loss = 0.6118, Test Loss = 0.7478348612785339:.4f\n",
      "Epoch 28: Train Loss = 0.6074, Test Loss = 0.7315353751182556:.4f\n",
      "Epoch 29: Train Loss = 0.6083, Test Loss = 0.7217602133750916:.4f\n",
      "Epoch 30: Train Loss = 0.6001, Test Loss = 0.7123223543167114:.4f\n",
      "Epoch 31: Train Loss = 0.5991, Test Loss = 0.7115603685379028:.4f\n",
      "Epoch 32: Train Loss = 0.5869, Test Loss = 0.7095316052436829:.4f\n",
      "Epoch 33: Train Loss = 0.5862, Test Loss = 0.7076786160469055:.4f\n",
      "Epoch 34: Train Loss = 0.5782, Test Loss = 0.7116224765777588:.4f\n",
      "Epoch 35: Train Loss = 0.5791, Test Loss = 0.7218059301376343:.4f\n",
      "Epoch 36: Train Loss = 0.5566, Test Loss = 0.7254987359046936:.4f\n",
      "Epoch 37: Train Loss = 0.5645, Test Loss = 0.728261411190033:.4f\n",
      "Epoch 38: Train Loss = 0.5791, Test Loss = 0.7357078194618225:.4f\n",
      "Epoch 39: Train Loss = 0.5643, Test Loss = 0.7341964840888977:.4f\n",
      "Epoch 40: Train Loss = 0.5513, Test Loss = 0.7219716310501099:.4f\n",
      "Epoch 41: Train Loss = 0.5493, Test Loss = 0.7126315236091614:.4f\n",
      "Epoch 42: Train Loss = 0.5446, Test Loss = 0.6985617876052856:.4f\n",
      "Epoch 43: Train Loss = 0.5487, Test Loss = 0.6916922926902771:.4f\n",
      "Epoch 44: Train Loss = 0.5358, Test Loss = 0.7009009122848511:.4f\n",
      "Epoch 45: Train Loss = 0.5352, Test Loss = 0.7123624086380005:.4f\n",
      "Epoch 46: Train Loss = 0.5401, Test Loss = 0.7175794839859009:.4f\n",
      "Epoch 47: Train Loss = 0.5293, Test Loss = 0.7039240598678589:.4f\n",
      "Epoch 48: Train Loss = 0.5269, Test Loss = 0.685146689414978:.4f\n",
      "Epoch 49: Train Loss = 0.5333, Test Loss = 0.6702951788902283:.4f\n",
      "Epoch 50: Train Loss = 0.5022, Test Loss = 0.6639222502708435:.4f\n",
      "Epoch 51: Train Loss = 0.5004, Test Loss = 0.6764634251594543:.4f\n",
      "Epoch 52: Train Loss = 0.5062, Test Loss = 0.6815909147262573:.4f\n",
      "Epoch 53: Train Loss = 0.5021, Test Loss = 0.6892755627632141:.4f\n",
      "Epoch 54: Train Loss = 0.4947, Test Loss = 0.6914766430854797:.4f\n",
      "Epoch 55: Train Loss = 0.4961, Test Loss = 0.6865068078041077:.4f\n",
      "Epoch 56: Train Loss = 0.4810, Test Loss = 0.6745485067367554:.4f\n",
      "Epoch 57: Train Loss = 0.4669, Test Loss = 0.6632871031761169:.4f\n",
      "Epoch 58: Train Loss = 0.4792, Test Loss = 0.6625605821609497:.4f\n",
      "Epoch 59: Train Loss = 0.4943, Test Loss = 0.6573004722595215:.4f\n",
      "Epoch 60: Train Loss = 0.4642, Test Loss = 0.6396924257278442:.4f\n",
      "Epoch 61: Train Loss = 0.4648, Test Loss = 0.6419343948364258:.4f\n",
      "Epoch 62: Train Loss = 0.4626, Test Loss = 0.6531624794006348:.4f\n",
      "Epoch 63: Train Loss = 0.4551, Test Loss = 0.6614712476730347:.4f\n",
      "Epoch 64: Train Loss = 0.4511, Test Loss = 0.6708031892776489:.4f\n",
      "Epoch 65: Train Loss = 0.4567, Test Loss = 0.6752385497093201:.4f\n",
      "Epoch 66: Train Loss = 0.4369, Test Loss = 0.6459158658981323:.4f\n",
      "Epoch 67: Train Loss = 0.4367, Test Loss = 0.6325867176055908:.4f\n",
      "Epoch 68: Train Loss = 0.4430, Test Loss = 0.626998245716095:.4f\n",
      "Epoch 69: Train Loss = 0.4436, Test Loss = 0.6355220079421997:.4f\n",
      "Epoch 70: Train Loss = 0.4214, Test Loss = 0.6347660422325134:.4f\n",
      "Epoch 71: Train Loss = 0.4255, Test Loss = 0.6407107710838318:.4f\n",
      "Epoch 72: Train Loss = 0.4179, Test Loss = 0.6377969980239868:.4f\n",
      "Epoch 73: Train Loss = 0.4325, Test Loss = 0.6291818618774414:.4f\n",
      "Epoch 74: Train Loss = 0.4123, Test Loss = 0.615436315536499:.4f\n",
      "Epoch 75: Train Loss = 0.3962, Test Loss = 0.6161239147186279:.4f\n",
      "Epoch 76: Train Loss = 0.4122, Test Loss = 0.6347187757492065:.4f\n",
      "Epoch 77: Train Loss = 0.4032, Test Loss = 0.6263060569763184:.4f\n",
      "Epoch 78: Train Loss = 0.4049, Test Loss = 0.6143293976783752:.4f\n",
      "Epoch 79: Train Loss = 0.4080, Test Loss = 0.618410587310791:.4f\n",
      "Epoch 80: Train Loss = 0.3876, Test Loss = 0.6114014387130737:.4f\n",
      "Epoch 81: Train Loss = 0.3929, Test Loss = 0.6087629795074463:.4f\n",
      "Epoch 82: Train Loss = 0.3752, Test Loss = 0.616460919380188:.4f\n",
      "Epoch 83: Train Loss = 0.3709, Test Loss = 0.6295585632324219:.4f\n",
      "Epoch 84: Train Loss = 0.3818, Test Loss = 0.6466615796089172:.4f\n",
      "Epoch 85: Train Loss = 0.3646, Test Loss = 0.6401157379150391:.4f\n",
      "Epoch 86: Train Loss = 0.3604, Test Loss = 0.6278765797615051:.4f\n",
      "Epoch 87: Train Loss = 0.3808, Test Loss = 0.6091340780258179:.4f\n",
      "Epoch 88: Train Loss = 0.3606, Test Loss = 0.5961947441101074:.4f\n",
      "Epoch 89: Train Loss = 0.3596, Test Loss = 0.58720862865448:.4f\n",
      "Epoch 90: Train Loss = 0.3665, Test Loss = 0.5977751016616821:.4f\n",
      "Epoch 91: Train Loss = 0.3616, Test Loss = 0.6028790473937988:.4f\n",
      "Epoch 92: Train Loss = 0.3743, Test Loss = 0.6081732511520386:.4f\n",
      "Epoch 93: Train Loss = 0.3801, Test Loss = 0.6197811961174011:.4f\n",
      "Epoch 94: Train Loss = 0.3672, Test Loss = 0.6348907947540283:.4f\n",
      "Epoch 95: Train Loss = 0.3885, Test Loss = 0.6238929033279419:.4f\n",
      "Epoch 96: Train Loss = 0.3444, Test Loss = 0.606905996799469:.4f\n",
      "Epoch 97: Train Loss = 0.3785, Test Loss = 0.6092924475669861:.4f\n",
      "Epoch 98: Train Loss = 0.3749, Test Loss = 0.60490882396698:.4f\n",
      "Epoch 99: Train Loss = 0.3312, Test Loss = 0.6210242509841919:.4f\n",
      "Epoch 100: Train Loss = 0.3503, Test Loss = 0.6271501779556274:.4f\n",
      "Epoch 101: Train Loss = 0.3312, Test Loss = 0.6276320219039917:.4f\n",
      "Epoch 102: Train Loss = 0.3445, Test Loss = 0.6147021055221558:.4f\n",
      "Epoch 103: Train Loss = 0.3175, Test Loss = 0.589501142501831:.4f\n",
      "Epoch 104: Train Loss = 0.3569, Test Loss = 0.5818812847137451:.4f\n",
      "Epoch 105: Train Loss = 0.3390, Test Loss = 0.5963046550750732:.4f\n",
      "Epoch 106: Train Loss = 0.3203, Test Loss = 0.612830638885498:.4f\n",
      "Epoch 107: Train Loss = 0.3428, Test Loss = 0.6124776601791382:.4f\n",
      "Epoch 108: Train Loss = 0.3162, Test Loss = 0.5947490930557251:.4f\n",
      "Epoch 109: Train Loss = 0.3369, Test Loss = 0.5908144116401672:.4f\n",
      "Epoch 110: Train Loss = 0.3334, Test Loss = 0.5931081771850586:.4f\n",
      "Epoch 111: Train Loss = 0.3344, Test Loss = 0.5991849899291992:.4f\n",
      "Epoch 112: Train Loss = 0.3169, Test Loss = 0.6014536023139954:.4f\n",
      "Epoch 113: Train Loss = 0.3273, Test Loss = 0.5968204736709595:.4f\n",
      "Epoch 114: Train Loss = 0.3463, Test Loss = 0.5946962237358093:.4f\n",
      "Epoch 115: Train Loss = 0.3128, Test Loss = 0.6112608313560486:.4f\n",
      "Epoch 116: Train Loss = 0.3108, Test Loss = 0.630066454410553:.4f\n",
      "Epoch 117: Train Loss = 0.3007, Test Loss = 0.6251485347747803:.4f\n",
      "Epoch 118: Train Loss = 0.3127, Test Loss = 0.6055169701576233:.4f\n",
      "Epoch 119: Train Loss = 0.3088, Test Loss = 0.5920368432998657:.4f\n",
      "Epoch 120: Train Loss = 0.2965, Test Loss = 0.5965914726257324:.4f\n",
      "Epoch 121: Train Loss = 0.3190, Test Loss = 0.5925790071487427:.4f\n",
      "Epoch 122: Train Loss = 0.3055, Test Loss = 0.5904625058174133:.4f\n",
      "Epoch 123: Train Loss = 0.3011, Test Loss = 0.5945758819580078:.4f\n",
      "Epoch 124: Train Loss = 0.2919, Test Loss = 0.608603835105896:.4f\n",
      "Epoch 125: Train Loss = 0.3153, Test Loss = 0.6119216680526733:.4f\n",
      "Epoch 126: Train Loss = 0.3038, Test Loss = 0.6013015508651733:.4f\n",
      "Epoch 127: Train Loss = 0.3073, Test Loss = 0.5969439744949341:.4f\n",
      "Epoch 128: Train Loss = 0.2808, Test Loss = 0.6026650667190552:.4f\n",
      "Epoch 129: Train Loss = 0.3095, Test Loss = 0.6070646643638611:.4f\n",
      "Epoch 130: Train Loss = 0.2920, Test Loss = 0.5943984985351562:.4f\n",
      "Epoch 131: Train Loss = 0.3099, Test Loss = 0.5978535413742065:.4f\n",
      "Epoch 132: Train Loss = 0.2958, Test Loss = 0.6007843017578125:.4f\n",
      "Epoch 133: Train Loss = 0.2680, Test Loss = 0.6068898439407349:.4f\n",
      "Epoch 134: Train Loss = 0.2856, Test Loss = 0.6208385229110718:.4f\n",
      "Epoch 135: Train Loss = 0.2950, Test Loss = 0.6176828742027283:.4f\n",
      "Epoch 136: Train Loss = 0.2990, Test Loss = 0.6053242683410645:.4f\n",
      "Epoch 137: Train Loss = 0.2843, Test Loss = 0.6103401780128479:.4f\n",
      "Epoch 138: Train Loss = 0.2888, Test Loss = 0.6285386085510254:.4f\n",
      "Epoch 139: Train Loss = 0.2933, Test Loss = 0.6167678833007812:.4f\n",
      "Epoch 140: Train Loss = 0.2749, Test Loss = 0.6080578565597534:.4f\n",
      "Epoch 141: Train Loss = 0.3171, Test Loss = 0.5976325869560242:.4f\n",
      "Epoch 142: Train Loss = 0.2608, Test Loss = 0.5955951809883118:.4f\n",
      "Epoch 143: Train Loss = 0.2734, Test Loss = 0.6020629405975342:.4f\n",
      "Epoch 144: Train Loss = 0.2794, Test Loss = 0.6129072904586792:.4f\n",
      "Epoch 145: Train Loss = 0.3072, Test Loss = 0.6143237948417664:.4f\n",
      "Epoch 146: Train Loss = 0.2837, Test Loss = 0.6186944246292114:.4f\n",
      "Epoch 147: Train Loss = 0.2766, Test Loss = 0.6256495714187622:.4f\n",
      "Epoch 148: Train Loss = 0.2527, Test Loss = 0.6410416960716248:.4f\n",
      "Epoch 149: Train Loss = 0.2822, Test Loss = 0.6452957987785339:.4f\n",
      "Epoch 150: Train Loss = 0.2887, Test Loss = 0.6244220733642578:.4f\n",
      "Epoch 151: Train Loss = 0.2688, Test Loss = 0.60276859998703:.4f\n",
      "Epoch 152: Train Loss = 0.2841, Test Loss = 0.589239239692688:.4f\n",
      "Epoch 153: Train Loss = 0.2693, Test Loss = 0.6014235019683838:.4f\n",
      "Epoch 154: Train Loss = 0.2838, Test Loss = 0.6154701113700867:.4f\n",
      "Epoch 155: Train Loss = 0.2909, Test Loss = 0.62492835521698:.4f\n",
      "Epoch 156: Train Loss = 0.2916, Test Loss = 0.637799859046936:.4f\n",
      "Epoch 157: Train Loss = 0.2780, Test Loss = 0.6452492475509644:.4f\n",
      "Epoch 158: Train Loss = 0.2778, Test Loss = 0.6331469416618347:.4f\n",
      "Epoch 159: Train Loss = 0.2628, Test Loss = 0.619437575340271:.4f\n",
      "Epoch 160: Train Loss = 0.2430, Test Loss = 0.6179040670394897:.4f\n",
      "Epoch 161: Train Loss = 0.2600, Test Loss = 0.6183858513832092:.4f\n",
      "Epoch 162: Train Loss = 0.2611, Test Loss = 0.6178275346755981:.4f\n",
      "Epoch 163: Train Loss = 0.2618, Test Loss = 0.6209884881973267:.4f\n",
      "Epoch 164: Train Loss = 0.2529, Test Loss = 0.6224536299705505:.4f\n",
      "Epoch 165: Train Loss = 0.2484, Test Loss = 0.6224411725997925:.4f\n",
      "Epoch 166: Train Loss = 0.2674, Test Loss = 0.6209021210670471:.4f\n",
      "Epoch 167: Train Loss = 0.2840, Test Loss = 0.6263123750686646:.4f\n",
      "Epoch 168: Train Loss = 0.2554, Test Loss = 0.6216468811035156:.4f\n",
      "Epoch 169: Train Loss = 0.2745, Test Loss = 0.6293607950210571:.4f\n",
      "Epoch 170: Train Loss = 0.2486, Test Loss = 0.6308276057243347:.4f\n",
      "Epoch 171: Train Loss = 0.2571, Test Loss = 0.6397494673728943:.4f\n",
      "Epoch 172: Train Loss = 0.2786, Test Loss = 0.6434739232063293:.4f\n",
      "Epoch 173: Train Loss = 0.2380, Test Loss = 0.6318721771240234:.4f\n",
      "Epoch 174: Train Loss = 0.2648, Test Loss = 0.6283113360404968:.4f\n",
      "Epoch 175: Train Loss = 0.2780, Test Loss = 0.6338757872581482:.4f\n",
      "Epoch 176: Train Loss = 0.2741, Test Loss = 0.6549431085586548:.4f\n",
      "Epoch 177: Train Loss = 0.2713, Test Loss = 0.6464215517044067:.4f\n",
      "Epoch 178: Train Loss = 0.2668, Test Loss = 0.6264116168022156:.4f\n",
      "Epoch 179: Train Loss = 0.2663, Test Loss = 0.6158627271652222:.4f\n",
      "Epoch 180: Train Loss = 0.2420, Test Loss = 0.6163132786750793:.4f\n",
      "Epoch 181: Train Loss = 0.2655, Test Loss = 0.6303962469100952:.4f\n",
      "Epoch 182: Train Loss = 0.2763, Test Loss = 0.6342873573303223:.4f\n",
      "Epoch 183: Train Loss = 0.2653, Test Loss = 0.6107567548751831:.4f\n",
      "Epoch 184: Train Loss = 0.2659, Test Loss = 0.6174992322921753:.4f\n",
      "Epoch 185: Train Loss = 0.2394, Test Loss = 0.6236503720283508:.4f\n",
      "Epoch 186: Train Loss = 0.2439, Test Loss = 0.6431540250778198:.4f\n",
      "Epoch 187: Train Loss = 0.2691, Test Loss = 0.6409667730331421:.4f\n",
      "Epoch 188: Train Loss = 0.2519, Test Loss = 0.6376534700393677:.4f\n",
      "Epoch 189: Train Loss = 0.2366, Test Loss = 0.6359004378318787:.4f\n",
      "Epoch 190: Train Loss = 0.2731, Test Loss = 0.6329430937767029:.4f\n",
      "Epoch 191: Train Loss = 0.2272, Test Loss = 0.6486724615097046:.4f\n",
      "Epoch 192: Train Loss = 0.2350, Test Loss = 0.6586658358573914:.4f\n",
      "Epoch 193: Train Loss = 0.2412, Test Loss = 0.6542595624923706:.4f\n",
      "Epoch 194: Train Loss = 0.2670, Test Loss = 0.63884437084198:.4f\n",
      "Epoch 195: Train Loss = 0.2569, Test Loss = 0.6347819566726685:.4f\n",
      "Epoch 196: Train Loss = 0.2556, Test Loss = 0.6347380876541138:.4f\n",
      "Epoch 197: Train Loss = 0.2390, Test Loss = 0.6424189805984497:.4f\n",
      "Epoch 198: Train Loss = 0.2405, Test Loss = 0.6337095499038696:.4f\n",
      "Epoch 199: Train Loss = 0.2213, Test Loss = 0.6402761340141296:.4f\n",
      "Epoch 200: Train Loss = 0.2380, Test Loss = 0.6417821049690247:.4f\n",
      "Epoch 201: Train Loss = 0.2498, Test Loss = 0.6426934003829956:.4f\n",
      "Epoch 202: Train Loss = 0.2258, Test Loss = 0.642535924911499:.4f\n",
      "Epoch 203: Train Loss = 0.2434, Test Loss = 0.6422929167747498:.4f\n",
      "Epoch 204: Train Loss = 0.2442, Test Loss = 0.6528016328811646:.4f\n",
      "Epoch 205: Train Loss = 0.2264, Test Loss = 0.6485525369644165:.4f\n",
      "Epoch 206: Train Loss = 0.2415, Test Loss = 0.6376028060913086:.4f\n",
      "Epoch 207: Train Loss = 0.2529, Test Loss = 0.6290419101715088:.4f\n",
      "Epoch 208: Train Loss = 0.2190, Test Loss = 0.6222923994064331:.4f\n",
      "Epoch 209: Train Loss = 0.2335, Test Loss = 0.6335535645484924:.4f\n",
      "Epoch 210: Train Loss = 0.2376, Test Loss = 0.6291967630386353:.4f\n",
      "Epoch 211: Train Loss = 0.2506, Test Loss = 0.6322451829910278:.4f\n",
      "Epoch 212: Train Loss = 0.2568, Test Loss = 0.6376407742500305:.4f\n",
      "Epoch 213: Train Loss = 0.2470, Test Loss = 0.6401330232620239:.4f\n",
      "Epoch 214: Train Loss = 0.2246, Test Loss = 0.6396037340164185:.4f\n",
      "Epoch 215: Train Loss = 0.2352, Test Loss = 0.6535829901695251:.4f\n",
      "Epoch 216: Train Loss = 0.2479, Test Loss = 0.6478978991508484:.4f\n",
      "Epoch 217: Train Loss = 0.2394, Test Loss = 0.6354079842567444:.4f\n",
      "Epoch 218: Train Loss = 0.2197, Test Loss = 0.6334120035171509:.4f\n",
      "Epoch 219: Train Loss = 0.2490, Test Loss = 0.6444204449653625:.4f\n",
      "Epoch 220: Train Loss = 0.2202, Test Loss = 0.6544720530509949:.4f\n",
      "Epoch 221: Train Loss = 0.2412, Test Loss = 0.6570354700088501:.4f\n",
      "Epoch 222: Train Loss = 0.2271, Test Loss = 0.6492121815681458:.4f\n",
      "Epoch 223: Train Loss = 0.2346, Test Loss = 0.6436771154403687:.4f\n",
      "Epoch 224: Train Loss = 0.2139, Test Loss = 0.647983193397522:.4f\n",
      "Epoch 225: Train Loss = 0.2172, Test Loss = 0.6573887467384338:.4f\n",
      "Epoch 226: Train Loss = 0.2445, Test Loss = 0.6630163788795471:.4f\n",
      "Epoch 227: Train Loss = 0.2209, Test Loss = 0.6365856528282166:.4f\n",
      "Epoch 228: Train Loss = 0.2517, Test Loss = 0.6317182779312134:.4f\n",
      "Epoch 229: Train Loss = 0.2305, Test Loss = 0.6429798007011414:.4f\n",
      "Epoch 230: Train Loss = 0.2360, Test Loss = 0.6579534411430359:.4f\n",
      "Epoch 231: Train Loss = 0.2351, Test Loss = 0.6547719240188599:.4f\n",
      "Epoch 232: Train Loss = 0.2276, Test Loss = 0.6491140723228455:.4f\n",
      "Epoch 233: Train Loss = 0.2245, Test Loss = 0.6530775427818298:.4f\n",
      "Epoch 234: Train Loss = 0.2108, Test Loss = 0.6610720753669739:.4f\n",
      "Epoch 235: Train Loss = 0.2331, Test Loss = 0.6638562083244324:.4f\n",
      "Epoch 236: Train Loss = 0.2170, Test Loss = 0.6609823107719421:.4f\n",
      "Epoch 237: Train Loss = 0.2299, Test Loss = 0.6552562713623047:.4f\n",
      "Epoch 238: Train Loss = 0.2045, Test Loss = 0.6583828330039978:.4f\n",
      "Epoch 239: Train Loss = 0.2211, Test Loss = 0.6600984930992126:.4f\n",
      "Epoch 240: Train Loss = 0.2334, Test Loss = 0.6438891291618347:.4f\n",
      "Epoch 241: Train Loss = 0.2562, Test Loss = 0.6420193910598755:.4f\n",
      "Epoch 242: Train Loss = 0.2482, Test Loss = 0.6507992148399353:.4f\n",
      "Epoch 243: Train Loss = 0.2142, Test Loss = 0.6584540605545044:.4f\n",
      "Epoch 244: Train Loss = 0.2280, Test Loss = 0.6677384376525879:.4f\n",
      "Epoch 245: Train Loss = 0.2140, Test Loss = 0.6671386957168579:.4f\n",
      "Epoch 246: Train Loss = 0.2171, Test Loss = 0.6536761522293091:.4f\n",
      "Epoch 247: Train Loss = 0.2340, Test Loss = 0.646312952041626:.4f\n",
      "Epoch 248: Train Loss = 0.2208, Test Loss = 0.6517851948738098:.4f\n",
      "Epoch 249: Train Loss = 0.2026, Test Loss = 0.662320077419281:.4f\n",
      "Epoch 250: Train Loss = 0.2364, Test Loss = 0.6589452028274536:.4f\n",
      "Epoch 251: Train Loss = 0.2109, Test Loss = 0.6595975160598755:.4f\n",
      "Epoch 252: Train Loss = 0.2378, Test Loss = 0.6560089588165283:.4f\n",
      "Epoch 253: Train Loss = 0.2187, Test Loss = 0.6558986306190491:.4f\n",
      "Epoch 254: Train Loss = 0.2132, Test Loss = 0.6647810339927673:.4f\n",
      "Epoch 255: Train Loss = 0.2037, Test Loss = 0.6682000756263733:.4f\n",
      "Epoch 256: Train Loss = 0.2167, Test Loss = 0.6681177020072937:.4f\n",
      "Epoch 257: Train Loss = 0.2199, Test Loss = 0.6586358547210693:.4f\n",
      "Epoch 258: Train Loss = 0.2086, Test Loss = 0.6525906324386597:.4f\n",
      "Epoch 259: Train Loss = 0.2267, Test Loss = 0.6546838879585266:.4f\n",
      "Epoch 260: Train Loss = 0.2163, Test Loss = 0.6593018770217896:.4f\n",
      "Epoch 261: Train Loss = 0.2064, Test Loss = 0.6730697154998779:.4f\n",
      "Epoch 262: Train Loss = 0.1985, Test Loss = 0.6922465562820435:.4f\n",
      "Epoch 263: Train Loss = 0.2190, Test Loss = 0.6917151808738708:.4f\n",
      "Epoch 264: Train Loss = 0.2148, Test Loss = 0.6741508841514587:.4f\n",
      "Epoch 265: Train Loss = 0.2100, Test Loss = 0.6584064364433289:.4f\n",
      "Epoch 266: Train Loss = 0.2138, Test Loss = 0.6594823598861694:.4f\n",
      "Epoch 267: Train Loss = 0.2009, Test Loss = 0.6678280830383301:.4f\n",
      "Epoch 268: Train Loss = 0.2173, Test Loss = 0.6723459959030151:.4f\n",
      "Epoch 269: Train Loss = 0.2109, Test Loss = 0.671049952507019:.4f\n",
      "Epoch 270: Train Loss = 0.2232, Test Loss = 0.6506396532058716:.4f\n",
      "Epoch 271: Train Loss = 0.2024, Test Loss = 0.6623784303665161:.4f\n",
      "Epoch 272: Train Loss = 0.1948, Test Loss = 0.6858524680137634:.4f\n",
      "Epoch 273: Train Loss = 0.2136, Test Loss = 0.6974241137504578:.4f\n",
      "Epoch 274: Train Loss = 0.2188, Test Loss = 0.6830838918685913:.4f\n",
      "Epoch 275: Train Loss = 0.2155, Test Loss = 0.6594804525375366:.4f\n",
      "Epoch 276: Train Loss = 0.2084, Test Loss = 0.656873345375061:.4f\n",
      "Epoch 277: Train Loss = 0.1963, Test Loss = 0.6635855436325073:.4f\n",
      "Epoch 278: Train Loss = 0.2108, Test Loss = 0.6660982966423035:.4f\n",
      "Epoch 279: Train Loss = 0.2254, Test Loss = 0.6773891448974609:.4f\n",
      "Epoch 280: Train Loss = 0.2252, Test Loss = 0.6945754289627075:.4f\n",
      "Epoch 281: Train Loss = 0.1994, Test Loss = 0.6995421051979065:.4f\n",
      "Epoch 282: Train Loss = 0.2209, Test Loss = 0.6901558041572571:.4f\n",
      "Epoch 283: Train Loss = 0.2179, Test Loss = 0.6886972784996033:.4f\n",
      "Epoch 284: Train Loss = 0.1996, Test Loss = 0.6875828504562378:.4f\n",
      "Epoch 285: Train Loss = 0.2104, Test Loss = 0.674647331237793:.4f\n",
      "Epoch 286: Train Loss = 0.2038, Test Loss = 0.6578927636146545:.4f\n",
      "Epoch 287: Train Loss = 0.2098, Test Loss = 0.6627952456474304:.4f\n",
      "Epoch 288: Train Loss = 0.2152, Test Loss = 0.6729376912117004:.4f\n",
      "Epoch 289: Train Loss = 0.1995, Test Loss = 0.6965699195861816:.4f\n",
      "Epoch 290: Train Loss = 0.2147, Test Loss = 0.6978023052215576:.4f\n",
      "Epoch 291: Train Loss = 0.2241, Test Loss = 0.6750743985176086:.4f\n",
      "Epoch 292: Train Loss = 0.1994, Test Loss = 0.6714043021202087:.4f\n",
      "Epoch 293: Train Loss = 0.2171, Test Loss = 0.6798633337020874:.4f\n",
      "Epoch 294: Train Loss = 0.2439, Test Loss = 0.7028616070747375:.4f\n",
      "Epoch 295: Train Loss = 0.2302, Test Loss = 0.6981970071792603:.4f\n",
      "Epoch 296: Train Loss = 0.2024, Test Loss = 0.7081653475761414:.4f\n",
      "Epoch 297: Train Loss = 0.2039, Test Loss = 0.7054266333580017:.4f\n",
      "Epoch 298: Train Loss = 0.2116, Test Loss = 0.6983523964881897:.4f\n",
      "Epoch 299: Train Loss = 0.2022, Test Loss = 0.6903024315834045:.4f\n",
      "Epoch 300: Train Loss = 0.2066, Test Loss = 0.6772392392158508:.4f\n",
      "Epoch 301: Train Loss = 0.2070, Test Loss = 0.6735635995864868:.4f\n",
      "Epoch 302: Train Loss = 0.2165, Test Loss = 0.6808896660804749:.4f\n",
      "Epoch 303: Train Loss = 0.1970, Test Loss = 0.6914453506469727:.4f\n",
      "Epoch 304: Train Loss = 0.1818, Test Loss = 0.706683337688446:.4f\n",
      "Epoch 305: Train Loss = 0.1817, Test Loss = 0.7143084406852722:.4f\n",
      "Epoch 306: Train Loss = 0.2049, Test Loss = 0.7131664752960205:.4f\n",
      "Epoch 307: Train Loss = 0.1882, Test Loss = 0.7012454867362976:.4f\n",
      "Epoch 308: Train Loss = 0.1961, Test Loss = 0.6910802125930786:.4f\n",
      "Epoch 309: Train Loss = 0.2056, Test Loss = 0.6930082440376282:.4f\n",
      "Epoch 310: Train Loss = 0.2063, Test Loss = 0.7008587121963501:.4f\n",
      "Epoch 311: Train Loss = 0.1922, Test Loss = 0.696528434753418:.4f\n",
      "Epoch 312: Train Loss = 0.1989, Test Loss = 0.6981359720230103:.4f\n",
      "Epoch 313: Train Loss = 0.2019, Test Loss = 0.6943424344062805:.4f\n",
      "Epoch 314: Train Loss = 0.1814, Test Loss = 0.688687801361084:.4f\n",
      "Epoch 315: Train Loss = 0.1943, Test Loss = 0.6937741637229919:.4f\n",
      "Epoch 316: Train Loss = 0.1869, Test Loss = 0.6986045837402344:.4f\n",
      "Epoch 317: Train Loss = 0.1845, Test Loss = 0.7052815556526184:.4f\n",
      "Epoch 318: Train Loss = 0.2051, Test Loss = 0.7246852517127991:.4f\n",
      "Epoch 319: Train Loss = 0.2247, Test Loss = 0.7089837789535522:.4f\n",
      "Epoch 320: Train Loss = 0.1996, Test Loss = 0.694571852684021:.4f\n",
      "Epoch 321: Train Loss = 0.2148, Test Loss = 0.6970479488372803:.4f\n",
      "Epoch 322: Train Loss = 0.2078, Test Loss = 0.6934379935264587:.4f\n",
      "Epoch 323: Train Loss = 0.1938, Test Loss = 0.7247616648674011:.4f\n",
      "Epoch 324: Train Loss = 0.1926, Test Loss = 0.7270201444625854:.4f\n",
      "Epoch 325: Train Loss = 0.1851, Test Loss = 0.7101630568504333:.4f\n",
      "Epoch 326: Train Loss = 0.2000, Test Loss = 0.7048887610435486:.4f\n",
      "Epoch 327: Train Loss = 0.2180, Test Loss = 0.6944326162338257:.4f\n",
      "Epoch 328: Train Loss = 0.1923, Test Loss = 0.7025638818740845:.4f\n",
      "Epoch 329: Train Loss = 0.1995, Test Loss = 0.7169284224510193:.4f\n",
      "Epoch 330: Train Loss = 0.1857, Test Loss = 0.7342187166213989:.4f\n",
      "Epoch 331: Train Loss = 0.2333, Test Loss = 0.7400283813476562:.4f\n",
      "Epoch 332: Train Loss = 0.1824, Test Loss = 0.7188528180122375:.4f\n",
      "Epoch 333: Train Loss = 0.2174, Test Loss = 0.7072375416755676:.4f\n",
      "Epoch 334: Train Loss = 0.2193, Test Loss = 0.7107088565826416:.4f\n",
      "Epoch 335: Train Loss = 0.1717, Test Loss = 0.7258156538009644:.4f\n",
      "Epoch 336: Train Loss = 0.1863, Test Loss = 0.7338910102844238:.4f\n",
      "Epoch 337: Train Loss = 0.2193, Test Loss = 0.7157493829727173:.4f\n",
      "Epoch 338: Train Loss = 0.1842, Test Loss = 0.744326651096344:.4f\n",
      "Epoch 339: Train Loss = 0.2011, Test Loss = 0.7693789601325989:.4f\n",
      "Epoch 340: Train Loss = 0.2023, Test Loss = 0.7856694459915161:.4f\n",
      "Epoch 341: Train Loss = 0.2111, Test Loss = 0.7623003721237183:.4f\n",
      "Epoch 342: Train Loss = 0.2054, Test Loss = 0.7140618562698364:.4f\n",
      "Epoch 343: Train Loss = 0.1908, Test Loss = 0.7091531753540039:.4f\n",
      "Epoch 344: Train Loss = 0.1922, Test Loss = 0.7150578498840332:.4f\n",
      "Epoch 345: Train Loss = 0.1943, Test Loss = 0.7291015386581421:.4f\n",
      "Epoch 346: Train Loss = 0.2043, Test Loss = 0.737094521522522:.4f\n",
      "Epoch 347: Train Loss = 0.2139, Test Loss = 0.7498851418495178:.4f\n",
      "Epoch 348: Train Loss = 0.2026, Test Loss = 0.742845892906189:.4f\n",
      "Epoch 349: Train Loss = 0.1840, Test Loss = 0.7139076590538025:.4f\n",
      "Epoch 350: Train Loss = 0.1952, Test Loss = 0.7154176831245422:.4f\n",
      "Epoch 351: Train Loss = 0.1875, Test Loss = 0.7217720746994019:.4f\n",
      "Epoch 352: Train Loss = 0.1930, Test Loss = 0.7453072667121887:.4f\n",
      "Epoch 353: Train Loss = 0.1970, Test Loss = 0.765411913394928:.4f\n",
      "Epoch 354: Train Loss = 0.1816, Test Loss = 0.7678807973861694:.4f\n",
      "Epoch 355: Train Loss = 0.1959, Test Loss = 0.7418543100357056:.4f\n",
      "Epoch 356: Train Loss = 0.1831, Test Loss = 0.7243938446044922:.4f\n",
      "Epoch 357: Train Loss = 0.2088, Test Loss = 0.720432460308075:.4f\n",
      "Epoch 358: Train Loss = 0.2052, Test Loss = 0.7260139584541321:.4f\n",
      "Epoch 359: Train Loss = 0.1948, Test Loss = 0.7248713374137878:.4f\n",
      "Epoch 360: Train Loss = 0.1865, Test Loss = 0.7370336651802063:.4f\n",
      "Epoch 361: Train Loss = 0.1957, Test Loss = 0.7476719617843628:.4f\n",
      "Epoch 362: Train Loss = 0.2268, Test Loss = 0.7637612819671631:.4f\n",
      "Epoch 363: Train Loss = 0.1909, Test Loss = 0.7818699479103088:.4f\n",
      "Epoch 364: Train Loss = 0.2039, Test Loss = 0.7778722047805786:.4f\n",
      "Epoch 365: Train Loss = 0.1892, Test Loss = 0.7441433072090149:.4f\n",
      "Epoch 366: Train Loss = 0.1748, Test Loss = 0.7285521030426025:.4f\n",
      "Epoch 367: Train Loss = 0.1747, Test Loss = 0.7359925508499146:.4f\n",
      "Epoch 368: Train Loss = 0.1911, Test Loss = 0.7459312677383423:.4f\n",
      "Epoch 369: Train Loss = 0.1828, Test Loss = 0.7352689504623413:.4f\n",
      "Epoch 370: Train Loss = 0.1907, Test Loss = 0.7386382818222046:.4f\n",
      "Epoch 371: Train Loss = 0.1863, Test Loss = 0.7494250535964966:.4f\n",
      "Epoch 372: Train Loss = 0.1707, Test Loss = 0.7498675584793091:.4f\n",
      "Epoch 373: Train Loss = 0.1719, Test Loss = 0.7544558644294739:.4f\n",
      "Epoch 374: Train Loss = 0.1882, Test Loss = 0.7511979937553406:.4f\n",
      "Epoch 375: Train Loss = 0.1948, Test Loss = 0.7522591352462769:.4f\n",
      "Epoch 376: Train Loss = 0.1945, Test Loss = 0.7527220845222473:.4f\n",
      "Epoch 377: Train Loss = 0.1736, Test Loss = 0.7436750531196594:.4f\n",
      "Epoch 378: Train Loss = 0.1919, Test Loss = 0.7390357851982117:.4f\n",
      "Epoch 379: Train Loss = 0.1854, Test Loss = 0.7387434244155884:.4f\n",
      "Epoch 380: Train Loss = 0.1707, Test Loss = 0.7322239875793457:.4f\n",
      "Epoch 381: Train Loss = 0.1850, Test Loss = 0.7461152076721191:.4f\n",
      "Epoch 382: Train Loss = 0.1978, Test Loss = 0.7658412456512451:.4f\n",
      "Epoch 383: Train Loss = 0.2251, Test Loss = 0.764764130115509:.4f\n",
      "Epoch 384: Train Loss = 0.1776, Test Loss = 0.762886106967926:.4f\n",
      "Epoch 385: Train Loss = 0.1862, Test Loss = 0.7610238194465637:.4f\n",
      "Epoch 386: Train Loss = 0.1696, Test Loss = 0.7537811994552612:.4f\n",
      "Epoch 387: Train Loss = 0.1968, Test Loss = 0.7684594988822937:.4f\n",
      "Epoch 388: Train Loss = 0.1794, Test Loss = 0.7628187537193298:.4f\n",
      "Epoch 389: Train Loss = 0.1825, Test Loss = 0.7540532350540161:.4f\n",
      "Epoch 390: Train Loss = 0.1859, Test Loss = 0.7745401263237:.4f\n",
      "Epoch 391: Train Loss = 0.1956, Test Loss = 0.7955998182296753:.4f\n",
      "Epoch 392: Train Loss = 0.1879, Test Loss = 0.801598846912384:.4f\n",
      "Epoch 393: Train Loss = 0.1978, Test Loss = 0.7883103489875793:.4f\n",
      "Epoch 394: Train Loss = 0.2021, Test Loss = 0.763562023639679:.4f\n",
      "Epoch 395: Train Loss = 0.1914, Test Loss = 0.7600615620613098:.4f\n",
      "Epoch 396: Train Loss = 0.1725, Test Loss = 0.7627250552177429:.4f\n",
      "Epoch 397: Train Loss = 0.1761, Test Loss = 0.7656865119934082:.4f\n",
      "Epoch 398: Train Loss = 0.1803, Test Loss = 0.7648328542709351:.4f\n",
      "Epoch 399: Train Loss = 0.1894, Test Loss = 0.7559709548950195:.4f\n",
      "Epoch 400: Train Loss = 0.2265, Test Loss = 0.7683273553848267:.4f\n",
      "Epoch 401: Train Loss = 0.1761, Test Loss = 0.7741951942443848:.4f\n",
      "Epoch 402: Train Loss = 0.2069, Test Loss = 0.7841469645500183:.4f\n",
      "Epoch 403: Train Loss = 0.1881, Test Loss = 0.7728603482246399:.4f\n",
      "Epoch 404: Train Loss = 0.1721, Test Loss = 0.7794884443283081:.4f\n",
      "Epoch 405: Train Loss = 0.2150, Test Loss = 0.769111692905426:.4f\n",
      "Epoch 406: Train Loss = 0.1953, Test Loss = 0.7490893602371216:.4f\n",
      "Epoch 407: Train Loss = 0.1889, Test Loss = 0.7676303386688232:.4f\n",
      "Epoch 408: Train Loss = 0.1803, Test Loss = 0.7939192056655884:.4f\n",
      "Epoch 409: Train Loss = 0.1727, Test Loss = 0.8135344386100769:.4f\n",
      "Epoch 410: Train Loss = 0.1939, Test Loss = 0.8021446466445923:.4f\n",
      "Epoch 411: Train Loss = 0.1907, Test Loss = 0.7615692019462585:.4f\n",
      "Epoch 412: Train Loss = 0.1728, Test Loss = 0.7427383661270142:.4f\n",
      "Epoch 413: Train Loss = 0.1832, Test Loss = 0.7491825222969055:.4f\n",
      "Epoch 414: Train Loss = 0.1949, Test Loss = 0.78926020860672:.4f\n",
      "Epoch 415: Train Loss = 0.1832, Test Loss = 0.8131597638130188:.4f\n",
      "Epoch 416: Train Loss = 0.2056, Test Loss = 0.8299392461776733:.4f\n",
      "Epoch 417: Train Loss = 0.1939, Test Loss = 0.7986510396003723:.4f\n",
      "Epoch 418: Train Loss = 0.1818, Test Loss = 0.7831078767776489:.4f\n",
      "Epoch 419: Train Loss = 0.1856, Test Loss = 0.7767937183380127:.4f\n",
      "Epoch 420: Train Loss = 0.1945, Test Loss = 0.7811940312385559:.4f\n",
      "Epoch 421: Train Loss = 0.2134, Test Loss = 0.7913376092910767:.4f\n",
      "Epoch 422: Train Loss = 0.1967, Test Loss = 0.7895575761795044:.4f\n",
      "Epoch 423: Train Loss = 0.1853, Test Loss = 0.791634202003479:.4f\n",
      "Epoch 424: Train Loss = 0.1767, Test Loss = 0.8035811185836792:.4f\n",
      "Epoch 425: Train Loss = 0.1644, Test Loss = 0.7948147058486938:.4f\n",
      "Epoch 426: Train Loss = 0.1805, Test Loss = 0.7857375144958496:.4f\n",
      "Epoch 427: Train Loss = 0.1810, Test Loss = 0.7850615978240967:.4f\n",
      "Epoch 428: Train Loss = 0.1720, Test Loss = 0.7908555865287781:.4f\n",
      "Epoch 429: Train Loss = 0.1669, Test Loss = 0.7941222190856934:.4f\n",
      "Epoch 430: Train Loss = 0.1757, Test Loss = 0.7996532917022705:.4f\n",
      "Epoch 431: Train Loss = 0.1959, Test Loss = 0.8058627247810364:.4f\n",
      "Epoch 432: Train Loss = 0.1793, Test Loss = 0.786805272102356:.4f\n",
      "Epoch 433: Train Loss = 0.1686, Test Loss = 0.7879605889320374:.4f\n",
      "Epoch 434: Train Loss = 0.1832, Test Loss = 0.7935150861740112:.4f\n",
      "Epoch 435: Train Loss = 0.1823, Test Loss = 0.791705846786499:.4f\n",
      "Epoch 436: Train Loss = 0.2060, Test Loss = 0.7971633672714233:.4f\n",
      "Epoch 437: Train Loss = 0.1853, Test Loss = 0.8104241490364075:.4f\n",
      "Epoch 438: Train Loss = 0.1655, Test Loss = 0.8062524795532227:.4f\n",
      "Epoch 439: Train Loss = 0.1944, Test Loss = 0.7917256355285645:.4f\n",
      "Epoch 440: Train Loss = 0.1691, Test Loss = 0.7880610227584839:.4f\n",
      "Epoch 441: Train Loss = 0.1832, Test Loss = 0.790784478187561:.4f\n",
      "Epoch 442: Train Loss = 0.1886, Test Loss = 0.7952076196670532:.4f\n",
      "Epoch 443: Train Loss = 0.1566, Test Loss = 0.8038051724433899:.4f\n",
      "Epoch 444: Train Loss = 0.1955, Test Loss = 0.8004782795906067:.4f\n",
      "Epoch 445: Train Loss = 0.2024, Test Loss = 0.8118921518325806:.4f\n",
      "Epoch 446: Train Loss = 0.1867, Test Loss = 0.8218210935592651:.4f\n",
      "Epoch 447: Train Loss = 0.1829, Test Loss = 0.8205096125602722:.4f\n",
      "Epoch 448: Train Loss = 0.1761, Test Loss = 0.7965267896652222:.4f\n",
      "Epoch 449: Train Loss = 0.1873, Test Loss = 0.8025979995727539:.4f\n",
      "Epoch 450: Train Loss = 0.1653, Test Loss = 0.8120622634887695:.4f\n",
      "Epoch 451: Train Loss = 0.1592, Test Loss = 0.8294499516487122:.4f\n",
      "Epoch 452: Train Loss = 0.1770, Test Loss = 0.8299533724784851:.4f\n",
      "Epoch 453: Train Loss = 0.1668, Test Loss = 0.8269270658493042:.4f\n",
      "Epoch 454: Train Loss = 0.2000, Test Loss = 0.8250738978385925:.4f\n",
      "Epoch 455: Train Loss = 0.1918, Test Loss = 0.822311520576477:.4f\n",
      "Epoch 456: Train Loss = 0.1864, Test Loss = 0.8155959248542786:.4f\n",
      "Epoch 457: Train Loss = 0.1676, Test Loss = 0.8073785901069641:.4f\n",
      "Epoch 458: Train Loss = 0.1592, Test Loss = 0.8070135116577148:.4f\n",
      "Epoch 459: Train Loss = 0.1866, Test Loss = 0.814344584941864:.4f\n",
      "Epoch 460: Train Loss = 0.1802, Test Loss = 0.8077389001846313:.4f\n",
      "Epoch 461: Train Loss = 0.2009, Test Loss = 0.8011085391044617:.4f\n",
      "Epoch 462: Train Loss = 0.1580, Test Loss = 0.8195368051528931:.4f\n",
      "Epoch 463: Train Loss = 0.1633, Test Loss = 0.8424824476242065:.4f\n",
      "Epoch 464: Train Loss = 0.1798, Test Loss = 0.8476364016532898:.4f\n",
      "Epoch 465: Train Loss = 0.1664, Test Loss = 0.8444538116455078:.4f\n",
      "Epoch 466: Train Loss = 0.1824, Test Loss = 0.8370696306228638:.4f\n",
      "Epoch 467: Train Loss = 0.2016, Test Loss = 0.8144537210464478:.4f\n",
      "Epoch 468: Train Loss = 0.1937, Test Loss = 0.7967106699943542:.4f\n",
      "Epoch 469: Train Loss = 0.1955, Test Loss = 0.8109035491943359:.4f\n",
      "Epoch 470: Train Loss = 0.2028, Test Loss = 0.8357095718383789:.4f\n",
      "Epoch 471: Train Loss = 0.1638, Test Loss = 0.8424586057662964:.4f\n",
      "Epoch 472: Train Loss = 0.1587, Test Loss = 0.8454340100288391:.4f\n",
      "Epoch 473: Train Loss = 0.1847, Test Loss = 0.8337322473526001:.4f\n",
      "Epoch 474: Train Loss = 0.1855, Test Loss = 0.8080183863639832:.4f\n",
      "Epoch 475: Train Loss = 0.1624, Test Loss = 0.8039323091506958:.4f\n",
      "Epoch 476: Train Loss = 0.1653, Test Loss = 0.8146864175796509:.4f\n",
      "Epoch 477: Train Loss = 0.1814, Test Loss = 0.8251432180404663:.4f\n",
      "Epoch 478: Train Loss = 0.1835, Test Loss = 0.8357645869255066:.4f\n",
      "Epoch 479: Train Loss = 0.1738, Test Loss = 0.8361496925354004:.4f\n",
      "Epoch 480: Train Loss = 0.1719, Test Loss = 0.8401495814323425:.4f\n",
      "Epoch 481: Train Loss = 0.1649, Test Loss = 0.8357990980148315:.4f\n",
      "Epoch 482: Train Loss = 0.1973, Test Loss = 0.8344987630844116:.4f\n",
      "Epoch 483: Train Loss = 0.1606, Test Loss = 0.8348824381828308:.4f\n",
      "Epoch 484: Train Loss = 0.1712, Test Loss = 0.836016058921814:.4f\n",
      "Epoch 485: Train Loss = 0.1559, Test Loss = 0.8293368220329285:.4f\n",
      "Epoch 486: Train Loss = 0.1973, Test Loss = 0.8209740519523621:.4f\n",
      "Epoch 487: Train Loss = 0.1793, Test Loss = 0.8300504684448242:.4f\n",
      "Epoch 488: Train Loss = 0.1873, Test Loss = 0.8294690251350403:.4f\n",
      "Epoch 489: Train Loss = 0.1567, Test Loss = 0.8464237451553345:.4f\n",
      "Epoch 490: Train Loss = 0.1802, Test Loss = 0.856688380241394:.4f\n",
      "Epoch 491: Train Loss = 0.1854, Test Loss = 0.8486951589584351:.4f\n",
      "Epoch 492: Train Loss = 0.1717, Test Loss = 0.8314329385757446:.4f\n",
      "Epoch 493: Train Loss = 0.1693, Test Loss = 0.8366045951843262:.4f\n",
      "Epoch 494: Train Loss = 0.1775, Test Loss = 0.834301769733429:.4f\n",
      "Epoch 495: Train Loss = 0.1601, Test Loss = 0.846546471118927:.4f\n",
      "Epoch 496: Train Loss = 0.1759, Test Loss = 0.8631983995437622:.4f\n",
      "Epoch 497: Train Loss = 0.2097, Test Loss = 0.8724721074104309:.4f\n",
      "Epoch 498: Train Loss = 0.1782, Test Loss = 0.866805374622345:.4f\n",
      "Epoch 499: Train Loss = 0.1876, Test Loss = 0.845206081867218:.4f\n",
      "Epoch 500: Train Loss = 0.1745, Test Loss = 0.8329917788505554:.4f\n",
      "Epoch 501: Train Loss = 0.1654, Test Loss = 0.8413535952568054:.4f\n",
      "Epoch 502: Train Loss = 0.1791, Test Loss = 0.848039984703064:.4f\n",
      "Epoch 503: Train Loss = 0.1602, Test Loss = 0.8631883859634399:.4f\n",
      "Epoch 504: Train Loss = 0.1687, Test Loss = 0.8687280416488647:.4f\n",
      "Epoch 505: Train Loss = 0.1907, Test Loss = 0.8363261222839355:.4f\n",
      "Epoch 506: Train Loss = 0.1643, Test Loss = 0.8328911066055298:.4f\n",
      "Epoch 507: Train Loss = 0.1709, Test Loss = 0.8402825593948364:.4f\n",
      "Epoch 508: Train Loss = 0.1730, Test Loss = 0.842021107673645:.4f\n",
      "Epoch 509: Train Loss = 0.1603, Test Loss = 0.8699167966842651:.4f\n",
      "Epoch 510: Train Loss = 0.1734, Test Loss = 0.8872838020324707:.4f\n",
      "Epoch 511: Train Loss = 0.1866, Test Loss = 0.859215259552002:.4f\n",
      "Epoch 512: Train Loss = 0.1666, Test Loss = 0.8411602973937988:.4f\n",
      "Epoch 513: Train Loss = 0.1609, Test Loss = 0.8323447108268738:.4f\n",
      "Epoch 514: Train Loss = 0.1607, Test Loss = 0.8335259556770325:.4f\n",
      "Epoch 515: Train Loss = 0.1851, Test Loss = 0.8448351621627808:.4f\n",
      "Epoch 516: Train Loss = 0.1988, Test Loss = 0.839049220085144:.4f\n",
      "Epoch 517: Train Loss = 0.1922, Test Loss = 0.8638604879379272:.4f\n",
      "Epoch 518: Train Loss = 0.1906, Test Loss = 0.8766048550605774:.4f\n",
      "Epoch 519: Train Loss = 0.1760, Test Loss = 0.8718795776367188:.4f\n",
      "Epoch 520: Train Loss = 0.1580, Test Loss = 0.8531144857406616:.4f\n",
      "Epoch 521: Train Loss = 0.1787, Test Loss = 0.8246439695358276:.4f\n",
      "Epoch 522: Train Loss = 0.1802, Test Loss = 0.8227978944778442:.4f\n",
      "Epoch 523: Train Loss = 0.1590, Test Loss = 0.8531492948532104:.4f\n",
      "Epoch 524: Train Loss = 0.1775, Test Loss = 0.887366771697998:.4f\n",
      "Epoch 525: Train Loss = 0.1607, Test Loss = 0.8728764653205872:.4f\n",
      "Epoch 526: Train Loss = 0.1479, Test Loss = 0.8650914430618286:.4f\n",
      "Epoch 527: Train Loss = 0.1523, Test Loss = 0.8558521270751953:.4f\n",
      "Epoch 528: Train Loss = 0.1729, Test Loss = 0.8407788276672363:.4f\n",
      "Epoch 529: Train Loss = 0.1668, Test Loss = 0.8434316515922546:.4f\n",
      "Epoch 530: Train Loss = 0.1591, Test Loss = 0.8719626665115356:.4f\n",
      "Epoch 531: Train Loss = 0.1953, Test Loss = 0.8884800672531128:.4f\n",
      "Epoch 532: Train Loss = 0.1944, Test Loss = 0.8727827072143555:.4f\n",
      "Epoch 533: Train Loss = 0.1761, Test Loss = 0.8515931367874146:.4f\n",
      "Epoch 534: Train Loss = 0.1980, Test Loss = 0.8526629209518433:.4f\n",
      "Epoch 535: Train Loss = 0.1738, Test Loss = 0.8710759282112122:.4f\n",
      "Epoch 536: Train Loss = 0.1674, Test Loss = 0.8847134709358215:.4f\n",
      "Epoch 537: Train Loss = 0.1578, Test Loss = 0.8732337951660156:.4f\n",
      "Epoch 538: Train Loss = 0.1994, Test Loss = 0.8692267537117004:.4f\n",
      "Epoch 539: Train Loss = 0.1931, Test Loss = 0.8710921406745911:.4f\n",
      "Epoch 540: Train Loss = 0.1710, Test Loss = 0.870446503162384:.4f\n",
      "Epoch 541: Train Loss = 0.1711, Test Loss = 0.8925072550773621:.4f\n",
      "Epoch 542: Train Loss = 0.1694, Test Loss = 0.8963819742202759:.4f\n",
      "Epoch 543: Train Loss = 0.1587, Test Loss = 0.8766390085220337:.4f\n",
      "Epoch 544: Train Loss = 0.1474, Test Loss = 0.8656676411628723:.4f\n",
      "Epoch 545: Train Loss = 0.1870, Test Loss = 0.8670955896377563:.4f\n",
      "Epoch 546: Train Loss = 0.1530, Test Loss = 0.8779760599136353:.4f\n",
      "Epoch 547: Train Loss = 0.1809, Test Loss = 0.8767707943916321:.4f\n",
      "Epoch 548: Train Loss = 0.1584, Test Loss = 0.8626082539558411:.4f\n",
      "Epoch 549: Train Loss = 0.1761, Test Loss = 0.8574637174606323:.4f\n",
      "Epoch 550: Train Loss = 0.1711, Test Loss = 0.8694685101509094:.4f\n",
      "Epoch 551: Train Loss = 0.1754, Test Loss = 0.8767076730728149:.4f\n",
      "Epoch 552: Train Loss = 0.1757, Test Loss = 0.8675119280815125:.4f\n",
      "Epoch 553: Train Loss = 0.1813, Test Loss = 0.8574916124343872:.4f\n",
      "Epoch 554: Train Loss = 0.1541, Test Loss = 0.8651955723762512:.4f\n",
      "Epoch 555: Train Loss = 0.1776, Test Loss = 0.8805190324783325:.4f\n",
      "Epoch 556: Train Loss = 0.1648, Test Loss = 0.889565646648407:.4f\n",
      "Epoch 557: Train Loss = 0.1525, Test Loss = 0.8857415914535522:.4f\n",
      "Epoch 558: Train Loss = 0.1752, Test Loss = 0.8812546730041504:.4f\n",
      "Epoch 559: Train Loss = 0.1756, Test Loss = 0.87675940990448:.4f\n",
      "Epoch 560: Train Loss = 0.1753, Test Loss = 0.8610579371452332:.4f\n",
      "Epoch 561: Train Loss = 0.1546, Test Loss = 0.8654146194458008:.4f\n",
      "Epoch 562: Train Loss = 0.1818, Test Loss = 0.8734019994735718:.4f\n",
      "Epoch 563: Train Loss = 0.1627, Test Loss = 0.8771332502365112:.4f\n",
      "Epoch 564: Train Loss = 0.1697, Test Loss = 0.8949189186096191:.4f\n",
      "Epoch 565: Train Loss = 0.1603, Test Loss = 0.9023923873901367:.4f\n",
      "Epoch 566: Train Loss = 0.1613, Test Loss = 0.8872887492179871:.4f\n",
      "Epoch 567: Train Loss = 0.1704, Test Loss = 0.8816189765930176:.4f\n",
      "Epoch 568: Train Loss = 0.1625, Test Loss = 0.8519634008407593:.4f\n",
      "Epoch 569: Train Loss = 0.1706, Test Loss = 0.8357179760932922:.4f\n",
      "Epoch 570: Train Loss = 0.1698, Test Loss = 0.8563725352287292:.4f\n",
      "Epoch 571: Train Loss = 0.1744, Test Loss = 0.875889003276825:.4f\n",
      "Epoch 572: Train Loss = 0.1855, Test Loss = 0.8901675343513489:.4f\n",
      "Epoch 573: Train Loss = 0.1755, Test Loss = 0.8951002955436707:.4f\n",
      "Epoch 574: Train Loss = 0.1495, Test Loss = 0.8915970921516418:.4f\n",
      "Epoch 575: Train Loss = 0.1731, Test Loss = 0.87615966796875:.4f\n",
      "Epoch 576: Train Loss = 0.1553, Test Loss = 0.8620009422302246:.4f\n",
      "Epoch 577: Train Loss = 0.1847, Test Loss = 0.8541421890258789:.4f\n",
      "Epoch 578: Train Loss = 0.1581, Test Loss = 0.8646023869514465:.4f\n",
      "Epoch 579: Train Loss = 0.1496, Test Loss = 0.8808196187019348:.4f\n",
      "Epoch 580: Train Loss = 0.2142, Test Loss = 0.8936206102371216:.4f\n",
      "Epoch 581: Train Loss = 0.1544, Test Loss = 0.8905211687088013:.4f\n",
      "Epoch 582: Train Loss = 0.1561, Test Loss = 0.8949558138847351:.4f\n",
      "Epoch 583: Train Loss = 0.1581, Test Loss = 0.8859269022941589:.4f\n",
      "Epoch 584: Train Loss = 0.1535, Test Loss = 0.8876676559448242:.4f\n",
      "Epoch 585: Train Loss = 0.1585, Test Loss = 0.8894933462142944:.4f\n",
      "Epoch 586: Train Loss = 0.1504, Test Loss = 0.8826003074645996:.4f\n",
      "Epoch 587: Train Loss = 0.1690, Test Loss = 0.86793452501297:.4f\n",
      "Epoch 588: Train Loss = 0.1602, Test Loss = 0.8730303049087524:.4f\n",
      "Epoch 589: Train Loss = 0.1737, Test Loss = 0.8729900121688843:.4f\n",
      "Epoch 590: Train Loss = 0.1572, Test Loss = 0.8893674612045288:.4f\n",
      "Epoch 591: Train Loss = 0.1624, Test Loss = 0.898714542388916:.4f\n",
      "Epoch 592: Train Loss = 0.1492, Test Loss = 0.8883031606674194:.4f\n",
      "Epoch 593: Train Loss = 0.1480, Test Loss = 0.8740054368972778:.4f\n",
      "Epoch 594: Train Loss = 0.1711, Test Loss = 0.8671132922172546:.4f\n",
      "Epoch 595: Train Loss = 0.1739, Test Loss = 0.8777820467948914:.4f\n",
      "Epoch 596: Train Loss = 0.1831, Test Loss = 0.890649676322937:.4f\n",
      "Epoch 597: Train Loss = 0.1715, Test Loss = 0.8896603584289551:.4f\n",
      "Epoch 598: Train Loss = 0.1870, Test Loss = 0.8840852975845337:.4f\n",
      "Epoch 599: Train Loss = 0.1733, Test Loss = 0.8820285797119141:.4f\n",
      "Epoch 600: Train Loss = 0.2045, Test Loss = 0.8974482417106628:.4f\n",
      "Epoch 601: Train Loss = 0.1732, Test Loss = 0.8677786588668823:.4f\n",
      "Epoch 602: Train Loss = 0.1779, Test Loss = 0.8642715215682983:.4f\n",
      "Epoch 603: Train Loss = 0.1550, Test Loss = 0.873520016670227:.4f\n",
      "Epoch 604: Train Loss = 0.1533, Test Loss = 0.8941906690597534:.4f\n",
      "Epoch 605: Train Loss = 0.1782, Test Loss = 0.8877319097518921:.4f\n",
      "Epoch 606: Train Loss = 0.1873, Test Loss = 0.8883787393569946:.4f\n",
      "Epoch 607: Train Loss = 0.1800, Test Loss = 0.8881216049194336:.4f\n",
      "Epoch 608: Train Loss = 0.1634, Test Loss = 0.8901292085647583:.4f\n",
      "Epoch 609: Train Loss = 0.1649, Test Loss = 0.8922451138496399:.4f\n",
      "Epoch 610: Train Loss = 0.1494, Test Loss = 0.8967143893241882:.4f\n",
      "Epoch 611: Train Loss = 0.1701, Test Loss = 0.9016024470329285:.4f\n",
      "Epoch 612: Train Loss = 0.1543, Test Loss = 0.8947803378105164:.4f\n",
      "Epoch 613: Train Loss = 0.1574, Test Loss = 0.8903253674507141:.4f\n",
      "Epoch 614: Train Loss = 0.1561, Test Loss = 0.8993567228317261:.4f\n",
      "Epoch 615: Train Loss = 0.1538, Test Loss = 0.9027006030082703:.4f\n",
      "Epoch 616: Train Loss = 0.1717, Test Loss = 0.9125837087631226:.4f\n",
      "Epoch 617: Train Loss = 0.1776, Test Loss = 0.9076512455940247:.4f\n",
      "Epoch 618: Train Loss = 0.1453, Test Loss = 0.8895490765571594:.4f\n",
      "Epoch 619: Train Loss = 0.1948, Test Loss = 0.8783023953437805:.4f\n",
      "Epoch 620: Train Loss = 0.1585, Test Loss = 0.8814187049865723:.4f\n",
      "Epoch 621: Train Loss = 0.1473, Test Loss = 0.8831303715705872:.4f\n",
      "Epoch 622: Train Loss = 0.1924, Test Loss = 0.8942075967788696:.4f\n",
      "Epoch 623: Train Loss = 0.1744, Test Loss = 0.8885036706924438:.4f\n",
      "Epoch 624: Train Loss = 0.1903, Test Loss = 0.8867243528366089:.4f\n",
      "Epoch 625: Train Loss = 0.1560, Test Loss = 0.8870676159858704:.4f\n",
      "Epoch 626: Train Loss = 0.1500, Test Loss = 0.9058049321174622:.4f\n",
      "Epoch 627: Train Loss = 0.1525, Test Loss = 0.9100363850593567:.4f\n",
      "Epoch 628: Train Loss = 0.1641, Test Loss = 0.9053493738174438:.4f\n",
      "Epoch 629: Train Loss = 0.1597, Test Loss = 0.8970508575439453:.4f\n",
      "Epoch 630: Train Loss = 0.1819, Test Loss = 0.9063711166381836:.4f\n",
      "Epoch 631: Train Loss = 0.1454, Test Loss = 0.9218276739120483:.4f\n",
      "Epoch 632: Train Loss = 0.1719, Test Loss = 0.9227830171585083:.4f\n",
      "Epoch 633: Train Loss = 0.2050, Test Loss = 0.8936752080917358:.4f\n",
      "Epoch 634: Train Loss = 0.1612, Test Loss = 0.882349967956543:.4f\n",
      "Epoch 635: Train Loss = 0.1716, Test Loss = 0.8907321691513062:.4f\n",
      "Epoch 636: Train Loss = 0.1819, Test Loss = 0.9075266122817993:.4f\n",
      "Epoch 637: Train Loss = 0.1410, Test Loss = 0.9356679916381836:.4f\n",
      "Epoch 638: Train Loss = 0.1646, Test Loss = 0.9344817996025085:.4f\n",
      "Epoch 639: Train Loss = 0.1780, Test Loss = 0.8941136598587036:.4f\n",
      "Epoch 640: Train Loss = 0.1652, Test Loss = 0.8808863759040833:.4f\n",
      "Epoch 641: Train Loss = 0.1642, Test Loss = 0.8889051675796509:.4f\n",
      "Epoch 642: Train Loss = 0.1598, Test Loss = 0.9059638977050781:.4f\n",
      "Epoch 643: Train Loss = 0.1738, Test Loss = 0.9176521301269531:.4f\n",
      "Epoch 644: Train Loss = 0.1543, Test Loss = 0.9180697202682495:.4f\n",
      "Epoch 645: Train Loss = 0.1589, Test Loss = 0.9216233491897583:.4f\n",
      "Epoch 646: Train Loss = 0.1901, Test Loss = 0.9116233587265015:.4f\n",
      "Epoch 647: Train Loss = 0.1804, Test Loss = 0.8919614553451538:.4f\n",
      "Epoch 648: Train Loss = 0.1912, Test Loss = 0.8832570314407349:.4f\n",
      "Epoch 649: Train Loss = 0.1552, Test Loss = 0.8899117708206177:.4f\n",
      "Epoch 650: Train Loss = 0.1534, Test Loss = 0.9023855924606323:.4f\n",
      "Epoch 651: Train Loss = 0.1968, Test Loss = 0.9144762754440308:.4f\n",
      "Epoch 652: Train Loss = 0.1799, Test Loss = 0.9129825830459595:.4f\n",
      "Epoch 653: Train Loss = 0.1649, Test Loss = 0.9004135131835938:.4f\n",
      "Epoch 654: Train Loss = 0.1560, Test Loss = 0.8909198641777039:.4f\n",
      "Epoch 655: Train Loss = 0.1559, Test Loss = 0.8952903747558594:.4f\n",
      "Epoch 656: Train Loss = 0.1791, Test Loss = 0.9018168449401855:.4f\n",
      "Epoch 657: Train Loss = 0.1421, Test Loss = 0.900151252746582:.4f\n",
      "Epoch 658: Train Loss = 0.1816, Test Loss = 0.9063132405281067:.4f\n",
      "Epoch 659: Train Loss = 0.1427, Test Loss = 0.9059175252914429:.4f\n",
      "Epoch 660: Train Loss = 0.1709, Test Loss = 0.9092639088630676:.4f\n",
      "Epoch 661: Train Loss = 0.1406, Test Loss = 0.9208532571792603:.4f\n",
      "Epoch 662: Train Loss = 0.1841, Test Loss = 0.9244450330734253:.4f\n",
      "Epoch 663: Train Loss = 0.1542, Test Loss = 0.9242409467697144:.4f\n",
      "Epoch 664: Train Loss = 0.1476, Test Loss = 0.9166294932365417:.4f\n",
      "Epoch 665: Train Loss = 0.1745, Test Loss = 0.8872068524360657:.4f\n",
      "Epoch 666: Train Loss = 0.1447, Test Loss = 0.8843992948532104:.4f\n",
      "Epoch 667: Train Loss = 0.1814, Test Loss = 0.8908470869064331:.4f\n",
      "Epoch 668: Train Loss = 0.1822, Test Loss = 0.9058758020401001:.4f\n",
      "Epoch 669: Train Loss = 0.1798, Test Loss = 0.9274604916572571:.4f\n",
      "Epoch 670: Train Loss = 0.1622, Test Loss = 0.9377083778381348:.4f\n",
      "Epoch 671: Train Loss = 0.1574, Test Loss = 0.9254721403121948:.4f\n",
      "Epoch 672: Train Loss = 0.1585, Test Loss = 0.8918137550354004:.4f\n",
      "Epoch 673: Train Loss = 0.1971, Test Loss = 0.8721131086349487:.4f\n",
      "Epoch 674: Train Loss = 0.1724, Test Loss = 0.8851226568222046:.4f\n",
      "Epoch 675: Train Loss = 0.1709, Test Loss = 0.9104326963424683:.4f\n",
      "Epoch 676: Train Loss = 0.1485, Test Loss = 0.939898669719696:.4f\n",
      "Epoch 677: Train Loss = 0.1515, Test Loss = 0.945052981376648:.4f\n",
      "Epoch 678: Train Loss = 0.1698, Test Loss = 0.9236226081848145:.4f\n",
      "Epoch 679: Train Loss = 0.1628, Test Loss = 0.9032444953918457:.4f\n",
      "Epoch 680: Train Loss = 0.1790, Test Loss = 0.9035868644714355:.4f\n",
      "Epoch 681: Train Loss = 0.1667, Test Loss = 0.9076608419418335:.4f\n",
      "Epoch 682: Train Loss = 0.1399, Test Loss = 0.9113826751708984:.4f\n",
      "Epoch 683: Train Loss = 0.1815, Test Loss = 0.9142541885375977:.4f\n",
      "Epoch 684: Train Loss = 0.1846, Test Loss = 0.9169363975524902:.4f\n",
      "Epoch 685: Train Loss = 0.1794, Test Loss = 0.9185574650764465:.4f\n",
      "Epoch 686: Train Loss = 0.1811, Test Loss = 0.9182959794998169:.4f\n",
      "Epoch 687: Train Loss = 0.1563, Test Loss = 0.9187979698181152:.4f\n",
      "Epoch 688: Train Loss = 0.1502, Test Loss = 0.9284623861312866:.4f\n",
      "Epoch 689: Train Loss = 0.1533, Test Loss = 0.921482264995575:.4f\n",
      "Epoch 690: Train Loss = 0.1477, Test Loss = 0.921726405620575:.4f\n",
      "Epoch 691: Train Loss = 0.1579, Test Loss = 0.9099243879318237:.4f\n",
      "Epoch 692: Train Loss = 0.1563, Test Loss = 0.8955733180046082:.4f\n",
      "Epoch 693: Train Loss = 0.1488, Test Loss = 0.894141674041748:.4f\n",
      "Epoch 694: Train Loss = 0.1449, Test Loss = 0.9109461903572083:.4f\n",
      "Epoch 695: Train Loss = 0.1713, Test Loss = 0.9279893636703491:.4f\n",
      "Epoch 696: Train Loss = 0.1567, Test Loss = 0.9233611822128296:.4f\n",
      "Epoch 697: Train Loss = 0.1801, Test Loss = 0.9182143211364746:.4f\n",
      "Epoch 698: Train Loss = 0.1611, Test Loss = 0.9241456985473633:.4f\n",
      "Epoch 699: Train Loss = 0.1760, Test Loss = 0.9265556335449219:.4f\n",
      "Epoch 700: Train Loss = 0.1714, Test Loss = 0.9280717968940735:.4f\n",
      "Epoch 701: Train Loss = 0.1559, Test Loss = 0.9182618856430054:.4f\n",
      "Epoch 702: Train Loss = 0.1391, Test Loss = 0.9102176427841187:.4f\n",
      "Epoch 703: Train Loss = 0.1735, Test Loss = 0.903384804725647:.4f\n",
      "Epoch 704: Train Loss = 0.1705, Test Loss = 0.916094183921814:.4f\n",
      "Epoch 705: Train Loss = 0.1506, Test Loss = 0.9259227514266968:.4f\n",
      "Epoch 706: Train Loss = 0.1629, Test Loss = 0.9280853271484375:.4f\n",
      "Epoch 707: Train Loss = 0.2211, Test Loss = 0.9208143353462219:.4f\n",
      "Epoch 708: Train Loss = 0.1592, Test Loss = 0.9232603311538696:.4f\n",
      "Epoch 709: Train Loss = 0.1811, Test Loss = 0.9166623950004578:.4f\n",
      "Epoch 710: Train Loss = 0.1772, Test Loss = 0.9206231236457825:.4f\n",
      "Epoch 711: Train Loss = 0.1742, Test Loss = 0.9127861857414246:.4f\n",
      "Epoch 712: Train Loss = 0.1801, Test Loss = 0.9020163416862488:.4f\n",
      "Epoch 713: Train Loss = 0.1499, Test Loss = 0.9108861684799194:.4f\n",
      "Epoch 714: Train Loss = 0.1529, Test Loss = 0.9191777110099792:.4f\n",
      "Epoch 715: Train Loss = 0.1633, Test Loss = 0.9219411015510559:.4f\n",
      "Epoch 716: Train Loss = 0.1544, Test Loss = 0.9276641607284546:.4f\n",
      "Epoch 717: Train Loss = 0.1612, Test Loss = 0.9424687623977661:.4f\n",
      "Epoch 718: Train Loss = 0.1581, Test Loss = 0.9340630769729614:.4f\n",
      "Epoch 719: Train Loss = 0.1475, Test Loss = 0.9148484468460083:.4f\n",
      "Epoch 720: Train Loss = 0.1714, Test Loss = 0.9010637402534485:.4f\n",
      "Epoch 721: Train Loss = 0.1641, Test Loss = 0.8970464468002319:.4f\n",
      "Epoch 722: Train Loss = 0.1532, Test Loss = 0.9202579259872437:.4f\n",
      "Epoch 723: Train Loss = 0.1992, Test Loss = 0.9290034174919128:.4f\n",
      "Epoch 724: Train Loss = 0.1462, Test Loss = 0.9513207674026489:.4f\n",
      "Epoch 725: Train Loss = 0.1601, Test Loss = 0.945522665977478:.4f\n",
      "Epoch 726: Train Loss = 0.1621, Test Loss = 0.9357932806015015:.4f\n",
      "Epoch 727: Train Loss = 0.1405, Test Loss = 0.9227803349494934:.4f\n",
      "Epoch 728: Train Loss = 0.1644, Test Loss = 0.9121600389480591:.4f\n",
      "Epoch 729: Train Loss = 0.1699, Test Loss = 0.9182268381118774:.4f\n",
      "Epoch 730: Train Loss = 0.1474, Test Loss = 0.9241997599601746:.4f\n",
      "Epoch 731: Train Loss = 0.1905, Test Loss = 0.9384796023368835:.4f\n",
      "Epoch 732: Train Loss = 0.1752, Test Loss = 0.9302068948745728:.4f\n",
      "Epoch 733: Train Loss = 0.1511, Test Loss = 0.9303115606307983:.4f\n",
      "Epoch 734: Train Loss = 0.1738, Test Loss = 0.9247848391532898:.4f\n",
      "Epoch 735: Train Loss = 0.1484, Test Loss = 0.9115398526191711:.4f\n",
      "Epoch 736: Train Loss = 0.1747, Test Loss = 0.9037531018257141:.4f\n",
      "Epoch 737: Train Loss = 0.1502, Test Loss = 0.9117066264152527:.4f\n",
      "Epoch 738: Train Loss = 0.1639, Test Loss = 0.9289913177490234:.4f\n",
      "Epoch 739: Train Loss = 0.1587, Test Loss = 0.9264609217643738:.4f\n",
      "Epoch 740: Train Loss = 0.1763, Test Loss = 0.9324862360954285:.4f\n",
      "Epoch 741: Train Loss = 0.1818, Test Loss = 0.9513471722602844:.4f\n",
      "Epoch 742: Train Loss = 0.1716, Test Loss = 0.955702006816864:.4f\n",
      "Epoch 743: Train Loss = 0.1785, Test Loss = 0.9430624842643738:.4f\n",
      "Epoch 744: Train Loss = 0.1479, Test Loss = 0.9308301210403442:.4f\n",
      "Epoch 745: Train Loss = 0.1526, Test Loss = 0.9191985130310059:.4f\n",
      "Epoch 746: Train Loss = 0.1660, Test Loss = 0.9079945683479309:.4f\n",
      "Epoch 747: Train Loss = 0.1498, Test Loss = 0.9032469987869263:.4f\n",
      "Epoch 748: Train Loss = 0.1515, Test Loss = 0.8982345461845398:.4f\n",
      "Epoch 749: Train Loss = 0.1449, Test Loss = 0.9117439389228821:.4f\n",
      "Epoch 750: Train Loss = 0.1529, Test Loss = 0.9256390333175659:.4f\n",
      "Epoch 751: Train Loss = 0.1392, Test Loss = 0.9338427782058716:.4f\n",
      "Epoch 752: Train Loss = 0.1973, Test Loss = 0.941982090473175:.4f\n",
      "Epoch 753: Train Loss = 0.1606, Test Loss = 0.9520238637924194:.4f\n",
      "Epoch 754: Train Loss = 0.1694, Test Loss = 0.9621148109436035:.4f\n",
      "Epoch 755: Train Loss = 0.1531, Test Loss = 0.9488979578018188:.4f\n",
      "Epoch 756: Train Loss = 0.2054, Test Loss = 0.9221140742301941:.4f\n",
      "Epoch 757: Train Loss = 0.1635, Test Loss = 0.9068020582199097:.4f\n",
      "Epoch 758: Train Loss = 0.1576, Test Loss = 0.9069035649299622:.4f\n",
      "Epoch 759: Train Loss = 0.1687, Test Loss = 0.9293473958969116:.4f\n",
      "Epoch 760: Train Loss = 0.1548, Test Loss = 0.9530459642410278:.4f\n",
      "Epoch 761: Train Loss = 0.1471, Test Loss = 0.9543150067329407:.4f\n",
      "Epoch 762: Train Loss = 0.2023, Test Loss = 0.9285138845443726:.4f\n",
      "Epoch 763: Train Loss = 0.1523, Test Loss = 0.9054607152938843:.4f\n",
      "Epoch 764: Train Loss = 0.1785, Test Loss = 0.907558798789978:.4f\n",
      "Epoch 765: Train Loss = 0.1600, Test Loss = 0.910212516784668:.4f\n",
      "Epoch 766: Train Loss = 0.1827, Test Loss = 0.930314838886261:.4f\n",
      "Epoch 767: Train Loss = 0.1608, Test Loss = 0.915460467338562:.4f\n",
      "Epoch 768: Train Loss = 0.1864, Test Loss = 0.9236257672309875:.4f\n",
      "Epoch 769: Train Loss = 0.1662, Test Loss = 0.9498803019523621:.4f\n",
      "Epoch 770: Train Loss = 0.1676, Test Loss = 0.958066463470459:.4f\n",
      "Epoch 771: Train Loss = 0.1677, Test Loss = 0.9431343078613281:.4f\n",
      "Epoch 772: Train Loss = 0.1615, Test Loss = 0.913133442401886:.4f\n",
      "Epoch 773: Train Loss = 0.1738, Test Loss = 0.8968044519424438:.4f\n",
      "Epoch 774: Train Loss = 0.1608, Test Loss = 0.8912236094474792:.4f\n",
      "Epoch 775: Train Loss = 0.1753, Test Loss = 0.9008769989013672:.4f\n",
      "Epoch 776: Train Loss = 0.1638, Test Loss = 0.9223225712776184:.4f\n",
      "Epoch 777: Train Loss = 0.1786, Test Loss = 0.9337313771247864:.4f\n",
      "Epoch 778: Train Loss = 0.1797, Test Loss = 0.954738974571228:.4f\n",
      "Epoch 779: Train Loss = 0.1470, Test Loss = 0.9476633071899414:.4f\n",
      "Epoch 780: Train Loss = 0.1635, Test Loss = 0.9314322471618652:.4f\n",
      "Epoch 781: Train Loss = 0.1568, Test Loss = 0.9318603277206421:.4f\n",
      "Epoch 782: Train Loss = 0.1504, Test Loss = 0.9295832514762878:.4f\n",
      "Epoch 783: Train Loss = 0.1651, Test Loss = 0.9326906204223633:.4f\n",
      "Epoch 784: Train Loss = 0.1823, Test Loss = 0.9413046836853027:.4f\n",
      "Epoch 785: Train Loss = 0.1731, Test Loss = 0.9336334466934204:.4f\n",
      "Epoch 786: Train Loss = 0.1555, Test Loss = 0.9249391555786133:.4f\n",
      "Epoch 787: Train Loss = 0.1564, Test Loss = 0.9231163263320923:.4f\n",
      "Epoch 788: Train Loss = 0.1447, Test Loss = 0.9224156141281128:.4f\n",
      "Epoch 789: Train Loss = 0.1475, Test Loss = 0.9157049059867859:.4f\n",
      "Epoch 790: Train Loss = 0.1506, Test Loss = 0.9258801341056824:.4f\n",
      "Epoch 791: Train Loss = 0.1605, Test Loss = 0.9305256009101868:.4f\n",
      "Epoch 792: Train Loss = 0.1455, Test Loss = 0.9358915090560913:.4f\n",
      "Epoch 793: Train Loss = 0.1519, Test Loss = 0.9463280439376831:.4f\n",
      "Epoch 794: Train Loss = 0.1525, Test Loss = 0.9637824892997742:.4f\n",
      "Epoch 795: Train Loss = 0.1481, Test Loss = 0.9594380259513855:.4f\n",
      "Epoch 796: Train Loss = 0.1619, Test Loss = 0.9558332562446594:.4f\n",
      "Epoch 797: Train Loss = 0.1596, Test Loss = 0.926456093788147:.4f\n",
      "Epoch 798: Train Loss = 0.1603, Test Loss = 0.9132708311080933:.4f\n",
      "Epoch 799: Train Loss = 0.1487, Test Loss = 0.9142969846725464:.4f\n",
      "Epoch 800: Train Loss = 0.1554, Test Loss = 0.9337784647941589:.4f\n",
      "Epoch 801: Train Loss = 0.1867, Test Loss = 0.9400407075881958:.4f\n",
      "Epoch 802: Train Loss = 0.1688, Test Loss = 0.9519095420837402:.4f\n",
      "Epoch 803: Train Loss = 0.1735, Test Loss = 0.9643815755844116:.4f\n",
      "Epoch 804: Train Loss = 0.1569, Test Loss = 0.9392367601394653:.4f\n",
      "Epoch 805: Train Loss = 0.1545, Test Loss = 0.9311468005180359:.4f\n",
      "Epoch 806: Train Loss = 0.2081, Test Loss = 0.9085860252380371:.4f\n",
      "Epoch 807: Train Loss = 0.1641, Test Loss = 0.9138181805610657:.4f\n",
      "Epoch 808: Train Loss = 0.1869, Test Loss = 0.9319545030593872:.4f\n",
      "Epoch 809: Train Loss = 0.1656, Test Loss = 0.94941246509552:.4f\n",
      "Epoch 810: Train Loss = 0.1622, Test Loss = 0.9698901176452637:.4f\n",
      "Epoch 811: Train Loss = 0.1538, Test Loss = 0.9566367268562317:.4f\n",
      "Epoch 812: Train Loss = 0.1962, Test Loss = 0.9262388944625854:.4f\n",
      "Epoch 813: Train Loss = 0.1581, Test Loss = 0.9162656664848328:.4f\n",
      "Epoch 814: Train Loss = 0.1576, Test Loss = 0.93690025806427:.4f\n",
      "Epoch 815: Train Loss = 0.1891, Test Loss = 0.9544123411178589:.4f\n",
      "Epoch 816: Train Loss = 0.1793, Test Loss = 0.9718515276908875:.4f\n",
      "Epoch 817: Train Loss = 0.1567, Test Loss = 0.9648140668869019:.4f\n",
      "Epoch 818: Train Loss = 0.1340, Test Loss = 0.9418081045150757:.4f\n",
      "Epoch 819: Train Loss = 0.1469, Test Loss = 0.9287649989128113:.4f\n",
      "Epoch 820: Train Loss = 0.1613, Test Loss = 0.9229083061218262:.4f\n",
      "Epoch 821: Train Loss = 0.1433, Test Loss = 0.9293581247329712:.4f\n",
      "Epoch 822: Train Loss = 0.1859, Test Loss = 0.948241114616394:.4f\n",
      "Epoch 823: Train Loss = 0.1635, Test Loss = 0.9333866834640503:.4f\n",
      "Epoch 824: Train Loss = 0.1362, Test Loss = 0.9218854904174805:.4f\n",
      "Epoch 825: Train Loss = 0.1699, Test Loss = 0.9238590002059937:.4f\n",
      "Epoch 826: Train Loss = 0.1534, Test Loss = 0.9393408894538879:.4f\n",
      "Epoch 827: Train Loss = 0.1469, Test Loss = 0.9461191296577454:.4f\n",
      "Epoch 828: Train Loss = 0.1517, Test Loss = 0.9471064805984497:.4f\n",
      "Epoch 829: Train Loss = 0.1507, Test Loss = 0.9436089396476746:.4f\n",
      "Epoch 830: Train Loss = 0.1848, Test Loss = 0.9323369860649109:.4f\n",
      "Epoch 831: Train Loss = 0.1530, Test Loss = 0.9296215772628784:.4f\n",
      "Epoch 832: Train Loss = 0.1599, Test Loss = 0.9354035258293152:.4f\n",
      "Epoch 833: Train Loss = 0.1572, Test Loss = 0.9478201866149902:.4f\n",
      "Epoch 834: Train Loss = 0.1541, Test Loss = 0.957813560962677:.4f\n",
      "Epoch 835: Train Loss = 0.1702, Test Loss = 0.9597066044807434:.4f\n",
      "Epoch 836: Train Loss = 0.1453, Test Loss = 0.9602608680725098:.4f\n",
      "Epoch 837: Train Loss = 0.1573, Test Loss = 0.9536582827568054:.4f\n",
      "Epoch 838: Train Loss = 0.1463, Test Loss = 0.9455100297927856:.4f\n",
      "Epoch 839: Train Loss = 0.1851, Test Loss = 0.9447722434997559:.4f\n",
      "Epoch 840: Train Loss = 0.1413, Test Loss = 0.9317957162857056:.4f\n",
      "Epoch 841: Train Loss = 0.1695, Test Loss = 0.9279060363769531:.4f\n",
      "Epoch 842: Train Loss = 0.1709, Test Loss = 0.9418553113937378:.4f\n",
      "Epoch 843: Train Loss = 0.1567, Test Loss = 0.9677074551582336:.4f\n",
      "Epoch 844: Train Loss = 0.1822, Test Loss = 0.9805753827095032:.4f\n",
      "Epoch 845: Train Loss = 0.1686, Test Loss = 0.9733186960220337:.4f\n",
      "Epoch 846: Train Loss = 0.1791, Test Loss = 0.9599040150642395:.4f\n",
      "Epoch 847: Train Loss = 0.1685, Test Loss = 0.9589893221855164:.4f\n",
      "Epoch 848: Train Loss = 0.1605, Test Loss = 0.9533141851425171:.4f\n",
      "Epoch 849: Train Loss = 0.1532, Test Loss = 0.9442710876464844:.4f\n",
      "Epoch 850: Train Loss = 0.1717, Test Loss = 0.9472735524177551:.4f\n",
      "Epoch 851: Train Loss = 0.2044, Test Loss = 0.9538801908493042:.4f\n",
      "Epoch 852: Train Loss = 0.1893, Test Loss = 0.943946361541748:.4f\n",
      "Epoch 853: Train Loss = 0.1710, Test Loss = 0.9378432035446167:.4f\n",
      "Epoch 854: Train Loss = 0.1567, Test Loss = 0.9458497166633606:.4f\n",
      "Epoch 855: Train Loss = 0.1564, Test Loss = 0.963650107383728:.4f\n",
      "Epoch 856: Train Loss = 0.1682, Test Loss = 0.9594683647155762:.4f\n",
      "Epoch 857: Train Loss = 0.1498, Test Loss = 0.9454053044319153:.4f\n",
      "Epoch 858: Train Loss = 0.1894, Test Loss = 0.9375094175338745:.4f\n",
      "Epoch 859: Train Loss = 0.1379, Test Loss = 0.9495260119438171:.4f\n",
      "Epoch 860: Train Loss = 0.1377, Test Loss = 0.9609168171882629:.4f\n",
      "Epoch 861: Train Loss = 0.1916, Test Loss = 0.9735263586044312:.4f\n",
      "Epoch 862: Train Loss = 0.1465, Test Loss = 0.9664518237113953:.4f\n",
      "Epoch 863: Train Loss = 0.1889, Test Loss = 0.9603290557861328:.4f\n",
      "Epoch 864: Train Loss = 0.1533, Test Loss = 0.9337558746337891:.4f\n",
      "Epoch 865: Train Loss = 0.1491, Test Loss = 0.9267259836196899:.4f\n",
      "Epoch 866: Train Loss = 0.1540, Test Loss = 0.9370530843734741:.4f\n",
      "Epoch 867: Train Loss = 0.1488, Test Loss = 0.9462458491325378:.4f\n",
      "Epoch 868: Train Loss = 0.1470, Test Loss = 0.9630537033081055:.4f\n",
      "Epoch 869: Train Loss = 0.1475, Test Loss = 0.9719945788383484:.4f\n",
      "Epoch 870: Train Loss = 0.1405, Test Loss = 0.9559729695320129:.4f\n",
      "Epoch 871: Train Loss = 0.1668, Test Loss = 0.9415640830993652:.4f\n",
      "Epoch 872: Train Loss = 0.1459, Test Loss = 0.940449595451355:.4f\n",
      "Epoch 873: Train Loss = 0.1639, Test Loss = 0.9429606199264526:.4f\n",
      "Epoch 874: Train Loss = 0.1531, Test Loss = 0.966404914855957:.4f\n",
      "Epoch 875: Train Loss = 0.1695, Test Loss = 0.9695571064949036:.4f\n",
      "Epoch 876: Train Loss = 0.1774, Test Loss = 0.9600784182548523:.4f\n",
      "Epoch 877: Train Loss = 0.1747, Test Loss = 0.9575042724609375:.4f\n",
      "Epoch 878: Train Loss = 0.1558, Test Loss = 0.9583083987236023:.4f\n",
      "Epoch 879: Train Loss = 0.1958, Test Loss = 0.960536777973175:.4f\n",
      "Epoch 880: Train Loss = 0.1399, Test Loss = 0.9534136652946472:.4f\n",
      "Epoch 881: Train Loss = 0.2002, Test Loss = 0.9517679214477539:.4f\n",
      "Epoch 882: Train Loss = 0.1614, Test Loss = 0.9601734280586243:.4f\n",
      "Epoch 883: Train Loss = 0.1459, Test Loss = 0.9774377942085266:.4f\n",
      "Epoch 884: Train Loss = 0.1490, Test Loss = 0.9701023101806641:.4f\n",
      "Epoch 885: Train Loss = 0.1765, Test Loss = 0.9569953680038452:.4f\n",
      "Epoch 886: Train Loss = 0.1737, Test Loss = 0.9623110890388489:.4f\n",
      "Epoch 887: Train Loss = 0.1570, Test Loss = 0.9717127680778503:.4f\n",
      "Epoch 888: Train Loss = 0.1465, Test Loss = 0.9619044065475464:.4f\n",
      "Epoch 889: Train Loss = 0.1385, Test Loss = 0.9744690656661987:.4f\n",
      "Epoch 890: Train Loss = 0.1998, Test Loss = 0.9647488594055176:.4f\n",
      "Epoch 891: Train Loss = 0.1485, Test Loss = 0.9580027461051941:.4f\n",
      "Epoch 892: Train Loss = 0.1855, Test Loss = 0.9550949931144714:.4f\n",
      "Epoch 893: Train Loss = 0.1464, Test Loss = 0.9663570523262024:.4f\n",
      "Epoch 894: Train Loss = 0.1501, Test Loss = 0.9705902934074402:.4f\n",
      "Epoch 895: Train Loss = 0.1749, Test Loss = 0.9616042971611023:.4f\n",
      "Epoch 896: Train Loss = 0.1531, Test Loss = 0.9543666839599609:.4f\n",
      "Epoch 897: Train Loss = 0.1730, Test Loss = 0.9538213610649109:.4f\n",
      "Epoch 898: Train Loss = 0.1453, Test Loss = 0.9653679132461548:.4f\n",
      "Epoch 899: Train Loss = 0.1565, Test Loss = 0.9617103338241577:.4f\n",
      "Epoch 900: Train Loss = 0.1425, Test Loss = 0.9584264755249023:.4f\n",
      "Epoch 901: Train Loss = 0.1902, Test Loss = 0.9495611190795898:.4f\n",
      "Epoch 902: Train Loss = 0.1473, Test Loss = 0.9595704078674316:.4f\n",
      "Epoch 903: Train Loss = 0.1601, Test Loss = 0.9687945246696472:.4f\n",
      "Epoch 904: Train Loss = 0.1479, Test Loss = 0.973258376121521:.4f\n",
      "Epoch 905: Train Loss = 0.1531, Test Loss = 0.9596408009529114:.4f\n",
      "Epoch 906: Train Loss = 0.1394, Test Loss = 0.9322455525398254:.4f\n",
      "Epoch 907: Train Loss = 0.1866, Test Loss = 0.934129536151886:.4f\n",
      "Epoch 908: Train Loss = 0.1691, Test Loss = 0.9629257321357727:.4f\n",
      "Epoch 909: Train Loss = 0.1654, Test Loss = 1.0073367357254028:.4f\n",
      "Epoch 910: Train Loss = 0.1481, Test Loss = 1.0235167741775513:.4f\n",
      "Epoch 911: Train Loss = 0.1608, Test Loss = 0.9989644289016724:.4f\n",
      "Epoch 912: Train Loss = 0.1410, Test Loss = 0.9542781114578247:.4f\n",
      "Epoch 913: Train Loss = 0.1811, Test Loss = 0.9237483739852905:.4f\n",
      "Epoch 914: Train Loss = 0.1578, Test Loss = 0.9160369038581848:.4f\n",
      "Epoch 915: Train Loss = 0.1425, Test Loss = 0.9396413564682007:.4f\n",
      "Epoch 916: Train Loss = 0.1451, Test Loss = 0.9628089070320129:.4f\n",
      "Epoch 917: Train Loss = 0.1638, Test Loss = 0.9777660369873047:.4f\n",
      "Epoch 918: Train Loss = 0.1350, Test Loss = 0.9858382940292358:.4f\n",
      "Epoch 919: Train Loss = 0.1824, Test Loss = 0.9879350662231445:.4f\n",
      "Epoch 920: Train Loss = 0.1528, Test Loss = 0.9765542149543762:.4f\n",
      "Epoch 921: Train Loss = 0.1519, Test Loss = 0.9596506953239441:.4f\n",
      "Epoch 922: Train Loss = 0.1569, Test Loss = 0.9380604028701782:.4f\n",
      "Epoch 923: Train Loss = 0.1742, Test Loss = 0.9508988261222839:.4f\n",
      "Epoch 924: Train Loss = 0.1711, Test Loss = 0.9756499528884888:.4f\n",
      "Epoch 925: Train Loss = 0.1823, Test Loss = 0.997779369354248:.4f\n",
      "Epoch 926: Train Loss = 0.1569, Test Loss = 1.0095914602279663:.4f\n",
      "Epoch 927: Train Loss = 0.1506, Test Loss = 0.9949928522109985:.4f\n",
      "Epoch 928: Train Loss = 0.1550, Test Loss = 0.9652732014656067:.4f\n",
      "Epoch 929: Train Loss = 0.1517, Test Loss = 0.9437091946601868:.4f\n",
      "Epoch 930: Train Loss = 0.1831, Test Loss = 0.9477123022079468:.4f\n",
      "Epoch 931: Train Loss = 0.1423, Test Loss = 0.9592384099960327:.4f\n",
      "Epoch 932: Train Loss = 0.1817, Test Loss = 0.9671401977539062:.4f\n",
      "Epoch 933: Train Loss = 0.1695, Test Loss = 0.9678300619125366:.4f\n",
      "Epoch 934: Train Loss = 0.1635, Test Loss = 0.9593760371208191:.4f\n",
      "Epoch 935: Train Loss = 0.1815, Test Loss = 0.9570916891098022:.4f\n",
      "Epoch 936: Train Loss = 0.1726, Test Loss = 0.966152548789978:.4f\n",
      "Epoch 937: Train Loss = 0.1452, Test Loss = 1.0024397373199463:.4f\n",
      "Epoch 938: Train Loss = 0.1492, Test Loss = 1.0137135982513428:.4f\n",
      "Epoch 939: Train Loss = 0.1720, Test Loss = 1.0109879970550537:.4f\n",
      "Epoch 940: Train Loss = 0.1697, Test Loss = 0.9980230331420898:.4f\n",
      "Epoch 941: Train Loss = 0.1706, Test Loss = 0.9768977165222168:.4f\n",
      "Epoch 942: Train Loss = 0.1809, Test Loss = 0.9681315422058105:.4f\n",
      "Epoch 943: Train Loss = 0.1531, Test Loss = 0.9614399075508118:.4f\n",
      "Epoch 944: Train Loss = 0.1465, Test Loss = 0.9630640745162964:.4f\n",
      "Epoch 945: Train Loss = 0.1425, Test Loss = 0.9815942049026489:.4f\n",
      "Epoch 946: Train Loss = 0.1528, Test Loss = 0.9989060163497925:.4f\n",
      "Epoch 947: Train Loss = 0.1820, Test Loss = 0.9874426126480103:.4f\n",
      "Epoch 948: Train Loss = 0.1587, Test Loss = 0.9702924489974976:.4f\n",
      "Epoch 949: Train Loss = 0.1465, Test Loss = 0.9702661633491516:.4f\n",
      "Epoch 950: Train Loss = 0.1928, Test Loss = 0.9606307148933411:.4f\n",
      "Epoch 951: Train Loss = 0.1505, Test Loss = 0.9619767069816589:.4f\n",
      "Epoch 952: Train Loss = 0.1519, Test Loss = 0.9621102213859558:.4f\n",
      "Epoch 953: Train Loss = 0.1578, Test Loss = 0.9566494226455688:.4f\n",
      "Epoch 954: Train Loss = 0.1538, Test Loss = 0.9576042890548706:.4f\n",
      "Epoch 955: Train Loss = 0.1447, Test Loss = 0.9794856309890747:.4f\n",
      "Epoch 956: Train Loss = 0.1454, Test Loss = 0.9909478425979614:.4f\n",
      "Epoch 957: Train Loss = 0.1525, Test Loss = 0.9929289817810059:.4f\n",
      "Epoch 958: Train Loss = 0.1464, Test Loss = 0.984032928943634:.4f\n",
      "Epoch 959: Train Loss = 0.1632, Test Loss = 0.9691107869148254:.4f\n",
      "Epoch 960: Train Loss = 0.1349, Test Loss = 0.9864022135734558:.4f\n",
      "Epoch 961: Train Loss = 0.1590, Test Loss = 0.9962528944015503:.4f\n",
      "Epoch 962: Train Loss = 0.1538, Test Loss = 0.9964507818222046:.4f\n",
      "Epoch 963: Train Loss = 0.1451, Test Loss = 0.9874690175056458:.4f\n",
      "Epoch 964: Train Loss = 0.1539, Test Loss = 0.9729728698730469:.4f\n",
      "Epoch 965: Train Loss = 0.1486, Test Loss = 0.9690852165222168:.4f\n",
      "Epoch 966: Train Loss = 0.1606, Test Loss = 0.9728487730026245:.4f\n",
      "Epoch 967: Train Loss = 0.1475, Test Loss = 0.9840752482414246:.4f\n",
      "Epoch 968: Train Loss = 0.1392, Test Loss = 0.9838787913322449:.4f\n",
      "Epoch 969: Train Loss = 0.1446, Test Loss = 0.9829605221748352:.4f\n",
      "Epoch 970: Train Loss = 0.1516, Test Loss = 0.9822227358818054:.4f\n",
      "Epoch 971: Train Loss = 0.1521, Test Loss = 0.9823164939880371:.4f\n",
      "Epoch 972: Train Loss = 0.1615, Test Loss = 0.9784096479415894:.4f\n",
      "Epoch 973: Train Loss = 0.1395, Test Loss = 0.9727096557617188:.4f\n",
      "Epoch 974: Train Loss = 0.1607, Test Loss = 0.9716021418571472:.4f\n",
      "Epoch 975: Train Loss = 0.1428, Test Loss = 0.9734552502632141:.4f\n",
      "Epoch 976: Train Loss = 0.1464, Test Loss = 0.973899245262146:.4f\n",
      "Epoch 977: Train Loss = 0.1608, Test Loss = 0.9727145433425903:.4f\n",
      "Epoch 978: Train Loss = 0.1919, Test Loss = 0.966330349445343:.4f\n",
      "Epoch 979: Train Loss = 0.1492, Test Loss = 0.9569255113601685:.4f\n",
      "Epoch 980: Train Loss = 0.1312, Test Loss = 0.9644735455513:.4f\n",
      "Epoch 981: Train Loss = 0.1757, Test Loss = 0.9756163358688354:.4f\n",
      "Epoch 982: Train Loss = 0.1664, Test Loss = 0.9880674481391907:.4f\n",
      "Epoch 983: Train Loss = 0.1677, Test Loss = 0.9935965538024902:.4f\n",
      "Epoch 984: Train Loss = 0.1573, Test Loss = 1.0001550912857056:.4f\n",
      "Epoch 985: Train Loss = 0.1496, Test Loss = 0.9898544549942017:.4f\n",
      "Epoch 986: Train Loss = 0.1706, Test Loss = 0.9805991053581238:.4f\n",
      "Epoch 987: Train Loss = 0.1939, Test Loss = 0.9887748956680298:.4f\n",
      "Epoch 988: Train Loss = 0.1798, Test Loss = 0.998836874961853:.4f\n",
      "Epoch 989: Train Loss = 0.1779, Test Loss = 1.0017682313919067:.4f\n",
      "Epoch 990: Train Loss = 0.1646, Test Loss = 0.9733568429946899:.4f\n",
      "Epoch 991: Train Loss = 0.1483, Test Loss = 0.9728254079818726:.4f\n",
      "Epoch 992: Train Loss = 0.1482, Test Loss = 0.9836078882217407:.4f\n",
      "Epoch 993: Train Loss = 0.1526, Test Loss = 0.9947131276130676:.4f\n",
      "Epoch 994: Train Loss = 0.1449, Test Loss = 1.01466965675354:.4f\n",
      "Epoch 995: Train Loss = 0.1542, Test Loss = 1.0065653324127197:.4f\n",
      "Epoch 996: Train Loss = 0.1933, Test Loss = 0.9983706474304199:.4f\n",
      "Epoch 997: Train Loss = 0.1632, Test Loss = 1.0027060508728027:.4f\n",
      "Epoch 998: Train Loss = 0.1629, Test Loss = 1.0160387754440308:.4f\n",
      "Epoch 999: Train Loss = 0.1547, Test Loss = 1.0207931995391846:.4f\n",
      "Epoch 1000: Train Loss = 0.1644, Test Loss = 1.028857707977295:.4f\n",
      "Epoch 1001: Train Loss = 0.1546, Test Loss = 1.0172288417816162:.4f\n",
      "Epoch 1002: Train Loss = 0.1647, Test Loss = 0.9936949610710144:.4f\n",
      "Epoch 1003: Train Loss = 0.1644, Test Loss = 0.9838371276855469:.4f\n",
      "Epoch 1004: Train Loss = 0.1380, Test Loss = 0.9855884313583374:.4f\n",
      "Epoch 1005: Train Loss = 0.1877, Test Loss = 0.9942986369132996:.4f\n",
      "Epoch 1006: Train Loss = 0.1358, Test Loss = 1.0095291137695312:.4f\n",
      "Epoch 1007: Train Loss = 0.1426, Test Loss = 1.002966284751892:.4f\n",
      "Epoch 1008: Train Loss = 0.1492, Test Loss = 0.9926624298095703:.4f\n",
      "Epoch 1009: Train Loss = 0.1774, Test Loss = 0.9972826242446899:.4f\n",
      "Epoch 1010: Train Loss = 0.1436, Test Loss = 0.9990715980529785:.4f\n",
      "Epoch 1011: Train Loss = 0.1505, Test Loss = 0.9933228492736816:.4f\n",
      "Epoch 1012: Train Loss = 0.1550, Test Loss = 0.9834665060043335:.4f\n",
      "Epoch 1013: Train Loss = 0.1655, Test Loss = 0.9843988418579102:.4f\n",
      "Epoch 1014: Train Loss = 0.1571, Test Loss = 0.9962436556816101:.4f\n",
      "Epoch 1015: Train Loss = 0.1425, Test Loss = 1.0064196586608887:.4f\n",
      "Epoch 1016: Train Loss = 0.1409, Test Loss = 1.0250451564788818:.4f\n",
      "Epoch 1017: Train Loss = 0.1840, Test Loss = 1.016087293624878:.4f\n",
      "Epoch 1018: Train Loss = 0.1803, Test Loss = 1.009538173675537:.4f\n",
      "Epoch 1019: Train Loss = 0.1487, Test Loss = 1.0134886503219604:.4f\n",
      "Epoch 1020: Train Loss = 0.1480, Test Loss = 1.0210130214691162:.4f\n",
      "Epoch 1021: Train Loss = 0.1956, Test Loss = 1.0089833736419678:.4f\n",
      "Epoch 1022: Train Loss = 0.1538, Test Loss = 1.0074427127838135:.4f\n",
      "Epoch 1023: Train Loss = 0.1906, Test Loss = 1.004708170890808:.4f\n",
      "Epoch 1024: Train Loss = 0.1613, Test Loss = 0.9999896883964539:.4f\n",
      "Epoch 1025: Train Loss = 0.1473, Test Loss = 1.002302646636963:.4f\n",
      "Epoch 1026: Train Loss = 0.1582, Test Loss = 0.9786332845687866:.4f\n",
      "Epoch 1027: Train Loss = 0.1836, Test Loss = 0.9727320671081543:.4f\n",
      "Epoch 1028: Train Loss = 0.1882, Test Loss = 1.0072165727615356:.4f\n",
      "Epoch 1029: Train Loss = 0.1777, Test Loss = 1.0285758972167969:.4f\n",
      "Epoch 1030: Train Loss = 0.1442, Test Loss = 1.0398104190826416:.4f\n",
      "Epoch 1031: Train Loss = 0.1610, Test Loss = 1.0320703983306885:.4f\n",
      "Epoch 1032: Train Loss = 0.1518, Test Loss = 1.0102708339691162:.4f\n",
      "Epoch 1033: Train Loss = 0.1786, Test Loss = 0.9930761456489563:.4f\n",
      "Epoch 1034: Train Loss = 0.1775, Test Loss = 0.9901026487350464:.4f\n",
      "Epoch 1035: Train Loss = 0.1535, Test Loss = 0.9884817004203796:.4f\n",
      "Epoch 1036: Train Loss = 0.1341, Test Loss = 0.9984766244888306:.4f\n",
      "Epoch 1037: Train Loss = 0.1374, Test Loss = 0.998893141746521:.4f\n",
      "Epoch 1038: Train Loss = 0.1463, Test Loss = 1.002640962600708:.4f\n",
      "Epoch 1039: Train Loss = 0.1524, Test Loss = 1.0041754245758057:.4f\n",
      "Epoch 1040: Train Loss = 0.1794, Test Loss = 1.0024381875991821:.4f\n",
      "Epoch 1041: Train Loss = 0.1452, Test Loss = 1.0029433965682983:.4f\n",
      "Epoch 1042: Train Loss = 0.1729, Test Loss = 1.013508915901184:.4f\n",
      "Epoch 1043: Train Loss = 0.1606, Test Loss = 1.0104243755340576:.4f\n",
      "Epoch 1044: Train Loss = 0.1305, Test Loss = 0.9975574612617493:.4f\n",
      "Epoch 1045: Train Loss = 0.1640, Test Loss = 0.9961296319961548:.4f\n",
      "Epoch 1046: Train Loss = 0.1778, Test Loss = 1.0079200267791748:.4f\n",
      "Epoch 1047: Train Loss = 0.1461, Test Loss = 1.0235135555267334:.4f\n",
      "Epoch 1048: Train Loss = 0.1610, Test Loss = 1.0260125398635864:.4f\n",
      "Epoch 1049: Train Loss = 0.1524, Test Loss = 1.0098644495010376:.4f\n",
      "Epoch 1050: Train Loss = 0.1845, Test Loss = 1.0019394159317017:.4f\n",
      "Epoch 1051: Train Loss = 0.1471, Test Loss = 1.0070639848709106:.4f\n",
      "Epoch 1052: Train Loss = 0.1721, Test Loss = 1.0045435428619385:.4f\n",
      "Epoch 1053: Train Loss = 0.1421, Test Loss = 1.0103795528411865:.4f\n",
      "Epoch 1054: Train Loss = 0.1521, Test Loss = 1.011704683303833:.4f\n",
      "Epoch 1055: Train Loss = 0.1767, Test Loss = 1.0111124515533447:.4f\n",
      "Epoch 1056: Train Loss = 0.1380, Test Loss = 1.0250556468963623:.4f\n",
      "Epoch 1057: Train Loss = 0.1396, Test Loss = 1.036339282989502:.4f\n",
      "Epoch 1058: Train Loss = 0.1478, Test Loss = 1.0304542779922485:.4f\n",
      "Epoch 1059: Train Loss = 0.1435, Test Loss = 1.0235927104949951:.4f\n",
      "Epoch 1060: Train Loss = 0.1314, Test Loss = 1.0099366903305054:.4f\n",
      "Epoch 1061: Train Loss = 0.1449, Test Loss = 0.9969857931137085:.4f\n",
      "Epoch 1062: Train Loss = 0.1407, Test Loss = 0.9923742413520813:.4f\n",
      "Epoch 1063: Train Loss = 0.1343, Test Loss = 1.002148151397705:.4f\n",
      "Epoch 1064: Train Loss = 0.1426, Test Loss = 1.0127055644989014:.4f\n",
      "Epoch 1065: Train Loss = 0.1819, Test Loss = 1.0224369764328003:.4f\n",
      "Epoch 1066: Train Loss = 0.1438, Test Loss = 1.031783938407898:.4f\n",
      "Epoch 1067: Train Loss = 0.1426, Test Loss = 1.0191044807434082:.4f\n",
      "Epoch 1068: Train Loss = 0.1426, Test Loss = 1.0188461542129517:.4f\n",
      "Epoch 1069: Train Loss = 0.1735, Test Loss = 1.0154173374176025:.4f\n",
      "Epoch 1070: Train Loss = 0.1386, Test Loss = 1.010647177696228:.4f\n",
      "Epoch 1071: Train Loss = 0.1941, Test Loss = 1.0162912607192993:.4f\n",
      "Epoch 1072: Train Loss = 0.1622, Test Loss = 1.0336077213287354:.4f\n",
      "Epoch 1073: Train Loss = 0.1804, Test Loss = 1.0399879217147827:.4f\n",
      "Epoch 1074: Train Loss = 0.1400, Test Loss = 1.0216466188430786:.4f\n",
      "Epoch 1075: Train Loss = 0.1507, Test Loss = 1.0022960901260376:.4f\n",
      "Epoch 1076: Train Loss = 0.1856, Test Loss = 0.9724213480949402:.4f\n",
      "Epoch 1077: Train Loss = 0.1683, Test Loss = 0.9648116827011108:.4f\n",
      "Epoch 1078: Train Loss = 0.1537, Test Loss = 0.9766057133674622:.4f\n",
      "Epoch 1079: Train Loss = 0.1463, Test Loss = 1.0028997659683228:.4f\n",
      "Epoch 1080: Train Loss = 0.1516, Test Loss = 1.0347217321395874:.4f\n",
      "Epoch 1081: Train Loss = 0.1796, Test Loss = 1.048353910446167:.4f\n",
      "Epoch 1082: Train Loss = 0.1392, Test Loss = 1.0266262292861938:.4f\n",
      "Epoch 1083: Train Loss = 0.1388, Test Loss = 0.9986969828605652:.4f\n",
      "Epoch 1084: Train Loss = 0.1456, Test Loss = 0.9947773218154907:.4f\n",
      "Epoch 1085: Train Loss = 0.1595, Test Loss = 1.0066505670547485:.4f\n",
      "Epoch 1086: Train Loss = 0.1535, Test Loss = 1.0073468685150146:.4f\n",
      "Epoch 1087: Train Loss = 0.1724, Test Loss = 1.0071208477020264:.4f\n",
      "Epoch 1088: Train Loss = 0.1605, Test Loss = 1.005519151687622:.4f\n",
      "Epoch 1089: Train Loss = 0.1629, Test Loss = 1.0142652988433838:.4f\n",
      "Epoch 1090: Train Loss = 0.1678, Test Loss = 1.0235216617584229:.4f\n",
      "Epoch 1091: Train Loss = 0.1671, Test Loss = 1.0197904109954834:.4f\n",
      "Epoch 1092: Train Loss = 0.1468, Test Loss = 1.0121996402740479:.4f\n",
      "Epoch 1093: Train Loss = 0.1563, Test Loss = 1.0097838640213013:.4f\n",
      "Epoch 1094: Train Loss = 0.1743, Test Loss = 1.021806001663208:.4f\n",
      "Epoch 1095: Train Loss = 0.1441, Test Loss = 1.026520848274231:.4f\n",
      "Epoch 1096: Train Loss = 0.1430, Test Loss = 1.0338013172149658:.4f\n",
      "Epoch 1097: Train Loss = 0.1412, Test Loss = 1.0409324169158936:.4f\n",
      "Epoch 1098: Train Loss = 0.1705, Test Loss = 1.0401854515075684:.4f\n",
      "Epoch 1099: Train Loss = 0.1549, Test Loss = 1.0381901264190674:.4f\n",
      "Epoch 1100: Train Loss = 0.1402, Test Loss = 1.0350592136383057:.4f\n",
      "Epoch 1101: Train Loss = 0.1380, Test Loss = 1.0145374536514282:.4f\n",
      "Epoch 1102: Train Loss = 0.1465, Test Loss = 1.0086497068405151:.4f\n",
      "Epoch 1103: Train Loss = 0.1522, Test Loss = 1.0106523036956787:.4f\n",
      "Epoch 1104: Train Loss = 0.1373, Test Loss = 1.0166586637496948:.4f\n",
      "Epoch 1105: Train Loss = 0.1697, Test Loss = 1.0256872177124023:.4f\n",
      "Epoch 1106: Train Loss = 0.1537, Test Loss = 1.0340913534164429:.4f\n",
      "Epoch 1107: Train Loss = 0.1390, Test Loss = 1.026524305343628:.4f\n",
      "Epoch 1108: Train Loss = 0.1590, Test Loss = 1.0216114521026611:.4f\n",
      "Epoch 1109: Train Loss = 0.1650, Test Loss = 1.0059138536453247:.4f\n",
      "Epoch 1110: Train Loss = 0.1395, Test Loss = 0.9975816607475281:.4f\n",
      "Epoch 1111: Train Loss = 0.1383, Test Loss = 1.0143064260482788:.4f\n",
      "Epoch 1112: Train Loss = 0.1500, Test Loss = 1.0329010486602783:.4f\n",
      "Epoch 1113: Train Loss = 0.1598, Test Loss = 1.0404044389724731:.4f\n",
      "Epoch 1114: Train Loss = 0.1527, Test Loss = 1.034777045249939:.4f\n",
      "Epoch 1115: Train Loss = 0.1547, Test Loss = 1.0269050598144531:.4f\n",
      "Epoch 1116: Train Loss = 0.1536, Test Loss = 1.0157573223114014:.4f\n",
      "Epoch 1117: Train Loss = 0.1369, Test Loss = 1.0158358812332153:.4f\n",
      "Epoch 1118: Train Loss = 0.1501, Test Loss = 1.0154975652694702:.4f\n",
      "Epoch 1119: Train Loss = 0.1567, Test Loss = 1.0313798189163208:.4f\n",
      "Epoch 1120: Train Loss = 0.1486, Test Loss = 1.0268261432647705:.4f\n",
      "Epoch 1121: Train Loss = 0.1568, Test Loss = 1.0156294107437134:.4f\n",
      "Epoch 1122: Train Loss = 0.1509, Test Loss = 1.008832573890686:.4f\n",
      "Epoch 1123: Train Loss = 0.1608, Test Loss = 1.0079121589660645:.4f\n",
      "Epoch 1124: Train Loss = 0.1871, Test Loss = 1.0215609073638916:.4f\n",
      "Epoch 1125: Train Loss = 0.2008, Test Loss = 1.0391261577606201:.4f\n",
      "Epoch 1126: Train Loss = 0.1596, Test Loss = 1.0429731607437134:.4f\n",
      "Epoch 1127: Train Loss = 0.1766, Test Loss = 1.038089394569397:.4f\n",
      "Epoch 1128: Train Loss = 0.1427, Test Loss = 1.0437850952148438:.4f\n",
      "Epoch 1129: Train Loss = 0.2019, Test Loss = 1.0420658588409424:.4f\n",
      "Epoch 1130: Train Loss = 0.1476, Test Loss = 1.0342051982879639:.4f\n",
      "Epoch 1131: Train Loss = 0.1612, Test Loss = 1.0228644609451294:.4f\n",
      "Epoch 1132: Train Loss = 0.1595, Test Loss = 1.0278356075286865:.4f\n",
      "Epoch 1133: Train Loss = 0.1385, Test Loss = 1.034911036491394:.4f\n",
      "Epoch 1134: Train Loss = 0.1693, Test Loss = 1.0508983135223389:.4f\n",
      "Epoch 1135: Train Loss = 0.1604, Test Loss = 1.0494625568389893:.4f\n",
      "Epoch 1136: Train Loss = 0.1417, Test Loss = 1.0317866802215576:.4f\n",
      "Epoch 1137: Train Loss = 0.1489, Test Loss = 1.0166878700256348:.4f\n",
      "Epoch 1138: Train Loss = 0.1371, Test Loss = 1.0112106800079346:.4f\n",
      "Epoch 1139: Train Loss = 0.1546, Test Loss = 1.0134594440460205:.4f\n",
      "Epoch 1140: Train Loss = 0.1630, Test Loss = 1.0332316160202026:.4f\n",
      "Epoch 1141: Train Loss = 0.1437, Test Loss = 1.0515141487121582:.4f\n",
      "Epoch 1142: Train Loss = 0.1611, Test Loss = 1.0571370124816895:.4f\n",
      "Epoch 1143: Train Loss = 0.1883, Test Loss = 1.0342782735824585:.4f\n",
      "Epoch 1144: Train Loss = 0.1349, Test Loss = 1.018869400024414:.4f\n",
      "Epoch 1145: Train Loss = 0.1359, Test Loss = 1.0114637613296509:.4f\n",
      "Epoch 1146: Train Loss = 0.1753, Test Loss = 1.0162773132324219:.4f\n",
      "Epoch 1147: Train Loss = 0.1411, Test Loss = 1.0220972299575806:.4f\n",
      "Epoch 1148: Train Loss = 0.1674, Test Loss = 1.030968427658081:.4f\n",
      "Epoch 1149: Train Loss = 0.1661, Test Loss = 1.0331465005874634:.4f\n",
      "Epoch 1150: Train Loss = 0.1588, Test Loss = 1.0379724502563477:.4f\n",
      "Epoch 1151: Train Loss = 0.1772, Test Loss = 1.0518667697906494:.4f\n",
      "Epoch 1152: Train Loss = 0.1481, Test Loss = 1.07470703125:.4f\n",
      "Epoch 1153: Train Loss = 0.1779, Test Loss = 1.0838826894760132:.4f\n",
      "Epoch 1154: Train Loss = 0.1840, Test Loss = 1.053754210472107:.4f\n",
      "Epoch 1155: Train Loss = 0.1346, Test Loss = 1.0262380838394165:.4f\n",
      "Epoch 1156: Train Loss = 0.1550, Test Loss = 1.0178163051605225:.4f\n",
      "Epoch 1157: Train Loss = 0.1437, Test Loss = 1.0308787822723389:.4f\n",
      "Epoch 1158: Train Loss = 0.1433, Test Loss = 1.0469493865966797:.4f\n",
      "Epoch 1159: Train Loss = 0.1499, Test Loss = 1.0535194873809814:.4f\n",
      "Epoch 1160: Train Loss = 0.1597, Test Loss = 1.0312727689743042:.4f\n",
      "Epoch 1161: Train Loss = 0.1728, Test Loss = 1.0149481296539307:.4f\n",
      "Epoch 1162: Train Loss = 0.1311, Test Loss = 1.0027077198028564:.4f\n",
      "Epoch 1163: Train Loss = 0.1764, Test Loss = 1.0074412822723389:.4f\n",
      "Epoch 1164: Train Loss = 0.1645, Test Loss = 1.0206807851791382:.4f\n",
      "Epoch 1165: Train Loss = 0.1424, Test Loss = 1.0380418300628662:.4f\n",
      "Epoch 1166: Train Loss = 0.1773, Test Loss = 1.0326231718063354:.4f\n",
      "Epoch 1167: Train Loss = 0.1575, Test Loss = 1.017035722732544:.4f\n",
      "Epoch 1168: Train Loss = 0.1606, Test Loss = 1.024847388267517:.4f\n",
      "Epoch 1169: Train Loss = 0.1613, Test Loss = 1.0379886627197266:.4f\n",
      "Epoch 1170: Train Loss = 0.1332, Test Loss = 1.066325068473816:.4f\n",
      "Epoch 1171: Train Loss = 0.1574, Test Loss = 1.0647239685058594:.4f\n",
      "Epoch 1172: Train Loss = 0.1887, Test Loss = 1.024155855178833:.4f\n",
      "Epoch 1173: Train Loss = 0.1612, Test Loss = 1.0186822414398193:.4f\n",
      "Epoch 1174: Train Loss = 0.1446, Test Loss = 1.0439801216125488:.4f\n",
      "Epoch 1175: Train Loss = 0.1415, Test Loss = 1.062995195388794:.4f\n",
      "Epoch 1176: Train Loss = 0.1420, Test Loss = 1.072194218635559:.4f\n",
      "Epoch 1177: Train Loss = 0.1442, Test Loss = 1.0651124715805054:.4f\n",
      "Epoch 1178: Train Loss = 0.1448, Test Loss = 1.0439444780349731:.4f\n",
      "Epoch 1179: Train Loss = 0.1365, Test Loss = 1.0456405878067017:.4f\n",
      "Epoch 1180: Train Loss = 0.1661, Test Loss = 1.0544838905334473:.4f\n",
      "Epoch 1181: Train Loss = 0.1563, Test Loss = 1.055201530456543:.4f\n",
      "Epoch 1182: Train Loss = 0.1534, Test Loss = 1.054244875907898:.4f\n",
      "Epoch 1183: Train Loss = 0.1759, Test Loss = 1.047751545906067:.4f\n",
      "Epoch 1184: Train Loss = 0.1613, Test Loss = 1.0407263040542603:.4f\n",
      "Epoch 1185: Train Loss = 0.1484, Test Loss = 1.0449286699295044:.4f\n",
      "Epoch 1186: Train Loss = 0.1930, Test Loss = 1.034266471862793:.4f\n",
      "Epoch 1187: Train Loss = 0.1475, Test Loss = 1.0416185855865479:.4f\n",
      "Epoch 1188: Train Loss = 0.1483, Test Loss = 1.0460760593414307:.4f\n",
      "Epoch 1189: Train Loss = 0.1542, Test Loss = 1.0401560068130493:.4f\n",
      "Epoch 1190: Train Loss = 0.1596, Test Loss = 1.0427792072296143:.4f\n",
      "Epoch 1191: Train Loss = 0.1574, Test Loss = 1.0438404083251953:.4f\n",
      "Epoch 1192: Train Loss = 0.1539, Test Loss = 1.0474331378936768:.4f\n",
      "Epoch 1193: Train Loss = 0.1470, Test Loss = 1.0568125247955322:.4f\n",
      "Epoch 1194: Train Loss = 0.1741, Test Loss = 1.0543922185897827:.4f\n",
      "Epoch 1195: Train Loss = 0.1532, Test Loss = 1.0481691360473633:.4f\n",
      "Epoch 1196: Train Loss = 0.1993, Test Loss = 1.0375036001205444:.4f\n",
      "Epoch 1197: Train Loss = 0.1721, Test Loss = 1.024644136428833:.4f\n",
      "Epoch 1198: Train Loss = 0.1526, Test Loss = 1.046008586883545:.4f\n",
      "Epoch 1199: Train Loss = 0.1660, Test Loss = 1.0649549961090088:.4f\n",
      "Epoch 1200: Train Loss = 0.1461, Test Loss = 1.0739331245422363:.4f\n",
      "Epoch 1201: Train Loss = 0.1403, Test Loss = 1.0537192821502686:.4f\n",
      "Epoch 1202: Train Loss = 0.1541, Test Loss = 1.0416381359100342:.4f\n",
      "Epoch 1203: Train Loss = 0.1411, Test Loss = 1.0428565740585327:.4f\n",
      "Epoch 1204: Train Loss = 0.1419, Test Loss = 1.0533573627471924:.4f\n",
      "Epoch 1205: Train Loss = 0.1682, Test Loss = 1.0631659030914307:.4f\n",
      "Epoch 1206: Train Loss = 0.1731, Test Loss = 1.0638928413391113:.4f\n",
      "Epoch 1207: Train Loss = 0.1344, Test Loss = 1.0667613744735718:.4f\n",
      "Epoch 1208: Train Loss = 0.1653, Test Loss = 1.0645086765289307:.4f\n",
      "Epoch 1209: Train Loss = 0.1354, Test Loss = 1.0672978162765503:.4f\n",
      "Epoch 1210: Train Loss = 0.1551, Test Loss = 1.0686159133911133:.4f\n",
      "Epoch 1211: Train Loss = 0.1617, Test Loss = 1.062243938446045:.4f\n",
      "Epoch 1212: Train Loss = 0.1636, Test Loss = 1.042752981185913:.4f\n",
      "Epoch 1213: Train Loss = 0.1515, Test Loss = 1.0288772583007812:.4f\n",
      "Epoch 1214: Train Loss = 0.1543, Test Loss = 1.0436686277389526:.4f\n",
      "Epoch 1215: Train Loss = 0.1515, Test Loss = 1.0615665912628174:.4f\n",
      "Epoch 1216: Train Loss = 0.1688, Test Loss = 1.0663349628448486:.4f\n",
      "Epoch 1217: Train Loss = 0.1334, Test Loss = 1.0474238395690918:.4f\n",
      "Epoch 1218: Train Loss = 0.1595, Test Loss = 1.0358364582061768:.4f\n",
      "Epoch 1219: Train Loss = 0.1631, Test Loss = 1.0439311265945435:.4f\n",
      "Epoch 1220: Train Loss = 0.1554, Test Loss = 1.0424282550811768:.4f\n",
      "Epoch 1221: Train Loss = 0.1472, Test Loss = 1.0435614585876465:.4f\n",
      "Epoch 1222: Train Loss = 0.1563, Test Loss = 1.0392132997512817:.4f\n",
      "Epoch 1223: Train Loss = 0.1672, Test Loss = 1.0420668125152588:.4f\n",
      "Epoch 1224: Train Loss = 0.1405, Test Loss = 1.0519086122512817:.4f\n",
      "Epoch 1225: Train Loss = 0.1704, Test Loss = 1.065648078918457:.4f\n",
      "Epoch 1226: Train Loss = 0.1453, Test Loss = 1.0852898359298706:.4f\n",
      "Epoch 1227: Train Loss = 0.1362, Test Loss = 1.089795470237732:.4f\n",
      "Epoch 1228: Train Loss = 0.1364, Test Loss = 1.080310583114624:.4f\n",
      "Epoch 1229: Train Loss = 0.1529, Test Loss = 1.067908525466919:.4f\n",
      "Epoch 1230: Train Loss = 0.1472, Test Loss = 1.060483694076538:.4f\n",
      "Epoch 1231: Train Loss = 0.1395, Test Loss = 1.0534919500350952:.4f\n",
      "Epoch 1232: Train Loss = 0.1559, Test Loss = 1.042297124862671:.4f\n",
      "Epoch 1233: Train Loss = 0.1430, Test Loss = 1.0628225803375244:.4f\n",
      "Epoch 1234: Train Loss = 0.1377, Test Loss = 1.0702317953109741:.4f\n",
      "Epoch 1235: Train Loss = 0.1440, Test Loss = 1.0821378231048584:.4f\n",
      "Epoch 1236: Train Loss = 0.1787, Test Loss = 1.0815249681472778:.4f\n",
      "Epoch 1237: Train Loss = 0.1569, Test Loss = 1.0603020191192627:.4f\n",
      "Epoch 1238: Train Loss = 0.1519, Test Loss = 1.0600303411483765:.4f\n",
      "Epoch 1239: Train Loss = 0.1681, Test Loss = 1.0596715211868286:.4f\n",
      "Epoch 1240: Train Loss = 0.1336, Test Loss = 1.072267770767212:.4f\n",
      "Epoch 1241: Train Loss = 0.1374, Test Loss = 1.0710340738296509:.4f\n",
      "Epoch 1242: Train Loss = 0.1643, Test Loss = 1.0663137435913086:.4f\n",
      "Epoch 1243: Train Loss = 0.1488, Test Loss = 1.0661699771881104:.4f\n",
      "Epoch 1244: Train Loss = 0.1525, Test Loss = 1.0586471557617188:.4f\n",
      "Epoch 1245: Train Loss = 0.1348, Test Loss = 1.0509984493255615:.4f\n",
      "Epoch 1246: Train Loss = 0.1708, Test Loss = 1.0487329959869385:.4f\n",
      "Epoch 1247: Train Loss = 0.1861, Test Loss = 1.0377395153045654:.4f\n",
      "Epoch 1248: Train Loss = 0.1546, Test Loss = 1.028177261352539:.4f\n",
      "Epoch 1249: Train Loss = 0.1671, Test Loss = 1.0498771667480469:.4f\n",
      "Epoch 1250: Train Loss = 0.1728, Test Loss = 1.079664945602417:.4f\n",
      "Epoch 1251: Train Loss = 0.1332, Test Loss = 1.0906951427459717:.4f\n",
      "Epoch 1252: Train Loss = 0.1602, Test Loss = 1.082453966140747:.4f\n",
      "Epoch 1253: Train Loss = 0.1743, Test Loss = 1.0676783323287964:.4f\n",
      "Epoch 1254: Train Loss = 0.1540, Test Loss = 1.0479824542999268:.4f\n",
      "Epoch 1255: Train Loss = 0.1471, Test Loss = 1.0337541103363037:.4f\n",
      "Epoch 1256: Train Loss = 0.1486, Test Loss = 1.0419495105743408:.4f\n",
      "Epoch 1257: Train Loss = 0.1478, Test Loss = 1.0436503887176514:.4f\n",
      "Epoch 1258: Train Loss = 0.1657, Test Loss = 1.0565869808197021:.4f\n",
      "Epoch 1259: Train Loss = 0.1516, Test Loss = 1.0821561813354492:.4f\n",
      "Epoch 1260: Train Loss = 0.1594, Test Loss = 1.1158117055892944:.4f\n",
      "Epoch 1261: Train Loss = 0.1641, Test Loss = 1.1163544654846191:.4f\n",
      "Epoch 1262: Train Loss = 0.1689, Test Loss = 1.0831077098846436:.4f\n",
      "Epoch 1263: Train Loss = 0.1773, Test Loss = 1.0442233085632324:.4f\n",
      "Epoch 1264: Train Loss = 0.1536, Test Loss = 1.0229120254516602:.4f\n",
      "Epoch 1265: Train Loss = 0.1555, Test Loss = 1.0354686975479126:.4f\n",
      "Epoch 1266: Train Loss = 0.1768, Test Loss = 1.0399196147918701:.4f\n",
      "Epoch 1267: Train Loss = 0.1552, Test Loss = 1.0629698038101196:.4f\n",
      "Epoch 1268: Train Loss = 0.1357, Test Loss = 1.0776602029800415:.4f\n",
      "Epoch 1269: Train Loss = 0.1643, Test Loss = 1.0762141942977905:.4f\n",
      "Epoch 1270: Train Loss = 0.1755, Test Loss = 1.0588271617889404:.4f\n",
      "Epoch 1271: Train Loss = 0.1834, Test Loss = 1.0479238033294678:.4f\n",
      "Epoch 1272: Train Loss = 0.1502, Test Loss = 1.057344913482666:.4f\n",
      "Epoch 1273: Train Loss = 0.1647, Test Loss = 1.0817970037460327:.4f\n",
      "Epoch 1274: Train Loss = 0.1429, Test Loss = 1.090527892112732:.4f\n",
      "Epoch 1275: Train Loss = 0.1741, Test Loss = 1.070781946182251:.4f\n",
      "Epoch 1276: Train Loss = 0.1389, Test Loss = 1.0570167303085327:.4f\n",
      "Epoch 1277: Train Loss = 0.1512, Test Loss = 1.0506244897842407:.4f\n",
      "Epoch 1278: Train Loss = 0.1794, Test Loss = 1.0527865886688232:.4f\n",
      "Epoch 1279: Train Loss = 0.1339, Test Loss = 1.0652580261230469:.4f\n",
      "Epoch 1280: Train Loss = 0.1851, Test Loss = 1.0681511163711548:.4f\n",
      "Epoch 1281: Train Loss = 0.1468, Test Loss = 1.0670348405838013:.4f\n",
      "Epoch 1282: Train Loss = 0.1552, Test Loss = 1.0475409030914307:.4f\n",
      "Epoch 1283: Train Loss = 0.1508, Test Loss = 1.0430253744125366:.4f\n",
      "Epoch 1284: Train Loss = 0.1463, Test Loss = 1.0589240789413452:.4f\n",
      "Epoch 1285: Train Loss = 0.1498, Test Loss = 1.0747604370117188:.4f\n",
      "Epoch 1286: Train Loss = 0.1561, Test Loss = 1.0904110670089722:.4f\n",
      "Epoch 1287: Train Loss = 0.1515, Test Loss = 1.102089285850525:.4f\n",
      "Epoch 1288: Train Loss = 0.1431, Test Loss = 1.0708733797073364:.4f\n",
      "Epoch 1289: Train Loss = 0.1720, Test Loss = 1.0604948997497559:.4f\n",
      "Epoch 1290: Train Loss = 0.1344, Test Loss = 1.0565550327301025:.4f\n",
      "Epoch 1291: Train Loss = 0.1658, Test Loss = 1.0734585523605347:.4f\n",
      "Epoch 1292: Train Loss = 0.1407, Test Loss = 1.0769706964492798:.4f\n",
      "Epoch 1293: Train Loss = 0.1354, Test Loss = 1.0738956928253174:.4f\n",
      "Epoch 1294: Train Loss = 0.1781, Test Loss = 1.0805405378341675:.4f\n",
      "Epoch 1295: Train Loss = 0.1663, Test Loss = 1.084885835647583:.4f\n",
      "Epoch 1296: Train Loss = 0.1526, Test Loss = 1.0828596353530884:.4f\n",
      "Epoch 1297: Train Loss = 0.2090, Test Loss = 1.07429039478302:.4f\n",
      "Epoch 1298: Train Loss = 0.1455, Test Loss = 1.0776376724243164:.4f\n",
      "Epoch 1299: Train Loss = 0.1543, Test Loss = 1.0896713733673096:.4f\n",
      "Epoch 1300: Train Loss = 0.1376, Test Loss = 1.107609510421753:.4f\n",
      "Epoch 1301: Train Loss = 0.1439, Test Loss = 1.1058908700942993:.4f\n",
      "Epoch 1302: Train Loss = 0.2005, Test Loss = 1.0864630937576294:.4f\n",
      "Epoch 1303: Train Loss = 0.1588, Test Loss = 1.0550429821014404:.4f\n",
      "Epoch 1304: Train Loss = 0.1632, Test Loss = 1.0471019744873047:.4f\n",
      "Epoch 1305: Train Loss = 0.1938, Test Loss = 1.044562578201294:.4f\n",
      "Epoch 1306: Train Loss = 0.1406, Test Loss = 1.0762790441513062:.4f\n",
      "Epoch 1307: Train Loss = 0.1688, Test Loss = 1.10635244846344:.4f\n",
      "Epoch 1308: Train Loss = 0.1486, Test Loss = 1.1041778326034546:.4f\n",
      "Epoch 1309: Train Loss = 0.1611, Test Loss = 1.0795539617538452:.4f\n",
      "Epoch 1310: Train Loss = 0.1858, Test Loss = 1.0636121034622192:.4f\n",
      "Epoch 1311: Train Loss = 0.1412, Test Loss = 1.0696686506271362:.4f\n",
      "Epoch 1312: Train Loss = 0.1534, Test Loss = 1.0790765285491943:.4f\n",
      "Epoch 1313: Train Loss = 0.1431, Test Loss = 1.0721385478973389:.4f\n",
      "Epoch 1314: Train Loss = 0.1612, Test Loss = 1.0583771467208862:.4f\n",
      "Epoch 1315: Train Loss = 0.2143, Test Loss = 1.0715720653533936:.4f\n",
      "Epoch 1316: Train Loss = 0.1470, Test Loss = 1.0827651023864746:.4f\n",
      "Epoch 1317: Train Loss = 0.1452, Test Loss = 1.0851770639419556:.4f\n",
      "Epoch 1318: Train Loss = 0.1361, Test Loss = 1.0610557794570923:.4f\n",
      "Epoch 1319: Train Loss = 0.1535, Test Loss = 1.0544555187225342:.4f\n",
      "Epoch 1320: Train Loss = 0.1631, Test Loss = 1.057337999343872:.4f\n",
      "Epoch 1321: Train Loss = 0.1485, Test Loss = 1.076633095741272:.4f\n",
      "Epoch 1322: Train Loss = 0.1667, Test Loss = 1.0943124294281006:.4f\n",
      "Epoch 1323: Train Loss = 0.1559, Test Loss = 1.091249704360962:.4f\n",
      "Epoch 1324: Train Loss = 0.1400, Test Loss = 1.0792591571807861:.4f\n",
      "Epoch 1325: Train Loss = 0.1353, Test Loss = 1.0717060565948486:.4f\n",
      "Epoch 1326: Train Loss = 0.1388, Test Loss = 1.0616474151611328:.4f\n",
      "Epoch 1327: Train Loss = 0.1331, Test Loss = 1.0716694593429565:.4f\n",
      "Epoch 1328: Train Loss = 0.1402, Test Loss = 1.073822021484375:.4f\n",
      "Epoch 1329: Train Loss = 0.1720, Test Loss = 1.0800044536590576:.4f\n",
      "Epoch 1330: Train Loss = 0.1721, Test Loss = 1.087361454963684:.4f\n",
      "Epoch 1331: Train Loss = 0.1471, Test Loss = 1.0843746662139893:.4f\n",
      "Epoch 1332: Train Loss = 0.1459, Test Loss = 1.094325304031372:.4f\n",
      "Epoch 1333: Train Loss = 0.1607, Test Loss = 1.089428424835205:.4f\n",
      "Epoch 1334: Train Loss = 0.1761, Test Loss = 1.0694864988327026:.4f\n",
      "Epoch 1335: Train Loss = 0.1565, Test Loss = 1.0519568920135498:.4f\n",
      "Epoch 1336: Train Loss = 0.1703, Test Loss = 1.0576565265655518:.4f\n",
      "Epoch 1337: Train Loss = 0.1668, Test Loss = 1.0889217853546143:.4f\n",
      "Epoch 1338: Train Loss = 0.1712, Test Loss = 1.1086736917495728:.4f\n",
      "Epoch 1339: Train Loss = 0.1404, Test Loss = 1.118295431137085:.4f\n",
      "Epoch 1340: Train Loss = 0.1394, Test Loss = 1.1015208959579468:.4f\n",
      "Epoch 1341: Train Loss = 0.1447, Test Loss = 1.0679326057434082:.4f\n",
      "Epoch 1342: Train Loss = 0.1426, Test Loss = 1.0442534685134888:.4f\n",
      "Epoch 1343: Train Loss = 0.1333, Test Loss = 1.0604913234710693:.4f\n",
      "Epoch 1344: Train Loss = 0.1767, Test Loss = 1.0838271379470825:.4f\n",
      "Epoch 1345: Train Loss = 0.1394, Test Loss = 1.1121259927749634:.4f\n",
      "Epoch 1346: Train Loss = 0.1784, Test Loss = 1.1249065399169922:.4f\n",
      "Epoch 1347: Train Loss = 0.1360, Test Loss = 1.1059308052062988:.4f\n",
      "Epoch 1348: Train Loss = 0.1657, Test Loss = 1.076603651046753:.4f\n",
      "Epoch 1349: Train Loss = 0.1412, Test Loss = 1.0584781169891357:.4f\n",
      "Epoch 1350: Train Loss = 0.1373, Test Loss = 1.0602244138717651:.4f\n",
      "Epoch 1351: Train Loss = 0.1517, Test Loss = 1.0703184604644775:.4f\n",
      "Epoch 1352: Train Loss = 0.1396, Test Loss = 1.0830374956130981:.4f\n",
      "Epoch 1353: Train Loss = 0.1509, Test Loss = 1.0970790386199951:.4f\n",
      "Epoch 1354: Train Loss = 0.1446, Test Loss = 1.1072336435317993:.4f\n",
      "Epoch 1355: Train Loss = 0.1383, Test Loss = 1.0957539081573486:.4f\n",
      "Epoch 1356: Train Loss = 0.1632, Test Loss = 1.095464825630188:.4f\n",
      "Epoch 1357: Train Loss = 0.1470, Test Loss = 1.1053152084350586:.4f\n",
      "Epoch 1358: Train Loss = 0.1465, Test Loss = 1.109067678451538:.4f\n",
      "Epoch 1359: Train Loss = 0.1441, Test Loss = 1.098537564277649:.4f\n",
      "Epoch 1360: Train Loss = 0.1509, Test Loss = 1.0743048191070557:.4f\n",
      "Epoch 1361: Train Loss = 0.1486, Test Loss = 1.0557844638824463:.4f\n",
      "Epoch 1362: Train Loss = 0.1695, Test Loss = 1.0602463483810425:.4f\n",
      "Epoch 1363: Train Loss = 0.1662, Test Loss = 1.0737860202789307:.4f\n",
      "Epoch 1364: Train Loss = 0.1580, Test Loss = 1.0955047607421875:.4f\n",
      "Epoch 1365: Train Loss = 0.1390, Test Loss = 1.1140434741973877:.4f\n",
      "Epoch 1366: Train Loss = 0.1852, Test Loss = 1.1130229234695435:.4f\n",
      "Epoch 1367: Train Loss = 0.1579, Test Loss = 1.1067849397659302:.4f\n",
      "Epoch 1368: Train Loss = 0.1474, Test Loss = 1.10212242603302:.4f\n",
      "Epoch 1369: Train Loss = 0.1663, Test Loss = 1.1003954410552979:.4f\n",
      "Epoch 1370: Train Loss = 0.1446, Test Loss = 1.093000054359436:.4f\n",
      "Epoch 1371: Train Loss = 0.1497, Test Loss = 1.0806610584259033:.4f\n",
      "Epoch 1372: Train Loss = 0.1553, Test Loss = 1.0747008323669434:.4f\n",
      "Epoch 1373: Train Loss = 0.1413, Test Loss = 1.1037523746490479:.4f\n",
      "Epoch 1374: Train Loss = 0.1549, Test Loss = 1.1226866245269775:.4f\n",
      "Epoch 1375: Train Loss = 0.1443, Test Loss = 1.1314990520477295:.4f\n",
      "Epoch 1376: Train Loss = 0.1665, Test Loss = 1.1196444034576416:.4f\n",
      "Epoch 1377: Train Loss = 0.1532, Test Loss = 1.0859692096710205:.4f\n",
      "Epoch 1378: Train Loss = 0.1754, Test Loss = 1.0776240825653076:.4f\n",
      "Epoch 1379: Train Loss = 0.1507, Test Loss = 1.08732008934021:.4f\n",
      "Epoch 1380: Train Loss = 0.1805, Test Loss = 1.099511742591858:.4f\n",
      "Epoch 1381: Train Loss = 0.1579, Test Loss = 1.0969173908233643:.4f\n",
      "Epoch 1382: Train Loss = 0.1646, Test Loss = 1.0941089391708374:.4f\n",
      "Epoch 1383: Train Loss = 0.1457, Test Loss = 1.0976464748382568:.4f\n",
      "Epoch 1384: Train Loss = 0.1718, Test Loss = 1.0971640348434448:.4f\n",
      "Epoch 1385: Train Loss = 0.1744, Test Loss = 1.089660882949829:.4f\n",
      "Epoch 1386: Train Loss = 0.1571, Test Loss = 1.0924663543701172:.4f\n",
      "Epoch 1387: Train Loss = 0.1637, Test Loss = 1.1011393070220947:.4f\n",
      "Epoch 1388: Train Loss = 0.1333, Test Loss = 1.1097041368484497:.4f\n",
      "Epoch 1389: Train Loss = 0.1338, Test Loss = 1.1091095209121704:.4f\n",
      "Epoch 1390: Train Loss = 0.1386, Test Loss = 1.0967817306518555:.4f\n",
      "Epoch 1391: Train Loss = 0.1307, Test Loss = 1.092498779296875:.4f\n",
      "Epoch 1392: Train Loss = 0.1511, Test Loss = 1.0854839086532593:.4f\n",
      "Epoch 1393: Train Loss = 0.1445, Test Loss = 1.0792148113250732:.4f\n",
      "Epoch 1394: Train Loss = 0.1357, Test Loss = 1.0804831981658936:.4f\n",
      "Epoch 1395: Train Loss = 0.1346, Test Loss = 1.0754940509796143:.4f\n",
      "Epoch 1396: Train Loss = 0.1641, Test Loss = 1.0705537796020508:.4f\n",
      "Epoch 1397: Train Loss = 0.1582, Test Loss = 1.0684398412704468:.4f\n",
      "Epoch 1398: Train Loss = 0.1545, Test Loss = 1.0825331211090088:.4f\n",
      "Epoch 1399: Train Loss = 0.1290, Test Loss = 1.09539794921875:.4f\n",
      "Epoch 1400: Train Loss = 0.1480, Test Loss = 1.10767662525177:.4f\n",
      "Epoch 1401: Train Loss = 0.1407, Test Loss = 1.097050428390503:.4f\n",
      "Epoch 1402: Train Loss = 0.1341, Test Loss = 1.0954698324203491:.4f\n",
      "Epoch 1403: Train Loss = 0.1464, Test Loss = 1.0864393711090088:.4f\n",
      "Epoch 1404: Train Loss = 0.1598, Test Loss = 1.067757248878479:.4f\n",
      "Epoch 1405: Train Loss = 0.1555, Test Loss = 1.0732908248901367:.4f\n",
      "Epoch 1406: Train Loss = 0.1559, Test Loss = 1.0753087997436523:.4f\n",
      "Epoch 1407: Train Loss = 0.1885, Test Loss = 1.0923365354537964:.4f\n",
      "Epoch 1408: Train Loss = 0.1364, Test Loss = 1.0813840627670288:.4f\n",
      "Epoch 1409: Train Loss = 0.1875, Test Loss = 1.0775980949401855:.4f\n",
      "Epoch 1410: Train Loss = 0.1481, Test Loss = 1.0883471965789795:.4f\n",
      "Epoch 1411: Train Loss = 0.1489, Test Loss = 1.1000498533248901:.4f\n",
      "Epoch 1412: Train Loss = 0.1723, Test Loss = 1.1241964101791382:.4f\n",
      "Epoch 1413: Train Loss = 0.1916, Test Loss = 1.1191203594207764:.4f\n",
      "Epoch 1414: Train Loss = 0.1553, Test Loss = 1.1035101413726807:.4f\n",
      "Epoch 1415: Train Loss = 0.1474, Test Loss = 1.0876575708389282:.4f\n",
      "Epoch 1416: Train Loss = 0.1746, Test Loss = 1.086310625076294:.4f\n",
      "Epoch 1417: Train Loss = 0.1414, Test Loss = 1.088611364364624:.4f\n",
      "Epoch 1418: Train Loss = 0.1425, Test Loss = 1.090861201286316:.4f\n",
      "Epoch 1419: Train Loss = 0.1354, Test Loss = 1.0870335102081299:.4f\n",
      "Epoch 1420: Train Loss = 0.1384, Test Loss = 1.0901812314987183:.4f\n",
      "Epoch 1421: Train Loss = 0.1351, Test Loss = 1.104346513748169:.4f\n",
      "Epoch 1422: Train Loss = 0.1621, Test Loss = 1.1048314571380615:.4f\n",
      "Epoch 1423: Train Loss = 0.1696, Test Loss = 1.1071447134017944:.4f\n",
      "Epoch 1424: Train Loss = 0.1471, Test Loss = 1.11190927028656:.4f\n",
      "Epoch 1425: Train Loss = 0.1559, Test Loss = 1.106835126876831:.4f\n",
      "Epoch 1426: Train Loss = 0.1357, Test Loss = 1.0893934965133667:.4f\n",
      "Epoch 1427: Train Loss = 0.1332, Test Loss = 1.0856677293777466:.4f\n",
      "Epoch 1428: Train Loss = 0.1595, Test Loss = 1.0839686393737793:.4f\n",
      "Epoch 1429: Train Loss = 0.1382, Test Loss = 1.0801022052764893:.4f\n",
      "Epoch 1430: Train Loss = 0.1376, Test Loss = 1.0760774612426758:.4f\n",
      "Epoch 1431: Train Loss = 0.1571, Test Loss = 1.0804554224014282:.4f\n",
      "Epoch 1432: Train Loss = 0.1596, Test Loss = 1.1014256477355957:.4f\n",
      "Epoch 1433: Train Loss = 0.1485, Test Loss = 1.1252074241638184:.4f\n",
      "Epoch 1434: Train Loss = 0.1394, Test Loss = 1.1362526416778564:.4f\n",
      "Epoch 1435: Train Loss = 0.1574, Test Loss = 1.1204097270965576:.4f\n",
      "Epoch 1436: Train Loss = 0.1381, Test Loss = 1.0994560718536377:.4f\n",
      "Epoch 1437: Train Loss = 0.1398, Test Loss = 1.0773983001708984:.4f\n",
      "Epoch 1438: Train Loss = 0.1751, Test Loss = 1.0718134641647339:.4f\n",
      "Epoch 1439: Train Loss = 0.1450, Test Loss = 1.0811318159103394:.4f\n",
      "Epoch 1440: Train Loss = 0.1431, Test Loss = 1.1154464483261108:.4f\n",
      "Epoch 1441: Train Loss = 0.1285, Test Loss = 1.1463143825531006:.4f\n",
      "Epoch 1442: Train Loss = 0.1496, Test Loss = 1.1559336185455322:.4f\n",
      "Epoch 1443: Train Loss = 0.1431, Test Loss = 1.1332823038101196:.4f\n",
      "Epoch 1444: Train Loss = 0.1610, Test Loss = 1.0975130796432495:.4f\n",
      "Epoch 1445: Train Loss = 0.1827, Test Loss = 1.0792404413223267:.4f\n",
      "Epoch 1446: Train Loss = 0.1427, Test Loss = 1.0895211696624756:.4f\n",
      "Epoch 1447: Train Loss = 0.1685, Test Loss = 1.1136486530303955:.4f\n",
      "Epoch 1448: Train Loss = 0.1397, Test Loss = 1.1340633630752563:.4f\n",
      "Epoch 1449: Train Loss = 0.1434, Test Loss = 1.1356079578399658:.4f\n",
      "Epoch 1450: Train Loss = 0.1454, Test Loss = 1.123429536819458:.4f\n",
      "Epoch 1451: Train Loss = 0.1384, Test Loss = 1.1031895875930786:.4f\n",
      "Epoch 1452: Train Loss = 0.1531, Test Loss = 1.076237440109253:.4f\n",
      "Epoch 1453: Train Loss = 0.1337, Test Loss = 1.0809502601623535:.4f\n",
      "Epoch 1454: Train Loss = 0.1549, Test Loss = 1.0919816493988037:.4f\n",
      "Epoch 1455: Train Loss = 0.1453, Test Loss = 1.1281070709228516:.4f\n",
      "Epoch 1456: Train Loss = 0.1697, Test Loss = 1.1436362266540527:.4f\n",
      "Epoch 1457: Train Loss = 0.1617, Test Loss = 1.1481670141220093:.4f\n",
      "Epoch 1458: Train Loss = 0.1535, Test Loss = 1.1296297311782837:.4f\n",
      "Epoch 1459: Train Loss = 0.1377, Test Loss = 1.0941804647445679:.4f\n",
      "Epoch 1460: Train Loss = 0.1773, Test Loss = 1.0818934440612793:.4f\n",
      "Epoch 1461: Train Loss = 0.1577, Test Loss = 1.0933340787887573:.4f\n",
      "Epoch 1462: Train Loss = 0.1445, Test Loss = 1.1176637411117554:.4f\n",
      "Epoch 1463: Train Loss = 0.1486, Test Loss = 1.1367071866989136:.4f\n",
      "Epoch 1464: Train Loss = 0.1934, Test Loss = 1.13631272315979:.4f\n",
      "Epoch 1465: Train Loss = 0.1498, Test Loss = 1.1187025308609009:.4f\n",
      "Epoch 1466: Train Loss = 0.1764, Test Loss = 1.1118593215942383:.4f\n",
      "Epoch 1467: Train Loss = 0.1792, Test Loss = 1.1142451763153076:.4f\n",
      "Epoch 1468: Train Loss = 0.1406, Test Loss = 1.1309998035430908:.4f\n",
      "Epoch 1469: Train Loss = 0.1470, Test Loss = 1.1349717378616333:.4f\n",
      "Epoch 1470: Train Loss = 0.1298, Test Loss = 1.1083667278289795:.4f\n",
      "Epoch 1471: Train Loss = 0.1480, Test Loss = 1.0991156101226807:.4f\n",
      "Epoch 1472: Train Loss = 0.1360, Test Loss = 1.1051509380340576:.4f\n",
      "Epoch 1473: Train Loss = 0.1723, Test Loss = 1.1020578145980835:.4f\n",
      "Epoch 1474: Train Loss = 0.1409, Test Loss = 1.1068044900894165:.4f\n",
      "Epoch 1475: Train Loss = 0.1427, Test Loss = 1.1080172061920166:.4f\n",
      "Epoch 1476: Train Loss = 0.1919, Test Loss = 1.1145906448364258:.4f\n",
      "Epoch 1477: Train Loss = 0.1380, Test Loss = 1.1265438795089722:.4f\n",
      "Epoch 1478: Train Loss = 0.1386, Test Loss = 1.1330063343048096:.4f\n",
      "Epoch 1479: Train Loss = 0.1806, Test Loss = 1.1270887851715088:.4f\n",
      "Epoch 1480: Train Loss = 0.1556, Test Loss = 1.1119067668914795:.4f\n",
      "Epoch 1481: Train Loss = 0.1644, Test Loss = 1.1033215522766113:.4f\n",
      "Epoch 1482: Train Loss = 0.1520, Test Loss = 1.1045538187026978:.4f\n",
      "Epoch 1483: Train Loss = 0.1597, Test Loss = 1.1019114255905151:.4f\n",
      "Epoch 1484: Train Loss = 0.1880, Test Loss = 1.1089743375778198:.4f\n",
      "Epoch 1485: Train Loss = 0.1421, Test Loss = 1.099157452583313:.4f\n",
      "Epoch 1486: Train Loss = 0.1936, Test Loss = 1.1041648387908936:.4f\n",
      "Epoch 1487: Train Loss = 0.1931, Test Loss = 1.1078814268112183:.4f\n",
      "Epoch 1488: Train Loss = 0.1463, Test Loss = 1.1139507293701172:.4f\n",
      "Epoch 1489: Train Loss = 0.1660, Test Loss = 1.1153218746185303:.4f\n",
      "Epoch 1490: Train Loss = 0.1461, Test Loss = 1.1068586111068726:.4f\n",
      "Epoch 1491: Train Loss = 0.1324, Test Loss = 1.1036456823349:.4f\n",
      "Epoch 1492: Train Loss = 0.1420, Test Loss = 1.111242651939392:.4f\n",
      "Epoch 1493: Train Loss = 0.1286, Test Loss = 1.1134988069534302:.4f\n",
      "Epoch 1494: Train Loss = 0.1344, Test Loss = 1.1170682907104492:.4f\n",
      "Epoch 1495: Train Loss = 0.1591, Test Loss = 1.116740345954895:.4f\n",
      "Epoch 1496: Train Loss = 0.1671, Test Loss = 1.1128329038619995:.4f\n",
      "Epoch 1497: Train Loss = 0.1569, Test Loss = 1.1134754419326782:.4f\n",
      "Epoch 1498: Train Loss = 0.1446, Test Loss = 1.099940299987793:.4f\n",
      "Epoch 1499: Train Loss = 0.1324, Test Loss = 1.099220871925354:.4f\n",
      "Epoch 1500: Train Loss = 0.2072, Test Loss = 1.0894447565078735:.4f\n",
      "Epoch 1501: Train Loss = 0.1470, Test Loss = 1.0891238451004028:.4f\n",
      "Epoch 1502: Train Loss = 0.1602, Test Loss = 1.1012017726898193:.4f\n",
      "Epoch 1503: Train Loss = 0.1382, Test Loss = 1.1114122867584229:.4f\n",
      "Epoch 1504: Train Loss = 0.1783, Test Loss = 1.1158784627914429:.4f\n",
      "Epoch 1505: Train Loss = 0.1969, Test Loss = 1.1141388416290283:.4f\n",
      "Epoch 1506: Train Loss = 0.1687, Test Loss = 1.1129906177520752:.4f\n",
      "Epoch 1507: Train Loss = 0.1579, Test Loss = 1.1256098747253418:.4f\n",
      "Epoch 1508: Train Loss = 0.1605, Test Loss = 1.1240876913070679:.4f\n",
      "Epoch 1509: Train Loss = 0.1347, Test Loss = 1.1359734535217285:.4f\n",
      "Epoch 1510: Train Loss = 0.1456, Test Loss = 1.1479952335357666:.4f\n",
      "Epoch 1511: Train Loss = 0.1710, Test Loss = 1.143338680267334:.4f\n",
      "Epoch 1512: Train Loss = 0.1457, Test Loss = 1.1326385736465454:.4f\n",
      "Epoch 1513: Train Loss = 0.1462, Test Loss = 1.1211236715316772:.4f\n",
      "Epoch 1514: Train Loss = 0.1396, Test Loss = 1.117623209953308:.4f\n",
      "Epoch 1515: Train Loss = 0.1389, Test Loss = 1.111748456954956:.4f\n",
      "Epoch 1516: Train Loss = 0.1355, Test Loss = 1.118788480758667:.4f\n",
      "Epoch 1517: Train Loss = 0.1663, Test Loss = 1.113146424293518:.4f\n",
      "Epoch 1518: Train Loss = 0.1481, Test Loss = 1.1025805473327637:.4f\n",
      "Epoch 1519: Train Loss = 0.1356, Test Loss = 1.0960612297058105:.4f\n",
      "Epoch 1520: Train Loss = 0.1567, Test Loss = 1.0946333408355713:.4f\n",
      "Epoch 1521: Train Loss = 0.1442, Test Loss = 1.1174678802490234:.4f\n",
      "Epoch 1522: Train Loss = 0.1743, Test Loss = 1.1271543502807617:.4f\n",
      "Epoch 1523: Train Loss = 0.1545, Test Loss = 1.1461669206619263:.4f\n",
      "Epoch 1524: Train Loss = 0.1648, Test Loss = 1.1602225303649902:.4f\n",
      "Epoch 1525: Train Loss = 0.1515, Test Loss = 1.143789291381836:.4f\n",
      "Epoch 1526: Train Loss = 0.1899, Test Loss = 1.1220966577529907:.4f\n",
      "Epoch 1527: Train Loss = 0.1686, Test Loss = 1.0951738357543945:.4f\n",
      "Epoch 1528: Train Loss = 0.1321, Test Loss = 1.074793815612793:.4f\n",
      "Epoch 1529: Train Loss = 0.1845, Test Loss = 1.0786939859390259:.4f\n",
      "Epoch 1530: Train Loss = 0.1373, Test Loss = 1.092226266860962:.4f\n",
      "Epoch 1531: Train Loss = 0.1494, Test Loss = 1.1144522428512573:.4f\n",
      "Epoch 1532: Train Loss = 0.1867, Test Loss = 1.1309804916381836:.4f\n",
      "Epoch 1533: Train Loss = 0.1488, Test Loss = 1.1232653856277466:.4f\n",
      "Epoch 1534: Train Loss = 0.1467, Test Loss = 1.1388283967971802:.4f\n",
      "Epoch 1535: Train Loss = 0.1540, Test Loss = 1.1366620063781738:.4f\n",
      "Epoch 1536: Train Loss = 0.1602, Test Loss = 1.1421862840652466:.4f\n",
      "Epoch 1537: Train Loss = 0.1595, Test Loss = 1.1392549276351929:.4f\n",
      "Epoch 1538: Train Loss = 0.2139, Test Loss = 1.0923962593078613:.4f\n",
      "Epoch 1539: Train Loss = 0.1498, Test Loss = 1.079683780670166:.4f\n",
      "Epoch 1540: Train Loss = 0.1589, Test Loss = 1.0840950012207031:.4f\n",
      "Epoch 1541: Train Loss = 0.1422, Test Loss = 1.123591423034668:.4f\n",
      "Epoch 1542: Train Loss = 0.1392, Test Loss = 1.1583716869354248:.4f\n",
      "Epoch 1543: Train Loss = 0.1479, Test Loss = 1.1504544019699097:.4f\n",
      "Epoch 1544: Train Loss = 0.1505, Test Loss = 1.1374439001083374:.4f\n",
      "Epoch 1545: Train Loss = 0.1487, Test Loss = 1.1236650943756104:.4f\n",
      "Epoch 1546: Train Loss = 0.1441, Test Loss = 1.1034749746322632:.4f\n",
      "Epoch 1547: Train Loss = 0.1894, Test Loss = 1.1084530353546143:.4f\n",
      "Epoch 1548: Train Loss = 0.1433, Test Loss = 1.1010111570358276:.4f\n",
      "Epoch 1549: Train Loss = 0.1560, Test Loss = 1.1212526559829712:.4f\n",
      "Epoch 1550: Train Loss = 0.1444, Test Loss = 1.1395022869110107:.4f\n",
      "Epoch 1551: Train Loss = 0.1369, Test Loss = 1.1555625200271606:.4f\n",
      "Epoch 1552: Train Loss = 0.1699, Test Loss = 1.1550909280776978:.4f\n",
      "Epoch 1553: Train Loss = 0.1953, Test Loss = 1.1418344974517822:.4f\n",
      "Epoch 1554: Train Loss = 0.2176, Test Loss = 1.1536591053009033:.4f\n",
      "Epoch 1555: Train Loss = 0.1572, Test Loss = 1.1536345481872559:.4f\n",
      "Epoch 1556: Train Loss = 0.1352, Test Loss = 1.1483994722366333:.4f\n",
      "Epoch 1557: Train Loss = 0.1471, Test Loss = 1.1300263404846191:.4f\n",
      "Epoch 1558: Train Loss = 0.1375, Test Loss = 1.1037757396697998:.4f\n",
      "Epoch 1559: Train Loss = 0.1298, Test Loss = 1.1016594171524048:.4f\n",
      "Epoch 1560: Train Loss = 0.1602, Test Loss = 1.1103527545928955:.4f\n",
      "Epoch 1561: Train Loss = 0.1331, Test Loss = 1.1171311140060425:.4f\n",
      "Epoch 1562: Train Loss = 0.1369, Test Loss = 1.1409164667129517:.4f\n",
      "Epoch 1563: Train Loss = 0.1362, Test Loss = 1.1405842304229736:.4f\n",
      "Epoch 1564: Train Loss = 0.1319, Test Loss = 1.1257176399230957:.4f\n",
      "Epoch 1565: Train Loss = 0.1312, Test Loss = 1.114684820175171:.4f\n",
      "Epoch 1566: Train Loss = 0.1825, Test Loss = 1.120284080505371:.4f\n",
      "Epoch 1567: Train Loss = 0.1344, Test Loss = 1.151376485824585:.4f\n",
      "Epoch 1568: Train Loss = 0.1419, Test Loss = 1.1622066497802734:.4f\n",
      "Epoch 1569: Train Loss = 0.1474, Test Loss = 1.165173053741455:.4f\n",
      "Epoch 1570: Train Loss = 0.1292, Test Loss = 1.1562024354934692:.4f\n",
      "Epoch 1571: Train Loss = 0.1332, Test Loss = 1.1408576965332031:.4f\n",
      "Epoch 1572: Train Loss = 0.1364, Test Loss = 1.1234210729599:.4f\n",
      "Epoch 1573: Train Loss = 0.1323, Test Loss = 1.1009209156036377:.4f\n",
      "Epoch 1574: Train Loss = 0.1783, Test Loss = 1.1015859842300415:.4f\n",
      "Epoch 1575: Train Loss = 0.1347, Test Loss = 1.1192203760147095:.4f\n",
      "Epoch 1576: Train Loss = 0.1499, Test Loss = 1.141875982284546:.4f\n",
      "Epoch 1577: Train Loss = 0.1394, Test Loss = 1.1508184671401978:.4f\n",
      "Epoch 1578: Train Loss = 0.1488, Test Loss = 1.138573408126831:.4f\n",
      "Epoch 1579: Train Loss = 0.1473, Test Loss = 1.1114966869354248:.4f\n",
      "Epoch 1580: Train Loss = 0.1462, Test Loss = 1.1072355508804321:.4f\n",
      "Epoch 1581: Train Loss = 0.1539, Test Loss = 1.1094000339508057:.4f\n",
      "Epoch 1582: Train Loss = 0.1480, Test Loss = 1.1122545003890991:.4f\n",
      "Epoch 1583: Train Loss = 0.1665, Test Loss = 1.1093518733978271:.4f\n",
      "Epoch 1584: Train Loss = 0.1457, Test Loss = 1.1152417659759521:.4f\n",
      "Epoch 1585: Train Loss = 0.1436, Test Loss = 1.14310622215271:.4f\n",
      "Epoch 1586: Train Loss = 0.1324, Test Loss = 1.1435184478759766:.4f\n",
      "Epoch 1587: Train Loss = 0.1972, Test Loss = 1.134432077407837:.4f\n",
      "Epoch 1588: Train Loss = 0.1646, Test Loss = 1.131316900253296:.4f\n",
      "Epoch 1589: Train Loss = 0.1461, Test Loss = 1.1352444887161255:.4f\n",
      "Epoch 1590: Train Loss = 0.1707, Test Loss = 1.1435692310333252:.4f\n",
      "Epoch 1591: Train Loss = 0.1645, Test Loss = 1.1439841985702515:.4f\n",
      "Epoch 1592: Train Loss = 0.1428, Test Loss = 1.139297604560852:.4f\n",
      "Epoch 1593: Train Loss = 0.1561, Test Loss = 1.1275639533996582:.4f\n",
      "Epoch 1594: Train Loss = 0.1608, Test Loss = 1.1134271621704102:.4f\n",
      "Epoch 1595: Train Loss = 0.1590, Test Loss = 1.122831106185913:.4f\n",
      "Epoch 1596: Train Loss = 0.1628, Test Loss = 1.134932518005371:.4f\n",
      "Epoch 1597: Train Loss = 0.1344, Test Loss = 1.1398473978042603:.4f\n",
      "Epoch 1598: Train Loss = 0.1499, Test Loss = 1.1367247104644775:.4f\n",
      "Epoch 1599: Train Loss = 0.1716, Test Loss = 1.1325839757919312:.4f\n",
      "Epoch 1600: Train Loss = 0.1476, Test Loss = 1.1230950355529785:.4f\n",
      "Epoch 1601: Train Loss = 0.1297, Test Loss = 1.1212692260742188:.4f\n",
      "Epoch 1602: Train Loss = 0.1259, Test Loss = 1.1177901029586792:.4f\n",
      "Epoch 1603: Train Loss = 0.1377, Test Loss = 1.1192734241485596:.4f\n",
      "Epoch 1604: Train Loss = 0.1706, Test Loss = 1.1111197471618652:.4f\n",
      "Epoch 1605: Train Loss = 0.1707, Test Loss = 1.1202162504196167:.4f\n",
      "Epoch 1606: Train Loss = 0.1761, Test Loss = 1.1143746376037598:.4f\n",
      "Epoch 1607: Train Loss = 0.1608, Test Loss = 1.1139600276947021:.4f\n",
      "Epoch 1608: Train Loss = 0.1481, Test Loss = 1.1336841583251953:.4f\n",
      "Epoch 1609: Train Loss = 0.1845, Test Loss = 1.1495460271835327:.4f\n",
      "Epoch 1610: Train Loss = 0.1425, Test Loss = 1.1338779926300049:.4f\n",
      "Epoch 1611: Train Loss = 0.1552, Test Loss = 1.1218838691711426:.4f\n",
      "Epoch 1612: Train Loss = 0.1349, Test Loss = 1.1033012866973877:.4f\n",
      "Epoch 1613: Train Loss = 0.1884, Test Loss = 1.0953456163406372:.4f\n",
      "Epoch 1614: Train Loss = 0.1619, Test Loss = 1.105092167854309:.4f\n",
      "Epoch 1615: Train Loss = 0.1665, Test Loss = 1.1158593893051147:.4f\n",
      "Epoch 1616: Train Loss = 0.1721, Test Loss = 1.1482985019683838:.4f\n",
      "Epoch 1617: Train Loss = 0.1597, Test Loss = 1.1494563817977905:.4f\n",
      "Epoch 1618: Train Loss = 0.1510, Test Loss = 1.1416304111480713:.4f\n",
      "Epoch 1619: Train Loss = 0.1390, Test Loss = 1.1230287551879883:.4f\n",
      "Epoch 1620: Train Loss = 0.1405, Test Loss = 1.1015973091125488:.4f\n",
      "Epoch 1621: Train Loss = 0.1471, Test Loss = 1.0991973876953125:.4f\n",
      "Epoch 1622: Train Loss = 0.1974, Test Loss = 1.1250287294387817:.4f\n",
      "Epoch 1623: Train Loss = 0.1371, Test Loss = 1.1602689027786255:.4f\n",
      "Epoch 1624: Train Loss = 0.1459, Test Loss = 1.1672658920288086:.4f\n",
      "Epoch 1625: Train Loss = 0.1520, Test Loss = 1.1454116106033325:.4f\n",
      "Epoch 1626: Train Loss = 0.1620, Test Loss = 1.115057110786438:.4f\n",
      "Epoch 1627: Train Loss = 0.1287, Test Loss = 1.1111843585968018:.4f\n",
      "Epoch 1628: Train Loss = 0.1868, Test Loss = 1.1132705211639404:.4f\n",
      "Epoch 1629: Train Loss = 0.1403, Test Loss = 1.1245501041412354:.4f\n",
      "Epoch 1630: Train Loss = 0.1469, Test Loss = 1.1309716701507568:.4f\n",
      "Epoch 1631: Train Loss = 0.1551, Test Loss = 1.1355022192001343:.4f\n",
      "Epoch 1632: Train Loss = 0.1371, Test Loss = 1.1471223831176758:.4f\n",
      "Epoch 1633: Train Loss = 0.1571, Test Loss = 1.1331626176834106:.4f\n",
      "Epoch 1634: Train Loss = 0.1428, Test Loss = 1.0962499380111694:.4f\n",
      "Epoch 1635: Train Loss = 0.1428, Test Loss = 1.094343900680542:.4f\n",
      "Epoch 1636: Train Loss = 0.1412, Test Loss = 1.096508264541626:.4f\n",
      "Epoch 1637: Train Loss = 0.1435, Test Loss = 1.119711995124817:.4f\n",
      "Epoch 1638: Train Loss = 0.1552, Test Loss = 1.137432336807251:.4f\n",
      "Epoch 1639: Train Loss = 0.1820, Test Loss = 1.1381449699401855:.4f\n",
      "Epoch 1640: Train Loss = 0.1401, Test Loss = 1.1543190479278564:.4f\n",
      "Epoch 1641: Train Loss = 0.1889, Test Loss = 1.1616154909133911:.4f\n",
      "Epoch 1642: Train Loss = 0.1603, Test Loss = 1.1580817699432373:.4f\n",
      "Epoch 1643: Train Loss = 0.1773, Test Loss = 1.1468231678009033:.4f\n",
      "Epoch 1644: Train Loss = 0.1603, Test Loss = 1.1037366390228271:.4f\n",
      "Epoch 1645: Train Loss = 0.1857, Test Loss = 1.0966606140136719:.4f\n",
      "Epoch 1646: Train Loss = 0.1709, Test Loss = 1.1213611364364624:.4f\n",
      "Epoch 1647: Train Loss = 0.1440, Test Loss = 1.1348503828048706:.4f\n",
      "Epoch 1648: Train Loss = 0.1457, Test Loss = 1.139699101448059:.4f\n",
      "Epoch 1649: Train Loss = 0.1422, Test Loss = 1.1411868333816528:.4f\n",
      "Epoch 1650: Train Loss = 0.1684, Test Loss = 1.125251054763794:.4f\n",
      "Epoch 1651: Train Loss = 0.1405, Test Loss = 1.1173094511032104:.4f\n",
      "Epoch 1652: Train Loss = 0.1405, Test Loss = 1.116442084312439:.4f\n",
      "Epoch 1653: Train Loss = 0.1756, Test Loss = 1.1199009418487549:.4f\n",
      "Epoch 1654: Train Loss = 0.1509, Test Loss = 1.1198511123657227:.4f\n",
      "Epoch 1655: Train Loss = 0.1695, Test Loss = 1.1158864498138428:.4f\n",
      "Epoch 1656: Train Loss = 0.1598, Test Loss = 1.1063283681869507:.4f\n",
      "Epoch 1657: Train Loss = 0.1654, Test Loss = 1.112755537033081:.4f\n",
      "Epoch 1658: Train Loss = 0.1361, Test Loss = 1.1238324642181396:.4f\n",
      "Epoch 1659: Train Loss = 0.1299, Test Loss = 1.1345294713974:.4f\n",
      "Epoch 1660: Train Loss = 0.1551, Test Loss = 1.1484133005142212:.4f\n",
      "Epoch 1661: Train Loss = 0.1446, Test Loss = 1.1457629203796387:.4f\n",
      "Epoch 1662: Train Loss = 0.1445, Test Loss = 1.1438950300216675:.4f\n",
      "Epoch 1663: Train Loss = 0.1575, Test Loss = 1.1158740520477295:.4f\n",
      "Epoch 1664: Train Loss = 0.1385, Test Loss = 1.1055028438568115:.4f\n",
      "Epoch 1665: Train Loss = 0.1626, Test Loss = 1.113967776298523:.4f\n",
      "Epoch 1666: Train Loss = 0.1417, Test Loss = 1.1323010921478271:.4f\n",
      "Epoch 1667: Train Loss = 0.1612, Test Loss = 1.154601812362671:.4f\n",
      "Epoch 1668: Train Loss = 0.1443, Test Loss = 1.1580525636672974:.4f\n",
      "Epoch 1669: Train Loss = 0.1327, Test Loss = 1.1604773998260498:.4f\n",
      "Epoch 1670: Train Loss = 0.1434, Test Loss = 1.1404335498809814:.4f\n",
      "Epoch 1671: Train Loss = 0.1394, Test Loss = 1.115468144416809:.4f\n",
      "Epoch 1672: Train Loss = 0.1448, Test Loss = 1.1009405851364136:.4f\n",
      "Epoch 1673: Train Loss = 0.1622, Test Loss = 1.1153972148895264:.4f\n",
      "Epoch 1674: Train Loss = 0.1459, Test Loss = 1.1340768337249756:.4f\n",
      "Epoch 1675: Train Loss = 0.1732, Test Loss = 1.1574286222457886:.4f\n",
      "Epoch 1676: Train Loss = 0.1928, Test Loss = 1.1584707498550415:.4f\n",
      "Epoch 1677: Train Loss = 0.1465, Test Loss = 1.1482248306274414:.4f\n",
      "Epoch 1678: Train Loss = 0.1616, Test Loss = 1.1283588409423828:.4f\n",
      "Epoch 1679: Train Loss = 0.1428, Test Loss = 1.1328507661819458:.4f\n",
      "Epoch 1680: Train Loss = 0.1503, Test Loss = 1.1212469339370728:.4f\n",
      "Epoch 1681: Train Loss = 0.1466, Test Loss = 1.115332007408142:.4f\n",
      "Epoch 1682: Train Loss = 0.1772, Test Loss = 1.126884937286377:.4f\n",
      "Epoch 1683: Train Loss = 0.1519, Test Loss = 1.1326607465744019:.4f\n",
      "Epoch 1684: Train Loss = 0.1637, Test Loss = 1.1505348682403564:.4f\n",
      "Epoch 1685: Train Loss = 0.1502, Test Loss = 1.154981255531311:.4f\n",
      "Epoch 1686: Train Loss = 0.1457, Test Loss = 1.1480885744094849:.4f\n",
      "Epoch 1687: Train Loss = 0.1414, Test Loss = 1.1536319255828857:.4f\n",
      "Epoch 1688: Train Loss = 0.1670, Test Loss = 1.1476762294769287:.4f\n",
      "Epoch 1689: Train Loss = 0.1382, Test Loss = 1.1385581493377686:.4f\n",
      "Epoch 1690: Train Loss = 0.1672, Test Loss = 1.1335457563400269:.4f\n",
      "Epoch 1691: Train Loss = 0.1325, Test Loss = 1.1313867568969727:.4f\n",
      "Epoch 1692: Train Loss = 0.1338, Test Loss = 1.1395385265350342:.4f\n",
      "Epoch 1693: Train Loss = 0.1862, Test Loss = 1.1411453485488892:.4f\n",
      "Epoch 1694: Train Loss = 0.1438, Test Loss = 1.1436879634857178:.4f\n",
      "Epoch 1695: Train Loss = 0.1376, Test Loss = 1.135673999786377:.4f\n",
      "Epoch 1696: Train Loss = 0.1344, Test Loss = 1.1384936571121216:.4f\n",
      "Epoch 1697: Train Loss = 0.1400, Test Loss = 1.1397274732589722:.4f\n",
      "Epoch 1698: Train Loss = 0.1355, Test Loss = 1.1275566816329956:.4f\n",
      "Epoch 1699: Train Loss = 0.1340, Test Loss = 1.1178224086761475:.4f\n",
      "Epoch 1700: Train Loss = 0.1685, Test Loss = 1.1320730447769165:.4f\n",
      "Epoch 1701: Train Loss = 0.1489, Test Loss = 1.1502314805984497:.4f\n",
      "Epoch 1702: Train Loss = 0.1455, Test Loss = 1.1480032205581665:.4f\n",
      "Epoch 1703: Train Loss = 0.1544, Test Loss = 1.1555144786834717:.4f\n",
      "Epoch 1704: Train Loss = 0.1446, Test Loss = 1.148406744003296:.4f\n",
      "Epoch 1705: Train Loss = 0.1397, Test Loss = 1.1382315158843994:.4f\n",
      "Epoch 1706: Train Loss = 0.1329, Test Loss = 1.125788927078247:.4f\n",
      "Epoch 1707: Train Loss = 0.1337, Test Loss = 1.1320630311965942:.4f\n",
      "Epoch 1708: Train Loss = 0.1456, Test Loss = 1.1416471004486084:.4f\n",
      "Epoch 1709: Train Loss = 0.1340, Test Loss = 1.1457642316818237:.4f\n",
      "Epoch 1710: Train Loss = 0.1391, Test Loss = 1.1436693668365479:.4f\n",
      "Epoch 1711: Train Loss = 0.1632, Test Loss = 1.1418776512145996:.4f\n",
      "Epoch 1712: Train Loss = 0.1647, Test Loss = 1.1312892436981201:.4f\n",
      "Epoch 1713: Train Loss = 0.1451, Test Loss = 1.1280773878097534:.4f\n",
      "Epoch 1714: Train Loss = 0.1280, Test Loss = 1.1214783191680908:.4f\n",
      "Epoch 1715: Train Loss = 0.1507, Test Loss = 1.117907166481018:.4f\n",
      "Epoch 1716: Train Loss = 0.1615, Test Loss = 1.1186598539352417:.4f\n",
      "Epoch 1717: Train Loss = 0.1687, Test Loss = 1.122409462928772:.4f\n",
      "Epoch 1718: Train Loss = 0.1560, Test Loss = 1.137382984161377:.4f\n",
      "Epoch 1719: Train Loss = 0.1862, Test Loss = 1.1395379304885864:.4f\n",
      "Epoch 1720: Train Loss = 0.1803, Test Loss = 1.130760908126831:.4f\n",
      "Epoch 1721: Train Loss = 0.1306, Test Loss = 1.1254023313522339:.4f\n",
      "Epoch 1722: Train Loss = 0.1442, Test Loss = 1.1302721500396729:.4f\n",
      "Epoch 1723: Train Loss = 0.1681, Test Loss = 1.1443262100219727:.4f\n",
      "Epoch 1724: Train Loss = 0.1693, Test Loss = 1.1548230648040771:.4f\n",
      "Epoch 1725: Train Loss = 0.1935, Test Loss = 1.1496808528900146:.4f\n",
      "Epoch 1726: Train Loss = 0.1893, Test Loss = 1.128950834274292:.4f\n",
      "Epoch 1727: Train Loss = 0.1767, Test Loss = 1.1281578540802002:.4f\n",
      "Epoch 1728: Train Loss = 0.1435, Test Loss = 1.1364727020263672:.4f\n",
      "Epoch 1729: Train Loss = 0.1767, Test Loss = 1.143709659576416:.4f\n",
      "Epoch 1730: Train Loss = 0.1524, Test Loss = 1.1230032444000244:.4f\n",
      "Epoch 1731: Train Loss = 0.1457, Test Loss = 1.1257952451705933:.4f\n",
      "Epoch 1732: Train Loss = 0.1461, Test Loss = 1.136245846748352:.4f\n",
      "Epoch 1733: Train Loss = 0.1350, Test Loss = 1.132871389389038:.4f\n",
      "Epoch 1734: Train Loss = 0.1402, Test Loss = 1.128717064857483:.4f\n",
      "Epoch 1735: Train Loss = 0.1689, Test Loss = 1.126814842224121:.4f\n",
      "Epoch 1736: Train Loss = 0.1713, Test Loss = 1.1267396211624146:.4f\n",
      "Epoch 1737: Train Loss = 0.1784, Test Loss = 1.1309136152267456:.4f\n",
      "Epoch 1738: Train Loss = 0.1706, Test Loss = 1.1357641220092773:.4f\n",
      "Epoch 1739: Train Loss = 0.1375, Test Loss = 1.1452147960662842:.4f\n",
      "Epoch 1740: Train Loss = 0.1440, Test Loss = 1.136008381843567:.4f\n",
      "Epoch 1741: Train Loss = 0.1339, Test Loss = 1.136409044265747:.4f\n",
      "Epoch 1742: Train Loss = 0.1418, Test Loss = 1.1412785053253174:.4f\n",
      "Epoch 1743: Train Loss = 0.1447, Test Loss = 1.1323693990707397:.4f\n",
      "Epoch 1744: Train Loss = 0.1574, Test Loss = 1.143816351890564:.4f\n",
      "Epoch 1745: Train Loss = 0.1419, Test Loss = 1.156484842300415:.4f\n",
      "Epoch 1746: Train Loss = 0.1457, Test Loss = 1.1619048118591309:.4f\n",
      "Epoch 1747: Train Loss = 0.1371, Test Loss = 1.1570587158203125:.4f\n",
      "Epoch 1748: Train Loss = 0.1562, Test Loss = 1.131411075592041:.4f\n",
      "Epoch 1749: Train Loss = 0.1742, Test Loss = 1.126840353012085:.4f\n",
      "Epoch 1750: Train Loss = 0.1529, Test Loss = 1.130657434463501:.4f\n",
      "Epoch 1751: Train Loss = 0.1428, Test Loss = 1.147742509841919:.4f\n",
      "Epoch 1752: Train Loss = 0.1790, Test Loss = 1.1664257049560547:.4f\n",
      "Epoch 1753: Train Loss = 0.1390, Test Loss = 1.1522409915924072:.4f\n",
      "Epoch 1754: Train Loss = 0.1446, Test Loss = 1.138951063156128:.4f\n",
      "Epoch 1755: Train Loss = 0.1722, Test Loss = 1.1304672956466675:.4f\n",
      "Epoch 1756: Train Loss = 0.1874, Test Loss = 1.1309939622879028:.4f\n",
      "Epoch 1757: Train Loss = 0.1634, Test Loss = 1.135912537574768:.4f\n",
      "Epoch 1758: Train Loss = 0.1453, Test Loss = 1.1394963264465332:.4f\n",
      "Epoch 1759: Train Loss = 0.1454, Test Loss = 1.1374770402908325:.4f\n",
      "Epoch 1760: Train Loss = 0.1411, Test Loss = 1.1389830112457275:.4f\n",
      "Epoch 1761: Train Loss = 0.1416, Test Loss = 1.131792426109314:.4f\n",
      "Epoch 1762: Train Loss = 0.1294, Test Loss = 1.126715064048767:.4f\n",
      "Epoch 1763: Train Loss = 0.1536, Test Loss = 1.1354988813400269:.4f\n",
      "Epoch 1764: Train Loss = 0.1608, Test Loss = 1.146358609199524:.4f\n",
      "Epoch 1765: Train Loss = 0.1288, Test Loss = 1.1529922485351562:.4f\n",
      "Epoch 1766: Train Loss = 0.1508, Test Loss = 1.1570857763290405:.4f\n",
      "Epoch 1767: Train Loss = 0.1576, Test Loss = 1.1578474044799805:.4f\n",
      "Epoch 1768: Train Loss = 0.1521, Test Loss = 1.1437311172485352:.4f\n",
      "Epoch 1769: Train Loss = 0.1353, Test Loss = 1.1347988843917847:.4f\n",
      "Epoch 1770: Train Loss = 0.1710, Test Loss = 1.1236088275909424:.4f\n",
      "Epoch 1771: Train Loss = 0.1534, Test Loss = 1.114992380142212:.4f\n",
      "Epoch 1772: Train Loss = 0.1708, Test Loss = 1.124149203300476:.4f\n",
      "Epoch 1773: Train Loss = 0.1373, Test Loss = 1.1239550113677979:.4f\n",
      "Epoch 1774: Train Loss = 0.1581, Test Loss = 1.1190904378890991:.4f\n",
      "Epoch 1775: Train Loss = 0.1402, Test Loss = 1.1229228973388672:.4f\n",
      "Epoch 1776: Train Loss = 0.1295, Test Loss = 1.1309727430343628:.4f\n",
      "Epoch 1777: Train Loss = 0.1810, Test Loss = 1.1362773180007935:.4f\n",
      "Epoch 1778: Train Loss = 0.1381, Test Loss = 1.142898678779602:.4f\n",
      "Epoch 1779: Train Loss = 0.1893, Test Loss = 1.1600431203842163:.4f\n",
      "Epoch 1780: Train Loss = 0.1946, Test Loss = 1.1561940908432007:.4f\n",
      "Epoch 1781: Train Loss = 0.1631, Test Loss = 1.1456098556518555:.4f\n",
      "Epoch 1782: Train Loss = 0.1434, Test Loss = 1.133529782295227:.4f\n",
      "Epoch 1783: Train Loss = 0.1566, Test Loss = 1.1246213912963867:.4f\n",
      "Epoch 1784: Train Loss = 0.1658, Test Loss = 1.1254335641860962:.4f\n",
      "Epoch 1785: Train Loss = 0.1759, Test Loss = 1.1236727237701416:.4f\n",
      "Epoch 1786: Train Loss = 0.1436, Test Loss = 1.1360347270965576:.4f\n",
      "Epoch 1787: Train Loss = 0.1422, Test Loss = 1.1467751264572144:.4f\n",
      "Epoch 1788: Train Loss = 0.1371, Test Loss = 1.1548982858657837:.4f\n",
      "Epoch 1789: Train Loss = 0.1345, Test Loss = 1.152245283126831:.4f\n",
      "Epoch 1790: Train Loss = 0.1341, Test Loss = 1.1309603452682495:.4f\n",
      "Epoch 1791: Train Loss = 0.1559, Test Loss = 1.127088189125061:.4f\n",
      "Epoch 1792: Train Loss = 0.1829, Test Loss = 1.1364319324493408:.4f\n",
      "Epoch 1793: Train Loss = 0.1545, Test Loss = 1.1382219791412354:.4f\n",
      "Epoch 1794: Train Loss = 0.1315, Test Loss = 1.1411607265472412:.4f\n",
      "Epoch 1795: Train Loss = 0.1338, Test Loss = 1.1527032852172852:.4f\n",
      "Epoch 1796: Train Loss = 0.1798, Test Loss = 1.1541951894760132:.4f\n",
      "Epoch 1797: Train Loss = 0.1319, Test Loss = 1.1427760124206543:.4f\n",
      "Epoch 1798: Train Loss = 0.1472, Test Loss = 1.1309617757797241:.4f\n",
      "Epoch 1799: Train Loss = 0.1534, Test Loss = 1.1149312257766724:.4f\n",
      "Epoch 1800: Train Loss = 0.1341, Test Loss = 1.1256128549575806:.4f\n",
      "Epoch 1801: Train Loss = 0.1435, Test Loss = 1.1426475048065186:.4f\n",
      "Epoch 1802: Train Loss = 0.1317, Test Loss = 1.1493635177612305:.4f\n",
      "Epoch 1803: Train Loss = 0.1866, Test Loss = 1.1518137454986572:.4f\n",
      "Epoch 1804: Train Loss = 0.1558, Test Loss = 1.1346698999404907:.4f\n",
      "Epoch 1805: Train Loss = 0.1262, Test Loss = 1.1227859258651733:.4f\n",
      "Epoch 1806: Train Loss = 0.1769, Test Loss = 1.122683048248291:.4f\n",
      "Epoch 1807: Train Loss = 0.1582, Test Loss = 1.1437971591949463:.4f\n",
      "Epoch 1808: Train Loss = 0.1471, Test Loss = 1.1780511140823364:.4f\n",
      "Epoch 1809: Train Loss = 0.1808, Test Loss = 1.1771748065948486:.4f\n",
      "Epoch 1810: Train Loss = 0.1573, Test Loss = 1.1506202220916748:.4f\n",
      "Epoch 1811: Train Loss = 0.1659, Test Loss = 1.1267281770706177:.4f\n",
      "Epoch 1812: Train Loss = 0.1388, Test Loss = 1.1298463344573975:.4f\n",
      "Epoch 1813: Train Loss = 0.1458, Test Loss = 1.136859655380249:.4f\n",
      "Epoch 1814: Train Loss = 0.1337, Test Loss = 1.136814832687378:.4f\n",
      "Epoch 1815: Train Loss = 0.1533, Test Loss = 1.141133189201355:.4f\n",
      "Epoch 1816: Train Loss = 0.1701, Test Loss = 1.1438465118408203:.4f\n",
      "Epoch 1817: Train Loss = 0.1466, Test Loss = 1.1494239568710327:.4f\n",
      "Epoch 1818: Train Loss = 0.1385, Test Loss = 1.1362617015838623:.4f\n",
      "Epoch 1819: Train Loss = 0.1798, Test Loss = 1.1253979206085205:.4f\n",
      "Epoch 1820: Train Loss = 0.1476, Test Loss = 1.1086543798446655:.4f\n",
      "Epoch 1821: Train Loss = 0.1618, Test Loss = 1.12673020362854:.4f\n",
      "Epoch 1822: Train Loss = 0.1343, Test Loss = 1.1495972871780396:.4f\n",
      "Epoch 1823: Train Loss = 0.1788, Test Loss = 1.17433500289917:.4f\n",
      "Epoch 1824: Train Loss = 0.1927, Test Loss = 1.1731317043304443:.4f\n",
      "Epoch 1825: Train Loss = 0.1489, Test Loss = 1.1699284315109253:.4f\n",
      "Epoch 1826: Train Loss = 0.1434, Test Loss = 1.1578236818313599:.4f\n",
      "Epoch 1827: Train Loss = 0.1727, Test Loss = 1.1495915651321411:.4f\n",
      "Epoch 1828: Train Loss = 0.1499, Test Loss = 1.1455641984939575:.4f\n",
      "Epoch 1829: Train Loss = 0.1342, Test Loss = 1.1365160942077637:.4f\n",
      "Epoch 1830: Train Loss = 0.1384, Test Loss = 1.1233711242675781:.4f\n",
      "Epoch 1831: Train Loss = 0.1335, Test Loss = 1.1321094036102295:.4f\n",
      "Epoch 1832: Train Loss = 0.1361, Test Loss = 1.14421808719635:.4f\n",
      "Epoch 1833: Train Loss = 0.1482, Test Loss = 1.156969428062439:.4f\n",
      "Epoch 1834: Train Loss = 0.1392, Test Loss = 1.1609951257705688:.4f\n",
      "Epoch 1835: Train Loss = 0.1359, Test Loss = 1.149012565612793:.4f\n",
      "Epoch 1836: Train Loss = 0.1467, Test Loss = 1.1351242065429688:.4f\n",
      "Epoch 1837: Train Loss = 0.1351, Test Loss = 1.1327790021896362:.4f\n",
      "Epoch 1838: Train Loss = 0.1694, Test Loss = 1.124881386756897:.4f\n",
      "Epoch 1839: Train Loss = 0.1401, Test Loss = 1.1248195171356201:.4f\n",
      "Epoch 1840: Train Loss = 0.1669, Test Loss = 1.150425672531128:.4f\n",
      "Epoch 1841: Train Loss = 0.1469, Test Loss = 1.1782360076904297:.4f\n",
      "Epoch 1842: Train Loss = 0.2133, Test Loss = 1.188405156135559:.4f\n",
      "Epoch 1843: Train Loss = 0.1835, Test Loss = 1.15235435962677:.4f\n",
      "Epoch 1844: Train Loss = 0.1322, Test Loss = 1.1424577236175537:.4f\n",
      "Epoch 1845: Train Loss = 0.1700, Test Loss = 1.129716157913208:.4f\n",
      "Epoch 1846: Train Loss = 0.1420, Test Loss = 1.1389713287353516:.4f\n",
      "Epoch 1847: Train Loss = 0.1324, Test Loss = 1.1494433879852295:.4f\n",
      "Epoch 1848: Train Loss = 0.1603, Test Loss = 1.1446846723556519:.4f\n",
      "Epoch 1849: Train Loss = 0.1678, Test Loss = 1.1366896629333496:.4f\n",
      "Epoch 1850: Train Loss = 0.1401, Test Loss = 1.1429102420806885:.4f\n",
      "Epoch 1851: Train Loss = 0.1450, Test Loss = 1.1543574333190918:.4f\n",
      "Epoch 1852: Train Loss = 0.1357, Test Loss = 1.1713364124298096:.4f\n",
      "Epoch 1853: Train Loss = 0.1681, Test Loss = 1.1685878038406372:.4f\n",
      "Epoch 1854: Train Loss = 0.1348, Test Loss = 1.1556980609893799:.4f\n",
      "Epoch 1855: Train Loss = 0.1512, Test Loss = 1.1421928405761719:.4f\n",
      "Epoch 1856: Train Loss = 0.1655, Test Loss = 1.1309263706207275:.4f\n",
      "Epoch 1857: Train Loss = 0.1584, Test Loss = 1.1331686973571777:.4f\n",
      "Epoch 1858: Train Loss = 0.1388, Test Loss = 1.1483343839645386:.4f\n",
      "Epoch 1859: Train Loss = 0.1551, Test Loss = 1.1582446098327637:.4f\n",
      "Epoch 1860: Train Loss = 0.1414, Test Loss = 1.1254609823226929:.4f\n",
      "Epoch 1861: Train Loss = 0.1677, Test Loss = 1.1121256351470947:.4f\n",
      "Epoch 1862: Train Loss = 0.1301, Test Loss = 1.1075541973114014:.4f\n",
      "Epoch 1863: Train Loss = 0.1417, Test Loss = 1.117803931236267:.4f\n",
      "Epoch 1864: Train Loss = 0.1566, Test Loss = 1.1268932819366455:.4f\n",
      "Epoch 1865: Train Loss = 0.1443, Test Loss = 1.144153356552124:.4f\n",
      "Epoch 1866: Train Loss = 0.1631, Test Loss = 1.1628221273422241:.4f\n",
      "Epoch 1867: Train Loss = 0.1444, Test Loss = 1.169090986251831:.4f\n",
      "Epoch 1868: Train Loss = 0.1449, Test Loss = 1.1778285503387451:.4f\n",
      "Epoch 1869: Train Loss = 0.1503, Test Loss = 1.1562104225158691:.4f\n",
      "Epoch 1870: Train Loss = 0.1555, Test Loss = 1.1150401830673218:.4f\n",
      "Epoch 1871: Train Loss = 0.1454, Test Loss = 1.0933010578155518:.4f\n",
      "Epoch 1872: Train Loss = 0.1638, Test Loss = 1.1041251420974731:.4f\n",
      "Epoch 1873: Train Loss = 0.1508, Test Loss = 1.147627592086792:.4f\n",
      "Epoch 1874: Train Loss = 0.2040, Test Loss = 1.1709914207458496:.4f\n",
      "Epoch 1875: Train Loss = 0.1382, Test Loss = 1.1617714166641235:.4f\n",
      "Epoch 1876: Train Loss = 0.1421, Test Loss = 1.164223074913025:.4f\n",
      "Epoch 1877: Train Loss = 0.1456, Test Loss = 1.1517757177352905:.4f\n",
      "Epoch 1878: Train Loss = 0.1414, Test Loss = 1.1555452346801758:.4f\n",
      "Epoch 1879: Train Loss = 0.1670, Test Loss = 1.1296377182006836:.4f\n",
      "Epoch 1880: Train Loss = 0.1500, Test Loss = 1.1146172285079956:.4f\n",
      "Epoch 1881: Train Loss = 0.1784, Test Loss = 1.1178709268569946:.4f\n",
      "Epoch 1882: Train Loss = 0.1337, Test Loss = 1.145310878753662:.4f\n",
      "Epoch 1883: Train Loss = 0.1643, Test Loss = 1.1800663471221924:.4f\n",
      "Epoch 1884: Train Loss = 0.1400, Test Loss = 1.182294487953186:.4f\n",
      "Epoch 1885: Train Loss = 0.1575, Test Loss = 1.1723755598068237:.4f\n",
      "Epoch 1886: Train Loss = 0.1664, Test Loss = 1.1496219635009766:.4f\n",
      "Epoch 1887: Train Loss = 0.1743, Test Loss = 1.1345585584640503:.4f\n",
      "Epoch 1888: Train Loss = 0.1378, Test Loss = 1.1421289443969727:.4f\n",
      "Epoch 1889: Train Loss = 0.1438, Test Loss = 1.1491734981536865:.4f\n",
      "Epoch 1890: Train Loss = 0.1806, Test Loss = 1.1212224960327148:.4f\n",
      "Epoch 1891: Train Loss = 0.1556, Test Loss = 1.1175286769866943:.4f\n",
      "Epoch 1892: Train Loss = 0.1569, Test Loss = 1.1340844631195068:.4f\n",
      "Epoch 1893: Train Loss = 0.1435, Test Loss = 1.162511944770813:.4f\n",
      "Epoch 1894: Train Loss = 0.1551, Test Loss = 1.1792151927947998:.4f\n",
      "Epoch 1895: Train Loss = 0.1581, Test Loss = 1.1776398420333862:.4f\n",
      "Epoch 1896: Train Loss = 0.1295, Test Loss = 1.1571877002716064:.4f\n",
      "Epoch 1897: Train Loss = 0.1502, Test Loss = 1.1429412364959717:.4f\n",
      "Epoch 1898: Train Loss = 0.1544, Test Loss = 1.1228748559951782:.4f\n",
      "Epoch 1899: Train Loss = 0.1514, Test Loss = 1.1249312162399292:.4f\n",
      "Epoch 1900: Train Loss = 0.1442, Test Loss = 1.1318193674087524:.4f\n",
      "Epoch 1901: Train Loss = 0.1624, Test Loss = 1.1272324323654175:.4f\n",
      "Epoch 1902: Train Loss = 0.1414, Test Loss = 1.1364006996154785:.4f\n",
      "Epoch 1903: Train Loss = 0.1904, Test Loss = 1.1467403173446655:.4f\n",
      "Epoch 1904: Train Loss = 0.1403, Test Loss = 1.1628265380859375:.4f\n",
      "Epoch 1905: Train Loss = 0.1643, Test Loss = 1.1586774587631226:.4f\n",
      "Epoch 1906: Train Loss = 0.1274, Test Loss = 1.1422687768936157:.4f\n",
      "Epoch 1907: Train Loss = 0.1359, Test Loss = 1.1271944046020508:.4f\n",
      "Epoch 1908: Train Loss = 0.1941, Test Loss = 1.1357825994491577:.4f\n",
      "Epoch 1909: Train Loss = 0.1480, Test Loss = 1.1646124124526978:.4f\n",
      "Epoch 1910: Train Loss = 0.1484, Test Loss = 1.1745446920394897:.4f\n",
      "Epoch 1911: Train Loss = 0.1544, Test Loss = 1.177927851676941:.4f\n",
      "Epoch 1912: Train Loss = 0.1898, Test Loss = 1.1612756252288818:.4f\n",
      "Epoch 1913: Train Loss = 0.1801, Test Loss = 1.1453253030776978:.4f\n",
      "Epoch 1914: Train Loss = 0.1405, Test Loss = 1.140845537185669:.4f\n",
      "Epoch 1915: Train Loss = 0.1397, Test Loss = 1.1383119821548462:.4f\n",
      "Epoch 1916: Train Loss = 0.1419, Test Loss = 1.1401036977767944:.4f\n",
      "Epoch 1917: Train Loss = 0.1427, Test Loss = 1.1419975757598877:.4f\n",
      "Epoch 1918: Train Loss = 0.1728, Test Loss = 1.1499412059783936:.4f\n",
      "Epoch 1919: Train Loss = 0.1374, Test Loss = 1.1428812742233276:.4f\n",
      "Epoch 1920: Train Loss = 0.1667, Test Loss = 1.1455401182174683:.4f\n",
      "Epoch 1921: Train Loss = 0.1401, Test Loss = 1.154821753501892:.4f\n",
      "Epoch 1922: Train Loss = 0.1436, Test Loss = 1.149057149887085:.4f\n",
      "Epoch 1923: Train Loss = 0.1651, Test Loss = 1.1528387069702148:.4f\n",
      "Epoch 1924: Train Loss = 0.2007, Test Loss = 1.158246636390686:.4f\n",
      "Epoch 1925: Train Loss = 0.1780, Test Loss = 1.146497368812561:.4f\n",
      "Epoch 1926: Train Loss = 0.1513, Test Loss = 1.162833571434021:.4f\n",
      "Epoch 1927: Train Loss = 0.1364, Test Loss = 1.1710532903671265:.4f\n",
      "Epoch 1928: Train Loss = 0.1578, Test Loss = 1.170229196548462:.4f\n",
      "Epoch 1929: Train Loss = 0.1491, Test Loss = 1.1512482166290283:.4f\n",
      "Epoch 1930: Train Loss = 0.1640, Test Loss = 1.136584997177124:.4f\n",
      "Epoch 1931: Train Loss = 0.1361, Test Loss = 1.1284698247909546:.4f\n",
      "Epoch 1932: Train Loss = 0.1347, Test Loss = 1.1310981512069702:.4f\n",
      "Epoch 1933: Train Loss = 0.1789, Test Loss = 1.1407039165496826:.4f\n",
      "Epoch 1934: Train Loss = 0.1758, Test Loss = 1.1532742977142334:.4f\n",
      "Epoch 1935: Train Loss = 0.1386, Test Loss = 1.149738073348999:.4f\n",
      "Epoch 1936: Train Loss = 0.1376, Test Loss = 1.1528780460357666:.4f\n",
      "Epoch 1937: Train Loss = 0.1664, Test Loss = 1.1416003704071045:.4f\n",
      "Epoch 1938: Train Loss = 0.1409, Test Loss = 1.1496706008911133:.4f\n",
      "Epoch 1939: Train Loss = 0.1680, Test Loss = 1.1624852418899536:.4f\n",
      "Epoch 1940: Train Loss = 0.1371, Test Loss = 1.1654173135757446:.4f\n",
      "Epoch 1941: Train Loss = 0.1731, Test Loss = 1.1596745252609253:.4f\n",
      "Epoch 1942: Train Loss = 0.1730, Test Loss = 1.1632204055786133:.4f\n",
      "Epoch 1943: Train Loss = 0.1814, Test Loss = 1.1715081930160522:.4f\n",
      "Epoch 1944: Train Loss = 0.1329, Test Loss = 1.1639937162399292:.4f\n",
      "Epoch 1945: Train Loss = 0.1281, Test Loss = 1.1526353359222412:.4f\n",
      "Epoch 1946: Train Loss = 0.1378, Test Loss = 1.1290465593338013:.4f\n",
      "Epoch 1947: Train Loss = 0.1712, Test Loss = 1.112657904624939:.4f\n",
      "Epoch 1948: Train Loss = 0.1615, Test Loss = 1.1176944971084595:.4f\n",
      "Epoch 1949: Train Loss = 0.1715, Test Loss = 1.1307333707809448:.4f\n",
      "Epoch 1950: Train Loss = 0.1301, Test Loss = 1.1537654399871826:.4f\n",
      "Epoch 1951: Train Loss = 0.1421, Test Loss = 1.1736546754837036:.4f\n",
      "Epoch 1952: Train Loss = 0.1287, Test Loss = 1.1730817556381226:.4f\n",
      "Epoch 1953: Train Loss = 0.1450, Test Loss = 1.1713236570358276:.4f\n",
      "Epoch 1954: Train Loss = 0.1377, Test Loss = 1.1598321199417114:.4f\n",
      "Epoch 1955: Train Loss = 0.1485, Test Loss = 1.1429588794708252:.4f\n",
      "Epoch 1956: Train Loss = 0.1640, Test Loss = 1.1376979351043701:.4f\n",
      "Epoch 1957: Train Loss = 0.1439, Test Loss = 1.1444964408874512:.4f\n",
      "Epoch 1958: Train Loss = 0.1794, Test Loss = 1.1505074501037598:.4f\n",
      "Epoch 1959: Train Loss = 0.1496, Test Loss = 1.161895751953125:.4f\n",
      "Epoch 1960: Train Loss = 0.1891, Test Loss = 1.1714622974395752:.4f\n",
      "Epoch 1961: Train Loss = 0.1575, Test Loss = 1.166812539100647:.4f\n",
      "Epoch 1962: Train Loss = 0.1349, Test Loss = 1.1599700450897217:.4f\n",
      "Epoch 1963: Train Loss = 0.1336, Test Loss = 1.1545474529266357:.4f\n",
      "Epoch 1964: Train Loss = 0.1325, Test Loss = 1.1447923183441162:.4f\n",
      "Epoch 1965: Train Loss = 0.1510, Test Loss = 1.146129846572876:.4f\n",
      "Epoch 1966: Train Loss = 0.1532, Test Loss = 1.1452820301055908:.4f\n",
      "Epoch 1967: Train Loss = 0.1427, Test Loss = 1.1462254524230957:.4f\n",
      "Epoch 1968: Train Loss = 0.1508, Test Loss = 1.1615530252456665:.4f\n",
      "Epoch 1969: Train Loss = 0.1312, Test Loss = 1.1717216968536377:.4f\n",
      "Epoch 1970: Train Loss = 0.1660, Test Loss = 1.168052077293396:.4f\n",
      "Epoch 1971: Train Loss = 0.1501, Test Loss = 1.16608464717865:.4f\n",
      "Epoch 1972: Train Loss = 0.1446, Test Loss = 1.1526734828948975:.4f\n",
      "Epoch 1973: Train Loss = 0.1704, Test Loss = 1.162819266319275:.4f\n",
      "Epoch 1974: Train Loss = 0.1428, Test Loss = 1.1664817333221436:.4f\n",
      "Epoch 1975: Train Loss = 0.1502, Test Loss = 1.158926248550415:.4f\n",
      "Epoch 1976: Train Loss = 0.1644, Test Loss = 1.1523805856704712:.4f\n",
      "Epoch 1977: Train Loss = 0.1526, Test Loss = 1.1452597379684448:.4f\n",
      "Epoch 1978: Train Loss = 0.1575, Test Loss = 1.1426060199737549:.4f\n",
      "Epoch 1979: Train Loss = 0.1713, Test Loss = 1.1512749195098877:.4f\n",
      "Epoch 1980: Train Loss = 0.1680, Test Loss = 1.1664659976959229:.4f\n",
      "Epoch 1981: Train Loss = 0.1997, Test Loss = 1.1678141355514526:.4f\n",
      "Epoch 1982: Train Loss = 0.1758, Test Loss = 1.176236867904663:.4f\n",
      "Epoch 1983: Train Loss = 0.1568, Test Loss = 1.196250319480896:.4f\n",
      "Epoch 1984: Train Loss = 0.1515, Test Loss = 1.20228111743927:.4f\n",
      "Epoch 1985: Train Loss = 0.1547, Test Loss = 1.2074387073516846:.4f\n",
      "Epoch 1986: Train Loss = 0.1517, Test Loss = 1.1878265142440796:.4f\n",
      "Epoch 1987: Train Loss = 0.1412, Test Loss = 1.154441237449646:.4f\n",
      "Epoch 1988: Train Loss = 0.1349, Test Loss = 1.1254003047943115:.4f\n",
      "Epoch 1989: Train Loss = 0.1521, Test Loss = 1.1136608123779297:.4f\n",
      "Epoch 1990: Train Loss = 0.1470, Test Loss = 1.1431037187576294:.4f\n",
      "Epoch 1991: Train Loss = 0.1317, Test Loss = 1.1866531372070312:.4f\n",
      "Epoch 1992: Train Loss = 0.1333, Test Loss = 1.203161597251892:.4f\n",
      "Epoch 1993: Train Loss = 0.1373, Test Loss = 1.1995576620101929:.4f\n",
      "Epoch 1994: Train Loss = 0.1292, Test Loss = 1.1762157678604126:.4f\n",
      "Epoch 1995: Train Loss = 0.1454, Test Loss = 1.157847285270691:.4f\n",
      "Epoch 1996: Train Loss = 0.1909, Test Loss = 1.1505732536315918:.4f\n",
      "Epoch 1997: Train Loss = 0.1443, Test Loss = 1.156641960144043:.4f\n",
      "Epoch 1998: Train Loss = 0.1864, Test Loss = 1.160320520401001:.4f\n",
      "Epoch 1999: Train Loss = 0.1654, Test Loss = 1.1673057079315186:.4f\n",
      "Epoch 2000: Train Loss = 0.1339, Test Loss = 1.1829763650894165:.4f\n",
      "Epoch 2001: Train Loss = 0.1802, Test Loss = 1.1796022653579712:.4f\n",
      "Epoch 2002: Train Loss = 0.1899, Test Loss = 1.1757447719573975:.4f\n",
      "Epoch 2003: Train Loss = 0.1839, Test Loss = 1.1629767417907715:.4f\n",
      "Epoch 2004: Train Loss = 0.1478, Test Loss = 1.1669262647628784:.4f\n",
      "Epoch 2005: Train Loss = 0.1710, Test Loss = 1.1745539903640747:.4f\n",
      "Epoch 2006: Train Loss = 0.1426, Test Loss = 1.1677558422088623:.4f\n",
      "Epoch 2007: Train Loss = 0.1412, Test Loss = 1.1718738079071045:.4f\n",
      "Epoch 2008: Train Loss = 0.1436, Test Loss = 1.1743422746658325:.4f\n",
      "Epoch 2009: Train Loss = 0.1520, Test Loss = 1.170661211013794:.4f\n",
      "Epoch 2010: Train Loss = 0.1346, Test Loss = 1.1805638074874878:.4f\n",
      "Epoch 2011: Train Loss = 0.1252, Test Loss = 1.1760437488555908:.4f\n",
      "Epoch 2012: Train Loss = 0.1434, Test Loss = 1.1743119955062866:.4f\n",
      "Epoch 2013: Train Loss = 0.1747, Test Loss = 1.1728073358535767:.4f\n",
      "Epoch 2014: Train Loss = 0.1635, Test Loss = 1.1705623865127563:.4f\n",
      "Epoch 2015: Train Loss = 0.1303, Test Loss = 1.1710631847381592:.4f\n",
      "Epoch 2016: Train Loss = 0.1634, Test Loss = 1.1665633916854858:.4f\n",
      "Epoch 2017: Train Loss = 0.1509, Test Loss = 1.1655720472335815:.4f\n",
      "Epoch 2018: Train Loss = 0.1434, Test Loss = 1.17706298828125:.4f\n",
      "Epoch 2019: Train Loss = 0.1404, Test Loss = 1.1841652393341064:.4f\n",
      "Epoch 2020: Train Loss = 0.1275, Test Loss = 1.174742579460144:.4f\n",
      "Epoch 2021: Train Loss = 0.1642, Test Loss = 1.1571522951126099:.4f\n",
      "Epoch 2022: Train Loss = 0.1430, Test Loss = 1.1584277153015137:.4f\n",
      "Epoch 2023: Train Loss = 0.1483, Test Loss = 1.1503459215164185:.4f\n",
      "Epoch 2024: Train Loss = 0.1425, Test Loss = 1.1642372608184814:.4f\n",
      "Epoch 2025: Train Loss = 0.1499, Test Loss = 1.1662613153457642:.4f\n",
      "Epoch 2026: Train Loss = 0.1596, Test Loss = 1.1595838069915771:.4f\n",
      "Epoch 2027: Train Loss = 0.1271, Test Loss = 1.1692979335784912:.4f\n",
      "Epoch 2028: Train Loss = 0.1443, Test Loss = 1.1720298528671265:.4f\n",
      "Epoch 2029: Train Loss = 0.1368, Test Loss = 1.1817710399627686:.4f\n",
      "Epoch 2030: Train Loss = 0.1346, Test Loss = 1.181976556777954:.4f\n",
      "Epoch 2031: Train Loss = 0.1425, Test Loss = 1.1783132553100586:.4f\n",
      "Epoch 2032: Train Loss = 0.1413, Test Loss = 1.1646039485931396:.4f\n",
      "Epoch 2033: Train Loss = 0.1752, Test Loss = 1.1520508527755737:.4f\n",
      "Epoch 2034: Train Loss = 0.1653, Test Loss = 1.140832543373108:.4f\n",
      "Epoch 2035: Train Loss = 0.1767, Test Loss = 1.1493288278579712:.4f\n",
      "Epoch 2036: Train Loss = 0.1917, Test Loss = 1.165718913078308:.4f\n",
      "Epoch 2037: Train Loss = 0.1448, Test Loss = 1.1531972885131836:.4f\n",
      "Epoch 2038: Train Loss = 0.1355, Test Loss = 1.1669784784317017:.4f\n",
      "Epoch 2039: Train Loss = 0.1627, Test Loss = 1.180249571800232:.4f\n",
      "Epoch 2040: Train Loss = 0.1768, Test Loss = 1.2004553079605103:.4f\n",
      "Epoch 2041: Train Loss = 0.2115, Test Loss = 1.1877902746200562:.4f\n",
      "Epoch 2042: Train Loss = 0.1457, Test Loss = 1.1694910526275635:.4f\n",
      "Epoch 2043: Train Loss = 0.1745, Test Loss = 1.1659791469573975:.4f\n",
      "Epoch 2044: Train Loss = 0.1404, Test Loss = 1.1677825450897217:.4f\n",
      "Epoch 2045: Train Loss = 0.1282, Test Loss = 1.1685826778411865:.4f\n",
      "Epoch 2046: Train Loss = 0.1458, Test Loss = 1.163037896156311:.4f\n",
      "Epoch 2047: Train Loss = 0.1815, Test Loss = 1.1579126119613647:.4f\n",
      "Epoch 2048: Train Loss = 0.1451, Test Loss = 1.149107575416565:.4f\n",
      "Epoch 2049: Train Loss = 0.1389, Test Loss = 1.1670417785644531:.4f\n",
      "Epoch 2050: Train Loss = 0.1458, Test Loss = 1.1736737489700317:.4f\n",
      "Epoch 2051: Train Loss = 0.1260, Test Loss = 1.1768779754638672:.4f\n",
      "Epoch 2052: Train Loss = 0.1451, Test Loss = 1.1682868003845215:.4f\n",
      "Epoch 2053: Train Loss = 0.1881, Test Loss = 1.1635568141937256:.4f\n",
      "Epoch 2054: Train Loss = 0.1534, Test Loss = 1.151092290878296:.4f\n",
      "Epoch 2055: Train Loss = 0.1817, Test Loss = 1.1510456800460815:.4f\n",
      "Epoch 2056: Train Loss = 0.1481, Test Loss = 1.1627840995788574:.4f\n",
      "Epoch 2057: Train Loss = 0.1254, Test Loss = 1.180938959121704:.4f\n",
      "Epoch 2058: Train Loss = 0.1432, Test Loss = 1.1769108772277832:.4f\n",
      "Epoch 2059: Train Loss = 0.1416, Test Loss = 1.170877456665039:.4f\n",
      "Epoch 2060: Train Loss = 0.1491, Test Loss = 1.1544997692108154:.4f\n",
      "Epoch 2061: Train Loss = 0.1774, Test Loss = 1.1575839519500732:.4f\n",
      "Epoch 2062: Train Loss = 0.1317, Test Loss = 1.1521580219268799:.4f\n",
      "Epoch 2063: Train Loss = 0.1602, Test Loss = 1.156520962715149:.4f\n",
      "Epoch 2064: Train Loss = 0.1475, Test Loss = 1.1650712490081787:.4f\n",
      "Epoch 2065: Train Loss = 0.1719, Test Loss = 1.1719987392425537:.4f\n",
      "Epoch 2066: Train Loss = 0.1439, Test Loss = 1.1689536571502686:.4f\n",
      "Epoch 2067: Train Loss = 0.1580, Test Loss = 1.166307806968689:.4f\n",
      "Epoch 2068: Train Loss = 0.1441, Test Loss = 1.169837236404419:.4f\n",
      "Epoch 2069: Train Loss = 0.1524, Test Loss = 1.1490507125854492:.4f\n",
      "Epoch 2070: Train Loss = 0.1654, Test Loss = 1.1408445835113525:.4f\n",
      "Epoch 2071: Train Loss = 0.1397, Test Loss = 1.151699423789978:.4f\n",
      "Epoch 2072: Train Loss = 0.1526, Test Loss = 1.1844055652618408:.4f\n",
      "Epoch 2073: Train Loss = 0.1534, Test Loss = 1.2079575061798096:.4f\n",
      "Epoch 2074: Train Loss = 0.1425, Test Loss = 1.1994783878326416:.4f\n",
      "Epoch 2075: Train Loss = 0.1470, Test Loss = 1.1762174367904663:.4f\n",
      "Epoch 2076: Train Loss = 0.1305, Test Loss = 1.1490412950515747:.4f\n",
      "Epoch 2077: Train Loss = 0.1419, Test Loss = 1.143929362297058:.4f\n",
      "Epoch 2078: Train Loss = 0.1365, Test Loss = 1.1497195959091187:.4f\n",
      "Epoch 2079: Train Loss = 0.1979, Test Loss = 1.1556953191757202:.4f\n",
      "Epoch 2080: Train Loss = 0.1398, Test Loss = 1.1580250263214111:.4f\n",
      "Epoch 2081: Train Loss = 0.1330, Test Loss = 1.1673582792282104:.4f\n",
      "Epoch 2082: Train Loss = 0.1461, Test Loss = 1.1673698425292969:.4f\n",
      "Epoch 2083: Train Loss = 0.1273, Test Loss = 1.157027006149292:.4f\n",
      "Epoch 2084: Train Loss = 0.1371, Test Loss = 1.1557974815368652:.4f\n",
      "Epoch 2085: Train Loss = 0.1775, Test Loss = 1.1597195863723755:.4f\n",
      "Epoch 2086: Train Loss = 0.1336, Test Loss = 1.1586190462112427:.4f\n",
      "Epoch 2087: Train Loss = 0.1816, Test Loss = 1.1529406309127808:.4f\n",
      "Epoch 2088: Train Loss = 0.1415, Test Loss = 1.1665406227111816:.4f\n",
      "Epoch 2089: Train Loss = 0.1489, Test Loss = 1.183896541595459:.4f\n",
      "Epoch 2090: Train Loss = 0.1334, Test Loss = 1.1858140230178833:.4f\n",
      "Epoch 2091: Train Loss = 0.1435, Test Loss = 1.1713905334472656:.4f\n",
      "Epoch 2092: Train Loss = 0.1261, Test Loss = 1.1499983072280884:.4f\n",
      "Epoch 2093: Train Loss = 0.1676, Test Loss = 1.1462310552597046:.4f\n",
      "Epoch 2094: Train Loss = 0.1458, Test Loss = 1.1526222229003906:.4f\n",
      "Epoch 2095: Train Loss = 0.1658, Test Loss = 1.1695529222488403:.4f\n",
      "Epoch 2096: Train Loss = 0.1614, Test Loss = 1.1793110370635986:.4f\n",
      "Epoch 2097: Train Loss = 0.1383, Test Loss = 1.1718213558197021:.4f\n",
      "Epoch 2098: Train Loss = 0.1444, Test Loss = 1.1620838642120361:.4f\n",
      "Epoch 2099: Train Loss = 0.1546, Test Loss = 1.1540371179580688:.4f\n",
      "Epoch 2100: Train Loss = 0.1920, Test Loss = 1.1419932842254639:.4f\n",
      "Epoch 2101: Train Loss = 0.1451, Test Loss = 1.1412700414657593:.4f\n",
      "Epoch 2102: Train Loss = 0.1681, Test Loss = 1.1623502969741821:.4f\n",
      "Epoch 2103: Train Loss = 0.1628, Test Loss = 1.173789381980896:.4f\n",
      "Epoch 2104: Train Loss = 0.1420, Test Loss = 1.168001413345337:.4f\n",
      "Epoch 2105: Train Loss = 0.1338, Test Loss = 1.1603420972824097:.4f\n",
      "Epoch 2106: Train Loss = 0.1359, Test Loss = 1.1416583061218262:.4f\n",
      "Epoch 2107: Train Loss = 0.1734, Test Loss = 1.1353026628494263:.4f\n",
      "Epoch 2108: Train Loss = 0.1339, Test Loss = 1.1412079334259033:.4f\n",
      "Epoch 2109: Train Loss = 0.1361, Test Loss = 1.1456842422485352:.4f\n",
      "Epoch 2110: Train Loss = 0.1435, Test Loss = 1.159247875213623:.4f\n",
      "Epoch 2111: Train Loss = 0.1622, Test Loss = 1.1767003536224365:.4f\n",
      "Epoch 2112: Train Loss = 0.1468, Test Loss = 1.1805453300476074:.4f\n",
      "Epoch 2113: Train Loss = 0.1961, Test Loss = 1.1517655849456787:.4f\n",
      "Epoch 2114: Train Loss = 0.1630, Test Loss = 1.1474642753601074:.4f\n",
      "Epoch 2115: Train Loss = 0.1731, Test Loss = 1.1700998544692993:.4f\n",
      "Epoch 2116: Train Loss = 0.1702, Test Loss = 1.1764216423034668:.4f\n",
      "Epoch 2117: Train Loss = 0.1221, Test Loss = 1.1938573122024536:.4f\n",
      "Epoch 2118: Train Loss = 0.1737, Test Loss = 1.1889746189117432:.4f\n",
      "Epoch 2119: Train Loss = 0.1920, Test Loss = 1.1583186388015747:.4f\n",
      "Epoch 2120: Train Loss = 0.1590, Test Loss = 1.1577403545379639:.4f\n",
      "Epoch 2121: Train Loss = 0.1345, Test Loss = 1.1789380311965942:.4f\n",
      "Epoch 2122: Train Loss = 0.1668, Test Loss = 1.1861958503723145:.4f\n",
      "Epoch 2123: Train Loss = 0.1463, Test Loss = 1.1918988227844238:.4f\n",
      "Epoch 2124: Train Loss = 0.1336, Test Loss = 1.1831340789794922:.4f\n",
      "Epoch 2125: Train Loss = 0.1271, Test Loss = 1.1633049249649048:.4f\n",
      "Epoch 2126: Train Loss = 0.1502, Test Loss = 1.1416651010513306:.4f\n",
      "Epoch 2127: Train Loss = 0.1283, Test Loss = 1.1396468877792358:.4f\n",
      "Epoch 2128: Train Loss = 0.1372, Test Loss = 1.1519371271133423:.4f\n",
      "Epoch 2129: Train Loss = 0.1624, Test Loss = 1.1508431434631348:.4f\n",
      "Epoch 2130: Train Loss = 0.1664, Test Loss = 1.1596145629882812:.4f\n",
      "Epoch 2131: Train Loss = 0.1476, Test Loss = 1.1594473123550415:.4f\n",
      "Epoch 2132: Train Loss = 0.1388, Test Loss = 1.1609421968460083:.4f\n",
      "Epoch 2133: Train Loss = 0.1457, Test Loss = 1.153559923171997:.4f\n",
      "Epoch 2134: Train Loss = 0.1490, Test Loss = 1.1519346237182617:.4f\n",
      "Epoch 2135: Train Loss = 0.1308, Test Loss = 1.1483145952224731:.4f\n",
      "Epoch 2136: Train Loss = 0.1550, Test Loss = 1.1447206735610962:.4f\n",
      "Epoch 2137: Train Loss = 0.1430, Test Loss = 1.1644177436828613:.4f\n",
      "Epoch 2138: Train Loss = 0.1624, Test Loss = 1.1665668487548828:.4f\n",
      "Epoch 2139: Train Loss = 0.1709, Test Loss = 1.173302412033081:.4f\n",
      "Epoch 2140: Train Loss = 0.1824, Test Loss = 1.170432686805725:.4f\n",
      "Epoch 2141: Train Loss = 0.1646, Test Loss = 1.1693708896636963:.4f\n",
      "Epoch 2142: Train Loss = 0.1726, Test Loss = 1.1782370805740356:.4f\n",
      "Epoch 2143: Train Loss = 0.1556, Test Loss = 1.1741793155670166:.4f\n",
      "Epoch 2144: Train Loss = 0.1614, Test Loss = 1.1456001996994019:.4f\n",
      "Epoch 2145: Train Loss = 0.1553, Test Loss = 1.134173035621643:.4f\n",
      "Epoch 2146: Train Loss = 0.1338, Test Loss = 1.1350953578948975:.4f\n",
      "Epoch 2147: Train Loss = 0.1647, Test Loss = 1.1416363716125488:.4f\n",
      "Epoch 2148: Train Loss = 0.1323, Test Loss = 1.1524723768234253:.4f\n",
      "Epoch 2149: Train Loss = 0.1460, Test Loss = 1.156696081161499:.4f\n",
      "Epoch 2150: Train Loss = 0.1700, Test Loss = 1.1612298488616943:.4f\n",
      "Epoch 2151: Train Loss = 0.1399, Test Loss = 1.15384840965271:.4f\n",
      "Epoch 2152: Train Loss = 0.1303, Test Loss = 1.1528664827346802:.4f\n",
      "Epoch 2153: Train Loss = 0.1482, Test Loss = 1.147559404373169:.4f\n",
      "Epoch 2154: Train Loss = 0.1582, Test Loss = 1.1412922143936157:.4f\n",
      "Epoch 2155: Train Loss = 0.1468, Test Loss = 1.1536999940872192:.4f\n",
      "Epoch 2156: Train Loss = 0.1431, Test Loss = 1.1545937061309814:.4f\n",
      "Epoch 2157: Train Loss = 0.1421, Test Loss = 1.164185643196106:.4f\n",
      "Epoch 2158: Train Loss = 0.1456, Test Loss = 1.1572632789611816:.4f\n",
      "Epoch 2159: Train Loss = 0.1253, Test Loss = 1.1491702795028687:.4f\n",
      "Epoch 2160: Train Loss = 0.1332, Test Loss = 1.133088231086731:.4f\n",
      "Epoch 2161: Train Loss = 0.1358, Test Loss = 1.138906717300415:.4f\n",
      "Epoch 2162: Train Loss = 0.1697, Test Loss = 1.1421018838882446:.4f\n",
      "Epoch 2163: Train Loss = 0.1783, Test Loss = 1.1390020847320557:.4f\n",
      "Epoch 2164: Train Loss = 0.1454, Test Loss = 1.1459236145019531:.4f\n",
      "Epoch 2165: Train Loss = 0.1422, Test Loss = 1.132995843887329:.4f\n",
      "Epoch 2166: Train Loss = 0.1376, Test Loss = 1.1209304332733154:.4f\n",
      "Epoch 2167: Train Loss = 0.1587, Test Loss = 1.1067111492156982:.4f\n",
      "Epoch 2168: Train Loss = 0.1434, Test Loss = 1.1178287267684937:.4f\n",
      "Epoch 2169: Train Loss = 0.1446, Test Loss = 1.1290123462677002:.4f\n",
      "Epoch 2170: Train Loss = 0.1593, Test Loss = 1.1512846946716309:.4f\n",
      "Epoch 2171: Train Loss = 0.1386, Test Loss = 1.1734516620635986:.4f\n",
      "Epoch 2172: Train Loss = 0.1865, Test Loss = 1.1790543794631958:.4f\n",
      "Epoch 2173: Train Loss = 0.1466, Test Loss = 1.1598765850067139:.4f\n",
      "Epoch 2174: Train Loss = 0.1489, Test Loss = 1.133867859840393:.4f\n",
      "Epoch 2175: Train Loss = 0.1425, Test Loss = 1.126755714416504:.4f\n",
      "Epoch 2176: Train Loss = 0.1856, Test Loss = 1.1317850351333618:.4f\n",
      "Epoch 2177: Train Loss = 0.1290, Test Loss = 1.1468393802642822:.4f\n",
      "Epoch 2178: Train Loss = 0.1443, Test Loss = 1.1567046642303467:.4f\n",
      "Epoch 2179: Train Loss = 0.1362, Test Loss = 1.1458425521850586:.4f\n",
      "Epoch 2180: Train Loss = 0.1358, Test Loss = 1.1383955478668213:.4f\n",
      "Epoch 2181: Train Loss = 0.1617, Test Loss = 1.1209536790847778:.4f\n",
      "Epoch 2182: Train Loss = 0.1429, Test Loss = 1.1127564907073975:.4f\n",
      "Epoch 2183: Train Loss = 0.1547, Test Loss = 1.1119215488433838:.4f\n",
      "Epoch 2184: Train Loss = 0.1512, Test Loss = 1.1198142766952515:.4f\n",
      "Epoch 2185: Train Loss = 0.1406, Test Loss = 1.1404839754104614:.4f\n",
      "Epoch 2186: Train Loss = 0.1404, Test Loss = 1.160543441772461:.4f\n",
      "Epoch 2187: Train Loss = 0.1445, Test Loss = 1.1634612083435059:.4f\n",
      "Epoch 2188: Train Loss = 0.1257, Test Loss = 1.1465178728103638:.4f\n",
      "Epoch 2189: Train Loss = 0.1285, Test Loss = 1.128481388092041:.4f\n",
      "Epoch 2190: Train Loss = 0.1355, Test Loss = 1.1111913919448853:.4f\n",
      "Epoch 2191: Train Loss = 0.1482, Test Loss = 1.1176100969314575:.4f\n",
      "Epoch 2192: Train Loss = 0.1359, Test Loss = 1.1289527416229248:.4f\n",
      "Epoch 2193: Train Loss = 0.1659, Test Loss = 1.1522921323776245:.4f\n",
      "Epoch 2194: Train Loss = 0.1492, Test Loss = 1.1668379306793213:.4f\n",
      "Epoch 2195: Train Loss = 0.1291, Test Loss = 1.1606559753417969:.4f\n",
      "Epoch 2196: Train Loss = 0.1397, Test Loss = 1.1433131694793701:.4f\n",
      "Epoch 2197: Train Loss = 0.1379, Test Loss = 1.112732172012329:.4f\n",
      "Epoch 2198: Train Loss = 0.1475, Test Loss = 1.088194727897644:.4f\n",
      "Epoch 2199: Train Loss = 0.1551, Test Loss = 1.1018859148025513:.4f\n",
      "Epoch 2200: Train Loss = 0.1976, Test Loss = 1.1312379837036133:.4f\n",
      "Epoch 2201: Train Loss = 0.1418, Test Loss = 1.1199358701705933:.4f\n",
      "Epoch 2202: Train Loss = 0.1307, Test Loss = 1.125357985496521:.4f\n",
      "Epoch 2203: Train Loss = 0.1276, Test Loss = 1.1332429647445679:.4f\n",
      "Epoch 2204: Train Loss = 0.1330, Test Loss = 1.1451810598373413:.4f\n",
      "Epoch 2205: Train Loss = 0.1552, Test Loss = 1.1482433080673218:.4f\n",
      "Epoch 2206: Train Loss = 0.1382, Test Loss = 1.136960744857788:.4f\n",
      "Epoch 2207: Train Loss = 0.1373, Test Loss = 1.1080148220062256:.4f\n",
      "Epoch 2208: Train Loss = 0.1357, Test Loss = 1.0929663181304932:.4f\n",
      "Epoch 2209: Train Loss = 0.1542, Test Loss = 1.1079963445663452:.4f\n",
      "Epoch 2210: Train Loss = 0.1534, Test Loss = 1.1291887760162354:.4f\n",
      "Epoch 2211: Train Loss = 0.1784, Test Loss = 1.1516664028167725:.4f\n",
      "Epoch 2212: Train Loss = 0.1485, Test Loss = 1.1519826650619507:.4f\n",
      "Epoch 2213: Train Loss = 0.1550, Test Loss = 1.1389367580413818:.4f\n",
      "Epoch 2214: Train Loss = 0.1616, Test Loss = 1.1320245265960693:.4f\n",
      "Epoch 2215: Train Loss = 0.1453, Test Loss = 1.1305650472640991:.4f\n",
      "Epoch 2216: Train Loss = 0.1426, Test Loss = 1.1265838146209717:.4f\n",
      "Epoch 2217: Train Loss = 0.1438, Test Loss = 1.1194145679473877:.4f\n",
      "Epoch 2218: Train Loss = 0.1486, Test Loss = 1.1019554138183594:.4f\n",
      "Epoch 2219: Train Loss = 0.1411, Test Loss = 1.0982578992843628:.4f\n",
      "Epoch 2220: Train Loss = 0.1546, Test Loss = 1.1051548719406128:.4f\n",
      "Epoch 2221: Train Loss = 0.1437, Test Loss = 1.1152622699737549:.4f\n",
      "Epoch 2222: Train Loss = 0.1320, Test Loss = 1.1447887420654297:.4f\n",
      "Epoch 2223: Train Loss = 0.1354, Test Loss = 1.1497845649719238:.4f\n",
      "Epoch 2224: Train Loss = 0.1423, Test Loss = 1.134156584739685:.4f\n",
      "Epoch 2225: Train Loss = 0.1357, Test Loss = 1.1245110034942627:.4f\n",
      "Epoch 2226: Train Loss = 0.1475, Test Loss = 1.113567590713501:.4f\n",
      "Epoch 2227: Train Loss = 0.1511, Test Loss = 1.1094930171966553:.4f\n",
      "Epoch 2228: Train Loss = 0.1891, Test Loss = 1.1253761053085327:.4f\n",
      "Epoch 2229: Train Loss = 0.1613, Test Loss = 1.1377402544021606:.4f\n",
      "Epoch 2230: Train Loss = 0.1457, Test Loss = 1.1359338760375977:.4f\n",
      "Epoch 2231: Train Loss = 0.1294, Test Loss = 1.1272556781768799:.4f\n",
      "Epoch 2232: Train Loss = 0.1810, Test Loss = 1.126271367073059:.4f\n",
      "Epoch 2233: Train Loss = 0.1472, Test Loss = 1.1065046787261963:.4f\n",
      "Epoch 2234: Train Loss = 0.1278, Test Loss = 1.11427640914917:.4f\n",
      "Epoch 2235: Train Loss = 0.1482, Test Loss = 1.1206918954849243:.4f\n",
      "Epoch 2236: Train Loss = 0.1235, Test Loss = 1.1194089651107788:.4f\n",
      "Epoch 2237: Train Loss = 0.1547, Test Loss = 1.1247037649154663:.4f\n",
      "Epoch 2238: Train Loss = 0.1492, Test Loss = 1.1245298385620117:.4f\n",
      "Epoch 2239: Train Loss = 0.1388, Test Loss = 1.121593952178955:.4f\n",
      "Epoch 2240: Train Loss = 0.1345, Test Loss = 1.1175854206085205:.4f\n",
      "Epoch 2241: Train Loss = 0.1350, Test Loss = 1.111053228378296:.4f\n",
      "Epoch 2242: Train Loss = 0.1671, Test Loss = 1.1003754138946533:.4f\n",
      "Epoch 2243: Train Loss = 0.1384, Test Loss = 1.1169832944869995:.4f\n",
      "Epoch 2244: Train Loss = 0.1713, Test Loss = 1.1440140008926392:.4f\n",
      "Epoch 2245: Train Loss = 0.1672, Test Loss = 1.1509299278259277:.4f\n",
      "Epoch 2246: Train Loss = 0.1361, Test Loss = 1.1542218923568726:.4f\n",
      "Epoch 2247: Train Loss = 0.1602, Test Loss = 1.151055097579956:.4f\n",
      "Epoch 2248: Train Loss = 0.1286, Test Loss = 1.1388089656829834:.4f\n",
      "Epoch 2249: Train Loss = 0.1677, Test Loss = 1.1241333484649658:.4f\n",
      "Epoch 2250: Train Loss = 0.1266, Test Loss = 1.1108771562576294:.4f\n",
      "Epoch 2251: Train Loss = 0.1323, Test Loss = 1.1136233806610107:.4f\n",
      "Epoch 2252: Train Loss = 0.1900, Test Loss = 1.112091064453125:.4f\n",
      "Epoch 2253: Train Loss = 0.1273, Test Loss = 1.103961706161499:.4f\n",
      "Epoch 2254: Train Loss = 0.1769, Test Loss = 1.1045358180999756:.4f\n",
      "Epoch 2255: Train Loss = 0.1516, Test Loss = 1.1226437091827393:.4f\n",
      "Epoch 2256: Train Loss = 0.1424, Test Loss = 1.1394068002700806:.4f\n",
      "Epoch 2257: Train Loss = 0.1725, Test Loss = 1.1421682834625244:.4f\n",
      "Epoch 2258: Train Loss = 0.1284, Test Loss = 1.124103307723999:.4f\n",
      "Epoch 2259: Train Loss = 0.1816, Test Loss = 1.117647409439087:.4f\n",
      "Epoch 2260: Train Loss = 0.1445, Test Loss = 1.1264102458953857:.4f\n",
      "Epoch 2261: Train Loss = 0.1327, Test Loss = 1.132810354232788:.4f\n",
      "Epoch 2262: Train Loss = 0.1318, Test Loss = 1.1336612701416016:.4f\n",
      "Epoch 2263: Train Loss = 0.1518, Test Loss = 1.1294211149215698:.4f\n",
      "Epoch 2264: Train Loss = 0.1421, Test Loss = 1.1014307737350464:.4f\n",
      "Epoch 2265: Train Loss = 0.1289, Test Loss = 1.1023266315460205:.4f\n",
      "Epoch 2266: Train Loss = 0.1341, Test Loss = 1.1125767230987549:.4f\n",
      "Epoch 2267: Train Loss = 0.1359, Test Loss = 1.1262354850769043:.4f\n",
      "Epoch 2268: Train Loss = 0.1487, Test Loss = 1.1435776948928833:.4f\n",
      "Epoch 2269: Train Loss = 0.1479, Test Loss = 1.144890308380127:.4f\n",
      "Epoch 2270: Train Loss = 0.1752, Test Loss = 1.1305500268936157:.4f\n",
      "Epoch 2271: Train Loss = 0.1303, Test Loss = 1.124146580696106:.4f\n",
      "Epoch 2272: Train Loss = 0.1609, Test Loss = 1.1179146766662598:.4f\n",
      "Epoch 2273: Train Loss = 0.1359, Test Loss = 1.1282919645309448:.4f\n",
      "Epoch 2274: Train Loss = 0.2006, Test Loss = 1.1330482959747314:.4f\n",
      "Epoch 2275: Train Loss = 0.1295, Test Loss = 1.1056007146835327:.4f\n",
      "Epoch 2276: Train Loss = 0.1394, Test Loss = 1.1178538799285889:.4f\n",
      "Epoch 2277: Train Loss = 0.1854, Test Loss = 1.1251754760742188:.4f\n",
      "Epoch 2278: Train Loss = 0.1258, Test Loss = 1.1371452808380127:.4f\n",
      "Epoch 2279: Train Loss = 0.1437, Test Loss = 1.1401135921478271:.4f\n",
      "Epoch 2280: Train Loss = 0.1371, Test Loss = 1.1348260641098022:.4f\n",
      "Epoch 2281: Train Loss = 0.1451, Test Loss = 1.1142317056655884:.4f\n",
      "Epoch 2282: Train Loss = 0.1452, Test Loss = 1.111246109008789:.4f\n",
      "Epoch 2283: Train Loss = 0.1331, Test Loss = 1.127895474433899:.4f\n",
      "Epoch 2284: Train Loss = 0.1307, Test Loss = 1.1293107271194458:.4f\n",
      "Epoch 2285: Train Loss = 0.1706, Test Loss = 1.1306347846984863:.4f\n",
      "Epoch 2286: Train Loss = 0.1272, Test Loss = 1.122483491897583:.4f\n",
      "Epoch 2287: Train Loss = 0.1819, Test Loss = 1.1252281665802002:.4f\n",
      "Epoch 2288: Train Loss = 0.1279, Test Loss = 1.1279125213623047:.4f\n",
      "Epoch 2289: Train Loss = 0.1356, Test Loss = 1.122201681137085:.4f\n",
      "Epoch 2290: Train Loss = 0.1315, Test Loss = 1.1205683946609497:.4f\n",
      "Epoch 2291: Train Loss = 0.1344, Test Loss = 1.129703164100647:.4f\n",
      "Epoch 2292: Train Loss = 0.1674, Test Loss = 1.1349267959594727:.4f\n",
      "Epoch 2293: Train Loss = 0.1913, Test Loss = 1.1299468278884888:.4f\n",
      "Epoch 2294: Train Loss = 0.1418, Test Loss = 1.1317919492721558:.4f\n",
      "Epoch 2295: Train Loss = 0.1292, Test Loss = 1.1259609460830688:.4f\n",
      "Epoch 2296: Train Loss = 0.1729, Test Loss = 1.121124505996704:.4f\n",
      "Epoch 2297: Train Loss = 0.1299, Test Loss = 1.123821496963501:.4f\n",
      "Epoch 2298: Train Loss = 0.1590, Test Loss = 1.1185716390609741:.4f\n",
      "Epoch 2299: Train Loss = 0.1244, Test Loss = 1.1220569610595703:.4f\n",
      "Epoch 2300: Train Loss = 0.1405, Test Loss = 1.1422085762023926:.4f\n",
      "Epoch 2301: Train Loss = 0.1494, Test Loss = 1.145046591758728:.4f\n",
      "Epoch 2302: Train Loss = 0.1277, Test Loss = 1.1280888319015503:.4f\n",
      "Epoch 2303: Train Loss = 0.1554, Test Loss = 1.1138896942138672:.4f\n",
      "Epoch 2304: Train Loss = 0.1397, Test Loss = 1.1112744808197021:.4f\n",
      "Epoch 2305: Train Loss = 0.1335, Test Loss = 1.109401822090149:.4f\n",
      "Epoch 2306: Train Loss = 0.1353, Test Loss = 1.1309466361999512:.4f\n",
      "Epoch 2307: Train Loss = 0.1442, Test Loss = 1.150834321975708:.4f\n",
      "Epoch 2308: Train Loss = 0.1478, Test Loss = 1.1469309329986572:.4f\n",
      "Epoch 2309: Train Loss = 0.1277, Test Loss = 1.135323166847229:.4f\n",
      "Epoch 2310: Train Loss = 0.1326, Test Loss = 1.1305973529815674:.4f\n",
      "Epoch 2311: Train Loss = 0.1438, Test Loss = 1.126587986946106:.4f\n",
      "Epoch 2312: Train Loss = 0.1261, Test Loss = 1.125325322151184:.4f\n",
      "Epoch 2313: Train Loss = 0.1399, Test Loss = 1.115370750427246:.4f\n",
      "Epoch 2314: Train Loss = 0.1716, Test Loss = 1.1107885837554932:.4f\n",
      "Epoch 2315: Train Loss = 0.1740, Test Loss = 1.1187093257904053:.4f\n",
      "Epoch 2316: Train Loss = 0.1594, Test Loss = 1.1428142786026:.4f\n",
      "Epoch 2317: Train Loss = 0.1352, Test Loss = 1.1561062335968018:.4f\n",
      "Epoch 2318: Train Loss = 0.1394, Test Loss = 1.1507251262664795:.4f\n",
      "Epoch 2319: Train Loss = 0.1488, Test Loss = 1.1236156225204468:.4f\n",
      "Epoch 2320: Train Loss = 0.1279, Test Loss = 1.0858832597732544:.4f\n",
      "Epoch 2321: Train Loss = 0.1384, Test Loss = 1.0665991306304932:.4f\n",
      "Epoch 2322: Train Loss = 0.1338, Test Loss = 1.0769813060760498:.4f\n",
      "Epoch 2323: Train Loss = 0.1713, Test Loss = 1.1029517650604248:.4f\n",
      "Epoch 2324: Train Loss = 0.1430, Test Loss = 1.141861081123352:.4f\n",
      "Epoch 2325: Train Loss = 0.1912, Test Loss = 1.1694122552871704:.4f\n",
      "Epoch 2326: Train Loss = 0.1926, Test Loss = 1.1695024967193604:.4f\n",
      "Epoch 2327: Train Loss = 0.1755, Test Loss = 1.1583062410354614:.4f\n",
      "Epoch 2328: Train Loss = 0.1552, Test Loss = 1.152669906616211:.4f\n",
      "Epoch 2329: Train Loss = 0.1343, Test Loss = 1.1399592161178589:.4f\n",
      "Epoch 2330: Train Loss = 0.1592, Test Loss = 1.1244232654571533:.4f\n",
      "Epoch 2331: Train Loss = 0.1448, Test Loss = 1.1081507205963135:.4f\n",
      "Epoch 2332: Train Loss = 0.1713, Test Loss = 1.1039752960205078:.4f\n",
      "Epoch 2333: Train Loss = 0.1536, Test Loss = 1.110716462135315:.4f\n",
      "Epoch 2334: Train Loss = 0.1369, Test Loss = 1.1268866062164307:.4f\n",
      "Epoch 2335: Train Loss = 0.1378, Test Loss = 1.1344895362854004:.4f\n",
      "Epoch 2336: Train Loss = 0.1565, Test Loss = 1.1349233388900757:.4f\n",
      "Epoch 2337: Train Loss = 0.1495, Test Loss = 1.1120588779449463:.4f\n",
      "Epoch 2338: Train Loss = 0.1705, Test Loss = 1.1154546737670898:.4f\n",
      "Epoch 2339: Train Loss = 0.1830, Test Loss = 1.1127561330795288:.4f\n",
      "Epoch 2340: Train Loss = 0.1431, Test Loss = 1.110945463180542:.4f\n",
      "Epoch 2341: Train Loss = 0.1363, Test Loss = 1.1093493700027466:.4f\n",
      "Epoch 2342: Train Loss = 0.1596, Test Loss = 1.1175282001495361:.4f\n",
      "Epoch 2343: Train Loss = 0.1482, Test Loss = 1.1272903680801392:.4f\n",
      "Epoch 2344: Train Loss = 0.1364, Test Loss = 1.1330968141555786:.4f\n",
      "Epoch 2345: Train Loss = 0.1458, Test Loss = 1.134351372718811:.4f\n",
      "Epoch 2346: Train Loss = 0.1324, Test Loss = 1.13755202293396:.4f\n",
      "Epoch 2347: Train Loss = 0.1401, Test Loss = 1.1473435163497925:.4f\n",
      "Epoch 2348: Train Loss = 0.1456, Test Loss = 1.137392282485962:.4f\n",
      "Epoch 2349: Train Loss = 0.1894, Test Loss = 1.1294587850570679:.4f\n",
      "Epoch 2350: Train Loss = 0.1253, Test Loss = 1.1243724822998047:.4f\n",
      "Epoch 2351: Train Loss = 0.1348, Test Loss = 1.124563455581665:.4f\n",
      "Epoch 2352: Train Loss = 0.1355, Test Loss = 1.1292136907577515:.4f\n",
      "Epoch 2353: Train Loss = 0.1380, Test Loss = 1.1210689544677734:.4f\n",
      "Epoch 2354: Train Loss = 0.1336, Test Loss = 1.1203261613845825:.4f\n",
      "Epoch 2355: Train Loss = 0.1535, Test Loss = 1.1242401599884033:.4f\n",
      "Epoch 2356: Train Loss = 0.1424, Test Loss = 1.1346638202667236:.4f\n",
      "Epoch 2357: Train Loss = 0.1479, Test Loss = 1.1284973621368408:.4f\n",
      "Epoch 2358: Train Loss = 0.1701, Test Loss = 1.1221266984939575:.4f\n",
      "Epoch 2359: Train Loss = 0.1859, Test Loss = 1.1123327016830444:.4f\n",
      "Epoch 2360: Train Loss = 0.1872, Test Loss = 1.143897533416748:.4f\n",
      "Epoch 2361: Train Loss = 0.1563, Test Loss = 1.1824891567230225:.4f\n",
      "Epoch 2362: Train Loss = 0.1470, Test Loss = 1.211759090423584:.4f\n",
      "Epoch 2363: Train Loss = 0.1693, Test Loss = 1.1852145195007324:.4f\n",
      "Epoch 2364: Train Loss = 0.1643, Test Loss = 1.15126371383667:.4f\n",
      "Epoch 2365: Train Loss = 0.1877, Test Loss = 1.1361901760101318:.4f\n",
      "Epoch 2366: Train Loss = 0.1454, Test Loss = 1.1237566471099854:.4f\n",
      "Epoch 2367: Train Loss = 0.1484, Test Loss = 1.1267772912979126:.4f\n",
      "Epoch 2368: Train Loss = 0.1417, Test Loss = 1.1434895992279053:.4f\n",
      "Epoch 2369: Train Loss = 0.1354, Test Loss = 1.1414902210235596:.4f\n",
      "Epoch 2370: Train Loss = 0.1311, Test Loss = 1.108124017715454:.4f\n",
      "Epoch 2371: Train Loss = 0.1290, Test Loss = 1.0977342128753662:.4f\n",
      "Epoch 2372: Train Loss = 0.1705, Test Loss = 1.1087267398834229:.4f\n",
      "Epoch 2373: Train Loss = 0.1420, Test Loss = 1.1250739097595215:.4f\n",
      "Epoch 2374: Train Loss = 0.1661, Test Loss = 1.1364811658859253:.4f\n",
      "Epoch 2375: Train Loss = 0.1291, Test Loss = 1.1196945905685425:.4f\n",
      "Epoch 2376: Train Loss = 0.1540, Test Loss = 1.1192246675491333:.4f\n",
      "Epoch 2377: Train Loss = 0.1471, Test Loss = 1.1310395002365112:.4f\n",
      "Epoch 2378: Train Loss = 0.1299, Test Loss = 1.1330220699310303:.4f\n",
      "Epoch 2379: Train Loss = 0.1481, Test Loss = 1.123448133468628:.4f\n",
      "Epoch 2380: Train Loss = 0.1441, Test Loss = 1.1246798038482666:.4f\n",
      "Epoch 2381: Train Loss = 0.1436, Test Loss = 1.1497524976730347:.4f\n",
      "Epoch 2382: Train Loss = 0.1304, Test Loss = 1.1476686000823975:.4f\n",
      "Epoch 2383: Train Loss = 0.1669, Test Loss = 1.1483972072601318:.4f\n",
      "Epoch 2384: Train Loss = 0.1403, Test Loss = 1.1421058177947998:.4f\n",
      "Epoch 2385: Train Loss = 0.1567, Test Loss = 1.1327588558197021:.4f\n",
      "Epoch 2386: Train Loss = 0.1435, Test Loss = 1.1353543996810913:.4f\n",
      "Epoch 2387: Train Loss = 0.1382, Test Loss = 1.135887861251831:.4f\n",
      "Epoch 2388: Train Loss = 0.1252, Test Loss = 1.1342415809631348:.4f\n",
      "Epoch 2389: Train Loss = 0.1705, Test Loss = 1.1307458877563477:.4f\n",
      "Epoch 2390: Train Loss = 0.1528, Test Loss = 1.1235241889953613:.4f\n",
      "Epoch 2391: Train Loss = 0.1663, Test Loss = 1.1129553318023682:.4f\n",
      "Epoch 2392: Train Loss = 0.1349, Test Loss = 1.130748987197876:.4f\n",
      "Epoch 2393: Train Loss = 0.1290, Test Loss = 1.1432812213897705:.4f\n",
      "Epoch 2394: Train Loss = 0.1243, Test Loss = 1.1473989486694336:.4f\n",
      "Epoch 2395: Train Loss = 0.1360, Test Loss = 1.1388788223266602:.4f\n",
      "Epoch 2396: Train Loss = 0.1353, Test Loss = 1.1281630992889404:.4f\n",
      "Epoch 2397: Train Loss = 0.1397, Test Loss = 1.1309354305267334:.4f\n",
      "Epoch 2398: Train Loss = 0.1505, Test Loss = 1.1254233121871948:.4f\n",
      "Epoch 2399: Train Loss = 0.1460, Test Loss = 1.1261780261993408:.4f\n",
      "Epoch 2400: Train Loss = 0.1331, Test Loss = 1.1149336099624634:.4f\n",
      "Epoch 2401: Train Loss = 0.1359, Test Loss = 1.1134392023086548:.4f\n",
      "Epoch 2402: Train Loss = 0.1391, Test Loss = 1.125353455543518:.4f\n",
      "Epoch 2403: Train Loss = 0.1649, Test Loss = 1.1317355632781982:.4f\n",
      "Epoch 2404: Train Loss = 0.1669, Test Loss = 1.131881833076477:.4f\n",
      "Epoch 2405: Train Loss = 0.1415, Test Loss = 1.1335152387619019:.4f\n",
      "Epoch 2406: Train Loss = 0.1421, Test Loss = 1.1408936977386475:.4f\n",
      "Epoch 2407: Train Loss = 0.1398, Test Loss = 1.1365880966186523:.4f\n",
      "Epoch 2408: Train Loss = 0.1490, Test Loss = 1.1349432468414307:.4f\n",
      "Epoch 2409: Train Loss = 0.1350, Test Loss = 1.1316226720809937:.4f\n",
      "Epoch 2410: Train Loss = 0.1708, Test Loss = 1.1200013160705566:.4f\n",
      "Epoch 2411: Train Loss = 0.1367, Test Loss = 1.1163727045059204:.4f\n",
      "Epoch 2412: Train Loss = 0.1639, Test Loss = 1.1365163326263428:.4f\n",
      "Epoch 2413: Train Loss = 0.1382, Test Loss = 1.1539433002471924:.4f\n",
      "Epoch 2414: Train Loss = 0.1315, Test Loss = 1.1580525636672974:.4f\n",
      "Epoch 2415: Train Loss = 0.1587, Test Loss = 1.1478242874145508:.4f\n",
      "Epoch 2416: Train Loss = 0.1842, Test Loss = 1.1363153457641602:.4f\n",
      "Epoch 2417: Train Loss = 0.1246, Test Loss = 1.1410424709320068:.4f\n",
      "Epoch 2418: Train Loss = 0.1442, Test Loss = 1.1395862102508545:.4f\n",
      "Epoch 2419: Train Loss = 0.1585, Test Loss = 1.1360838413238525:.4f\n",
      "Epoch 2420: Train Loss = 0.1416, Test Loss = 1.1403942108154297:.4f\n",
      "Epoch 2421: Train Loss = 0.1583, Test Loss = 1.122631311416626:.4f\n",
      "Epoch 2422: Train Loss = 0.1333, Test Loss = 1.1182546615600586:.4f\n",
      "Epoch 2423: Train Loss = 0.1459, Test Loss = 1.132798194885254:.4f\n",
      "Epoch 2424: Train Loss = 0.1523, Test Loss = 1.132417917251587:.4f\n",
      "Epoch 2425: Train Loss = 0.1330, Test Loss = 1.1148059368133545:.4f\n",
      "Epoch 2426: Train Loss = 0.1416, Test Loss = 1.1115505695343018:.4f\n",
      "Epoch 2427: Train Loss = 0.1472, Test Loss = 1.1155047416687012:.4f\n",
      "Epoch 2428: Train Loss = 0.1319, Test Loss = 1.1060166358947754:.4f\n",
      "Epoch 2429: Train Loss = 0.1724, Test Loss = 1.1070104837417603:.4f\n",
      "Epoch 2430: Train Loss = 0.1599, Test Loss = 1.105057716369629:.4f\n",
      "Epoch 2431: Train Loss = 0.1578, Test Loss = 1.126139760017395:.4f\n",
      "Epoch 2432: Train Loss = 0.1395, Test Loss = 1.1365387439727783:.4f\n",
      "Epoch 2433: Train Loss = 0.1557, Test Loss = 1.122011423110962:.4f\n",
      "Epoch 2434: Train Loss = 0.1558, Test Loss = 1.1183958053588867:.4f\n",
      "Epoch 2435: Train Loss = 0.1682, Test Loss = 1.1297056674957275:.4f\n",
      "Epoch 2436: Train Loss = 0.1319, Test Loss = 1.1394089460372925:.4f\n",
      "Epoch 2437: Train Loss = 0.1343, Test Loss = 1.1545751094818115:.4f\n",
      "Epoch 2438: Train Loss = 0.1453, Test Loss = 1.1663559675216675:.4f\n",
      "Epoch 2439: Train Loss = 0.1391, Test Loss = 1.1484066247940063:.4f\n",
      "Epoch 2440: Train Loss = 0.1381, Test Loss = 1.1192761659622192:.4f\n",
      "Epoch 2441: Train Loss = 0.1446, Test Loss = 1.1137118339538574:.4f\n",
      "Epoch 2442: Train Loss = 0.1730, Test Loss = 1.128472924232483:.4f\n",
      "Epoch 2443: Train Loss = 0.1422, Test Loss = 1.1356937885284424:.4f\n",
      "Epoch 2444: Train Loss = 0.1535, Test Loss = 1.1476540565490723:.4f\n",
      "Epoch 2445: Train Loss = 0.1252, Test Loss = 1.1450995206832886:.4f\n",
      "Epoch 2446: Train Loss = 0.1309, Test Loss = 1.1351087093353271:.4f\n",
      "Epoch 2447: Train Loss = 0.1957, Test Loss = 1.1388682126998901:.4f\n",
      "Epoch 2448: Train Loss = 0.1701, Test Loss = 1.1395583152770996:.4f\n",
      "Epoch 2449: Train Loss = 0.1261, Test Loss = 1.1469790935516357:.4f\n",
      "Epoch 2450: Train Loss = 0.1363, Test Loss = 1.149609923362732:.4f\n",
      "Epoch 2451: Train Loss = 0.1256, Test Loss = 1.1366610527038574:.4f\n",
      "Epoch 2452: Train Loss = 0.1562, Test Loss = 1.1192861795425415:.4f\n",
      "Epoch 2453: Train Loss = 0.1652, Test Loss = 1.1186275482177734:.4f\n",
      "Epoch 2454: Train Loss = 0.1554, Test Loss = 1.124161720275879:.4f\n",
      "Epoch 2455: Train Loss = 0.1531, Test Loss = 1.1642919778823853:.4f\n",
      "Epoch 2456: Train Loss = 0.1513, Test Loss = 1.1756296157836914:.4f\n",
      "Epoch 2457: Train Loss = 0.1366, Test Loss = 1.1392096281051636:.4f\n",
      "Epoch 2458: Train Loss = 0.1490, Test Loss = 1.1071491241455078:.4f\n",
      "Epoch 2459: Train Loss = 0.1443, Test Loss = 1.109126329421997:.4f\n",
      "Epoch 2460: Train Loss = 0.1288, Test Loss = 1.1307554244995117:.4f\n",
      "Epoch 2461: Train Loss = 0.1352, Test Loss = 1.1528750658035278:.4f\n",
      "Epoch 2462: Train Loss = 0.1467, Test Loss = 1.16194748878479:.4f\n",
      "Epoch 2463: Train Loss = 0.1738, Test Loss = 1.1415423154830933:.4f\n",
      "Epoch 2464: Train Loss = 0.1972, Test Loss = 1.1427643299102783:.4f\n",
      "Epoch 2465: Train Loss = 0.1554, Test Loss = 1.1603243350982666:.4f\n",
      "Epoch 2466: Train Loss = 0.1507, Test Loss = 1.1771692037582397:.4f\n",
      "Epoch 2467: Train Loss = 0.1327, Test Loss = 1.1909629106521606:.4f\n",
      "Epoch 2468: Train Loss = 0.1523, Test Loss = 1.1722408533096313:.4f\n",
      "Epoch 2469: Train Loss = 0.1893, Test Loss = 1.149061679840088:.4f\n",
      "Epoch 2470: Train Loss = 0.1590, Test Loss = 1.1426379680633545:.4f\n",
      "Epoch 2471: Train Loss = 0.1315, Test Loss = 1.1523512601852417:.4f\n",
      "Epoch 2472: Train Loss = 0.1336, Test Loss = 1.1542017459869385:.4f\n",
      "Epoch 2473: Train Loss = 0.1614, Test Loss = 1.1566357612609863:.4f\n",
      "Epoch 2474: Train Loss = 0.1386, Test Loss = 1.154754638671875:.4f\n",
      "Epoch 2475: Train Loss = 0.1533, Test Loss = 1.1586132049560547:.4f\n",
      "Epoch 2476: Train Loss = 0.1460, Test Loss = 1.1656991243362427:.4f\n",
      "Epoch 2477: Train Loss = 0.1699, Test Loss = 1.1614590883255005:.4f\n",
      "Epoch 2478: Train Loss = 0.1866, Test Loss = 1.1526453495025635:.4f\n",
      "Epoch 2479: Train Loss = 0.1337, Test Loss = 1.1421535015106201:.4f\n",
      "Epoch 2480: Train Loss = 0.1345, Test Loss = 1.1406694650650024:.4f\n",
      "Epoch 2481: Train Loss = 0.1301, Test Loss = 1.1531368494033813:.4f\n",
      "Epoch 2482: Train Loss = 0.1270, Test Loss = 1.161768913269043:.4f\n",
      "Epoch 2483: Train Loss = 0.1722, Test Loss = 1.1602973937988281:.4f\n",
      "Epoch 2484: Train Loss = 0.1552, Test Loss = 1.159462571144104:.4f\n",
      "Epoch 2485: Train Loss = 0.1328, Test Loss = 1.1585015058517456:.4f\n",
      "Epoch 2486: Train Loss = 0.1411, Test Loss = 1.1670777797698975:.4f\n",
      "Epoch 2487: Train Loss = 0.1417, Test Loss = 1.169055700302124:.4f\n",
      "Epoch 2488: Train Loss = 0.1431, Test Loss = 1.1658891439437866:.4f\n",
      "Epoch 2489: Train Loss = 0.1456, Test Loss = 1.1321159601211548:.4f\n",
      "Epoch 2490: Train Loss = 0.1332, Test Loss = 1.1187437772750854:.4f\n",
      "Epoch 2491: Train Loss = 0.1502, Test Loss = 1.1175787448883057:.4f\n",
      "Epoch 2492: Train Loss = 0.1911, Test Loss = 1.1392382383346558:.4f\n",
      "Epoch 2493: Train Loss = 0.1589, Test Loss = 1.1545668840408325:.4f\n",
      "Epoch 2494: Train Loss = 0.1495, Test Loss = 1.1616188287734985:.4f\n",
      "Epoch 2495: Train Loss = 0.1295, Test Loss = 1.1768264770507812:.4f\n",
      "Epoch 2496: Train Loss = 0.1836, Test Loss = 1.1876482963562012:.4f\n",
      "Epoch 2497: Train Loss = 0.1629, Test Loss = 1.1804112195968628:.4f\n",
      "Epoch 2498: Train Loss = 0.1495, Test Loss = 1.1508268117904663:.4f\n",
      "Epoch 2499: Train Loss = 0.1304, Test Loss = 1.1252073049545288:.4f\n",
      "Epoch 2500: Train Loss = 0.2076, Test Loss = 1.1084301471710205:.4f\n",
      "Epoch 2501: Train Loss = 0.1527, Test Loss = 1.1109821796417236:.4f\n",
      "Epoch 2502: Train Loss = 0.1304, Test Loss = 1.1267008781433105:.4f\n",
      "Epoch 2503: Train Loss = 0.1376, Test Loss = 1.1442502737045288:.4f\n",
      "Epoch 2504: Train Loss = 0.1834, Test Loss = 1.1657660007476807:.4f\n",
      "Epoch 2505: Train Loss = 0.1546, Test Loss = 1.1658109426498413:.4f\n",
      "Epoch 2506: Train Loss = 0.1287, Test Loss = 1.1508108377456665:.4f\n",
      "Epoch 2507: Train Loss = 0.1797, Test Loss = 1.1252050399780273:.4f\n",
      "Epoch 2508: Train Loss = 0.1745, Test Loss = 1.1007132530212402:.4f\n",
      "Epoch 2509: Train Loss = 0.1642, Test Loss = 1.1070070266723633:.4f\n",
      "Epoch 2510: Train Loss = 0.1373, Test Loss = 1.1223499774932861:.4f\n",
      "Epoch 2511: Train Loss = 0.1318, Test Loss = 1.1457082033157349:.4f\n",
      "Epoch 2512: Train Loss = 0.1337, Test Loss = 1.1526232957839966:.4f\n",
      "Epoch 2513: Train Loss = 0.1588, Test Loss = 1.163812279701233:.4f\n",
      "Epoch 2514: Train Loss = 0.1221, Test Loss = 1.1584322452545166:.4f\n",
      "Epoch 2515: Train Loss = 0.1790, Test Loss = 1.1555105447769165:.4f\n",
      "Epoch 2516: Train Loss = 0.1327, Test Loss = 1.149597406387329:.4f\n",
      "Epoch 2517: Train Loss = 0.1490, Test Loss = 1.1367311477661133:.4f\n",
      "Epoch 2518: Train Loss = 0.1498, Test Loss = 1.1440492868423462:.4f\n",
      "Epoch 2519: Train Loss = 0.1432, Test Loss = 1.1389117240905762:.4f\n",
      "Epoch 2520: Train Loss = 0.1528, Test Loss = 1.1233558654785156:.4f\n",
      "Epoch 2521: Train Loss = 0.1384, Test Loss = 1.1218445301055908:.4f\n",
      "Epoch 2522: Train Loss = 0.1487, Test Loss = 1.1279981136322021:.4f\n",
      "Epoch 2523: Train Loss = 0.1319, Test Loss = 1.138991117477417:.4f\n",
      "Epoch 2524: Train Loss = 0.1766, Test Loss = 1.1513266563415527:.4f\n",
      "Epoch 2525: Train Loss = 0.1322, Test Loss = 1.1505944728851318:.4f\n",
      "Epoch 2526: Train Loss = 0.1632, Test Loss = 1.1393426656723022:.4f\n",
      "Epoch 2527: Train Loss = 0.1261, Test Loss = 1.1459424495697021:.4f\n",
      "Epoch 2528: Train Loss = 0.1517, Test Loss = 1.160498857498169:.4f\n",
      "Epoch 2529: Train Loss = 0.1461, Test Loss = 1.1678717136383057:.4f\n",
      "Epoch 2530: Train Loss = 0.1309, Test Loss = 1.1623404026031494:.4f\n",
      "Epoch 2531: Train Loss = 0.1406, Test Loss = 1.1370762586593628:.4f\n",
      "Epoch 2532: Train Loss = 0.1989, Test Loss = 1.1084396839141846:.4f\n",
      "Epoch 2533: Train Loss = 0.1751, Test Loss = 1.1076149940490723:.4f\n",
      "Epoch 2534: Train Loss = 0.1416, Test Loss = 1.124578595161438:.4f\n",
      "Epoch 2535: Train Loss = 0.1249, Test Loss = 1.1538556814193726:.4f\n",
      "Epoch 2536: Train Loss = 0.1236, Test Loss = 1.1689562797546387:.4f\n",
      "Epoch 2537: Train Loss = 0.1387, Test Loss = 1.168792963027954:.4f\n",
      "Epoch 2538: Train Loss = 0.2097, Test Loss = 1.1494594812393188:.4f\n",
      "Epoch 2539: Train Loss = 0.1499, Test Loss = 1.1432149410247803:.4f\n",
      "Epoch 2540: Train Loss = 0.1468, Test Loss = 1.1467889547348022:.4f\n",
      "Epoch 2541: Train Loss = 0.1589, Test Loss = 1.160832166671753:.4f\n",
      "Epoch 2542: Train Loss = 0.1519, Test Loss = 1.1798253059387207:.4f\n",
      "Epoch 2543: Train Loss = 0.1376, Test Loss = 1.1482285261154175:.4f\n",
      "Epoch 2544: Train Loss = 0.1438, Test Loss = 1.1231812238693237:.4f\n",
      "Epoch 2545: Train Loss = 0.1450, Test Loss = 1.1208094358444214:.4f\n",
      "Epoch 2546: Train Loss = 0.1317, Test Loss = 1.1128520965576172:.4f\n",
      "Epoch 2547: Train Loss = 0.1317, Test Loss = 1.1257197856903076:.4f\n",
      "Epoch 2548: Train Loss = 0.1316, Test Loss = 1.154009461402893:.4f\n",
      "Epoch 2549: Train Loss = 0.1487, Test Loss = 1.1510766744613647:.4f\n",
      "Epoch 2550: Train Loss = 0.1370, Test Loss = 1.1515419483184814:.4f\n",
      "Epoch 2551: Train Loss = 0.1292, Test Loss = 1.1379748582839966:.4f\n",
      "Epoch 2552: Train Loss = 0.1835, Test Loss = 1.1322739124298096:.4f\n",
      "Epoch 2553: Train Loss = 0.1527, Test Loss = 1.128556489944458:.4f\n",
      "Epoch 2554: Train Loss = 0.1362, Test Loss = 1.1203893423080444:.4f\n",
      "Epoch 2555: Train Loss = 0.1540, Test Loss = 1.1169211864471436:.4f\n",
      "Epoch 2556: Train Loss = 0.1607, Test Loss = 1.1249535083770752:.4f\n",
      "Epoch 2557: Train Loss = 0.1469, Test Loss = 1.1426161527633667:.4f\n",
      "Epoch 2558: Train Loss = 0.1368, Test Loss = 1.1571811437606812:.4f\n",
      "Epoch 2559: Train Loss = 0.1616, Test Loss = 1.1630017757415771:.4f\n",
      "Epoch 2560: Train Loss = 0.1314, Test Loss = 1.1550548076629639:.4f\n",
      "Epoch 2561: Train Loss = 0.1464, Test Loss = 1.1393331289291382:.4f\n",
      "Epoch 2562: Train Loss = 0.1421, Test Loss = 1.1187975406646729:.4f\n",
      "Epoch 2563: Train Loss = 0.1621, Test Loss = 1.1029272079467773:.4f\n",
      "Epoch 2564: Train Loss = 0.1383, Test Loss = 1.1206424236297607:.4f\n",
      "Epoch 2565: Train Loss = 0.1297, Test Loss = 1.1303656101226807:.4f\n",
      "Epoch 2566: Train Loss = 0.1616, Test Loss = 1.1413244009017944:.4f\n",
      "Epoch 2567: Train Loss = 0.1414, Test Loss = 1.1592142581939697:.4f\n",
      "Epoch 2568: Train Loss = 0.1798, Test Loss = 1.1654126644134521:.4f\n",
      "Epoch 2569: Train Loss = 0.1326, Test Loss = 1.137671709060669:.4f\n",
      "Epoch 2570: Train Loss = 0.1490, Test Loss = 1.1188656091690063:.4f\n",
      "Epoch 2571: Train Loss = 0.1385, Test Loss = 1.110642671585083:.4f\n",
      "Epoch 2572: Train Loss = 0.1305, Test Loss = 1.1175543069839478:.4f\n",
      "Epoch 2573: Train Loss = 0.1412, Test Loss = 1.1224045753479004:.4f\n",
      "Epoch 2574: Train Loss = 0.1314, Test Loss = 1.1315176486968994:.4f\n",
      "Epoch 2575: Train Loss = 0.1780, Test Loss = 1.1231517791748047:.4f\n",
      "Epoch 2576: Train Loss = 0.1345, Test Loss = 1.1396942138671875:.4f\n",
      "Epoch 2577: Train Loss = 0.1505, Test Loss = 1.1509387493133545:.4f\n",
      "Epoch 2578: Train Loss = 0.1462, Test Loss = 1.155147910118103:.4f\n",
      "Epoch 2579: Train Loss = 0.1437, Test Loss = 1.1503723859786987:.4f\n",
      "Epoch 2580: Train Loss = 0.1419, Test Loss = 1.1431103944778442:.4f\n",
      "Epoch 2581: Train Loss = 0.1314, Test Loss = 1.1147220134735107:.4f\n",
      "Epoch 2582: Train Loss = 0.1733, Test Loss = 1.1075518131256104:.4f\n",
      "Epoch 2583: Train Loss = 0.1535, Test Loss = 1.1349314451217651:.4f\n",
      "Epoch 2584: Train Loss = 0.1430, Test Loss = 1.1548233032226562:.4f\n",
      "Epoch 2585: Train Loss = 0.1501, Test Loss = 1.1612361669540405:.4f\n",
      "Epoch 2586: Train Loss = 0.1472, Test Loss = 1.1540231704711914:.4f\n",
      "Epoch 2587: Train Loss = 0.1514, Test Loss = 1.1496351957321167:.4f\n",
      "Epoch 2588: Train Loss = 0.1259, Test Loss = 1.1315611600875854:.4f\n",
      "Epoch 2589: Train Loss = 0.1462, Test Loss = 1.129901647567749:.4f\n",
      "Epoch 2590: Train Loss = 0.1709, Test Loss = 1.1228549480438232:.4f\n",
      "Epoch 2591: Train Loss = 0.1335, Test Loss = 1.1232261657714844:.4f\n",
      "Epoch 2592: Train Loss = 0.1510, Test Loss = 1.1156078577041626:.4f\n",
      "Epoch 2593: Train Loss = 0.1328, Test Loss = 1.1310093402862549:.4f\n",
      "Epoch 2594: Train Loss = 0.1329, Test Loss = 1.1611545085906982:.4f\n",
      "Epoch 2595: Train Loss = 0.1421, Test Loss = 1.1658554077148438:.4f\n",
      "Epoch 2596: Train Loss = 0.1508, Test Loss = 1.1674177646636963:.4f\n",
      "Epoch 2597: Train Loss = 0.1914, Test Loss = 1.1459256410598755:.4f\n",
      "Epoch 2598: Train Loss = 0.1753, Test Loss = 1.1309053897857666:.4f\n",
      "Epoch 2599: Train Loss = 0.1502, Test Loss = 1.112694501876831:.4f\n",
      "Epoch 2600: Train Loss = 0.1439, Test Loss = 1.1199404001235962:.4f\n",
      "Epoch 2601: Train Loss = 0.2057, Test Loss = 1.1377043724060059:.4f\n",
      "Epoch 2602: Train Loss = 0.1328, Test Loss = 1.1224191188812256:.4f\n",
      "Epoch 2603: Train Loss = 0.1465, Test Loss = 1.1165531873703003:.4f\n",
      "Epoch 2604: Train Loss = 0.1694, Test Loss = 1.12772798538208:.4f\n",
      "Epoch 2605: Train Loss = 0.1383, Test Loss = 1.1421505212783813:.4f\n",
      "Epoch 2606: Train Loss = 0.1415, Test Loss = 1.127236247062683:.4f\n",
      "Epoch 2607: Train Loss = 0.1566, Test Loss = 1.116470456123352:.4f\n",
      "Epoch 2608: Train Loss = 0.1381, Test Loss = 1.1164354085922241:.4f\n",
      "Epoch 2609: Train Loss = 0.1421, Test Loss = 1.138319969177246:.4f\n",
      "Epoch 2610: Train Loss = 0.1489, Test Loss = 1.1410610675811768:.4f\n",
      "Epoch 2611: Train Loss = 0.1228, Test Loss = 1.134208083152771:.4f\n",
      "Epoch 2612: Train Loss = 0.1345, Test Loss = 1.131129503250122:.4f\n",
      "Epoch 2613: Train Loss = 0.1461, Test Loss = 1.1153697967529297:.4f\n",
      "Epoch 2614: Train Loss = 0.1625, Test Loss = 1.1164350509643555:.4f\n",
      "Epoch 2615: Train Loss = 0.1350, Test Loss = 1.1209789514541626:.4f\n",
      "Epoch 2616: Train Loss = 0.1373, Test Loss = 1.1195917129516602:.4f\n",
      "Epoch 2617: Train Loss = 0.1340, Test Loss = 1.131678581237793:.4f\n",
      "Epoch 2618: Train Loss = 0.1483, Test Loss = 1.139431357383728:.4f\n",
      "Epoch 2619: Train Loss = 0.2157, Test Loss = 1.1378519535064697:.4f\n",
      "Epoch 2620: Train Loss = 0.1383, Test Loss = 1.1458714008331299:.4f\n",
      "Epoch 2621: Train Loss = 0.1319, Test Loss = 1.147503137588501:.4f\n",
      "Epoch 2622: Train Loss = 0.1486, Test Loss = 1.142343282699585:.4f\n",
      "Epoch 2623: Train Loss = 0.1512, Test Loss = 1.1424702405929565:.4f\n",
      "Epoch 2624: Train Loss = 0.1840, Test Loss = 1.1448554992675781:.4f\n",
      "Epoch 2625: Train Loss = 0.1464, Test Loss = 1.1321746110916138:.4f\n",
      "Epoch 2626: Train Loss = 0.1885, Test Loss = 1.1111268997192383:.4f\n",
      "Epoch 2627: Train Loss = 0.1482, Test Loss = 1.1248716115951538:.4f\n",
      "Epoch 2628: Train Loss = 0.1508, Test Loss = 1.1336252689361572:.4f\n",
      "Epoch 2629: Train Loss = 0.1383, Test Loss = 1.1477559804916382:.4f\n",
      "Epoch 2630: Train Loss = 0.1423, Test Loss = 1.1391360759735107:.4f\n",
      "Epoch 2631: Train Loss = 0.1374, Test Loss = 1.1216129064559937:.4f\n",
      "Epoch 2632: Train Loss = 0.1294, Test Loss = 1.114417314529419:.4f\n",
      "Epoch 2633: Train Loss = 0.1345, Test Loss = 1.1087701320648193:.4f\n",
      "Epoch 2634: Train Loss = 0.1602, Test Loss = 1.12044358253479:.4f\n",
      "Epoch 2635: Train Loss = 0.1318, Test Loss = 1.1239360570907593:.4f\n",
      "Epoch 2636: Train Loss = 0.1323, Test Loss = 1.1345689296722412:.4f\n",
      "Epoch 2637: Train Loss = 0.1257, Test Loss = 1.138944387435913:.4f\n",
      "Epoch 2638: Train Loss = 0.1413, Test Loss = 1.1406426429748535:.4f\n",
      "Epoch 2639: Train Loss = 0.1263, Test Loss = 1.137029767036438:.4f\n",
      "Epoch 2640: Train Loss = 0.1728, Test Loss = 1.1423804759979248:.4f\n",
      "Epoch 2641: Train Loss = 0.1325, Test Loss = 1.1346180438995361:.4f\n",
      "Epoch 2642: Train Loss = 0.1342, Test Loss = 1.1300605535507202:.4f\n",
      "Epoch 2643: Train Loss = 0.1482, Test Loss = 1.1320421695709229:.4f\n",
      "Epoch 2644: Train Loss = 0.1634, Test Loss = 1.1384127140045166:.4f\n",
      "Epoch 2645: Train Loss = 0.1724, Test Loss = 1.1373718976974487:.4f\n",
      "Epoch 2646: Train Loss = 0.1538, Test Loss = 1.1364017724990845:.4f\n",
      "Epoch 2647: Train Loss = 0.1341, Test Loss = 1.1226928234100342:.4f\n",
      "Epoch 2648: Train Loss = 0.1366, Test Loss = 1.1226521730422974:.4f\n",
      "Epoch 2649: Train Loss = 0.1366, Test Loss = 1.1372123956680298:.4f\n",
      "Epoch 2650: Train Loss = 0.1701, Test Loss = 1.1263439655303955:.4f\n",
      "Epoch 2651: Train Loss = 0.1681, Test Loss = 1.1224476099014282:.4f\n",
      "Epoch 2652: Train Loss = 0.1327, Test Loss = 1.1163933277130127:.4f\n",
      "Epoch 2653: Train Loss = 0.1725, Test Loss = 1.1314667463302612:.4f\n",
      "Epoch 2654: Train Loss = 0.1361, Test Loss = 1.155141830444336:.4f\n",
      "Epoch 2655: Train Loss = 0.1483, Test Loss = 1.177562952041626:.4f\n",
      "Epoch 2656: Train Loss = 0.1581, Test Loss = 1.1633094549179077:.4f\n",
      "Epoch 2657: Train Loss = 0.1653, Test Loss = 1.1279078722000122:.4f\n",
      "Epoch 2658: Train Loss = 0.1342, Test Loss = 1.1125192642211914:.4f\n",
      "Epoch 2659: Train Loss = 0.1486, Test Loss = 1.1221243143081665:.4f\n",
      "Epoch 2660: Train Loss = 0.1454, Test Loss = 1.1323267221450806:.4f\n",
      "Epoch 2661: Train Loss = 0.1423, Test Loss = 1.1393272876739502:.4f\n",
      "Epoch 2662: Train Loss = 0.1474, Test Loss = 1.1362894773483276:.4f\n",
      "Epoch 2663: Train Loss = 0.1512, Test Loss = 1.1315805912017822:.4f\n",
      "Epoch 2664: Train Loss = 0.1464, Test Loss = 1.1315882205963135:.4f\n",
      "Epoch 2665: Train Loss = 0.1688, Test Loss = 1.1374549865722656:.4f\n",
      "Epoch 2666: Train Loss = 0.1331, Test Loss = 1.1388399600982666:.4f\n",
      "Epoch 2667: Train Loss = 0.1293, Test Loss = 1.144460678100586:.4f\n",
      "Epoch 2668: Train Loss = 0.1679, Test Loss = 1.1525089740753174:.4f\n",
      "Epoch 2669: Train Loss = 0.1499, Test Loss = 1.1482765674591064:.4f\n",
      "Epoch 2670: Train Loss = 0.1744, Test Loss = 1.132232427597046:.4f\n",
      "Epoch 2671: Train Loss = 0.1338, Test Loss = 1.1133582592010498:.4f\n",
      "Epoch 2672: Train Loss = 0.1296, Test Loss = 1.1106350421905518:.4f\n",
      "Epoch 2673: Train Loss = 0.1614, Test Loss = 1.1236733198165894:.4f\n",
      "Epoch 2674: Train Loss = 0.1323, Test Loss = 1.1409965753555298:.4f\n",
      "Epoch 2675: Train Loss = 0.1428, Test Loss = 1.1440420150756836:.4f\n",
      "Epoch 2676: Train Loss = 0.1361, Test Loss = 1.1425060033798218:.4f\n",
      "Epoch 2677: Train Loss = 0.1531, Test Loss = 1.1234403848648071:.4f\n",
      "Epoch 2678: Train Loss = 0.1822, Test Loss = 1.1107826232910156:.4f\n",
      "Epoch 2679: Train Loss = 0.1273, Test Loss = 1.1061228513717651:.4f\n",
      "Epoch 2680: Train Loss = 0.1399, Test Loss = 1.1049976348876953:.4f\n",
      "Epoch 2681: Train Loss = 0.1570, Test Loss = 1.1192904710769653:.4f\n",
      "Epoch 2682: Train Loss = 0.1569, Test Loss = 1.1340482234954834:.4f\n",
      "Epoch 2683: Train Loss = 0.1413, Test Loss = 1.1442357301712036:.4f\n",
      "Epoch 2684: Train Loss = 0.1448, Test Loss = 1.1431443691253662:.4f\n",
      "Epoch 2685: Train Loss = 0.1261, Test Loss = 1.146115779876709:.4f\n",
      "Epoch 2686: Train Loss = 0.1513, Test Loss = 1.1452468633651733:.4f\n",
      "Epoch 2687: Train Loss = 0.1630, Test Loss = 1.1312119960784912:.4f\n",
      "Epoch 2688: Train Loss = 0.1547, Test Loss = 1.124596357345581:.4f\n",
      "Epoch 2689: Train Loss = 0.1406, Test Loss = 1.1084610223770142:.4f\n",
      "Epoch 2690: Train Loss = 0.1356, Test Loss = 1.107843279838562:.4f\n",
      "Epoch 2691: Train Loss = 0.1365, Test Loss = 1.1093621253967285:.4f\n",
      "Epoch 2692: Train Loss = 0.1617, Test Loss = 1.1204683780670166:.4f\n",
      "Epoch 2693: Train Loss = 0.1328, Test Loss = 1.1404222249984741:.4f\n",
      "Epoch 2694: Train Loss = 0.1441, Test Loss = 1.142404556274414:.4f\n",
      "Epoch 2695: Train Loss = 0.1621, Test Loss = 1.146164894104004:.4f\n",
      "Epoch 2696: Train Loss = 0.1665, Test Loss = 1.150382161140442:.4f\n",
      "Epoch 2697: Train Loss = 0.1366, Test Loss = 1.1639018058776855:.4f\n",
      "Epoch 2698: Train Loss = 0.1330, Test Loss = 1.170819640159607:.4f\n",
      "Epoch 2699: Train Loss = 0.1413, Test Loss = 1.1574177742004395:.4f\n",
      "Epoch 2700: Train Loss = 0.1339, Test Loss = 1.1369826793670654:.4f\n",
      "Epoch 2701: Train Loss = 0.1727, Test Loss = 1.1120322942733765:.4f\n",
      "Epoch 2702: Train Loss = 0.1625, Test Loss = 1.0942578315734863:.4f\n",
      "Epoch 2703: Train Loss = 0.1298, Test Loss = 1.1166999340057373:.4f\n",
      "Epoch 2704: Train Loss = 0.1541, Test Loss = 1.1379597187042236:.4f\n",
      "Epoch 2705: Train Loss = 0.1680, Test Loss = 1.1634066104888916:.4f\n",
      "Epoch 2706: Train Loss = 0.1534, Test Loss = 1.1604087352752686:.4f\n",
      "Epoch 2707: Train Loss = 0.1325, Test Loss = 1.1513876914978027:.4f\n",
      "Epoch 2708: Train Loss = 0.1518, Test Loss = 1.1367199420928955:.4f\n",
      "Epoch 2709: Train Loss = 0.1307, Test Loss = 1.1325743198394775:.4f\n",
      "Epoch 2710: Train Loss = 0.1482, Test Loss = 1.1200826168060303:.4f\n",
      "Epoch 2711: Train Loss = 0.1311, Test Loss = 1.1233738660812378:.4f\n",
      "Epoch 2712: Train Loss = 0.1385, Test Loss = 1.1174156665802002:.4f\n",
      "Epoch 2713: Train Loss = 0.1343, Test Loss = 1.1273767948150635:.4f\n",
      "Epoch 2714: Train Loss = 0.1299, Test Loss = 1.1439398527145386:.4f\n",
      "Epoch 2715: Train Loss = 0.1429, Test Loss = 1.1423673629760742:.4f\n",
      "Epoch 2716: Train Loss = 0.1432, Test Loss = 1.1266332864761353:.4f\n",
      "Epoch 2717: Train Loss = 0.1375, Test Loss = 1.1230192184448242:.4f\n",
      "Epoch 2718: Train Loss = 0.1546, Test Loss = 1.11590576171875:.4f\n",
      "Epoch 2719: Train Loss = 0.1337, Test Loss = 1.123645305633545:.4f\n",
      "Epoch 2720: Train Loss = 0.1281, Test Loss = 1.1292310953140259:.4f\n",
      "Epoch 2721: Train Loss = 0.1421, Test Loss = 1.1224950551986694:.4f\n",
      "Epoch 2722: Train Loss = 0.1439, Test Loss = 1.1293528079986572:.4f\n",
      "Epoch 2723: Train Loss = 0.1473, Test Loss = 1.1377806663513184:.4f\n",
      "Epoch 2724: Train Loss = 0.1480, Test Loss = 1.1460700035095215:.4f\n",
      "Epoch 2725: Train Loss = 0.1230, Test Loss = 1.1534901857376099:.4f\n",
      "Epoch 2726: Train Loss = 0.1325, Test Loss = 1.1445884704589844:.4f\n",
      "Epoch 2727: Train Loss = 0.1347, Test Loss = 1.132502794265747:.4f\n",
      "Epoch 2728: Train Loss = 0.1237, Test Loss = 1.118921160697937:.4f\n",
      "Epoch 2729: Train Loss = 0.1356, Test Loss = 1.1201575994491577:.4f\n",
      "Epoch 2730: Train Loss = 0.1376, Test Loss = 1.1380865573883057:.4f\n",
      "Epoch 2731: Train Loss = 0.1431, Test Loss = 1.1383635997772217:.4f\n",
      "Epoch 2732: Train Loss = 0.1422, Test Loss = 1.1303298473358154:.4f\n",
      "Epoch 2733: Train Loss = 0.1410, Test Loss = 1.1035889387130737:.4f\n",
      "Epoch 2734: Train Loss = 0.1349, Test Loss = 1.1059454679489136:.4f\n",
      "Epoch 2735: Train Loss = 0.1761, Test Loss = 1.127007246017456:.4f\n",
      "Epoch 2736: Train Loss = 0.1307, Test Loss = 1.1473249197006226:.4f\n",
      "Epoch 2737: Train Loss = 0.1320, Test Loss = 1.1619648933410645:.4f\n",
      "Epoch 2738: Train Loss = 0.1501, Test Loss = 1.1660547256469727:.4f\n",
      "Epoch 2739: Train Loss = 0.1679, Test Loss = 1.1647502183914185:.4f\n",
      "Epoch 2740: Train Loss = 0.1824, Test Loss = 1.1604620218276978:.4f\n",
      "Epoch 2741: Train Loss = 0.1862, Test Loss = 1.1542627811431885:.4f\n",
      "Epoch 2742: Train Loss = 0.1736, Test Loss = 1.1729953289031982:.4f\n",
      "Epoch 2743: Train Loss = 0.1369, Test Loss = 1.19552481174469:.4f\n",
      "Epoch 2744: Train Loss = 0.1625, Test Loss = 1.1783815622329712:.4f\n",
      "Epoch 2745: Train Loss = 0.1776, Test Loss = 1.1407673358917236:.4f\n",
      "Epoch 2746: Train Loss = 0.1589, Test Loss = 1.1153644323349:.4f\n",
      "Epoch 2747: Train Loss = 0.1449, Test Loss = 1.1079225540161133:.4f\n",
      "Epoch 2748: Train Loss = 0.1661, Test Loss = 1.1218092441558838:.4f\n",
      "Epoch 2749: Train Loss = 0.1694, Test Loss = 1.152673363685608:.4f\n",
      "Epoch 2750: Train Loss = 0.1319, Test Loss = 1.149375557899475:.4f\n",
      "Epoch 2751: Train Loss = 0.1596, Test Loss = 1.1388357877731323:.4f\n",
      "Epoch 2752: Train Loss = 0.1496, Test Loss = 1.130849003791809:.4f\n",
      "Epoch 2753: Train Loss = 0.1470, Test Loss = 1.134174108505249:.4f\n",
      "Epoch 2754: Train Loss = 0.1382, Test Loss = 1.1397128105163574:.4f\n",
      "Epoch 2755: Train Loss = 0.2288, Test Loss = 1.1375927925109863:.4f\n",
      "Epoch 2756: Train Loss = 0.1572, Test Loss = 1.1160669326782227:.4f\n",
      "Epoch 2757: Train Loss = 0.1959, Test Loss = 1.1387819051742554:.4f\n",
      "Epoch 2758: Train Loss = 0.1854, Test Loss = 1.1889474391937256:.4f\n",
      "Epoch 2759: Train Loss = 0.1600, Test Loss = 1.210723638534546:.4f\n",
      "Epoch 2760: Train Loss = 0.1585, Test Loss = 1.2045531272888184:.4f\n",
      "Epoch 2761: Train Loss = 0.1525, Test Loss = 1.1593626737594604:.4f\n",
      "Epoch 2762: Train Loss = 0.1405, Test Loss = 1.113957166671753:.4f\n",
      "Epoch 2763: Train Loss = 0.1448, Test Loss = 1.077813982963562:.4f\n",
      "Epoch 2764: Train Loss = 0.1420, Test Loss = 1.0782924890518188:.4f\n",
      "Epoch 2765: Train Loss = 0.1861, Test Loss = 1.1158850193023682:.4f\n",
      "Epoch 2766: Train Loss = 0.1886, Test Loss = 1.1604326963424683:.4f\n",
      "Epoch 2767: Train Loss = 0.1779, Test Loss = 1.1647799015045166:.4f\n",
      "Epoch 2768: Train Loss = 0.1749, Test Loss = 1.1381328105926514:.4f\n",
      "Epoch 2769: Train Loss = 0.1527, Test Loss = 1.1189125776290894:.4f\n",
      "Epoch 2770: Train Loss = 0.1574, Test Loss = 1.1323031187057495:.4f\n",
      "Epoch 2771: Train Loss = 0.1595, Test Loss = 1.1453583240509033:.4f\n",
      "Epoch 2772: Train Loss = 0.1604, Test Loss = 1.1656615734100342:.4f\n",
      "Epoch 2773: Train Loss = 0.1301, Test Loss = 1.1686729192733765:.4f\n",
      "Epoch 2774: Train Loss = 0.1737, Test Loss = 1.153003454208374:.4f\n",
      "Epoch 2775: Train Loss = 0.1666, Test Loss = 1.1337538957595825:.4f\n",
      "Epoch 2776: Train Loss = 0.1646, Test Loss = 1.1321395635604858:.4f\n",
      "Epoch 2777: Train Loss = 0.1576, Test Loss = 1.1255114078521729:.4f\n",
      "Epoch 2778: Train Loss = 0.1382, Test Loss = 1.1174051761627197:.4f\n",
      "Epoch 2779: Train Loss = 0.1264, Test Loss = 1.1045420169830322:.4f\n",
      "Epoch 2780: Train Loss = 0.1444, Test Loss = 1.106621503829956:.4f\n",
      "Epoch 2781: Train Loss = 0.1318, Test Loss = 1.130549669265747:.4f\n",
      "Epoch 2782: Train Loss = 0.1398, Test Loss = 1.1531612873077393:.4f\n",
      "Epoch 2783: Train Loss = 0.1428, Test Loss = 1.1726492643356323:.4f\n",
      "Epoch 2784: Train Loss = 0.1676, Test Loss = 1.172378659248352:.4f\n",
      "Epoch 2785: Train Loss = 0.1291, Test Loss = 1.1483629941940308:.4f\n",
      "Epoch 2786: Train Loss = 0.1353, Test Loss = 1.1220629215240479:.4f\n",
      "Epoch 2787: Train Loss = 0.1316, Test Loss = 1.1159985065460205:.4f\n",
      "Epoch 2788: Train Loss = 0.1399, Test Loss = 1.1150627136230469:.4f\n",
      "Epoch 2789: Train Loss = 0.1510, Test Loss = 1.1361958980560303:.4f\n",
      "Epoch 2790: Train Loss = 0.1792, Test Loss = 1.159869909286499:.4f\n",
      "Epoch 2791: Train Loss = 0.1412, Test Loss = 1.1706846952438354:.4f\n",
      "Epoch 2792: Train Loss = 0.1601, Test Loss = 1.1596848964691162:.4f\n",
      "Epoch 2793: Train Loss = 0.1320, Test Loss = 1.1399104595184326:.4f\n",
      "Epoch 2794: Train Loss = 0.1859, Test Loss = 1.1327495574951172:.4f\n",
      "Epoch 2795: Train Loss = 0.1368, Test Loss = 1.138801097869873:.4f\n",
      "Epoch 2796: Train Loss = 0.1686, Test Loss = 1.1635022163391113:.4f\n",
      "Epoch 2797: Train Loss = 0.1564, Test Loss = 1.1668843030929565:.4f\n",
      "Epoch 2798: Train Loss = 0.1424, Test Loss = 1.1637271642684937:.4f\n",
      "Epoch 2799: Train Loss = 0.1435, Test Loss = 1.144028902053833:.4f\n",
      "Epoch 2800: Train Loss = 0.1826, Test Loss = 1.1328718662261963:.4f\n",
      "Epoch 2801: Train Loss = 0.1384, Test Loss = 1.1241230964660645:.4f\n",
      "Epoch 2802: Train Loss = 0.1408, Test Loss = 1.1060841083526611:.4f\n",
      "Epoch 2803: Train Loss = 0.1714, Test Loss = 1.1120249032974243:.4f\n",
      "Epoch 2804: Train Loss = 0.1399, Test Loss = 1.1459431648254395:.4f\n",
      "Epoch 2805: Train Loss = 0.1553, Test Loss = 1.1523549556732178:.4f\n",
      "Epoch 2806: Train Loss = 0.1389, Test Loss = 1.1562321186065674:.4f\n",
      "Epoch 2807: Train Loss = 0.1286, Test Loss = 1.1432100534439087:.4f\n",
      "Epoch 2808: Train Loss = 0.1497, Test Loss = 1.13358736038208:.4f\n",
      "Epoch 2809: Train Loss = 0.1318, Test Loss = 1.1337268352508545:.4f\n",
      "Epoch 2810: Train Loss = 0.1507, Test Loss = 1.1260929107666016:.4f\n",
      "Epoch 2811: Train Loss = 0.1289, Test Loss = 1.1348985433578491:.4f\n",
      "Epoch 2812: Train Loss = 0.1768, Test Loss = 1.1555485725402832:.4f\n",
      "Epoch 2813: Train Loss = 0.1312, Test Loss = 1.1560863256454468:.4f\n",
      "Epoch 2814: Train Loss = 0.1575, Test Loss = 1.15816068649292:.4f\n",
      "Epoch 2815: Train Loss = 0.1460, Test Loss = 1.1532599925994873:.4f\n",
      "Epoch 2816: Train Loss = 0.1264, Test Loss = 1.1315358877182007:.4f\n",
      "Epoch 2817: Train Loss = 0.1363, Test Loss = 1.1171528100967407:.4f\n",
      "Epoch 2818: Train Loss = 0.1672, Test Loss = 1.1064434051513672:.4f\n",
      "Epoch 2819: Train Loss = 0.1669, Test Loss = 1.1126797199249268:.4f\n",
      "Epoch 2820: Train Loss = 0.1738, Test Loss = 1.1291357278823853:.4f\n",
      "Epoch 2821: Train Loss = 0.1257, Test Loss = 1.1576683521270752:.4f\n",
      "Epoch 2822: Train Loss = 0.1373, Test Loss = 1.172057032585144:.4f\n",
      "Epoch 2823: Train Loss = 0.1447, Test Loss = 1.1620886325836182:.4f\n",
      "Epoch 2824: Train Loss = 0.1423, Test Loss = 1.138551115989685:.4f\n",
      "Epoch 2825: Train Loss = 0.1421, Test Loss = 1.1265442371368408:.4f\n",
      "Epoch 2826: Train Loss = 0.1492, Test Loss = 1.120684027671814:.4f\n",
      "Epoch 2827: Train Loss = 0.1329, Test Loss = 1.1227580308914185:.4f\n",
      "Epoch 2828: Train Loss = 0.1270, Test Loss = 1.1453083753585815:.4f\n",
      "Epoch 2829: Train Loss = 0.1379, Test Loss = 1.1712002754211426:.4f\n",
      "Epoch 2830: Train Loss = 0.1368, Test Loss = 1.182448387145996:.4f\n",
      "Epoch 2831: Train Loss = 0.1678, Test Loss = 1.1581941843032837:.4f\n",
      "Epoch 2832: Train Loss = 0.1500, Test Loss = 1.1537874937057495:.4f\n",
      "Epoch 2833: Train Loss = 0.1567, Test Loss = 1.1364930868148804:.4f\n",
      "Epoch 2834: Train Loss = 0.1560, Test Loss = 1.130326271057129:.4f\n",
      "Epoch 2835: Train Loss = 0.1330, Test Loss = 1.1235759258270264:.4f\n",
      "Epoch 2836: Train Loss = 0.1344, Test Loss = 1.116941213607788:.4f\n",
      "Epoch 2837: Train Loss = 0.1342, Test Loss = 1.1171715259552002:.4f\n",
      "Epoch 2838: Train Loss = 0.1336, Test Loss = 1.1209437847137451:.4f\n",
      "Epoch 2839: Train Loss = 0.1427, Test Loss = 1.131617784500122:.4f\n",
      "Epoch 2840: Train Loss = 0.1451, Test Loss = 1.158493995666504:.4f\n",
      "Epoch 2841: Train Loss = 0.1433, Test Loss = 1.1724618673324585:.4f\n",
      "Epoch 2842: Train Loss = 0.1530, Test Loss = 1.1674426794052124:.4f\n",
      "Epoch 2843: Train Loss = 0.1689, Test Loss = 1.146843433380127:.4f\n",
      "Epoch 2844: Train Loss = 0.1295, Test Loss = 1.1201725006103516:.4f\n",
      "Epoch 2845: Train Loss = 0.1670, Test Loss = 1.1054596900939941:.4f\n",
      "Epoch 2846: Train Loss = 0.1528, Test Loss = 1.1062357425689697:.4f\n",
      "Epoch 2847: Train Loss = 0.1404, Test Loss = 1.107944369316101:.4f\n",
      "Epoch 2848: Train Loss = 0.1643, Test Loss = 1.1184017658233643:.4f\n",
      "Epoch 2849: Train Loss = 0.1377, Test Loss = 1.122679352760315:.4f\n",
      "Epoch 2850: Train Loss = 0.1619, Test Loss = 1.1116516590118408:.4f\n",
      "Epoch 2851: Train Loss = 0.1858, Test Loss = 1.1026651859283447:.4f\n",
      "Epoch 2852: Train Loss = 0.1450, Test Loss = 1.1247906684875488:.4f\n",
      "Epoch 2853: Train Loss = 0.1500, Test Loss = 1.1441926956176758:.4f\n",
      "Epoch 2854: Train Loss = 0.1693, Test Loss = 1.1538796424865723:.4f\n",
      "Epoch 2855: Train Loss = 0.1330, Test Loss = 1.1455833911895752:.4f\n",
      "Epoch 2856: Train Loss = 0.1304, Test Loss = 1.1267815828323364:.4f\n",
      "Epoch 2857: Train Loss = 0.1386, Test Loss = 1.1066334247589111:.4f\n",
      "Epoch 2858: Train Loss = 0.1496, Test Loss = 1.0851380825042725:.4f\n",
      "Epoch 2859: Train Loss = 0.1265, Test Loss = 1.0833162069320679:.4f\n",
      "Epoch 2860: Train Loss = 0.1351, Test Loss = 1.0961182117462158:.4f\n",
      "Epoch 2861: Train Loss = 0.1735, Test Loss = 1.1187264919281006:.4f\n",
      "Epoch 2862: Train Loss = 0.1346, Test Loss = 1.1309897899627686:.4f\n",
      "Epoch 2863: Train Loss = 0.1690, Test Loss = 1.128037691116333:.4f\n",
      "Epoch 2864: Train Loss = 0.1438, Test Loss = 1.133402943611145:.4f\n",
      "Epoch 2865: Train Loss = 0.1339, Test Loss = 1.1478445529937744:.4f\n",
      "Epoch 2866: Train Loss = 0.1493, Test Loss = 1.149708867073059:.4f\n",
      "Epoch 2867: Train Loss = 0.1288, Test Loss = 1.1408771276474:.4f\n",
      "Epoch 2868: Train Loss = 0.1595, Test Loss = 1.1307182312011719:.4f\n",
      "Epoch 2869: Train Loss = 0.1453, Test Loss = 1.1296747922897339:.4f\n",
      "Epoch 2870: Train Loss = 0.1376, Test Loss = 1.120742678642273:.4f\n",
      "Epoch 2871: Train Loss = 0.1382, Test Loss = 1.0988892316818237:.4f\n",
      "Epoch 2872: Train Loss = 0.1281, Test Loss = 1.0932128429412842:.4f\n",
      "Epoch 2873: Train Loss = 0.1342, Test Loss = 1.0980076789855957:.4f\n",
      "Epoch 2874: Train Loss = 0.1318, Test Loss = 1.1115154027938843:.4f\n",
      "Epoch 2875: Train Loss = 0.1629, Test Loss = 1.1212468147277832:.4f\n",
      "Epoch 2876: Train Loss = 0.1267, Test Loss = 1.1289317607879639:.4f\n",
      "Epoch 2877: Train Loss = 0.1352, Test Loss = 1.1388137340545654:.4f\n",
      "Epoch 2878: Train Loss = 0.1289, Test Loss = 1.1475123167037964:.4f\n",
      "Epoch 2879: Train Loss = 0.1345, Test Loss = 1.140993595123291:.4f\n",
      "Epoch 2880: Train Loss = 0.1293, Test Loss = 1.1234577894210815:.4f\n",
      "Epoch 2881: Train Loss = 0.1258, Test Loss = 1.113715410232544:.4f\n",
      "Epoch 2882: Train Loss = 0.1334, Test Loss = 1.1053898334503174:.4f\n",
      "Epoch 2883: Train Loss = 0.1525, Test Loss = 1.1172062158584595:.4f\n",
      "Epoch 2884: Train Loss = 0.1710, Test Loss = 1.1217567920684814:.4f\n",
      "Epoch 2885: Train Loss = 0.1384, Test Loss = 1.1156957149505615:.4f\n",
      "Epoch 2886: Train Loss = 0.1855, Test Loss = 1.1324448585510254:.4f\n",
      "Epoch 2887: Train Loss = 0.1313, Test Loss = 1.1508891582489014:.4f\n",
      "Epoch 2888: Train Loss = 0.1837, Test Loss = 1.1492929458618164:.4f\n",
      "Epoch 2889: Train Loss = 0.1338, Test Loss = 1.144654393196106:.4f\n",
      "Epoch 2890: Train Loss = 0.1546, Test Loss = 1.1313183307647705:.4f\n",
      "Epoch 2891: Train Loss = 0.1499, Test Loss = 1.1256463527679443:.4f\n",
      "Epoch 2892: Train Loss = 0.1318, Test Loss = 1.1222790479660034:.4f\n",
      "Epoch 2893: Train Loss = 0.1532, Test Loss = 1.1160671710968018:.4f\n",
      "Epoch 2894: Train Loss = 0.1321, Test Loss = 1.1109340190887451:.4f\n",
      "Epoch 2895: Train Loss = 0.1467, Test Loss = 1.1291279792785645:.4f\n",
      "Epoch 2896: Train Loss = 0.1349, Test Loss = 1.1328461170196533:.4f\n",
      "Epoch 2897: Train Loss = 0.2113, Test Loss = 1.1372623443603516:.4f\n",
      "Epoch 2898: Train Loss = 0.1612, Test Loss = 1.1232408285140991:.4f\n",
      "Epoch 2899: Train Loss = 0.1802, Test Loss = 1.1003334522247314:.4f\n",
      "Epoch 2900: Train Loss = 0.1294, Test Loss = 1.097274661064148:.4f\n",
      "Epoch 2901: Train Loss = 0.1459, Test Loss = 1.1065601110458374:.4f\n",
      "Epoch 2902: Train Loss = 0.1416, Test Loss = 1.1186845302581787:.4f\n",
      "Epoch 2903: Train Loss = 0.1942, Test Loss = 1.1279354095458984:.4f\n",
      "Epoch 2904: Train Loss = 0.1308, Test Loss = 1.1402055025100708:.4f\n",
      "Epoch 2905: Train Loss = 0.1446, Test Loss = 1.144789218902588:.4f\n",
      "Epoch 2906: Train Loss = 0.1369, Test Loss = 1.136474847793579:.4f\n",
      "Epoch 2907: Train Loss = 0.1405, Test Loss = 1.1259756088256836:.4f\n",
      "Epoch 2908: Train Loss = 0.1671, Test Loss = 1.1078513860702515:.4f\n",
      "Epoch 2909: Train Loss = 0.1699, Test Loss = 1.0944015979766846:.4f\n",
      "Epoch 2910: Train Loss = 0.1512, Test Loss = 1.1091848611831665:.4f\n",
      "Epoch 2911: Train Loss = 0.1831, Test Loss = 1.1240767240524292:.4f\n",
      "Epoch 2912: Train Loss = 0.1383, Test Loss = 1.1508095264434814:.4f\n",
      "Epoch 2913: Train Loss = 0.1266, Test Loss = 1.1546642780303955:.4f\n",
      "Epoch 2914: Train Loss = 0.1469, Test Loss = 1.139685869216919:.4f\n",
      "Epoch 2915: Train Loss = 0.1500, Test Loss = 1.1179786920547485:.4f\n",
      "Epoch 2916: Train Loss = 0.1961, Test Loss = 1.1068415641784668:.4f\n",
      "Epoch 2917: Train Loss = 0.1429, Test Loss = 1.1189076900482178:.4f\n",
      "Epoch 2918: Train Loss = 0.1298, Test Loss = 1.1426970958709717:.4f\n",
      "Epoch 2919: Train Loss = 0.1465, Test Loss = 1.149106740951538:.4f\n",
      "Epoch 2920: Train Loss = 0.1502, Test Loss = 1.141558051109314:.4f\n",
      "Epoch 2921: Train Loss = 0.1280, Test Loss = 1.1400216817855835:.4f\n",
      "Epoch 2922: Train Loss = 0.1364, Test Loss = 1.135606050491333:.4f\n",
      "Epoch 2923: Train Loss = 0.1612, Test Loss = 1.1417324542999268:.4f\n",
      "Epoch 2924: Train Loss = 0.1513, Test Loss = 1.1478087902069092:.4f\n",
      "Epoch 2925: Train Loss = 0.1343, Test Loss = 1.1523351669311523:.4f\n",
      "Epoch 2926: Train Loss = 0.1244, Test Loss = 1.1518434286117554:.4f\n",
      "Epoch 2927: Train Loss = 0.1503, Test Loss = 1.154151201248169:.4f\n",
      "Epoch 2928: Train Loss = 0.1607, Test Loss = 1.1530088186264038:.4f\n",
      "Epoch 2929: Train Loss = 0.1230, Test Loss = 1.151310682296753:.4f\n",
      "Epoch 2930: Train Loss = 0.1679, Test Loss = 1.1456782817840576:.4f\n",
      "Epoch 2931: Train Loss = 0.1297, Test Loss = 1.145840048789978:.4f\n",
      "Epoch 2932: Train Loss = 0.1441, Test Loss = 1.1504801511764526:.4f\n",
      "Epoch 2933: Train Loss = 0.1285, Test Loss = 1.1581412553787231:.4f\n",
      "Epoch 2934: Train Loss = 0.1643, Test Loss = 1.150086522102356:.4f\n",
      "Epoch 2935: Train Loss = 0.1293, Test Loss = 1.1360960006713867:.4f\n",
      "Epoch 2936: Train Loss = 0.1538, Test Loss = 1.1316020488739014:.4f\n",
      "Epoch 2937: Train Loss = 0.1638, Test Loss = 1.128369927406311:.4f\n",
      "Epoch 2938: Train Loss = 0.1765, Test Loss = 1.1279215812683105:.4f\n",
      "Epoch 2939: Train Loss = 0.1415, Test Loss = 1.1280999183654785:.4f\n",
      "Epoch 2940: Train Loss = 0.1491, Test Loss = 1.131408452987671:.4f\n",
      "Epoch 2941: Train Loss = 0.1397, Test Loss = 1.1326335668563843:.4f\n",
      "Epoch 2942: Train Loss = 0.1428, Test Loss = 1.1344105005264282:.4f\n",
      "Epoch 2943: Train Loss = 0.1318, Test Loss = 1.137935996055603:.4f\n",
      "Epoch 2944: Train Loss = 0.1375, Test Loss = 1.1231603622436523:.4f\n",
      "Epoch 2945: Train Loss = 0.1445, Test Loss = 1.1154087781906128:.4f\n",
      "Epoch 2946: Train Loss = 0.1356, Test Loss = 1.1119530200958252:.4f\n",
      "Epoch 2947: Train Loss = 0.1265, Test Loss = 1.125606894493103:.4f\n",
      "Epoch 2948: Train Loss = 0.1754, Test Loss = 1.1369235515594482:.4f\n",
      "Epoch 2949: Train Loss = 0.1578, Test Loss = 1.1515567302703857:.4f\n",
      "Epoch 2950: Train Loss = 0.1534, Test Loss = 1.1424176692962646:.4f\n",
      "Epoch 2951: Train Loss = 0.1563, Test Loss = 1.145675539970398:.4f\n",
      "Epoch 2952: Train Loss = 0.1537, Test Loss = 1.1490991115570068:.4f\n",
      "Epoch 2953: Train Loss = 0.1293, Test Loss = 1.1447649002075195:.4f\n",
      "Epoch 2954: Train Loss = 0.1645, Test Loss = 1.1361714601516724:.4f\n",
      "Epoch 2955: Train Loss = 0.1388, Test Loss = 1.1197580099105835:.4f\n",
      "Epoch 2956: Train Loss = 0.1447, Test Loss = 1.1197725534439087:.4f\n",
      "Epoch 2957: Train Loss = 0.1585, Test Loss = 1.1288217306137085:.4f\n",
      "Epoch 2958: Train Loss = 0.1597, Test Loss = 1.1560766696929932:.4f\n",
      "Epoch 2959: Train Loss = 0.1501, Test Loss = 1.1553876399993896:.4f\n",
      "Epoch 2960: Train Loss = 0.1501, Test Loss = 1.1477254629135132:.4f\n",
      "Epoch 2961: Train Loss = 0.1748, Test Loss = 1.1414172649383545:.4f\n",
      "Epoch 2962: Train Loss = 0.1713, Test Loss = 1.1323630809783936:.4f\n",
      "Epoch 2963: Train Loss = 0.1450, Test Loss = 1.1194567680358887:.4f\n",
      "Epoch 2964: Train Loss = 0.1523, Test Loss = 1.1181843280792236:.4f\n",
      "Epoch 2965: Train Loss = 0.1349, Test Loss = 1.1451916694641113:.4f\n",
      "Epoch 2966: Train Loss = 0.1540, Test Loss = 1.1517846584320068:.4f\n",
      "Epoch 2967: Train Loss = 0.1863, Test Loss = 1.1241991519927979:.4f\n",
      "Epoch 2968: Train Loss = 0.1334, Test Loss = 1.1119835376739502:.4f\n",
      "Epoch 2969: Train Loss = 0.1562, Test Loss = 1.1127375364303589:.4f\n",
      "Epoch 2970: Train Loss = 0.1309, Test Loss = 1.1301103830337524:.4f\n",
      "Epoch 2971: Train Loss = 0.1660, Test Loss = 1.1598622798919678:.4f\n",
      "Epoch 2972: Train Loss = 0.1551, Test Loss = 1.173537254333496:.4f\n",
      "Epoch 2973: Train Loss = 0.1426, Test Loss = 1.1606194972991943:.4f\n",
      "Epoch 2974: Train Loss = 0.1586, Test Loss = 1.1593787670135498:.4f\n",
      "Epoch 2975: Train Loss = 0.1761, Test Loss = 1.1618695259094238:.4f\n",
      "Epoch 2976: Train Loss = 0.1539, Test Loss = 1.1604888439178467:.4f\n",
      "Epoch 2977: Train Loss = 0.1449, Test Loss = 1.1400864124298096:.4f\n",
      "Epoch 2978: Train Loss = 0.1324, Test Loss = 1.1246309280395508:.4f\n",
      "Epoch 2979: Train Loss = 0.1498, Test Loss = 1.1198910474777222:.4f\n",
      "Epoch 2980: Train Loss = 0.1863, Test Loss = 1.1248362064361572:.4f\n",
      "Epoch 2981: Train Loss = 0.1591, Test Loss = 1.1225380897521973:.4f\n",
      "Epoch 2982: Train Loss = 0.1630, Test Loss = 1.1340278387069702:.4f\n",
      "Epoch 2983: Train Loss = 0.1709, Test Loss = 1.146043062210083:.4f\n",
      "Epoch 2984: Train Loss = 0.1292, Test Loss = 1.1544522047042847:.4f\n",
      "Epoch 2985: Train Loss = 0.1671, Test Loss = 1.1454722881317139:.4f\n",
      "Epoch 2986: Train Loss = 0.1341, Test Loss = 1.1277148723602295:.4f\n",
      "Epoch 2987: Train Loss = 0.1494, Test Loss = 1.1219030618667603:.4f\n",
      "Epoch 2988: Train Loss = 0.1608, Test Loss = 1.1303151845932007:.4f\n",
      "Epoch 2989: Train Loss = 0.1714, Test Loss = 1.1534297466278076:.4f\n",
      "Epoch 2990: Train Loss = 0.1708, Test Loss = 1.1672766208648682:.4f\n",
      "Epoch 2991: Train Loss = 0.1464, Test Loss = 1.151526927947998:.4f\n",
      "Epoch 2992: Train Loss = 0.1622, Test Loss = 1.1247106790542603:.4f\n",
      "Epoch 2993: Train Loss = 0.1321, Test Loss = 1.1166874170303345:.4f\n",
      "Epoch 2994: Train Loss = 0.1957, Test Loss = 1.1128417253494263:.4f\n",
      "Epoch 2995: Train Loss = 0.1310, Test Loss = 1.1293853521347046:.4f\n",
      "Epoch 2996: Train Loss = 0.1512, Test Loss = 1.138466238975525:.4f\n",
      "Epoch 2997: Train Loss = 0.1387, Test Loss = 1.1354502439498901:.4f\n",
      "Epoch 2998: Train Loss = 0.1543, Test Loss = 1.1265575885772705:.4f\n",
      "Epoch 2999: Train Loss = 0.1615, Test Loss = 1.112130880355835:.4f\n",
      "Epoch 3000: Train Loss = 0.1340, Test Loss = 1.1198692321777344:.4f\n",
      "Epoch 3001: Train Loss = 0.1458, Test Loss = 1.1345250606536865:.4f\n",
      "Epoch 3002: Train Loss = 0.1488, Test Loss = 1.1410247087478638:.4f\n",
      "Epoch 3003: Train Loss = 0.1324, Test Loss = 1.136228322982788:.4f\n",
      "Epoch 3004: Train Loss = 0.1407, Test Loss = 1.1199865341186523:.4f\n",
      "Epoch 3005: Train Loss = 0.1490, Test Loss = 1.1090960502624512:.4f\n",
      "Epoch 3006: Train Loss = 0.1268, Test Loss = 1.1245273351669312:.4f\n",
      "Epoch 3007: Train Loss = 0.1265, Test Loss = 1.152835488319397:.4f\n",
      "Epoch 3008: Train Loss = 0.1435, Test Loss = 1.1724926233291626:.4f\n",
      "Epoch 3009: Train Loss = 0.1444, Test Loss = 1.1540018320083618:.4f\n",
      "Epoch 3010: Train Loss = 0.1514, Test Loss = 1.1330329179763794:.4f\n",
      "Epoch 3011: Train Loss = 0.1414, Test Loss = 1.1189121007919312:.4f\n",
      "Epoch 3012: Train Loss = 0.1587, Test Loss = 1.119889259338379:.4f\n",
      "Epoch 3013: Train Loss = 0.1357, Test Loss = 1.1463167667388916:.4f\n",
      "Epoch 3014: Train Loss = 0.1731, Test Loss = 1.160516381263733:.4f\n",
      "Epoch 3015: Train Loss = 0.1385, Test Loss = 1.1510794162750244:.4f\n",
      "Epoch 3016: Train Loss = 0.1411, Test Loss = 1.127777099609375:.4f\n",
      "Epoch 3017: Train Loss = 0.1341, Test Loss = 1.130125880241394:.4f\n",
      "Epoch 3018: Train Loss = 0.1762, Test Loss = 1.1317025423049927:.4f\n",
      "Epoch 3019: Train Loss = 0.1339, Test Loss = 1.1161696910858154:.4f\n",
      "Epoch 3020: Train Loss = 0.1466, Test Loss = 1.112623929977417:.4f\n",
      "Epoch 3021: Train Loss = 0.1671, Test Loss = 1.1229274272918701:.4f\n",
      "Epoch 3022: Train Loss = 0.1902, Test Loss = 1.125343680381775:.4f\n",
      "Epoch 3023: Train Loss = 0.1461, Test Loss = 1.1156197786331177:.4f\n",
      "Epoch 3024: Train Loss = 0.1685, Test Loss = 1.1133508682250977:.4f\n",
      "Epoch 3025: Train Loss = 0.1337, Test Loss = 1.1181824207305908:.4f\n",
      "Epoch 3026: Train Loss = 0.1265, Test Loss = 1.1254520416259766:.4f\n",
      "Epoch 3027: Train Loss = 0.1341, Test Loss = 1.1245242357254028:.4f\n",
      "Epoch 3028: Train Loss = 0.1533, Test Loss = 1.1245330572128296:.4f\n",
      "Epoch 3029: Train Loss = 0.1674, Test Loss = 1.118713617324829:.4f\n",
      "Epoch 3030: Train Loss = 0.1323, Test Loss = 1.1184663772583008:.4f\n",
      "Epoch 3031: Train Loss = 0.1642, Test Loss = 1.1442911624908447:.4f\n",
      "Epoch 3032: Train Loss = 0.1295, Test Loss = 1.1759494543075562:.4f\n",
      "Epoch 3033: Train Loss = 0.1252, Test Loss = 1.183882474899292:.4f\n",
      "Epoch 3034: Train Loss = 0.1346, Test Loss = 1.166023850440979:.4f\n",
      "Epoch 3035: Train Loss = 0.1815, Test Loss = 1.1372692584991455:.4f\n",
      "Epoch 3036: Train Loss = 0.1533, Test Loss = 1.1058167219161987:.4f\n",
      "Epoch 3037: Train Loss = 0.1433, Test Loss = 1.1005046367645264:.4f\n",
      "Epoch 3038: Train Loss = 0.1408, Test Loss = 1.1061646938323975:.4f\n",
      "Epoch 3039: Train Loss = 0.1737, Test Loss = 1.119009256362915:.4f\n",
      "Epoch 3040: Train Loss = 0.1379, Test Loss = 1.1199795007705688:.4f\n",
      "Epoch 3041: Train Loss = 0.1239, Test Loss = 1.1221957206726074:.4f\n",
      "Epoch 3042: Train Loss = 0.1675, Test Loss = 1.1218504905700684:.4f\n",
      "Epoch 3043: Train Loss = 0.1635, Test Loss = 1.11747145652771:.4f\n",
      "Epoch 3044: Train Loss = 0.1508, Test Loss = 1.110803484916687:.4f\n",
      "Epoch 3045: Train Loss = 0.1631, Test Loss = 1.1154650449752808:.4f\n",
      "Epoch 3046: Train Loss = 0.1886, Test Loss = 1.1232528686523438:.4f\n",
      "Epoch 3047: Train Loss = 0.1362, Test Loss = 1.1308410167694092:.4f\n",
      "Epoch 3048: Train Loss = 0.1758, Test Loss = 1.1498504877090454:.4f\n",
      "Epoch 3049: Train Loss = 0.1541, Test Loss = 1.170616865158081:.4f\n",
      "Epoch 3050: Train Loss = 0.1527, Test Loss = 1.1595745086669922:.4f\n",
      "Epoch 3051: Train Loss = 0.1365, Test Loss = 1.1494489908218384:.4f\n",
      "Epoch 3052: Train Loss = 0.1697, Test Loss = 1.1336349248886108:.4f\n",
      "Epoch 3053: Train Loss = 0.1664, Test Loss = 1.1194584369659424:.4f\n",
      "Epoch 3054: Train Loss = 0.1649, Test Loss = 1.107421875:.4f\n",
      "Epoch 3055: Train Loss = 0.1660, Test Loss = 1.0955723524093628:.4f\n",
      "Epoch 3056: Train Loss = 0.1486, Test Loss = 1.1060073375701904:.4f\n",
      "Epoch 3057: Train Loss = 0.1527, Test Loss = 1.1261122226715088:.4f\n",
      "Epoch 3058: Train Loss = 0.1366, Test Loss = 1.1585075855255127:.4f\n",
      "Epoch 3059: Train Loss = 0.1357, Test Loss = 1.1624412536621094:.4f\n",
      "Epoch 3060: Train Loss = 0.1380, Test Loss = 1.1550571918487549:.4f\n",
      "Epoch 3061: Train Loss = 0.1348, Test Loss = 1.1361104249954224:.4f\n",
      "Epoch 3062: Train Loss = 0.1275, Test Loss = 1.1088839769363403:.4f\n",
      "Epoch 3063: Train Loss = 0.1484, Test Loss = 1.1004736423492432:.4f\n",
      "Epoch 3064: Train Loss = 0.1385, Test Loss = 1.1142992973327637:.4f\n",
      "Epoch 3065: Train Loss = 0.1521, Test Loss = 1.135413408279419:.4f\n",
      "Epoch 3066: Train Loss = 0.1498, Test Loss = 1.151801347732544:.4f\n",
      "Epoch 3067: Train Loss = 0.1439, Test Loss = 1.1568137407302856:.4f\n",
      "Epoch 3068: Train Loss = 0.1971, Test Loss = 1.1520086526870728:.4f\n",
      "Epoch 3069: Train Loss = 0.1782, Test Loss = 1.1412104368209839:.4f\n",
      "Epoch 3070: Train Loss = 0.1673, Test Loss = 1.1379140615463257:.4f\n",
      "Epoch 3071: Train Loss = 0.1240, Test Loss = 1.1371312141418457:.4f\n",
      "Epoch 3072: Train Loss = 0.1483, Test Loss = 1.1236507892608643:.4f\n",
      "Epoch 3073: Train Loss = 0.1618, Test Loss = 1.1066429615020752:.4f\n",
      "Epoch 3074: Train Loss = 0.1686, Test Loss = 1.1174596548080444:.4f\n",
      "Epoch 3075: Train Loss = 0.1374, Test Loss = 1.1437251567840576:.4f\n",
      "Epoch 3076: Train Loss = 0.1475, Test Loss = 1.1463278532028198:.4f\n",
      "Epoch 3077: Train Loss = 0.1289, Test Loss = 1.1387836933135986:.4f\n",
      "Epoch 3078: Train Loss = 0.1707, Test Loss = 1.133484125137329:.4f\n",
      "Epoch 3079: Train Loss = 0.1365, Test Loss = 1.1084178686141968:.4f\n",
      "Epoch 3080: Train Loss = 0.1368, Test Loss = 1.0965898036956787:.4f\n",
      "Epoch 3081: Train Loss = 0.1660, Test Loss = 1.0960921049118042:.4f\n",
      "Epoch 3082: Train Loss = 0.1312, Test Loss = 1.1155844926834106:.4f\n",
      "Epoch 3083: Train Loss = 0.1452, Test Loss = 1.1401723623275757:.4f\n",
      "Epoch 3084: Train Loss = 0.1324, Test Loss = 1.1356916427612305:.4f\n",
      "Epoch 3085: Train Loss = 0.1264, Test Loss = 1.1284739971160889:.4f\n",
      "Epoch 3086: Train Loss = 0.1340, Test Loss = 1.1156812906265259:.4f\n",
      "Epoch 3087: Train Loss = 0.1375, Test Loss = 1.1057627201080322:.4f\n",
      "Epoch 3088: Train Loss = 0.1387, Test Loss = 1.1183849573135376:.4f\n",
      "Epoch 3089: Train Loss = 0.1535, Test Loss = 1.1295762062072754:.4f\n",
      "Epoch 3090: Train Loss = 0.1433, Test Loss = 1.1405353546142578:.4f\n",
      "Epoch 3091: Train Loss = 0.1251, Test Loss = 1.146117925643921:.4f\n",
      "Epoch 3092: Train Loss = 0.1595, Test Loss = 1.1492555141448975:.4f\n",
      "Epoch 3093: Train Loss = 0.1593, Test Loss = 1.141037940979004:.4f\n",
      "Epoch 3094: Train Loss = 0.1692, Test Loss = 1.1195261478424072:.4f\n",
      "Epoch 3095: Train Loss = 0.1641, Test Loss = 1.1086652278900146:.4f\n",
      "Epoch 3096: Train Loss = 0.1252, Test Loss = 1.1093947887420654:.4f\n",
      "Epoch 3097: Train Loss = 0.1473, Test Loss = 1.1093990802764893:.4f\n",
      "Epoch 3098: Train Loss = 0.1464, Test Loss = 1.1192419528961182:.4f\n",
      "Epoch 3099: Train Loss = 0.1347, Test Loss = 1.1352417469024658:.4f\n",
      "Epoch 3100: Train Loss = 0.1565, Test Loss = 1.152137279510498:.4f\n",
      "Epoch 3101: Train Loss = 0.1253, Test Loss = 1.1558506488800049:.4f\n",
      "Epoch 3102: Train Loss = 0.1404, Test Loss = 1.142416000366211:.4f\n",
      "Epoch 3103: Train Loss = 0.1307, Test Loss = 1.1256743669509888:.4f\n",
      "Epoch 3104: Train Loss = 0.1298, Test Loss = 1.1050878763198853:.4f\n",
      "Epoch 3105: Train Loss = 0.1377, Test Loss = 1.118369698524475:.4f\n",
      "Epoch 3106: Train Loss = 0.1421, Test Loss = 1.1326301097869873:.4f\n",
      "Epoch 3107: Train Loss = 0.1404, Test Loss = 1.1563297510147095:.4f\n",
      "Epoch 3108: Train Loss = 0.1302, Test Loss = 1.1502015590667725:.4f\n",
      "Epoch 3109: Train Loss = 0.1462, Test Loss = 1.1277309656143188:.4f\n",
      "Epoch 3110: Train Loss = 0.1253, Test Loss = 1.1234089136123657:.4f\n",
      "Epoch 3111: Train Loss = 0.1864, Test Loss = 1.117658019065857:.4f\n",
      "Epoch 3112: Train Loss = 0.1602, Test Loss = 1.116847276687622:.4f\n",
      "Epoch 3113: Train Loss = 0.1475, Test Loss = 1.1188925504684448:.4f\n",
      "Epoch 3114: Train Loss = 0.1357, Test Loss = 1.1315771341323853:.4f\n",
      "Epoch 3115: Train Loss = 0.2080, Test Loss = 1.143336534500122:.4f\n",
      "Epoch 3116: Train Loss = 0.1287, Test Loss = 1.1320048570632935:.4f\n",
      "Epoch 3117: Train Loss = 0.1606, Test Loss = 1.1417485475540161:.4f\n",
      "Epoch 3118: Train Loss = 0.1497, Test Loss = 1.130801796913147:.4f\n",
      "Epoch 3119: Train Loss = 0.1806, Test Loss = 1.1381580829620361:.4f\n",
      "Epoch 3120: Train Loss = 0.1369, Test Loss = 1.120929479598999:.4f\n",
      "Epoch 3121: Train Loss = 0.1314, Test Loss = 1.1016247272491455:.4f\n",
      "Epoch 3122: Train Loss = 0.1774, Test Loss = 1.1046068668365479:.4f\n",
      "Epoch 3123: Train Loss = 0.1719, Test Loss = 1.1313620805740356:.4f\n",
      "Epoch 3124: Train Loss = 0.1408, Test Loss = 1.128563642501831:.4f\n",
      "Epoch 3125: Train Loss = 0.1349, Test Loss = 1.1242204904556274:.4f\n",
      "Epoch 3126: Train Loss = 0.1717, Test Loss = 1.126489281654358:.4f\n",
      "Epoch 3127: Train Loss = 0.1374, Test Loss = 1.135939359664917:.4f\n",
      "Epoch 3128: Train Loss = 0.1486, Test Loss = 1.147200345993042:.4f\n",
      "Epoch 3129: Train Loss = 0.1357, Test Loss = 1.1377508640289307:.4f\n",
      "Epoch 3130: Train Loss = 0.1472, Test Loss = 1.1261975765228271:.4f\n",
      "Epoch 3131: Train Loss = 0.1587, Test Loss = 1.1304422616958618:.4f\n",
      "Epoch 3132: Train Loss = 0.1347, Test Loss = 1.1382067203521729:.4f\n",
      "Epoch 3133: Train Loss = 0.1539, Test Loss = 1.1493968963623047:.4f\n",
      "Epoch 3134: Train Loss = 0.1487, Test Loss = 1.147505760192871:.4f\n",
      "Epoch 3135: Train Loss = 0.1454, Test Loss = 1.148919939994812:.4f\n",
      "Epoch 3136: Train Loss = 0.1890, Test Loss = 1.1301939487457275:.4f\n",
      "Epoch 3137: Train Loss = 0.1844, Test Loss = 1.1365758180618286:.4f\n",
      "Epoch 3138: Train Loss = 0.1558, Test Loss = 1.1396560668945312:.4f\n",
      "Epoch 3139: Train Loss = 0.1583, Test Loss = 1.1418706178665161:.4f\n",
      "Epoch 3140: Train Loss = 0.1769, Test Loss = 1.133979320526123:.4f\n",
      "Epoch 3141: Train Loss = 0.1696, Test Loss = 1.1255046129226685:.4f\n",
      "Epoch 3142: Train Loss = 0.1268, Test Loss = 1.1171175241470337:.4f\n",
      "Epoch 3143: Train Loss = 0.1428, Test Loss = 1.1170704364776611:.4f\n",
      "Epoch 3144: Train Loss = 0.1272, Test Loss = 1.1251317262649536:.4f\n",
      "Epoch 3145: Train Loss = 0.1919, Test Loss = 1.1333340406417847:.4f\n",
      "Epoch 3146: Train Loss = 0.1324, Test Loss = 1.1330792903900146:.4f\n",
      "Epoch 3147: Train Loss = 0.1454, Test Loss = 1.1239898204803467:.4f\n",
      "Epoch 3148: Train Loss = 0.1332, Test Loss = 1.1271450519561768:.4f\n",
      "Epoch 3149: Train Loss = 0.1413, Test Loss = 1.1296038627624512:.4f\n",
      "Epoch 3150: Train Loss = 0.1914, Test Loss = 1.1397600173950195:.4f\n",
      "Epoch 3151: Train Loss = 0.1600, Test Loss = 1.1398457288742065:.4f\n",
      "Epoch 3152: Train Loss = 0.1696, Test Loss = 1.1474554538726807:.4f\n",
      "Epoch 3153: Train Loss = 0.1598, Test Loss = 1.174214243888855:.4f\n",
      "Epoch 3154: Train Loss = 0.1705, Test Loss = 1.1814906597137451:.4f\n",
      "Epoch 3155: Train Loss = 0.1506, Test Loss = 1.184216022491455:.4f\n",
      "Epoch 3156: Train Loss = 0.1354, Test Loss = 1.1549630165100098:.4f\n",
      "Epoch 3157: Train Loss = 0.1348, Test Loss = 1.1183257102966309:.4f\n",
      "Epoch 3158: Train Loss = 0.1703, Test Loss = 1.0852936506271362:.4f\n",
      "Epoch 3159: Train Loss = 0.1549, Test Loss = 1.0779507160186768:.4f\n",
      "Epoch 3160: Train Loss = 0.1846, Test Loss = 1.10146164894104:.4f\n",
      "Epoch 3161: Train Loss = 0.1515, Test Loss = 1.1571054458618164:.4f\n",
      "Epoch 3162: Train Loss = 0.1391, Test Loss = 1.184372067451477:.4f\n",
      "Epoch 3163: Train Loss = 0.1459, Test Loss = 1.1644985675811768:.4f\n",
      "Epoch 3164: Train Loss = 0.1732, Test Loss = 1.13447105884552:.4f\n",
      "Epoch 3165: Train Loss = 0.1632, Test Loss = 1.1233532428741455:.4f\n",
      "Epoch 3166: Train Loss = 0.1620, Test Loss = 1.1124427318572998:.4f\n",
      "Epoch 3167: Train Loss = 0.1798, Test Loss = 1.1259268522262573:.4f\n",
      "Epoch 3168: Train Loss = 0.1245, Test Loss = 1.140432596206665:.4f\n",
      "Epoch 3169: Train Loss = 0.1242, Test Loss = 1.152561902999878:.4f\n",
      "Epoch 3170: Train Loss = 0.1256, Test Loss = 1.1554309129714966:.4f\n",
      "Epoch 3171: Train Loss = 0.1339, Test Loss = 1.1448931694030762:.4f\n",
      "Epoch 3172: Train Loss = 0.1642, Test Loss = 1.1255847215652466:.4f\n",
      "Epoch 3173: Train Loss = 0.1463, Test Loss = 1.12541663646698:.4f\n",
      "Epoch 3174: Train Loss = 0.1420, Test Loss = 1.139535903930664:.4f\n",
      "Epoch 3175: Train Loss = 0.1580, Test Loss = 1.1501784324645996:.4f\n",
      "Epoch 3176: Train Loss = 0.1947, Test Loss = 1.141425609588623:.4f\n",
      "Epoch 3177: Train Loss = 0.1231, Test Loss = 1.1291792392730713:.4f\n",
      "Epoch 3178: Train Loss = 0.1570, Test Loss = 1.1289111375808716:.4f\n",
      "Epoch 3179: Train Loss = 0.1239, Test Loss = 1.1475772857666016:.4f\n",
      "Epoch 3180: Train Loss = 0.1302, Test Loss = 1.1558997631072998:.4f\n",
      "Epoch 3181: Train Loss = 0.1317, Test Loss = 1.147284984588623:.4f\n",
      "Epoch 3182: Train Loss = 0.1419, Test Loss = 1.1332361698150635:.4f\n",
      "Epoch 3183: Train Loss = 0.1337, Test Loss = 1.1278587579727173:.4f\n",
      "Epoch 3184: Train Loss = 0.1542, Test Loss = 1.1180894374847412:.4f\n",
      "Epoch 3185: Train Loss = 0.1362, Test Loss = 1.1249144077301025:.4f\n",
      "Epoch 3186: Train Loss = 0.1705, Test Loss = 1.1354568004608154:.4f\n",
      "Epoch 3187: Train Loss = 0.1348, Test Loss = 1.1518102884292603:.4f\n",
      "Epoch 3188: Train Loss = 0.1730, Test Loss = 1.1712452173233032:.4f\n",
      "Epoch 3189: Train Loss = 0.1808, Test Loss = 1.2008650302886963:.4f\n",
      "Epoch 3190: Train Loss = 0.1346, Test Loss = 1.2039976119995117:.4f\n",
      "Epoch 3191: Train Loss = 0.1647, Test Loss = 1.1744210720062256:.4f\n",
      "Epoch 3192: Train Loss = 0.1264, Test Loss = 1.1467106342315674:.4f\n",
      "Epoch 3193: Train Loss = 0.1550, Test Loss = 1.1280992031097412:.4f\n",
      "Epoch 3194: Train Loss = 0.1385, Test Loss = 1.1098556518554688:.4f\n",
      "Epoch 3195: Train Loss = 0.1318, Test Loss = 1.121260166168213:.4f\n",
      "Epoch 3196: Train Loss = 0.1519, Test Loss = 1.1436083316802979:.4f\n",
      "Epoch 3197: Train Loss = 0.1627, Test Loss = 1.148606538772583:.4f\n",
      "Epoch 3198: Train Loss = 0.1795, Test Loss = 1.1410893201828003:.4f\n",
      "Epoch 3199: Train Loss = 0.1575, Test Loss = 1.1315391063690186:.4f\n",
      "Epoch 3200: Train Loss = 0.1494, Test Loss = 1.129540205001831:.4f\n",
      "Epoch 3201: Train Loss = 0.1328, Test Loss = 1.1215097904205322:.4f\n",
      "Epoch 3202: Train Loss = 0.1573, Test Loss = 1.129874587059021:.4f\n",
      "Epoch 3203: Train Loss = 0.1685, Test Loss = 1.1346445083618164:.4f\n",
      "Epoch 3204: Train Loss = 0.1579, Test Loss = 1.1408828496932983:.4f\n",
      "Epoch 3205: Train Loss = 0.1449, Test Loss = 1.1551048755645752:.4f\n",
      "Epoch 3206: Train Loss = 0.1417, Test Loss = 1.1652084589004517:.4f\n",
      "Epoch 3207: Train Loss = 0.1810, Test Loss = 1.1558457612991333:.4f\n",
      "Epoch 3208: Train Loss = 0.1229, Test Loss = 1.143859624862671:.4f\n",
      "Epoch 3209: Train Loss = 0.1277, Test Loss = 1.1299550533294678:.4f\n",
      "Epoch 3210: Train Loss = 0.1878, Test Loss = 1.1201450824737549:.4f\n",
      "Epoch 3211: Train Loss = 0.1702, Test Loss = 1.133065938949585:.4f\n",
      "Epoch 3212: Train Loss = 0.1314, Test Loss = 1.1468223333358765:.4f\n",
      "Epoch 3213: Train Loss = 0.1434, Test Loss = 1.1537654399871826:.4f\n",
      "Epoch 3214: Train Loss = 0.1407, Test Loss = 1.1547586917877197:.4f\n",
      "Epoch 3215: Train Loss = 0.1581, Test Loss = 1.1444554328918457:.4f\n",
      "Epoch 3216: Train Loss = 0.1465, Test Loss = 1.1307318210601807:.4f\n",
      "Epoch 3217: Train Loss = 0.1634, Test Loss = 1.1116130352020264:.4f\n",
      "Epoch 3218: Train Loss = 0.1561, Test Loss = 1.1084253787994385:.4f\n",
      "Epoch 3219: Train Loss = 0.1704, Test Loss = 1.134455680847168:.4f\n",
      "Epoch 3220: Train Loss = 0.1487, Test Loss = 1.1582930088043213:.4f\n",
      "Epoch 3221: Train Loss = 0.1500, Test Loss = 1.1508243083953857:.4f\n",
      "Epoch 3222: Train Loss = 0.1333, Test Loss = 1.1270965337753296:.4f\n",
      "Epoch 3223: Train Loss = 0.1512, Test Loss = 1.1113413572311401:.4f\n",
      "Epoch 3224: Train Loss = 0.1729, Test Loss = 1.1074036359786987:.4f\n",
      "Epoch 3225: Train Loss = 0.1521, Test Loss = 1.10773766040802:.4f\n",
      "Epoch 3226: Train Loss = 0.1340, Test Loss = 1.1388144493103027:.4f\n",
      "Epoch 3227: Train Loss = 0.1472, Test Loss = 1.153247594833374:.4f\n",
      "Epoch 3228: Train Loss = 0.1460, Test Loss = 1.1577341556549072:.4f\n",
      "Epoch 3229: Train Loss = 0.1372, Test Loss = 1.147141695022583:.4f\n",
      "Epoch 3230: Train Loss = 0.1693, Test Loss = 1.1119840145111084:.4f\n",
      "Epoch 3231: Train Loss = 0.1365, Test Loss = 1.0913597345352173:.4f\n",
      "Epoch 3232: Train Loss = 0.1750, Test Loss = 1.0974018573760986:.4f\n",
      "Epoch 3233: Train Loss = 0.1675, Test Loss = 1.1107761859893799:.4f\n",
      "Epoch 3234: Train Loss = 0.1760, Test Loss = 1.138606309890747:.4f\n",
      "Epoch 3235: Train Loss = 0.1694, Test Loss = 1.1366182565689087:.4f\n",
      "Epoch 3236: Train Loss = 0.1563, Test Loss = 1.1423105001449585:.4f\n",
      "Epoch 3237: Train Loss = 0.1238, Test Loss = 1.1346244812011719:.4f\n",
      "Epoch 3238: Train Loss = 0.1451, Test Loss = 1.1424163579940796:.4f\n",
      "Epoch 3239: Train Loss = 0.1351, Test Loss = 1.1512004137039185:.4f\n",
      "Epoch 3240: Train Loss = 0.1409, Test Loss = 1.1467311382293701:.4f\n",
      "Epoch 3241: Train Loss = 0.1288, Test Loss = 1.1328949928283691:.4f\n",
      "Epoch 3242: Train Loss = 0.1933, Test Loss = 1.123543620109558:.4f\n",
      "Epoch 3243: Train Loss = 0.1211, Test Loss = 1.1324387788772583:.4f\n",
      "Epoch 3244: Train Loss = 0.1424, Test Loss = 1.1376584768295288:.4f\n",
      "Epoch 3245: Train Loss = 0.1347, Test Loss = 1.1413367986679077:.4f\n",
      "Epoch 3246: Train Loss = 0.1525, Test Loss = 1.1319236755371094:.4f\n",
      "Epoch 3247: Train Loss = 0.1507, Test Loss = 1.1454451084136963:.4f\n",
      "Epoch 3248: Train Loss = 0.1617, Test Loss = 1.1419684886932373:.4f\n",
      "Epoch 3249: Train Loss = 0.1596, Test Loss = 1.1413615942001343:.4f\n",
      "Epoch 3250: Train Loss = 0.1253, Test Loss = 1.150322675704956:.4f\n",
      "Epoch 3251: Train Loss = 0.1585, Test Loss = 1.1458303928375244:.4f\n",
      "Epoch 3252: Train Loss = 0.1416, Test Loss = 1.1482115983963013:.4f\n",
      "Epoch 3253: Train Loss = 0.1334, Test Loss = 1.1408756971359253:.4f\n",
      "Epoch 3254: Train Loss = 0.1204, Test Loss = 1.1221740245819092:.4f\n",
      "Epoch 3255: Train Loss = 0.1759, Test Loss = 1.1179786920547485:.4f\n",
      "Epoch 3256: Train Loss = 0.1443, Test Loss = 1.1240028142929077:.4f\n",
      "Epoch 3257: Train Loss = 0.1434, Test Loss = 1.1408525705337524:.4f\n",
      "Epoch 3258: Train Loss = 0.1582, Test Loss = 1.1558996438980103:.4f\n",
      "Epoch 3259: Train Loss = 0.1369, Test Loss = 1.161820650100708:.4f\n",
      "Epoch 3260: Train Loss = 0.1550, Test Loss = 1.1541551351547241:.4f\n",
      "Epoch 3261: Train Loss = 0.1658, Test Loss = 1.1284061670303345:.4f\n",
      "Epoch 3262: Train Loss = 0.1307, Test Loss = 1.1296093463897705:.4f\n",
      "Epoch 3263: Train Loss = 0.1699, Test Loss = 1.122951865196228:.4f\n",
      "Epoch 3264: Train Loss = 0.1411, Test Loss = 1.1194777488708496:.4f\n",
      "Epoch 3265: Train Loss = 0.1714, Test Loss = 1.125451922416687:.4f\n",
      "Epoch 3266: Train Loss = 0.1630, Test Loss = 1.1390116214752197:.4f\n",
      "Epoch 3267: Train Loss = 0.1729, Test Loss = 1.139707088470459:.4f\n",
      "Epoch 3268: Train Loss = 0.1357, Test Loss = 1.1308481693267822:.4f\n",
      "Epoch 3269: Train Loss = 0.1522, Test Loss = 1.124680757522583:.4f\n",
      "Epoch 3270: Train Loss = 0.1418, Test Loss = 1.1395771503448486:.4f\n",
      "Epoch 3271: Train Loss = 0.1289, Test Loss = 1.1428052186965942:.4f\n",
      "Epoch 3272: Train Loss = 0.1774, Test Loss = 1.1373097896575928:.4f\n",
      "Epoch 3273: Train Loss = 0.1566, Test Loss = 1.1329638957977295:.4f\n",
      "Epoch 3274: Train Loss = 0.1681, Test Loss = 1.1465297937393188:.4f\n",
      "Epoch 3275: Train Loss = 0.1354, Test Loss = 1.1478348970413208:.4f\n",
      "Epoch 3276: Train Loss = 0.1520, Test Loss = 1.1443477869033813:.4f\n",
      "Epoch 3277: Train Loss = 0.1455, Test Loss = 1.1571563482284546:.4f\n",
      "Epoch 3278: Train Loss = 0.1281, Test Loss = 1.1364117860794067:.4f\n",
      "Epoch 3279: Train Loss = 0.1406, Test Loss = 1.1212412118911743:.4f\n",
      "Epoch 3280: Train Loss = 0.1327, Test Loss = 1.1124107837677002:.4f\n",
      "Epoch 3281: Train Loss = 0.1723, Test Loss = 1.0976598262786865:.4f\n",
      "Epoch 3282: Train Loss = 0.1573, Test Loss = 1.093750238418579:.4f\n",
      "Epoch 3283: Train Loss = 0.1699, Test Loss = 1.1141555309295654:.4f\n",
      "Epoch 3284: Train Loss = 0.1287, Test Loss = 1.1263271570205688:.4f\n",
      "Epoch 3285: Train Loss = 0.1311, Test Loss = 1.147072434425354:.4f\n",
      "Epoch 3286: Train Loss = 0.1910, Test Loss = 1.1500438451766968:.4f\n",
      "Epoch 3287: Train Loss = 0.1579, Test Loss = 1.133838176727295:.4f\n",
      "Epoch 3288: Train Loss = 0.1766, Test Loss = 1.1318200826644897:.4f\n",
      "Epoch 3289: Train Loss = 0.1434, Test Loss = 1.135375738143921:.4f\n",
      "Epoch 3290: Train Loss = 0.1682, Test Loss = 1.1530992984771729:.4f\n",
      "Epoch 3291: Train Loss = 0.1716, Test Loss = 1.1780585050582886:.4f\n",
      "Epoch 3292: Train Loss = 0.1745, Test Loss = 1.1674453020095825:.4f\n",
      "Epoch 3293: Train Loss = 0.1753, Test Loss = 1.1421239376068115:.4f\n",
      "Epoch 3294: Train Loss = 0.1711, Test Loss = 1.1431105136871338:.4f\n",
      "Epoch 3295: Train Loss = 0.1772, Test Loss = 1.1667959690093994:.4f\n",
      "Epoch 3296: Train Loss = 0.1573, Test Loss = 1.1802057027816772:.4f\n",
      "Epoch 3297: Train Loss = 0.1669, Test Loss = 1.1758089065551758:.4f\n",
      "Epoch 3298: Train Loss = 0.1374, Test Loss = 1.1551299095153809:.4f\n",
      "Epoch 3299: Train Loss = 0.1363, Test Loss = 1.1397308111190796:.4f\n",
      "Epoch 3300: Train Loss = 0.1754, Test Loss = 1.126387357711792:.4f\n",
      "Epoch 3301: Train Loss = 0.1258, Test Loss = 1.1312187910079956:.4f\n",
      "Epoch 3302: Train Loss = 0.1485, Test Loss = 1.1457808017730713:.4f\n",
      "Epoch 3303: Train Loss = 0.1369, Test Loss = 1.1518431901931763:.4f\n",
      "Epoch 3304: Train Loss = 0.1888, Test Loss = 1.1528795957565308:.4f\n",
      "Epoch 3305: Train Loss = 0.1475, Test Loss = 1.1543498039245605:.4f\n",
      "Epoch 3306: Train Loss = 0.1318, Test Loss = 1.1375646591186523:.4f\n",
      "Epoch 3307: Train Loss = 0.1369, Test Loss = 1.1233307123184204:.4f\n",
      "Epoch 3308: Train Loss = 0.1271, Test Loss = 1.1202857494354248:.4f\n",
      "Epoch 3309: Train Loss = 0.1442, Test Loss = 1.1228138208389282:.4f\n",
      "Epoch 3310: Train Loss = 0.1619, Test Loss = 1.105262041091919:.4f\n",
      "Epoch 3311: Train Loss = 0.1453, Test Loss = 1.127711534500122:.4f\n",
      "Epoch 3312: Train Loss = 0.1318, Test Loss = 1.1491702795028687:.4f\n",
      "Epoch 3313: Train Loss = 0.1368, Test Loss = 1.1671022176742554:.4f\n",
      "Epoch 3314: Train Loss = 0.1253, Test Loss = 1.1719123125076294:.4f\n",
      "Epoch 3315: Train Loss = 0.1390, Test Loss = 1.1571624279022217:.4f\n",
      "Epoch 3316: Train Loss = 0.1387, Test Loss = 1.1318531036376953:.4f\n",
      "Epoch 3317: Train Loss = 0.1325, Test Loss = 1.118971586227417:.4f\n",
      "Epoch 3318: Train Loss = 0.1609, Test Loss = 1.1283981800079346:.4f\n",
      "Epoch 3319: Train Loss = 0.1329, Test Loss = 1.1537201404571533:.4f\n",
      "Epoch 3320: Train Loss = 0.1409, Test Loss = 1.1639305353164673:.4f\n",
      "Epoch 3321: Train Loss = 0.1418, Test Loss = 1.1523877382278442:.4f\n",
      "Epoch 3322: Train Loss = 0.1223, Test Loss = 1.1562085151672363:.4f\n",
      "Epoch 3323: Train Loss = 0.1257, Test Loss = 1.1603361368179321:.4f\n",
      "Epoch 3324: Train Loss = 0.1668, Test Loss = 1.1612226963043213:.4f\n",
      "Epoch 3325: Train Loss = 0.1391, Test Loss = 1.1590604782104492:.4f\n",
      "Epoch 3326: Train Loss = 0.1320, Test Loss = 1.152825951576233:.4f\n",
      "Epoch 3327: Train Loss = 0.1426, Test Loss = 1.1395018100738525:.4f\n",
      "Epoch 3328: Train Loss = 0.1643, Test Loss = 1.111377477645874:.4f\n",
      "Epoch 3329: Train Loss = 0.1320, Test Loss = 1.1097712516784668:.4f\n",
      "Epoch 3330: Train Loss = 0.1801, Test Loss = 1.1140178442001343:.4f\n",
      "Epoch 3331: Train Loss = 0.1694, Test Loss = 1.146462082862854:.4f\n",
      "Epoch 3332: Train Loss = 0.1524, Test Loss = 1.1597702503204346:.4f\n",
      "Epoch 3333: Train Loss = 0.1658, Test Loss = 1.158385992050171:.4f\n",
      "Epoch 3334: Train Loss = 0.1515, Test Loss = 1.1645289659500122:.4f\n",
      "Epoch 3335: Train Loss = 0.1608, Test Loss = 1.1501843929290771:.4f\n",
      "Epoch 3336: Train Loss = 0.1302, Test Loss = 1.146004319190979:.4f\n",
      "Epoch 3337: Train Loss = 0.1249, Test Loss = 1.1388227939605713:.4f\n",
      "Epoch 3338: Train Loss = 0.1595, Test Loss = 1.1299158334732056:.4f\n",
      "Epoch 3339: Train Loss = 0.1566, Test Loss = 1.1283750534057617:.4f\n",
      "Epoch 3340: Train Loss = 0.1613, Test Loss = 1.1481544971466064:.4f\n",
      "Epoch 3341: Train Loss = 0.1800, Test Loss = 1.1588895320892334:.4f\n",
      "Epoch 3342: Train Loss = 0.1746, Test Loss = 1.1574698686599731:.4f\n",
      "Epoch 3343: Train Loss = 0.1583, Test Loss = 1.1400344371795654:.4f\n",
      "Epoch 3344: Train Loss = 0.1364, Test Loss = 1.135676622390747:.4f\n",
      "Epoch 3345: Train Loss = 0.1418, Test Loss = 1.120752215385437:.4f\n",
      "Epoch 3346: Train Loss = 0.1364, Test Loss = 1.1092020273208618:.4f\n",
      "Epoch 3347: Train Loss = 0.1239, Test Loss = 1.1057780981063843:.4f\n",
      "Epoch 3348: Train Loss = 0.1293, Test Loss = 1.1199467182159424:.4f\n",
      "Epoch 3349: Train Loss = 0.1678, Test Loss = 1.1419618129730225:.4f\n",
      "Epoch 3350: Train Loss = 0.1493, Test Loss = 1.1457092761993408:.4f\n",
      "Epoch 3351: Train Loss = 0.1335, Test Loss = 1.133729338645935:.4f\n",
      "Epoch 3352: Train Loss = 0.1523, Test Loss = 1.1334123611450195:.4f\n",
      "Epoch 3353: Train Loss = 0.1736, Test Loss = 1.1411406993865967:.4f\n",
      "Epoch 3354: Train Loss = 0.1229, Test Loss = 1.1510469913482666:.4f\n",
      "Epoch 3355: Train Loss = 0.1593, Test Loss = 1.1603899002075195:.4f\n",
      "Epoch 3356: Train Loss = 0.1327, Test Loss = 1.1625398397445679:.4f\n",
      "Epoch 3357: Train Loss = 0.1315, Test Loss = 1.1452089548110962:.4f\n",
      "Epoch 3358: Train Loss = 0.1254, Test Loss = 1.140162706375122:.4f\n",
      "Epoch 3359: Train Loss = 0.1721, Test Loss = 1.130450963973999:.4f\n",
      "Epoch 3360: Train Loss = 0.1401, Test Loss = 1.131483554840088:.4f\n",
      "Epoch 3361: Train Loss = 0.1552, Test Loss = 1.143186092376709:.4f\n",
      "Epoch 3362: Train Loss = 0.1342, Test Loss = 1.1505112648010254:.4f\n",
      "Epoch 3363: Train Loss = 0.1340, Test Loss = 1.1583218574523926:.4f\n",
      "Epoch 3364: Train Loss = 0.1230, Test Loss = 1.157356858253479:.4f\n",
      "Epoch 3365: Train Loss = 0.1319, Test Loss = 1.1441253423690796:.4f\n",
      "Epoch 3366: Train Loss = 0.1375, Test Loss = 1.1272913217544556:.4f\n",
      "Epoch 3367: Train Loss = 0.1390, Test Loss = 1.1277626752853394:.4f\n",
      "Epoch 3368: Train Loss = 0.1389, Test Loss = 1.1404755115509033:.4f\n",
      "Epoch 3369: Train Loss = 0.1239, Test Loss = 1.1586859226226807:.4f\n",
      "Epoch 3370: Train Loss = 0.1572, Test Loss = 1.1542813777923584:.4f\n",
      "Epoch 3371: Train Loss = 0.1258, Test Loss = 1.1428048610687256:.4f\n",
      "Epoch 3372: Train Loss = 0.1371, Test Loss = 1.1362011432647705:.4f\n",
      "Epoch 3373: Train Loss = 0.1290, Test Loss = 1.132340669631958:.4f\n",
      "Epoch 3374: Train Loss = 0.1483, Test Loss = 1.1473314762115479:.4f\n",
      "Epoch 3375: Train Loss = 0.1472, Test Loss = 1.1559773683547974:.4f\n",
      "Epoch 3376: Train Loss = 0.1363, Test Loss = 1.158447027206421:.4f\n",
      "Epoch 3377: Train Loss = 0.1685, Test Loss = 1.143920660018921:.4f\n",
      "Epoch 3378: Train Loss = 0.1646, Test Loss = 1.1455981731414795:.4f\n",
      "Epoch 3379: Train Loss = 0.1853, Test Loss = 1.1473562717437744:.4f\n",
      "Epoch 3380: Train Loss = 0.1340, Test Loss = 1.1526339054107666:.4f\n",
      "Epoch 3381: Train Loss = 0.1351, Test Loss = 1.1611053943634033:.4f\n",
      "Epoch 3382: Train Loss = 0.1639, Test Loss = 1.1634323596954346:.4f\n",
      "Epoch 3383: Train Loss = 0.1390, Test Loss = 1.150122046470642:.4f\n",
      "Epoch 3384: Train Loss = 0.1537, Test Loss = 1.1419751644134521:.4f\n",
      "Epoch 3385: Train Loss = 0.1762, Test Loss = 1.136314868927002:.4f\n",
      "Epoch 3386: Train Loss = 0.1265, Test Loss = 1.1373586654663086:.4f\n",
      "Epoch 3387: Train Loss = 0.1404, Test Loss = 1.1306551694869995:.4f\n",
      "Epoch 3388: Train Loss = 0.1562, Test Loss = 1.1239569187164307:.4f\n",
      "Epoch 3389: Train Loss = 0.1352, Test Loss = 1.138556718826294:.4f\n",
      "Epoch 3390: Train Loss = 0.1651, Test Loss = 1.1490086317062378:.4f\n",
      "Epoch 3391: Train Loss = 0.1605, Test Loss = 1.1435571908950806:.4f\n",
      "Epoch 3392: Train Loss = 0.1585, Test Loss = 1.1513268947601318:.4f\n",
      "Epoch 3393: Train Loss = 0.1687, Test Loss = 1.138991117477417:.4f\n",
      "Epoch 3394: Train Loss = 0.1440, Test Loss = 1.1336352825164795:.4f\n",
      "Epoch 3395: Train Loss = 0.1523, Test Loss = 1.1269711256027222:.4f\n",
      "Epoch 3396: Train Loss = 0.1658, Test Loss = 1.138671636581421:.4f\n",
      "Epoch 3397: Train Loss = 0.1847, Test Loss = 1.130955696105957:.4f\n",
      "Epoch 3398: Train Loss = 0.1480, Test Loss = 1.1098105907440186:.4f\n",
      "Epoch 3399: Train Loss = 0.1646, Test Loss = 1.106177568435669:.4f\n",
      "Epoch 3400: Train Loss = 0.1462, Test Loss = 1.126287579536438:.4f\n",
      "Epoch 3401: Train Loss = 0.1799, Test Loss = 1.1584786176681519:.4f\n",
      "Epoch 3402: Train Loss = 0.1253, Test Loss = 1.1799046993255615:.4f\n",
      "Epoch 3403: Train Loss = 0.1666, Test Loss = 1.1722246408462524:.4f\n",
      "Epoch 3404: Train Loss = 0.1519, Test Loss = 1.1507192850112915:.4f\n",
      "Epoch 3405: Train Loss = 0.1334, Test Loss = 1.1272166967391968:.4f\n",
      "Epoch 3406: Train Loss = 0.1343, Test Loss = 1.1164871454238892:.4f\n",
      "Epoch 3407: Train Loss = 0.1383, Test Loss = 1.0952013731002808:.4f\n",
      "Epoch 3408: Train Loss = 0.1977, Test Loss = 1.0865296125411987:.4f\n",
      "Epoch 3409: Train Loss = 0.1328, Test Loss = 1.119356632232666:.4f\n",
      "Epoch 3410: Train Loss = 0.1434, Test Loss = 1.1711534261703491:.4f\n",
      "Epoch 3411: Train Loss = 0.1359, Test Loss = 1.2021267414093018:.4f\n",
      "Epoch 3412: Train Loss = 0.1403, Test Loss = 1.195629596710205:.4f\n",
      "Epoch 3413: Train Loss = 0.1290, Test Loss = 1.1703159809112549:.4f\n",
      "Epoch 3414: Train Loss = 0.1407, Test Loss = 1.1468441486358643:.4f\n",
      "Epoch 3415: Train Loss = 0.1340, Test Loss = 1.1402134895324707:.4f\n",
      "Epoch 3416: Train Loss = 0.1351, Test Loss = 1.1274772882461548:.4f\n",
      "Epoch 3417: Train Loss = 0.1873, Test Loss = 1.1221116781234741:.4f\n",
      "Epoch 3418: Train Loss = 0.1434, Test Loss = 1.1004528999328613:.4f\n",
      "Epoch 3419: Train Loss = 0.1653, Test Loss = 1.114863634109497:.4f\n",
      "Epoch 3420: Train Loss = 0.1473, Test Loss = 1.13079035282135:.4f\n",
      "Epoch 3421: Train Loss = 0.1424, Test Loss = 1.1518306732177734:.4f\n",
      "Epoch 3422: Train Loss = 0.1391, Test Loss = 1.1642811298370361:.4f\n",
      "Epoch 3423: Train Loss = 0.1391, Test Loss = 1.1615562438964844:.4f\n",
      "Epoch 3424: Train Loss = 0.1527, Test Loss = 1.1420501470565796:.4f\n",
      "Epoch 3425: Train Loss = 0.1683, Test Loss = 1.117796540260315:.4f\n",
      "Epoch 3426: Train Loss = 0.1549, Test Loss = 1.133561134338379:.4f\n",
      "Epoch 3427: Train Loss = 0.1386, Test Loss = 1.1486455202102661:.4f\n",
      "Epoch 3428: Train Loss = 0.1582, Test Loss = 1.1522778272628784:.4f\n",
      "Epoch 3429: Train Loss = 0.1437, Test Loss = 1.1518718004226685:.4f\n",
      "Epoch 3430: Train Loss = 0.1660, Test Loss = 1.1448816061019897:.4f\n",
      "Epoch 3431: Train Loss = 0.1416, Test Loss = 1.1277804374694824:.4f\n",
      "Epoch 3432: Train Loss = 0.1803, Test Loss = 1.1224620342254639:.4f\n",
      "Epoch 3433: Train Loss = 0.1654, Test Loss = 1.1299970149993896:.4f\n",
      "Epoch 3434: Train Loss = 0.1387, Test Loss = 1.1463289260864258:.4f\n",
      "Epoch 3435: Train Loss = 0.1858, Test Loss = 1.1595500707626343:.4f\n",
      "Epoch 3436: Train Loss = 0.1493, Test Loss = 1.1646188497543335:.4f\n",
      "Epoch 3437: Train Loss = 0.1259, Test Loss = 1.1567537784576416:.4f\n",
      "Epoch 3438: Train Loss = 0.1250, Test Loss = 1.1569163799285889:.4f\n",
      "Epoch 3439: Train Loss = 0.1427, Test Loss = 1.1681594848632812:.4f\n",
      "Epoch 3440: Train Loss = 0.1278, Test Loss = 1.1514688730239868:.4f\n",
      "Epoch 3441: Train Loss = 0.1619, Test Loss = 1.1339213848114014:.4f\n",
      "Epoch 3442: Train Loss = 0.1327, Test Loss = 1.1305936574935913:.4f\n",
      "Epoch 3443: Train Loss = 0.1241, Test Loss = 1.134312391281128:.4f\n",
      "Epoch 3444: Train Loss = 0.1771, Test Loss = 1.1413545608520508:.4f\n",
      "Epoch 3445: Train Loss = 0.1254, Test Loss = 1.1311233043670654:.4f\n",
      "Epoch 3446: Train Loss = 0.1461, Test Loss = 1.1302207708358765:.4f\n",
      "Epoch 3447: Train Loss = 0.1446, Test Loss = 1.1298805475234985:.4f\n",
      "Epoch 3448: Train Loss = 0.1609, Test Loss = 1.1500589847564697:.4f\n",
      "Epoch 3449: Train Loss = 0.1602, Test Loss = 1.1488914489746094:.4f\n",
      "Epoch 3450: Train Loss = 0.2030, Test Loss = 1.1570543050765991:.4f\n",
      "Epoch 3451: Train Loss = 0.1449, Test Loss = 1.1575992107391357:.4f\n",
      "Epoch 3452: Train Loss = 0.1294, Test Loss = 1.1616191864013672:.4f\n",
      "Epoch 3453: Train Loss = 0.1261, Test Loss = 1.151309847831726:.4f\n",
      "Epoch 3454: Train Loss = 0.1388, Test Loss = 1.1347248554229736:.4f\n",
      "Epoch 3455: Train Loss = 0.1305, Test Loss = 1.136983036994934:.4f\n",
      "Epoch 3456: Train Loss = 0.1301, Test Loss = 1.1390706300735474:.4f\n",
      "Epoch 3457: Train Loss = 0.1568, Test Loss = 1.139357089996338:.4f\n",
      "Epoch 3458: Train Loss = 0.1444, Test Loss = 1.1541788578033447:.4f\n",
      "Epoch 3459: Train Loss = 0.1440, Test Loss = 1.1432435512542725:.4f\n",
      "Epoch 3460: Train Loss = 0.1580, Test Loss = 1.12346613407135:.4f\n",
      "Epoch 3461: Train Loss = 0.1437, Test Loss = 1.1139944791793823:.4f\n",
      "Epoch 3462: Train Loss = 0.1494, Test Loss = 1.1115515232086182:.4f\n",
      "Epoch 3463: Train Loss = 0.1532, Test Loss = 1.1286200284957886:.4f\n",
      "Epoch 3464: Train Loss = 0.1442, Test Loss = 1.150460958480835:.4f\n",
      "Epoch 3465: Train Loss = 0.1383, Test Loss = 1.1678314208984375:.4f\n",
      "Epoch 3466: Train Loss = 0.1536, Test Loss = 1.1635457277297974:.4f\n",
      "Epoch 3467: Train Loss = 0.1968, Test Loss = 1.1606030464172363:.4f\n",
      "Epoch 3468: Train Loss = 0.1430, Test Loss = 1.1439945697784424:.4f\n",
      "Epoch 3469: Train Loss = 0.1528, Test Loss = 1.1275811195373535:.4f\n",
      "Epoch 3470: Train Loss = 0.1499, Test Loss = 1.1453816890716553:.4f\n",
      "Epoch 3471: Train Loss = 0.1697, Test Loss = 1.1502172946929932:.4f\n",
      "Epoch 3472: Train Loss = 0.1725, Test Loss = 1.1457974910736084:.4f\n",
      "Epoch 3473: Train Loss = 0.1540, Test Loss = 1.145229697227478:.4f\n",
      "Epoch 3474: Train Loss = 0.1605, Test Loss = 1.1631596088409424:.4f\n",
      "Epoch 3475: Train Loss = 0.1905, Test Loss = 1.1737865209579468:.4f\n",
      "Epoch 3476: Train Loss = 0.1545, Test Loss = 1.1867960691452026:.4f\n",
      "Epoch 3477: Train Loss = 0.1275, Test Loss = 1.1662490367889404:.4f\n",
      "Epoch 3478: Train Loss = 0.1537, Test Loss = 1.144633173942566:.4f\n",
      "Epoch 3479: Train Loss = 0.1542, Test Loss = 1.1278092861175537:.4f\n",
      "Epoch 3480: Train Loss = 0.1707, Test Loss = 1.1251986026763916:.4f\n",
      "Epoch 3481: Train Loss = 0.1437, Test Loss = 1.117621898651123:.4f\n",
      "Epoch 3482: Train Loss = 0.1415, Test Loss = 1.113925814628601:.4f\n",
      "Epoch 3483: Train Loss = 0.1457, Test Loss = 1.1525590419769287:.4f\n",
      "Epoch 3484: Train Loss = 0.1388, Test Loss = 1.1783360242843628:.4f\n",
      "Epoch 3485: Train Loss = 0.1251, Test Loss = 1.1846673488616943:.4f\n",
      "Epoch 3486: Train Loss = 0.1506, Test Loss = 1.1795191764831543:.4f\n",
      "Epoch 3487: Train Loss = 0.1404, Test Loss = 1.1521708965301514:.4f\n",
      "Epoch 3488: Train Loss = 0.1336, Test Loss = 1.1302624940872192:.4f\n",
      "Epoch 3489: Train Loss = 0.1355, Test Loss = 1.1196908950805664:.4f\n",
      "Epoch 3490: Train Loss = 0.1314, Test Loss = 1.110393762588501:.4f\n",
      "Epoch 3491: Train Loss = 0.1954, Test Loss = 1.1221086978912354:.4f\n",
      "Epoch 3492: Train Loss = 0.1260, Test Loss = 1.1506476402282715:.4f\n",
      "Epoch 3493: Train Loss = 0.1460, Test Loss = 1.1803557872772217:.4f\n",
      "Epoch 3494: Train Loss = 0.1445, Test Loss = 1.1871182918548584:.4f\n",
      "Epoch 3495: Train Loss = 0.1409, Test Loss = 1.1658532619476318:.4f\n",
      "Epoch 3496: Train Loss = 0.1671, Test Loss = 1.1340208053588867:.4f\n",
      "Epoch 3497: Train Loss = 0.1631, Test Loss = 1.0887818336486816:.4f\n",
      "Epoch 3498: Train Loss = 0.1475, Test Loss = 1.1014697551727295:.4f\n",
      "Epoch 3499: Train Loss = 0.1700, Test Loss = 1.1325247287750244:.4f\n",
      "Epoch 3500: Train Loss = 0.1786, Test Loss = 1.1614208221435547:.4f\n"
     ]
    }
   ],
   "source": [
    "model = NN(input_size, num_classes)\n",
    "train_model(model, train_loader, test_loader, epochs = 3500,lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdbdd0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e6a471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npatience (int) : how many epochs to wait after last improvement\\nmin_delta (float) : min change to qualify improvement\\nverbose (bool) : if true prints the message for each improvement\\npath (str) to save best model \\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "patience (int) : how many epochs to wait after last improvement\n",
    "min_delta (float) : min change to qualify improvement\n",
    "verbose (bool) : if true prints the message for each improvement\n",
    "path (str) to save best model \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd3692e",
   "metadata": {},
   "source": [
    "# early stopping implemented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82f1d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0, verbose=False, path='checkpoint'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.path=path\n",
    "        self.best_model_weight = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss   # bcz we want to minimize the loss\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "            \n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                # if self.verbose:\n",
    "                #     print(\"Early stopping triggered.\")\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "            \n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        ''' Saves model when val loss improves'''\n",
    "        if self.verbose:\n",
    "            print(f\"Validation loss improved. Saving model to {self.path}\")\n",
    "        torch.save(model.state_dict(), self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3111f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def train_model(model, train_loader, test_loader, epochs=3500, lr=0.01, patience=350, min_delta=0.0):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    early_stopper = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for input_feature_batch, input_label_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(input_feature_batch)\n",
    "            loss = loss_fn(preds, input_label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_train_loss/ len(train_loader)\n",
    "        train_losses.append(avg_train_loss)    \n",
    "        \n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for input_feature_batch,input_label_batch in test_loader:\n",
    "                 preds = model(input_feature_batch)\n",
    "                 loss = loss_fn(preds, input_label_batch)\n",
    "                 running_test_loss += loss.item()\n",
    "                 \n",
    "        avg_test_loss = running_test_loss/ len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Test Loss = {avg_test_loss:.4f}\") \n",
    "        \n",
    "        early_stopper(avg_test_loss, model)\n",
    "        \n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered , Training stopped\")   \n",
    "            break\n",
    "        \n",
    "    model.load_state_dict(torch.load(early_stopper.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a0e8025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.7077, Test Loss = 0.6980\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 2: Train Loss = 0.6915, Test Loss = 0.7019\n",
      "EarlyStopping counter: 1 / 300\n",
      "Epoch 3: Train Loss = 0.6921, Test Loss = 0.7029\n",
      "EarlyStopping counter: 2 / 300\n",
      "Epoch 4: Train Loss = 0.6782, Test Loss = 0.7100\n",
      "EarlyStopping counter: 3 / 300\n",
      "Epoch 5: Train Loss = 0.6780, Test Loss = 0.7179\n",
      "EarlyStopping counter: 4 / 300\n",
      "Epoch 6: Train Loss = 0.6708, Test Loss = 0.7227\n",
      "EarlyStopping counter: 5 / 300\n",
      "Epoch 7: Train Loss = 0.6649, Test Loss = 0.7249\n",
      "EarlyStopping counter: 6 / 300\n",
      "Epoch 8: Train Loss = 0.6621, Test Loss = 0.7220\n",
      "EarlyStopping counter: 7 / 300\n",
      "Epoch 9: Train Loss = 0.6496, Test Loss = 0.7180\n",
      "EarlyStopping counter: 8 / 300\n",
      "Epoch 10: Train Loss = 0.6524, Test Loss = 0.7162\n",
      "EarlyStopping counter: 9 / 300\n",
      "Epoch 11: Train Loss = 0.6426, Test Loss = 0.7146\n",
      "EarlyStopping counter: 10 / 300\n",
      "Epoch 12: Train Loss = 0.6462, Test Loss = 0.7135\n",
      "EarlyStopping counter: 11 / 300\n",
      "Epoch 13: Train Loss = 0.6345, Test Loss = 0.7133\n",
      "EarlyStopping counter: 12 / 300\n",
      "Epoch 14: Train Loss = 0.6199, Test Loss = 0.7131\n",
      "EarlyStopping counter: 13 / 300\n",
      "Epoch 15: Train Loss = 0.6261, Test Loss = 0.7178\n",
      "EarlyStopping counter: 14 / 300\n",
      "Epoch 16: Train Loss = 0.6069, Test Loss = 0.7175\n",
      "EarlyStopping counter: 15 / 300\n",
      "Epoch 17: Train Loss = 0.6255, Test Loss = 0.7287\n",
      "EarlyStopping counter: 16 / 300\n",
      "Epoch 18: Train Loss = 0.6038, Test Loss = 0.7307\n",
      "EarlyStopping counter: 17 / 300\n",
      "Epoch 19: Train Loss = 0.6029, Test Loss = 0.7349\n",
      "EarlyStopping counter: 18 / 300\n",
      "Epoch 20: Train Loss = 0.6002, Test Loss = 0.7328\n",
      "EarlyStopping counter: 19 / 300\n",
      "Epoch 21: Train Loss = 0.6073, Test Loss = 0.7249\n",
      "EarlyStopping counter: 20 / 300\n",
      "Epoch 22: Train Loss = 0.5784, Test Loss = 0.7215\n",
      "EarlyStopping counter: 21 / 300\n",
      "Epoch 23: Train Loss = 0.5829, Test Loss = 0.7181\n",
      "EarlyStopping counter: 22 / 300\n",
      "Epoch 24: Train Loss = 0.5740, Test Loss = 0.7148\n",
      "EarlyStopping counter: 23 / 300\n",
      "Epoch 25: Train Loss = 0.5771, Test Loss = 0.7116\n",
      "EarlyStopping counter: 24 / 300\n",
      "Epoch 26: Train Loss = 0.5731, Test Loss = 0.7067\n",
      "EarlyStopping counter: 25 / 300\n",
      "Epoch 27: Train Loss = 0.5598, Test Loss = 0.7011\n",
      "EarlyStopping counter: 26 / 300\n",
      "Epoch 28: Train Loss = 0.5579, Test Loss = 0.6946\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 29: Train Loss = 0.5581, Test Loss = 0.6919\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 30: Train Loss = 0.5415, Test Loss = 0.6853\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 31: Train Loss = 0.5351, Test Loss = 0.6819\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 32: Train Loss = 0.5540, Test Loss = 0.6732\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 33: Train Loss = 0.5207, Test Loss = 0.6651\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 34: Train Loss = 0.5269, Test Loss = 0.6581\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 35: Train Loss = 0.5249, Test Loss = 0.6561\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 36: Train Loss = 0.5093, Test Loss = 0.6603\n",
      "EarlyStopping counter: 1 / 300\n",
      "Epoch 37: Train Loss = 0.5063, Test Loss = 0.6689\n",
      "EarlyStopping counter: 2 / 300\n",
      "Epoch 38: Train Loss = 0.5110, Test Loss = 0.6746\n",
      "EarlyStopping counter: 3 / 300\n",
      "Epoch 39: Train Loss = 0.5028, Test Loss = 0.6651\n",
      "EarlyStopping counter: 4 / 300\n",
      "Epoch 40: Train Loss = 0.4902, Test Loss = 0.6638\n",
      "EarlyStopping counter: 5 / 300\n",
      "Epoch 41: Train Loss = 0.4968, Test Loss = 0.6530\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 42: Train Loss = 0.4748, Test Loss = 0.6398\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 43: Train Loss = 0.4730, Test Loss = 0.6254\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 44: Train Loss = 0.4664, Test Loss = 0.6130\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 45: Train Loss = 0.4674, Test Loss = 0.6108\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 46: Train Loss = 0.4480, Test Loss = 0.6133\n",
      "EarlyStopping counter: 1 / 300\n",
      "Epoch 47: Train Loss = 0.4428, Test Loss = 0.6237\n",
      "EarlyStopping counter: 2 / 300\n",
      "Epoch 48: Train Loss = 0.4400, Test Loss = 0.6346\n",
      "EarlyStopping counter: 3 / 300\n",
      "Epoch 49: Train Loss = 0.4611, Test Loss = 0.6261\n",
      "EarlyStopping counter: 4 / 300\n",
      "Epoch 50: Train Loss = 0.4473, Test Loss = 0.6094\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 51: Train Loss = 0.4324, Test Loss = 0.6015\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 52: Train Loss = 0.4125, Test Loss = 0.6079\n",
      "EarlyStopping counter: 1 / 300\n",
      "Epoch 53: Train Loss = 0.4148, Test Loss = 0.6137\n",
      "EarlyStopping counter: 2 / 300\n",
      "Epoch 54: Train Loss = 0.4177, Test Loss = 0.6178\n",
      "EarlyStopping counter: 3 / 300\n",
      "Epoch 55: Train Loss = 0.3966, Test Loss = 0.6180\n",
      "EarlyStopping counter: 4 / 300\n",
      "Epoch 56: Train Loss = 0.4016, Test Loss = 0.6123\n",
      "EarlyStopping counter: 5 / 300\n",
      "Epoch 57: Train Loss = 0.4009, Test Loss = 0.6049\n",
      "EarlyStopping counter: 6 / 300\n",
      "Epoch 58: Train Loss = 0.3816, Test Loss = 0.6162\n",
      "EarlyStopping counter: 7 / 300\n",
      "Epoch 59: Train Loss = 0.4019, Test Loss = 0.6144\n",
      "EarlyStopping counter: 8 / 300\n",
      "Epoch 60: Train Loss = 0.3779, Test Loss = 0.6075\n",
      "EarlyStopping counter: 9 / 300\n",
      "Epoch 61: Train Loss = 0.3869, Test Loss = 0.6121\n",
      "EarlyStopping counter: 10 / 300\n",
      "Epoch 62: Train Loss = 0.3775, Test Loss = 0.6104\n",
      "EarlyStopping counter: 11 / 300\n",
      "Epoch 63: Train Loss = 0.3913, Test Loss = 0.6083\n",
      "EarlyStopping counter: 12 / 300\n",
      "Epoch 64: Train Loss = 0.3634, Test Loss = 0.5939\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 65: Train Loss = 0.3621, Test Loss = 0.5819\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 66: Train Loss = 0.3685, Test Loss = 0.5778\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 67: Train Loss = 0.3611, Test Loss = 0.5728\n",
      "Validation loss improved. Saving model to checkpoint\n",
      "Epoch 68: Train Loss = 0.3607, Test Loss = 0.5828\n",
      "EarlyStopping counter: 1 / 300\n",
      "Epoch 69: Train Loss = 0.3776, Test Loss = 0.5977\n",
      "EarlyStopping counter: 2 / 300\n",
      "Epoch 70: Train Loss = 0.3488, Test Loss = 0.6154\n",
      "EarlyStopping counter: 3 / 300\n",
      "Epoch 71: Train Loss = 0.3585, Test Loss = 0.6157\n",
      "EarlyStopping counter: 4 / 300\n",
      "Epoch 72: Train Loss = 0.3381, Test Loss = 0.6047\n",
      "EarlyStopping counter: 5 / 300\n",
      "Epoch 73: Train Loss = 0.3530, Test Loss = 0.5910\n",
      "EarlyStopping counter: 6 / 300\n",
      "Epoch 74: Train Loss = 0.3384, Test Loss = 0.5868\n",
      "EarlyStopping counter: 7 / 300\n",
      "Epoch 75: Train Loss = 0.3501, Test Loss = 0.5993\n",
      "EarlyStopping counter: 8 / 300\n",
      "Epoch 76: Train Loss = 0.3491, Test Loss = 0.5920\n",
      "EarlyStopping counter: 9 / 300\n",
      "Epoch 77: Train Loss = 0.3333, Test Loss = 0.5818\n",
      "EarlyStopping counter: 10 / 300\n",
      "Epoch 78: Train Loss = 0.3230, Test Loss = 0.5840\n",
      "EarlyStopping counter: 11 / 300\n",
      "Epoch 79: Train Loss = 0.3323, Test Loss = 0.5862\n",
      "EarlyStopping counter: 12 / 300\n",
      "Epoch 80: Train Loss = 0.3271, Test Loss = 0.5836\n",
      "EarlyStopping counter: 13 / 300\n",
      "Epoch 81: Train Loss = 0.3286, Test Loss = 0.5914\n",
      "EarlyStopping counter: 14 / 300\n",
      "Epoch 82: Train Loss = 0.3132, Test Loss = 0.6014\n",
      "EarlyStopping counter: 15 / 300\n",
      "Epoch 83: Train Loss = 0.3165, Test Loss = 0.6010\n",
      "EarlyStopping counter: 16 / 300\n",
      "Epoch 84: Train Loss = 0.3299, Test Loss = 0.5914\n",
      "EarlyStopping counter: 17 / 300\n",
      "Epoch 85: Train Loss = 0.3040, Test Loss = 0.5847\n",
      "EarlyStopping counter: 18 / 300\n",
      "Epoch 86: Train Loss = 0.3191, Test Loss = 0.5760\n",
      "EarlyStopping counter: 19 / 300\n",
      "Epoch 87: Train Loss = 0.3041, Test Loss = 0.5773\n",
      "EarlyStopping counter: 20 / 300\n",
      "Epoch 88: Train Loss = 0.3193, Test Loss = 0.5866\n",
      "EarlyStopping counter: 21 / 300\n",
      "Epoch 89: Train Loss = 0.3096, Test Loss = 0.5987\n",
      "EarlyStopping counter: 22 / 300\n",
      "Epoch 90: Train Loss = 0.3011, Test Loss = 0.6009\n",
      "EarlyStopping counter: 23 / 300\n",
      "Epoch 91: Train Loss = 0.2903, Test Loss = 0.5973\n",
      "EarlyStopping counter: 24 / 300\n",
      "Epoch 92: Train Loss = 0.2813, Test Loss = 0.5893\n",
      "EarlyStopping counter: 25 / 300\n",
      "Epoch 93: Train Loss = 0.3141, Test Loss = 0.5882\n",
      "EarlyStopping counter: 26 / 300\n",
      "Epoch 94: Train Loss = 0.2982, Test Loss = 0.5911\n",
      "EarlyStopping counter: 27 / 300\n",
      "Epoch 95: Train Loss = 0.3030, Test Loss = 0.5952\n",
      "EarlyStopping counter: 28 / 300\n",
      "Epoch 96: Train Loss = 0.2896, Test Loss = 0.5943\n",
      "EarlyStopping counter: 29 / 300\n",
      "Epoch 97: Train Loss = 0.3037, Test Loss = 0.6000\n",
      "EarlyStopping counter: 30 / 300\n",
      "Epoch 98: Train Loss = 0.3052, Test Loss = 0.5932\n",
      "EarlyStopping counter: 31 / 300\n",
      "Epoch 99: Train Loss = 0.2898, Test Loss = 0.5940\n",
      "EarlyStopping counter: 32 / 300\n",
      "Epoch 100: Train Loss = 0.3056, Test Loss = 0.5879\n",
      "EarlyStopping counter: 33 / 300\n",
      "Epoch 101: Train Loss = 0.2834, Test Loss = 0.5827\n",
      "EarlyStopping counter: 34 / 300\n",
      "Epoch 102: Train Loss = 0.2904, Test Loss = 0.5844\n",
      "EarlyStopping counter: 35 / 300\n",
      "Epoch 103: Train Loss = 0.2690, Test Loss = 0.5876\n",
      "EarlyStopping counter: 36 / 300\n",
      "Epoch 104: Train Loss = 0.2755, Test Loss = 0.5878\n",
      "EarlyStopping counter: 37 / 300\n",
      "Epoch 105: Train Loss = 0.2914, Test Loss = 0.5946\n",
      "EarlyStopping counter: 38 / 300\n",
      "Epoch 106: Train Loss = 0.2785, Test Loss = 0.5965\n",
      "EarlyStopping counter: 39 / 300\n",
      "Epoch 107: Train Loss = 0.2658, Test Loss = 0.6035\n",
      "EarlyStopping counter: 40 / 300\n",
      "Epoch 108: Train Loss = 0.2688, Test Loss = 0.5980\n",
      "EarlyStopping counter: 41 / 300\n",
      "Epoch 109: Train Loss = 0.2768, Test Loss = 0.5768\n",
      "EarlyStopping counter: 42 / 300\n",
      "Epoch 110: Train Loss = 0.2937, Test Loss = 0.5806\n",
      "EarlyStopping counter: 43 / 300\n",
      "Epoch 111: Train Loss = 0.2826, Test Loss = 0.5847\n",
      "EarlyStopping counter: 44 / 300\n",
      "Epoch 112: Train Loss = 0.2630, Test Loss = 0.5887\n",
      "EarlyStopping counter: 45 / 300\n",
      "Epoch 113: Train Loss = 0.2754, Test Loss = 0.5949\n",
      "EarlyStopping counter: 46 / 300\n",
      "Epoch 114: Train Loss = 0.2768, Test Loss = 0.5938\n",
      "EarlyStopping counter: 47 / 300\n",
      "Epoch 115: Train Loss = 0.2764, Test Loss = 0.5941\n",
      "EarlyStopping counter: 48 / 300\n",
      "Epoch 116: Train Loss = 0.2698, Test Loss = 0.5912\n",
      "EarlyStopping counter: 49 / 300\n",
      "Epoch 117: Train Loss = 0.2759, Test Loss = 0.5952\n",
      "EarlyStopping counter: 50 / 300\n",
      "Epoch 118: Train Loss = 0.2528, Test Loss = 0.6047\n",
      "EarlyStopping counter: 51 / 300\n",
      "Epoch 119: Train Loss = 0.2664, Test Loss = 0.6032\n",
      "EarlyStopping counter: 52 / 300\n",
      "Epoch 120: Train Loss = 0.2559, Test Loss = 0.5916\n",
      "EarlyStopping counter: 53 / 300\n",
      "Epoch 121: Train Loss = 0.2490, Test Loss = 0.5941\n",
      "EarlyStopping counter: 54 / 300\n",
      "Epoch 122: Train Loss = 0.2659, Test Loss = 0.5955\n",
      "EarlyStopping counter: 55 / 300\n",
      "Epoch 123: Train Loss = 0.2439, Test Loss = 0.5982\n",
      "EarlyStopping counter: 56 / 300\n",
      "Epoch 124: Train Loss = 0.2594, Test Loss = 0.5994\n",
      "EarlyStopping counter: 57 / 300\n",
      "Epoch 125: Train Loss = 0.2434, Test Loss = 0.6070\n",
      "EarlyStopping counter: 58 / 300\n",
      "Epoch 126: Train Loss = 0.2535, Test Loss = 0.6041\n",
      "EarlyStopping counter: 59 / 300\n",
      "Epoch 127: Train Loss = 0.2670, Test Loss = 0.5958\n",
      "EarlyStopping counter: 60 / 300\n",
      "Epoch 128: Train Loss = 0.2587, Test Loss = 0.5968\n",
      "EarlyStopping counter: 61 / 300\n",
      "Epoch 129: Train Loss = 0.2441, Test Loss = 0.6056\n",
      "EarlyStopping counter: 62 / 300\n",
      "Epoch 130: Train Loss = 0.2507, Test Loss = 0.6100\n",
      "EarlyStopping counter: 63 / 300\n",
      "Epoch 131: Train Loss = 0.2501, Test Loss = 0.6107\n",
      "EarlyStopping counter: 64 / 300\n",
      "Epoch 132: Train Loss = 0.2483, Test Loss = 0.6208\n",
      "EarlyStopping counter: 65 / 300\n",
      "Epoch 133: Train Loss = 0.2416, Test Loss = 0.6242\n",
      "EarlyStopping counter: 66 / 300\n",
      "Epoch 134: Train Loss = 0.2568, Test Loss = 0.6183\n",
      "EarlyStopping counter: 67 / 300\n",
      "Epoch 135: Train Loss = 0.2489, Test Loss = 0.6145\n",
      "EarlyStopping counter: 68 / 300\n",
      "Epoch 136: Train Loss = 0.2463, Test Loss = 0.6081\n",
      "EarlyStopping counter: 69 / 300\n",
      "Epoch 137: Train Loss = 0.2451, Test Loss = 0.6084\n",
      "EarlyStopping counter: 70 / 300\n",
      "Epoch 138: Train Loss = 0.2248, Test Loss = 0.6068\n",
      "EarlyStopping counter: 71 / 300\n",
      "Epoch 139: Train Loss = 0.2464, Test Loss = 0.6160\n",
      "EarlyStopping counter: 72 / 300\n",
      "Epoch 140: Train Loss = 0.2509, Test Loss = 0.6106\n",
      "EarlyStopping counter: 73 / 300\n",
      "Epoch 141: Train Loss = 0.2333, Test Loss = 0.5988\n",
      "EarlyStopping counter: 74 / 300\n",
      "Epoch 142: Train Loss = 0.2485, Test Loss = 0.5971\n",
      "EarlyStopping counter: 75 / 300\n",
      "Epoch 143: Train Loss = 0.2369, Test Loss = 0.6035\n",
      "EarlyStopping counter: 76 / 300\n",
      "Epoch 144: Train Loss = 0.2445, Test Loss = 0.6095\n",
      "EarlyStopping counter: 77 / 300\n",
      "Epoch 145: Train Loss = 0.2390, Test Loss = 0.6177\n",
      "EarlyStopping counter: 78 / 300\n",
      "Epoch 146: Train Loss = 0.2332, Test Loss = 0.6206\n",
      "EarlyStopping counter: 79 / 300\n",
      "Epoch 147: Train Loss = 0.2333, Test Loss = 0.6060\n",
      "EarlyStopping counter: 80 / 300\n",
      "Epoch 148: Train Loss = 0.2568, Test Loss = 0.5981\n",
      "EarlyStopping counter: 81 / 300\n",
      "Epoch 149: Train Loss = 0.2557, Test Loss = 0.6050\n",
      "EarlyStopping counter: 82 / 300\n",
      "Epoch 150: Train Loss = 0.2303, Test Loss = 0.6051\n",
      "EarlyStopping counter: 83 / 300\n",
      "Epoch 151: Train Loss = 0.2424, Test Loss = 0.5975\n",
      "EarlyStopping counter: 84 / 300\n",
      "Epoch 152: Train Loss = 0.2349, Test Loss = 0.6062\n",
      "EarlyStopping counter: 85 / 300\n",
      "Epoch 153: Train Loss = 0.2099, Test Loss = 0.6304\n",
      "EarlyStopping counter: 86 / 300\n",
      "Epoch 154: Train Loss = 0.2247, Test Loss = 0.6487\n",
      "EarlyStopping counter: 87 / 300\n",
      "Epoch 155: Train Loss = 0.2224, Test Loss = 0.6508\n",
      "EarlyStopping counter: 88 / 300\n",
      "Epoch 156: Train Loss = 0.2172, Test Loss = 0.6325\n",
      "EarlyStopping counter: 89 / 300\n",
      "Epoch 157: Train Loss = 0.2379, Test Loss = 0.6128\n",
      "EarlyStopping counter: 90 / 300\n",
      "Epoch 158: Train Loss = 0.2299, Test Loss = 0.6035\n",
      "EarlyStopping counter: 91 / 300\n",
      "Epoch 159: Train Loss = 0.2341, Test Loss = 0.6037\n",
      "EarlyStopping counter: 92 / 300\n",
      "Epoch 160: Train Loss = 0.2173, Test Loss = 0.6134\n",
      "EarlyStopping counter: 93 / 300\n",
      "Epoch 161: Train Loss = 0.2138, Test Loss = 0.6214\n",
      "EarlyStopping counter: 94 / 300\n",
      "Epoch 162: Train Loss = 0.2263, Test Loss = 0.6250\n",
      "EarlyStopping counter: 95 / 300\n",
      "Epoch 163: Train Loss = 0.2167, Test Loss = 0.6389\n",
      "EarlyStopping counter: 96 / 300\n",
      "Epoch 164: Train Loss = 0.2105, Test Loss = 0.6343\n",
      "EarlyStopping counter: 97 / 300\n",
      "Epoch 165: Train Loss = 0.2187, Test Loss = 0.6140\n",
      "EarlyStopping counter: 98 / 300\n",
      "Epoch 166: Train Loss = 0.2436, Test Loss = 0.6066\n",
      "EarlyStopping counter: 99 / 300\n",
      "Epoch 167: Train Loss = 0.2099, Test Loss = 0.6131\n",
      "EarlyStopping counter: 100 / 300\n",
      "Epoch 168: Train Loss = 0.2214, Test Loss = 0.6206\n",
      "EarlyStopping counter: 101 / 300\n",
      "Epoch 169: Train Loss = 0.2202, Test Loss = 0.6228\n",
      "EarlyStopping counter: 102 / 300\n",
      "Epoch 170: Train Loss = 0.2217, Test Loss = 0.6269\n",
      "EarlyStopping counter: 103 / 300\n",
      "Epoch 171: Train Loss = 0.2459, Test Loss = 0.6189\n",
      "EarlyStopping counter: 104 / 300\n",
      "Epoch 172: Train Loss = 0.2129, Test Loss = 0.6218\n",
      "EarlyStopping counter: 105 / 300\n",
      "Epoch 173: Train Loss = 0.2116, Test Loss = 0.6218\n",
      "EarlyStopping counter: 106 / 300\n",
      "Epoch 174: Train Loss = 0.2346, Test Loss = 0.6164\n",
      "EarlyStopping counter: 107 / 300\n",
      "Epoch 175: Train Loss = 0.2120, Test Loss = 0.6149\n",
      "EarlyStopping counter: 108 / 300\n",
      "Epoch 176: Train Loss = 0.2180, Test Loss = 0.6102\n",
      "EarlyStopping counter: 109 / 300\n",
      "Epoch 177: Train Loss = 0.2094, Test Loss = 0.6201\n",
      "EarlyStopping counter: 110 / 300\n",
      "Epoch 178: Train Loss = 0.2005, Test Loss = 0.6260\n",
      "EarlyStopping counter: 111 / 300\n",
      "Epoch 179: Train Loss = 0.2185, Test Loss = 0.6175\n",
      "EarlyStopping counter: 112 / 300\n",
      "Epoch 180: Train Loss = 0.2304, Test Loss = 0.6360\n",
      "EarlyStopping counter: 113 / 300\n",
      "Epoch 181: Train Loss = 0.1997, Test Loss = 0.6372\n",
      "EarlyStopping counter: 114 / 300\n",
      "Epoch 182: Train Loss = 0.2035, Test Loss = 0.6332\n",
      "EarlyStopping counter: 115 / 300\n",
      "Epoch 183: Train Loss = 0.2063, Test Loss = 0.6319\n",
      "EarlyStopping counter: 116 / 300\n",
      "Epoch 184: Train Loss = 0.2352, Test Loss = 0.6228\n",
      "EarlyStopping counter: 117 / 300\n",
      "Epoch 185: Train Loss = 0.2139, Test Loss = 0.6227\n",
      "EarlyStopping counter: 118 / 300\n",
      "Epoch 186: Train Loss = 0.2034, Test Loss = 0.6288\n",
      "EarlyStopping counter: 119 / 300\n",
      "Epoch 187: Train Loss = 0.2085, Test Loss = 0.6303\n",
      "EarlyStopping counter: 120 / 300\n",
      "Epoch 188: Train Loss = 0.1956, Test Loss = 0.6351\n",
      "EarlyStopping counter: 121 / 300\n",
      "Epoch 189: Train Loss = 0.2235, Test Loss = 0.6371\n",
      "EarlyStopping counter: 122 / 300\n",
      "Epoch 190: Train Loss = 0.2273, Test Loss = 0.6337\n",
      "EarlyStopping counter: 123 / 300\n",
      "Epoch 191: Train Loss = 0.2343, Test Loss = 0.6261\n",
      "EarlyStopping counter: 124 / 300\n",
      "Epoch 192: Train Loss = 0.1975, Test Loss = 0.6276\n",
      "EarlyStopping counter: 125 / 300\n",
      "Epoch 193: Train Loss = 0.1861, Test Loss = 0.6226\n",
      "EarlyStopping counter: 126 / 300\n",
      "Epoch 194: Train Loss = 0.1970, Test Loss = 0.6251\n",
      "EarlyStopping counter: 127 / 300\n",
      "Epoch 195: Train Loss = 0.2299, Test Loss = 0.6272\n",
      "EarlyStopping counter: 128 / 300\n",
      "Epoch 196: Train Loss = 0.2071, Test Loss = 0.6407\n",
      "EarlyStopping counter: 129 / 300\n",
      "Epoch 197: Train Loss = 0.2246, Test Loss = 0.6419\n",
      "EarlyStopping counter: 130 / 300\n",
      "Epoch 198: Train Loss = 0.2125, Test Loss = 0.6494\n",
      "EarlyStopping counter: 131 / 300\n",
      "Epoch 199: Train Loss = 0.2079, Test Loss = 0.6578\n",
      "EarlyStopping counter: 132 / 300\n",
      "Epoch 200: Train Loss = 0.2224, Test Loss = 0.6460\n",
      "EarlyStopping counter: 133 / 300\n",
      "Epoch 201: Train Loss = 0.2142, Test Loss = 0.6461\n",
      "EarlyStopping counter: 134 / 300\n",
      "Epoch 202: Train Loss = 0.2144, Test Loss = 0.6438\n",
      "EarlyStopping counter: 135 / 300\n",
      "Epoch 203: Train Loss = 0.2126, Test Loss = 0.6492\n",
      "EarlyStopping counter: 136 / 300\n",
      "Epoch 204: Train Loss = 0.1918, Test Loss = 0.6559\n",
      "EarlyStopping counter: 137 / 300\n",
      "Epoch 205: Train Loss = 0.1959, Test Loss = 0.6447\n",
      "EarlyStopping counter: 138 / 300\n",
      "Epoch 206: Train Loss = 0.2108, Test Loss = 0.6365\n",
      "EarlyStopping counter: 139 / 300\n",
      "Epoch 207: Train Loss = 0.2104, Test Loss = 0.6347\n",
      "EarlyStopping counter: 140 / 300\n",
      "Epoch 208: Train Loss = 0.1962, Test Loss = 0.6303\n",
      "EarlyStopping counter: 141 / 300\n",
      "Epoch 209: Train Loss = 0.1888, Test Loss = 0.6231\n",
      "EarlyStopping counter: 142 / 300\n",
      "Epoch 210: Train Loss = 0.1830, Test Loss = 0.6260\n",
      "EarlyStopping counter: 143 / 300\n",
      "Epoch 211: Train Loss = 0.2340, Test Loss = 0.6297\n",
      "EarlyStopping counter: 144 / 300\n",
      "Epoch 212: Train Loss = 0.1808, Test Loss = 0.6371\n",
      "EarlyStopping counter: 145 / 300\n",
      "Epoch 213: Train Loss = 0.2072, Test Loss = 0.6578\n",
      "EarlyStopping counter: 146 / 300\n",
      "Epoch 214: Train Loss = 0.2193, Test Loss = 0.6546\n",
      "EarlyStopping counter: 147 / 300\n",
      "Epoch 215: Train Loss = 0.2210, Test Loss = 0.6440\n",
      "EarlyStopping counter: 148 / 300\n",
      "Epoch 216: Train Loss = 0.1989, Test Loss = 0.6358\n",
      "EarlyStopping counter: 149 / 300\n",
      "Epoch 217: Train Loss = 0.2037, Test Loss = 0.6335\n",
      "EarlyStopping counter: 150 / 300\n",
      "Epoch 218: Train Loss = 0.2115, Test Loss = 0.6205\n",
      "EarlyStopping counter: 151 / 300\n",
      "Epoch 219: Train Loss = 0.1988, Test Loss = 0.6299\n",
      "EarlyStopping counter: 152 / 300\n",
      "Epoch 220: Train Loss = 0.2038, Test Loss = 0.6430\n",
      "EarlyStopping counter: 153 / 300\n",
      "Epoch 221: Train Loss = 0.2032, Test Loss = 0.6560\n",
      "EarlyStopping counter: 154 / 300\n",
      "Epoch 222: Train Loss = 0.2082, Test Loss = 0.6661\n",
      "EarlyStopping counter: 155 / 300\n",
      "Epoch 223: Train Loss = 0.1859, Test Loss = 0.6589\n",
      "EarlyStopping counter: 156 / 300\n",
      "Epoch 224: Train Loss = 0.2080, Test Loss = 0.6361\n",
      "EarlyStopping counter: 157 / 300\n",
      "Epoch 225: Train Loss = 0.1950, Test Loss = 0.6283\n",
      "EarlyStopping counter: 158 / 300\n",
      "Epoch 226: Train Loss = 0.1876, Test Loss = 0.6345\n",
      "EarlyStopping counter: 159 / 300\n",
      "Epoch 227: Train Loss = 0.1976, Test Loss = 0.6318\n",
      "EarlyStopping counter: 160 / 300\n",
      "Epoch 228: Train Loss = 0.1771, Test Loss = 0.6442\n",
      "EarlyStopping counter: 161 / 300\n",
      "Epoch 229: Train Loss = 0.1858, Test Loss = 0.6485\n",
      "EarlyStopping counter: 162 / 300\n",
      "Epoch 230: Train Loss = 0.1777, Test Loss = 0.6390\n",
      "EarlyStopping counter: 163 / 300\n",
      "Epoch 231: Train Loss = 0.1747, Test Loss = 0.6369\n",
      "EarlyStopping counter: 164 / 300\n",
      "Epoch 232: Train Loss = 0.2195, Test Loss = 0.6365\n",
      "EarlyStopping counter: 165 / 300\n",
      "Epoch 233: Train Loss = 0.1917, Test Loss = 0.6479\n",
      "EarlyStopping counter: 166 / 300\n",
      "Epoch 234: Train Loss = 0.1946, Test Loss = 0.6527\n",
      "EarlyStopping counter: 167 / 300\n",
      "Epoch 235: Train Loss = 0.1944, Test Loss = 0.6504\n",
      "EarlyStopping counter: 168 / 300\n",
      "Epoch 236: Train Loss = 0.2142, Test Loss = 0.6542\n",
      "EarlyStopping counter: 169 / 300\n",
      "Epoch 237: Train Loss = 0.2038, Test Loss = 0.6624\n",
      "EarlyStopping counter: 170 / 300\n",
      "Epoch 238: Train Loss = 0.1856, Test Loss = 0.6684\n",
      "EarlyStopping counter: 171 / 300\n",
      "Epoch 239: Train Loss = 0.1961, Test Loss = 0.6781\n",
      "EarlyStopping counter: 172 / 300\n",
      "Epoch 240: Train Loss = 0.2172, Test Loss = 0.6591\n",
      "EarlyStopping counter: 173 / 300\n",
      "Epoch 241: Train Loss = 0.1845, Test Loss = 0.6419\n",
      "EarlyStopping counter: 174 / 300\n",
      "Epoch 242: Train Loss = 0.2155, Test Loss = 0.6453\n",
      "EarlyStopping counter: 175 / 300\n",
      "Epoch 243: Train Loss = 0.1908, Test Loss = 0.6580\n",
      "EarlyStopping counter: 176 / 300\n",
      "Epoch 244: Train Loss = 0.1911, Test Loss = 0.6563\n",
      "EarlyStopping counter: 177 / 300\n",
      "Epoch 245: Train Loss = 0.1786, Test Loss = 0.6554\n",
      "EarlyStopping counter: 178 / 300\n",
      "Epoch 246: Train Loss = 0.1759, Test Loss = 0.6604\n",
      "EarlyStopping counter: 179 / 300\n",
      "Epoch 247: Train Loss = 0.1855, Test Loss = 0.6616\n",
      "EarlyStopping counter: 180 / 300\n",
      "Epoch 248: Train Loss = 0.1856, Test Loss = 0.6509\n",
      "EarlyStopping counter: 181 / 300\n",
      "Epoch 249: Train Loss = 0.1764, Test Loss = 0.6466\n",
      "EarlyStopping counter: 182 / 300\n",
      "Epoch 250: Train Loss = 0.2094, Test Loss = 0.6492\n",
      "EarlyStopping counter: 183 / 300\n",
      "Epoch 251: Train Loss = 0.1919, Test Loss = 0.6560\n",
      "EarlyStopping counter: 184 / 300\n",
      "Epoch 252: Train Loss = 0.2006, Test Loss = 0.6557\n",
      "EarlyStopping counter: 185 / 300\n",
      "Epoch 253: Train Loss = 0.1943, Test Loss = 0.6703\n",
      "EarlyStopping counter: 186 / 300\n",
      "Epoch 254: Train Loss = 0.1929, Test Loss = 0.6883\n",
      "EarlyStopping counter: 187 / 300\n",
      "Epoch 255: Train Loss = 0.1828, Test Loss = 0.6823\n",
      "EarlyStopping counter: 188 / 300\n",
      "Epoch 256: Train Loss = 0.1722, Test Loss = 0.6540\n",
      "EarlyStopping counter: 189 / 300\n",
      "Epoch 257: Train Loss = 0.1846, Test Loss = 0.6394\n",
      "EarlyStopping counter: 190 / 300\n",
      "Epoch 258: Train Loss = 0.2047, Test Loss = 0.6449\n",
      "EarlyStopping counter: 191 / 300\n",
      "Epoch 259: Train Loss = 0.1807, Test Loss = 0.6538\n",
      "EarlyStopping counter: 192 / 300\n",
      "Epoch 260: Train Loss = 0.1896, Test Loss = 0.6591\n",
      "EarlyStopping counter: 193 / 300\n",
      "Epoch 261: Train Loss = 0.1976, Test Loss = 0.6638\n",
      "EarlyStopping counter: 194 / 300\n",
      "Epoch 262: Train Loss = 0.1914, Test Loss = 0.6589\n",
      "EarlyStopping counter: 195 / 300\n",
      "Epoch 263: Train Loss = 0.2141, Test Loss = 0.6557\n",
      "EarlyStopping counter: 196 / 300\n",
      "Epoch 264: Train Loss = 0.1969, Test Loss = 0.6468\n",
      "EarlyStopping counter: 197 / 300\n",
      "Epoch 265: Train Loss = 0.1782, Test Loss = 0.6568\n",
      "EarlyStopping counter: 198 / 300\n",
      "Epoch 266: Train Loss = 0.1908, Test Loss = 0.6554\n",
      "EarlyStopping counter: 199 / 300\n",
      "Epoch 267: Train Loss = 0.1757, Test Loss = 0.6610\n",
      "EarlyStopping counter: 200 / 300\n",
      "Epoch 268: Train Loss = 0.1800, Test Loss = 0.6627\n",
      "EarlyStopping counter: 201 / 300\n",
      "Epoch 269: Train Loss = 0.2019, Test Loss = 0.6761\n",
      "EarlyStopping counter: 202 / 300\n",
      "Epoch 270: Train Loss = 0.1941, Test Loss = 0.6856\n",
      "EarlyStopping counter: 203 / 300\n",
      "Epoch 271: Train Loss = 0.2055, Test Loss = 0.6792\n",
      "EarlyStopping counter: 204 / 300\n",
      "Epoch 272: Train Loss = 0.1902, Test Loss = 0.6526\n",
      "EarlyStopping counter: 205 / 300\n",
      "Epoch 273: Train Loss = 0.1951, Test Loss = 0.6474\n",
      "EarlyStopping counter: 206 / 300\n",
      "Epoch 274: Train Loss = 0.1860, Test Loss = 0.6487\n",
      "EarlyStopping counter: 207 / 300\n",
      "Epoch 275: Train Loss = 0.1950, Test Loss = 0.6472\n",
      "EarlyStopping counter: 208 / 300\n",
      "Epoch 276: Train Loss = 0.1629, Test Loss = 0.6591\n",
      "EarlyStopping counter: 209 / 300\n",
      "Epoch 277: Train Loss = 0.1850, Test Loss = 0.6752\n",
      "EarlyStopping counter: 210 / 300\n",
      "Epoch 278: Train Loss = 0.1595, Test Loss = 0.6603\n",
      "EarlyStopping counter: 211 / 300\n",
      "Epoch 279: Train Loss = 0.1799, Test Loss = 0.6497\n",
      "EarlyStopping counter: 212 / 300\n",
      "Epoch 280: Train Loss = 0.1736, Test Loss = 0.6493\n",
      "EarlyStopping counter: 213 / 300\n",
      "Epoch 281: Train Loss = 0.1807, Test Loss = 0.6430\n",
      "EarlyStopping counter: 214 / 300\n",
      "Epoch 282: Train Loss = 0.2142, Test Loss = 0.6536\n",
      "EarlyStopping counter: 215 / 300\n",
      "Epoch 283: Train Loss = 0.2016, Test Loss = 0.6796\n",
      "EarlyStopping counter: 216 / 300\n",
      "Epoch 284: Train Loss = 0.2120, Test Loss = 0.6970\n",
      "EarlyStopping counter: 217 / 300\n",
      "Epoch 285: Train Loss = 0.1786, Test Loss = 0.6937\n",
      "EarlyStopping counter: 218 / 300\n",
      "Epoch 286: Train Loss = 0.1722, Test Loss = 0.6780\n",
      "EarlyStopping counter: 219 / 300\n",
      "Epoch 287: Train Loss = 0.1597, Test Loss = 0.6513\n",
      "EarlyStopping counter: 220 / 300\n",
      "Epoch 288: Train Loss = 0.2013, Test Loss = 0.6391\n",
      "EarlyStopping counter: 221 / 300\n",
      "Epoch 289: Train Loss = 0.1759, Test Loss = 0.6332\n",
      "EarlyStopping counter: 222 / 300\n",
      "Epoch 290: Train Loss = 0.1842, Test Loss = 0.6517\n",
      "EarlyStopping counter: 223 / 300\n",
      "Epoch 291: Train Loss = 0.1829, Test Loss = 0.6797\n",
      "EarlyStopping counter: 224 / 300\n",
      "Epoch 292: Train Loss = 0.1799, Test Loss = 0.6890\n",
      "EarlyStopping counter: 225 / 300\n",
      "Epoch 293: Train Loss = 0.1855, Test Loss = 0.6909\n",
      "EarlyStopping counter: 226 / 300\n",
      "Epoch 294: Train Loss = 0.1769, Test Loss = 0.6893\n",
      "EarlyStopping counter: 227 / 300\n",
      "Epoch 295: Train Loss = 0.1718, Test Loss = 0.6635\n",
      "EarlyStopping counter: 228 / 300\n",
      "Epoch 296: Train Loss = 0.1874, Test Loss = 0.6524\n",
      "EarlyStopping counter: 229 / 300\n",
      "Epoch 297: Train Loss = 0.1848, Test Loss = 0.6546\n",
      "EarlyStopping counter: 230 / 300\n",
      "Epoch 298: Train Loss = 0.1823, Test Loss = 0.6618\n",
      "EarlyStopping counter: 231 / 300\n",
      "Epoch 299: Train Loss = 0.1949, Test Loss = 0.6659\n",
      "EarlyStopping counter: 232 / 300\n",
      "Epoch 300: Train Loss = 0.1904, Test Loss = 0.6732\n",
      "EarlyStopping counter: 233 / 300\n",
      "Epoch 301: Train Loss = 0.1865, Test Loss = 0.6801\n",
      "EarlyStopping counter: 234 / 300\n",
      "Epoch 302: Train Loss = 0.2121, Test Loss = 0.6654\n",
      "EarlyStopping counter: 235 / 300\n",
      "Epoch 303: Train Loss = 0.1771, Test Loss = 0.6610\n",
      "EarlyStopping counter: 236 / 300\n",
      "Epoch 304: Train Loss = 0.1758, Test Loss = 0.6551\n",
      "EarlyStopping counter: 237 / 300\n",
      "Epoch 305: Train Loss = 0.1798, Test Loss = 0.6562\n",
      "EarlyStopping counter: 238 / 300\n",
      "Epoch 306: Train Loss = 0.1882, Test Loss = 0.6697\n",
      "EarlyStopping counter: 239 / 300\n",
      "Epoch 307: Train Loss = 0.1766, Test Loss = 0.6743\n",
      "EarlyStopping counter: 240 / 300\n",
      "Epoch 308: Train Loss = 0.1655, Test Loss = 0.6705\n",
      "EarlyStopping counter: 241 / 300\n",
      "Epoch 309: Train Loss = 0.1647, Test Loss = 0.6629\n",
      "EarlyStopping counter: 242 / 300\n",
      "Epoch 310: Train Loss = 0.1797, Test Loss = 0.6595\n",
      "EarlyStopping counter: 243 / 300\n",
      "Epoch 311: Train Loss = 0.1758, Test Loss = 0.6530\n",
      "EarlyStopping counter: 244 / 300\n",
      "Epoch 312: Train Loss = 0.1644, Test Loss = 0.6584\n",
      "EarlyStopping counter: 245 / 300\n",
      "Epoch 313: Train Loss = 0.1938, Test Loss = 0.6680\n",
      "EarlyStopping counter: 246 / 300\n",
      "Epoch 314: Train Loss = 0.1691, Test Loss = 0.6945\n",
      "EarlyStopping counter: 247 / 300\n",
      "Epoch 315: Train Loss = 0.1770, Test Loss = 0.6828\n",
      "EarlyStopping counter: 248 / 300\n",
      "Epoch 316: Train Loss = 0.1640, Test Loss = 0.6794\n",
      "EarlyStopping counter: 249 / 300\n",
      "Epoch 317: Train Loss = 0.1611, Test Loss = 0.6707\n",
      "EarlyStopping counter: 250 / 300\n",
      "Epoch 318: Train Loss = 0.1925, Test Loss = 0.6680\n",
      "EarlyStopping counter: 251 / 300\n",
      "Epoch 319: Train Loss = 0.1929, Test Loss = 0.6758\n",
      "EarlyStopping counter: 252 / 300\n",
      "Epoch 320: Train Loss = 0.1741, Test Loss = 0.6666\n",
      "EarlyStopping counter: 253 / 300\n",
      "Epoch 321: Train Loss = 0.1670, Test Loss = 0.6669\n",
      "EarlyStopping counter: 254 / 300\n",
      "Epoch 322: Train Loss = 0.1731, Test Loss = 0.6606\n",
      "EarlyStopping counter: 255 / 300\n",
      "Epoch 323: Train Loss = 0.1649, Test Loss = 0.6748\n",
      "EarlyStopping counter: 256 / 300\n",
      "Epoch 324: Train Loss = 0.1793, Test Loss = 0.6762\n",
      "EarlyStopping counter: 257 / 300\n",
      "Epoch 325: Train Loss = 0.1811, Test Loss = 0.6725\n",
      "EarlyStopping counter: 258 / 300\n",
      "Epoch 326: Train Loss = 0.1505, Test Loss = 0.6849\n",
      "EarlyStopping counter: 259 / 300\n",
      "Epoch 327: Train Loss = 0.1798, Test Loss = 0.6924\n",
      "EarlyStopping counter: 260 / 300\n",
      "Epoch 328: Train Loss = 0.1707, Test Loss = 0.7027\n",
      "EarlyStopping counter: 261 / 300\n",
      "Epoch 329: Train Loss = 0.1640, Test Loss = 0.6893\n",
      "EarlyStopping counter: 262 / 300\n",
      "Epoch 330: Train Loss = 0.1744, Test Loss = 0.6652\n",
      "EarlyStopping counter: 263 / 300\n",
      "Epoch 331: Train Loss = 0.1604, Test Loss = 0.6707\n",
      "EarlyStopping counter: 264 / 300\n",
      "Epoch 332: Train Loss = 0.1819, Test Loss = 0.6824\n",
      "EarlyStopping counter: 265 / 300\n",
      "Epoch 333: Train Loss = 0.1586, Test Loss = 0.6960\n",
      "EarlyStopping counter: 266 / 300\n",
      "Epoch 334: Train Loss = 0.1818, Test Loss = 0.6868\n",
      "EarlyStopping counter: 267 / 300\n",
      "Epoch 335: Train Loss = 0.1778, Test Loss = 0.6885\n",
      "EarlyStopping counter: 268 / 300\n",
      "Epoch 336: Train Loss = 0.1731, Test Loss = 0.6954\n",
      "EarlyStopping counter: 269 / 300\n",
      "Epoch 337: Train Loss = 0.1913, Test Loss = 0.6778\n",
      "EarlyStopping counter: 270 / 300\n",
      "Epoch 338: Train Loss = 0.1724, Test Loss = 0.6611\n",
      "EarlyStopping counter: 271 / 300\n",
      "Epoch 339: Train Loss = 0.1815, Test Loss = 0.6580\n",
      "EarlyStopping counter: 272 / 300\n",
      "Epoch 340: Train Loss = 0.1802, Test Loss = 0.6671\n",
      "EarlyStopping counter: 273 / 300\n",
      "Epoch 341: Train Loss = 0.1756, Test Loss = 0.6894\n",
      "EarlyStopping counter: 274 / 300\n",
      "Epoch 342: Train Loss = 0.1509, Test Loss = 0.6940\n",
      "EarlyStopping counter: 275 / 300\n",
      "Epoch 343: Train Loss = 0.1584, Test Loss = 0.6983\n",
      "EarlyStopping counter: 276 / 300\n",
      "Epoch 344: Train Loss = 0.1747, Test Loss = 0.6954\n",
      "EarlyStopping counter: 277 / 300\n",
      "Epoch 345: Train Loss = 0.1817, Test Loss = 0.7149\n",
      "EarlyStopping counter: 278 / 300\n",
      "Epoch 346: Train Loss = 0.1804, Test Loss = 0.7108\n",
      "EarlyStopping counter: 279 / 300\n",
      "Epoch 347: Train Loss = 0.1709, Test Loss = 0.6976\n",
      "EarlyStopping counter: 280 / 300\n",
      "Epoch 348: Train Loss = 0.1808, Test Loss = 0.6793\n",
      "EarlyStopping counter: 281 / 300\n",
      "Epoch 349: Train Loss = 0.1533, Test Loss = 0.6749\n",
      "EarlyStopping counter: 282 / 300\n",
      "Epoch 350: Train Loss = 0.1618, Test Loss = 0.6739\n",
      "EarlyStopping counter: 283 / 300\n",
      "Epoch 351: Train Loss = 0.1704, Test Loss = 0.6800\n",
      "EarlyStopping counter: 284 / 300\n",
      "Epoch 352: Train Loss = 0.1684, Test Loss = 0.6750\n",
      "EarlyStopping counter: 285 / 300\n",
      "Epoch 353: Train Loss = 0.1703, Test Loss = 0.6862\n",
      "EarlyStopping counter: 286 / 300\n",
      "Epoch 354: Train Loss = 0.2308, Test Loss = 0.6991\n",
      "EarlyStopping counter: 287 / 300\n",
      "Epoch 355: Train Loss = 0.1597, Test Loss = 0.7230\n",
      "EarlyStopping counter: 288 / 300\n",
      "Epoch 356: Train Loss = 0.1849, Test Loss = 0.7124\n",
      "EarlyStopping counter: 289 / 300\n",
      "Epoch 357: Train Loss = 0.1695, Test Loss = 0.6910\n",
      "EarlyStopping counter: 290 / 300\n",
      "Epoch 358: Train Loss = 0.1493, Test Loss = 0.6820\n",
      "EarlyStopping counter: 291 / 300\n",
      "Epoch 359: Train Loss = 0.1654, Test Loss = 0.6792\n",
      "EarlyStopping counter: 292 / 300\n",
      "Epoch 360: Train Loss = 0.1902, Test Loss = 0.6833\n",
      "EarlyStopping counter: 293 / 300\n",
      "Epoch 361: Train Loss = 0.1663, Test Loss = 0.6967\n",
      "EarlyStopping counter: 294 / 300\n",
      "Epoch 362: Train Loss = 0.1624, Test Loss = 0.6990\n",
      "EarlyStopping counter: 295 / 300\n",
      "Epoch 363: Train Loss = 0.1869, Test Loss = 0.6965\n",
      "EarlyStopping counter: 296 / 300\n",
      "Epoch 364: Train Loss = 0.1557, Test Loss = 0.6951\n",
      "EarlyStopping counter: 297 / 300\n",
      "Epoch 365: Train Loss = 0.1556, Test Loss = 0.6882\n",
      "EarlyStopping counter: 298 / 300\n",
      "Epoch 366: Train Loss = 0.1522, Test Loss = 0.6851\n",
      "EarlyStopping counter: 299 / 300\n",
      "Epoch 367: Train Loss = 0.1714, Test Loss = 0.6849\n",
      "EarlyStopping counter: 300 / 300\n",
      "Early stopping triggered , Training stopped\n"
     ]
    }
   ],
   "source": [
    "input_size = X.shape[1]\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "model = NN(input_size, num_classes)\n",
    "train_model(model, train_loader, test_loader, epochs = 3500,lr=0.01 ,patience =300,min_delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9fdb456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d209ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39fbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a96c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f558ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c30271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34616a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca974560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da13cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e609714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00626a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
