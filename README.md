# Deep-Learning-From-Scratch


```markdown
# Deep Learning From Scratch

This repository contains a complete implementation of deep learning concepts built entirely from scratch without using Pytorch.  
The goal of this project is to deeply understand how neural networks and their components work under the hood by implementing everything using only basic Python and NumPy.

---

##  Folder Structure

Deep-Learning-From-Scratch/
│
├── CNNs/                        # Convolutional Neural Network implementations
├── Gradient_descent/            # Gradient Descent algorithms
├── MLP/                          # Multi-Layer Perceptron implementation
├── activation_functions/        # Sigmoid, ReLU, Tanh, Softmax, etc.
├── dropouts/                     # Dropout implementation to prevent overfitting
├── improving_NN/                 # Techniques to improve neural network performance
├── perceptron/                   # Basic perceptron model
├── regularization/               # L1, L2, and other regularization techniques
├── weight_initialization_techniques/  # Xavier, He, etc.
│
├── NeuralNetwork.ipynb           # Notebook demonstrating how everything fits together
└── README.md                     # Project documentation


##  Features
- Build neural networks step-by-step without black-box libraries.
- Understand the math and algorithms behind:
  - Activation functions
  - Gradient descent optimization
  - Weight initialization
  - Dropout and regularization techniques
- Implement a Convolutional Neural Network (CNN) from scratch.
- Clear notebook (`NeuralNetwork.ipynb`) demonstrating usage.
- Great for learning, teaching, or interview preparation.

---

##  Topics Covered
1. Perceptron
2. Multi-Layer Perceptron (MLP)
3. Gradient Descent Variants  
4. Activation Functions  
5. Weight Initialization Techniques  
6. Dropout Regularization
7. Improving Neural Networks (Feature scaling, normalization, etc.)  
8. Convolutional Neural Networks (CNNs)  

---


##  Contributing

Contributions are welcome!
If you have suggestions or find bugs, feel free to **open an issue** or **submit a pull request**.

---

##  License

This project is licensed under the MIT License – see the [LICENSE](LICENSE) file for details.

```
 
